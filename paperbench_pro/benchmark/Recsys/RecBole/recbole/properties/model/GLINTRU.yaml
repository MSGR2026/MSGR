# Model architecture parameters
embedding_size: 128              # Item embedding dimension
hidden_size: 128                # Hidden layer dimension
inner_size: 128
num_layers: 1                   # Number of GRU layers
dropout_prob: 0.3               # General dropout rate

# Attention parameters
n_heads: 8                      # Number of attention heads
hidden_dropout_prob: 0.2        # Hidden layer dropout
attn_dropout_prob: 0.2          # Attention dropout
hidden_act: 'gelu'
layer_norm_eps: 1e-12           # Layer normalization epsilon
initializer_range: 0.02

# Training parameters
loss_type: 'CE'                 # Loss function type: 'BPR' or 'CE'
learning_rate: 0.001            # Learning rate
train_batch_size: 2048          # Training batch size
eval_batch_size: 2048           # Evaluation batch size
train_neg_sample_args: ~        # (dict) Disable negative sampling for CE loss.
neg_sampling: None
mask_ratio: 0.2

