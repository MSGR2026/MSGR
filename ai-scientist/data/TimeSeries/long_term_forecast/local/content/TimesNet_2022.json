{
  "id": "TimesNet_2022",
  "paper_title": "TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis",
  "alias": "TimesNet",
  "year": 2022,
  "domain": "TimeSeries",
  "task": "anomaly_detection",
  "idea": "TimesNet transforms 1D time series into 2D space based on multi-periodicity analysis using FFT, enabling simultaneous modeling of intraperiod-variation (within periods) and interperiod-variation (across periods). The model employs a modular TimesBlock architecture with parameter-efficient inception blocks to capture temporal 2D-variations from multiple discovered periods, then adaptively aggregates representations using normalized amplitude values as importance weights. This design bridges 1D time series analysis with 2D vision backbones, achieving state-of-the-art performance across five mainstream tasks: forecasting, imputation, classification, and anomaly detection.",
  "introduction": "# 1 INTRODUCTION\n\nTime series analysis is widely used in extensive real-world applications, such as the forecasting of meteorological factors for weather prediction (Wu et al., 2021), imputation of missing data for data mining (Friedman, 1962), anomaly detection of monitoring data for industrial maintenance (Xu et al., 2021) and classification of trajectories for action recognition (Franceschi et al., 2019). Because of its immense practical value, time series analysis has received great interest (Lim & Zohren, 2021).\n\nDifferent from other types of sequential data, such as language or video, time series is recorded continuously and each time point only saves some scalars. Since one single time point usually cannot provide sufficient semantic information for analysis, many works focus on the temporal variation, which is more informative and can reflect the inherent properties of time series, such as the continuity, periodicity, trend and etc. However, the variations of real-world time series always involve intricate temporal patterns, where multiple variations (e.g. rising, falling, fluctuation and etc.) mix and overlap with each other, making the temporal variation modeling extremely challenging.\n\nEspecially in the deep learning communities, benefiting from the powerful non-linear modeling capacity of deep models, many works have been proposed to capture the complex temporal variations in real-world time series. One category of methods adopts recurrent neural networks (RNN) to model the successive time points based on the Markov assumption (Hochreiter & Schmidhuber, 1997; Lai et al., 2018; Shen et al., 2020). However, these methods usually fail in capturing the long-term dependencies and their efficiencies suffer from the sequential computation paradigm. Another category of methods utilizes the convolutional neural network along the temporal dimension (TCN)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/608993e244e41dee2c1d50b5a08fbebd7851a96a9907d0d28f94140f250a23ab.jpg)  \nFigure 1: Multi-periodicity and temporal 2D-variation of time series. Each period involves the intraperiod-variation and interperiod-variation. We transform the original 1D time series into a set of 2D tensors based on multiple periods, which can unify the intraperiod- and interperiod-variations.\n\nto extract the variation information (Franceschi et al., 2019; He & Zhao, 2019). Also, because of the locality property of the one-dimension convolution kernels, they can only model the variations among adjacent time points, thereby still failing in long-term dependencies. Recently, Transformers with attention mechanism have been widely used in sequential modeling (Brown et al., 2020; Dosovitskiy et al., 2021; Liu et al., 2021b). In time series analysis, many Transformer-based models adopt the attention mechanism or its variants to capture the pair-wise temporal dependencies among time points (Li et al., 2019; Kitaev et al., 2020; Zhou et al., 2021; 2022). But it is hard for attention mechanism to find out reliable dependencies directly from scattered time points, since the temporal dependencies can be obscured deeply in intricate temporal patterns (Wu et al., 2021).\n\nIn this paper, to tackle the intricate temporal variations, we analyze the time series from a new dimension of multi-periodicity. Firstly, we observe that real-world time series usually present multi-periodicity, such as daily and yearly variations for weather observations, weekly and quarterly variations for electricity consumption. These multiple periods overlap and interact with each other, making the variation modeling intractable. Secondly, for each period, we find out that the variation of each time point is not only affected by the temporal pattern of its adjacent area but also highly related to the variations of its adjacent periods. For clearness, we name these two types of temporal variations as intraperiod-variation and interperiod-variation respectively. The former indicates short-term temporal patterns within a period. The latter can reflect long-term trends of consecutive different periods. Note that for the time series without clear periodicity, the variations will be dominated by the intraperiod-variation and is equivalent to the ones with infinite period length.\n\nSince different periods will lead to different intraperiod- and interperiod-variations, the multiperiodicity can naturally derive a modular architecture for temporal variation modeling, where we can capture the variations derived by a certain period in one module. Besides, this design makes the intricate temporal patterns disentangled, benefiting the temporal variation modeling. However, it is notable that the 1D time series is hard to explicitly present two different types of variations simultaneously. To tackle this obstacle, we extend the analysis of temporal variations into the 2D space. Concretely, as shown in Figure 1, we can reshape the 1D time series into a 2D tensor, where each column contains the time points within a period and each row involves the time points at the same phase among different periods. Thus, by transforming 1D time series into a set of 2D tensors, we can break the bottleneck of representation capability in the original 1D space and successfully unify the intraperiod- and interperiod-variations in 2D space, obtaining the temporal 2D-variations.\n\nTechnically, based on above motivations, we go beyond previous backbones and propose the TimesNet as a new task-general model for time series analysis. Empowering by TimesBlock, TimesNet can discover the multi-periodicity of time series and capture the corresponding temporal variations in a modular architecture. Concretely, TimesBlock can adaptively transform the 1D time series into a set of 2D tensors based on learned periods and further capture intraperiod- and interperiod-variations in the 2D space by a parameter-efficient inception block. Experimentally, TimesNet achieves the consistent state-of-the-art in five mainstream analysis tasks, including short- and long-term forecasting, imputation, classification and anomaly detection. Our contributions are summarized in three folds:\n\n- Motivated by multi-periodicity and complex interactions within and between periods, we find out a modular way for temporal variation modeling. By transforming the 1D time series into 2D space, we can present the intraperiod- and interperiod-variations simultaneously.\n\n- We propose the TimesNet with TimesBlock to discover multiple periods and capture temporal 2D-variations from transformed 2D tensors by a parameter-efficient inception block.  \n- As a task-general foundation model, TimesNet achieves the consistent state-of-the-art in five mainstream time series analysis tasks. Detailed and insightful visualizations are included.\n",
  "method": "# 3 TIMESNET\n\nAs aforementioned, based on the multi-periodicity of time series, we propose the TimesNet with a modular architecture to capture the temporal patterns derived from different periods. For each period, to capture the corresponding intraperiod- and interperiod-variations, we design a TimesBlock within the TimesNet, which can transform the 1D time series into 2D space and simultaneously model the two types of variations by a parameter-efficient inception block.\n\n# 3.1 TRANSFORM 1D-VARIATIONS INTO 2D-VARIATIONS\n\nAs shown in Figure 1, each time point involves two types of temporal variations with its adjacent area and with the same phase among different periods simultaneously, namely intraperiod- and interperiod-variations. However, this original 1D structure of time series can only present the variations among adjacent time points. To tackle this limitation, we explore the two-dimension structure for temporal variations, which can explicitly present variations within and between periods, thereby with more advantages in representation capability and benefiting the subsequent representation learning.\n\nConcretely, for the length- $T$  time series with  $C$  recorded variates, the original 1D organization is  $\\mathbf{X}_{\\mathrm{1D}} \\in \\mathbb{R}^{T \\times C}$ . To represent the interperiod-variation, we need to discover periods first. Technically, we analyze the time series in the frequency domain by Fast Fourier Transform (FFT) as follows:\n\n$$\n\\mathbf {A} = \\operatorname {A v g} \\left(\\operatorname {A m p} \\left(\\operatorname {F F T} \\left(\\mathbf {X} _ {\\mathrm {1 D}}\\right)\\right)\\right), \\left\\{f _ {1}, \\dots , f _ {k} \\right\\} = \\underset {f _ {*} \\in \\{1, \\dots , \\left[ \\frac {T}{2} \\right] \\}} {\\arg \\operatorname {T o p k}} (\\mathbf {A}), p _ {i} = \\left\\lceil \\frac {T}{f _ {i}} \\right\\rceil , i \\in \\{1, \\dots , k \\}. \\tag {1}\n$$\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/22e73e51c4f70f90e82713795a119382caccc3612145e5565a7b696948086bb7.jpg)  \nFigure 2: A univariate example to illustrate 2D structure in time series. By discovering the periodicity, we can transform the original 1D time series into structured 2D tensors, which can be processed by 2D kernels conveniently. By conducting the same reshape operation to all variates of time series, we can extend the above process to multivariate time series.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/31824bb89521f1e228b1b0d8498997038be4977eacf4e4bd51fe82063525667c.jpg)\n\nHere,  $\\mathrm{FFT}(\\cdot)$  and  $\\mathrm{Amp}(\\cdot)$  denote the FFT and the calculation of amplitude values.  $\\mathbf{A}\\in \\mathbb{R}^T$  represents the calculated amplitude of each frequency, which is averaged from  $C$  dimensions by  $\\mathrm{Avg}(\\cdot)$ . Note that the  $j$ -th value  $\\mathbf{A}_j$  represents the intensity of the frequency- $j$  periodic basis function, corresponding to the period length  $\\lceil \\frac{T}{j}\\rceil$ . Considering the sparsity of frequency domain and to avoid the noises brought by meaningless high frequencies (Chatfield, 1981; Zhou et al., 2022), we only select the top- $k$  amplitude values and obtain the most significant frequencies  $\\{f_1,\\dots ,f_k\\}$  with the unnormalized amplitudes  $\\{\\mathbf{A}_{f_1},\\dots ,\\mathbf{A}_{f_k}\\}$ , where  $k$  is the hyper-parameter. These selected frequencies also correspond to  $k$  period lengths  $\\{p_1,\\dots ,p_k\\}$ . Due to the conjugacy of frequency domain, we only consider the frequencies within  $\\{1,\\dots ,[\\frac{T}{2} ]\\}$ . We summarize Equation 1 as follows:\n\n$$\n\\mathbf {A}, \\left\\{f _ {1}, \\dots , f _ {k} \\right\\}, \\left\\{p _ {1}, \\dots , p _ {k} \\right\\} = \\operatorname {P e r i o d} \\left(\\mathbf {X} _ {\\mathrm {1 D}}\\right). \\tag {2}\n$$\n\nBased on the selected frequencies  $\\{f_1,\\dots ,f_k\\}$  and corresponding period lengths  $\\{p_1,\\dots ,p_k\\}$ , we can reshape the 1D time series  $\\mathbf{X}_{\\mathrm{1D}}\\in \\mathbb{R}^{T\\times C}$  into multiple 2D tensors by the following equations:\n\n$$\n\\mathbf {X} _ {\\mathrm {2 D}} ^ {i} = \\operatorname {R e s h a p e} _ {p _ {i}, f _ {i}} \\left(\\operatorname {P a d d i n g} \\left(\\mathbf {X} _ {\\mathrm {1 D}}\\right)\\right), i \\in \\{1, \\dots , k \\}, \\tag {3}\n$$\n\nwhere  $\\mathrm{Padding}(\\cdot)$  is to extend the time series by zeros along temporal dimension to make it compatible for  $\\mathrm{Reshape}_{p_i, f_i}(\\cdot)$ , where  $p_i$  and  $f_i$  represent the number of rows and columns of the transformed 2D tensors respectively. Note that  $\\mathbf{X}_{2\\mathrm{D}}^i \\in \\mathbb{R}^{p_i \\times f_i \\times C}$  denotes the  $i$ -th reshaped time series based on frequency-  $f_i$ , whose columns and rows represent the intraperiod-variation and interperiod-variation under the corresponding period length  $p_i$  respectively. Eventually, as shown in Figure 2, based on the selected frequencies and estimated periods, we obtain a set of 2D tensors  $\\{\\mathbf{X}_{2\\mathrm{D}}^1, \\dots, \\mathbf{X}_{2\\mathrm{D}}^k\\}$ , which indicates  $k$  different temporal 2D-variations derived by different periods.\n\nIt is also notable that, this transformation brings two types of localities to the transformed 2D tensors, that is localities among adjacent time points (columns, intraperiod-variation) and adjacent periods (rows, interperiod-variation). Thus, the temporal 2D-variations can be easily processed by 2D kernels.\n\n# 3.2 TIMESBLOCK\n\nAs shown in Figure 3, we organize the TimesBlock in a residual way (He et al., 2016). Concretely, for the length- $T$  1D input time series  $\\mathbf{X}_{\\mathrm{1D}} \\in \\mathbb{R}^{T \\times C}$ , we project the raw inputs into the deep features  $\\mathbf{X}_{\\mathrm{1D}}^0 \\in \\mathbb{R}^{T \\times d_{\\mathrm{model}}}$  by the embedding layer  $\\mathbf{X}_{\\mathrm{1D}}^0 = \\operatorname{Embed}(\\mathbf{X}_{\\mathrm{1D}})$  at the very beginning. For the  $l$ -th layer of TimesNet, the input is  $\\mathbf{X}_{\\mathrm{1D}}^{l-1} \\in \\mathbb{R}^{T \\times d_{\\mathrm{model}}}$  and the process can be formalized as:\n\n$$\n\\mathbf {X} _ {\\mathrm {1 D}} ^ {l} = \\text {T i m e s B l o c k} \\left(\\mathbf {X} _ {\\mathrm {1 D}} ^ {l - 1}\\right) + \\mathbf {X} _ {\\mathrm {1 D}} ^ {l - 1}. \\tag {4}\n$$\n\nAs shown in Figure 3, for the  $l$ -th TimesBlock, the whole process involves two successive parts: capturing temporal 2D-variations and adaptively aggregating representations from different periods.\n\nCapturing temporal 2D-variations Similar to Equation 1, we can estimate period lengths for deep features  $\\mathbf{X}_{\\mathrm{1D}}^{l-1}$  by  $\\mathrm{Period}(\\cdot)$ . Based on estimated period lengths, we can transform the 1D time series\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/12e8c71e642976596a6a4ac00056578f248bbeefd1e349016895fe96e50b6724.jpg)  \nFigure 3: Overall architecture of TimesNet. TimesNet is stacked by TimesBlocks in a residual way. TimesBlocks can capture various temporal 2D-variations from  $k$  different reshaped tensors by a parameter-efficient inception block in 2D space and fuse them based on normalized amplitude values.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/8dd34208029d628b5821f894f72950091b08c94f1842fc675162adbc7ea6325c.jpg)\n\ninto 2D space and obtain a set of 2D tensors, from which we can obtain informative representations by parameter-efficient inception block conveniently. The process is formalized as follows:\n\n$$\n\\mathbf {A} ^ {l - 1}, \\{f _ {1}, \\dots , f _ {k} \\}, \\{p _ {1}, \\dots , p _ {k} \\} = \\operatorname {P e r i o d} \\left(\\mathbf {X} _ {\\mathrm {I D}} ^ {l - 1}\\right),\n$$\n\n$$\n\\mathbf {X} _ {\\mathrm {2 D}} ^ {l, i} = \\mathrm {R e s h a p e} _ {p _ {i}, f _ {i}} \\left(\\mathrm {P a d d i n g} (\\mathbf {X} _ {\\mathrm {1 D}} ^ {l - 1})\\right), i \\in \\{1, \\dots , k \\}\n$$\n\n$$\n\\widehat {\\mathbf {X}} _ {2 \\mathrm {D}} ^ {l, i} = \\text {I n c e p t i o n} \\left(\\mathbf {X} _ {2 \\mathrm {D}} ^ {l, i}\\right), i \\in \\{1, \\dots , k \\} \\tag {5}\n$$\n\n$$\n\\widehat {\\mathbf {X}} _ {\\mathrm {1 D}} ^ {l, i} = \\operatorname {T r u n c} \\left(\\operatorname {R e s h a p e} _ {1, (p _ {i} \\times f _ {i})} \\left(\\widehat {\\mathbf {X}} _ {\\mathrm {2 D}} ^ {l, i}\\right)\\right), i \\in \\{1, \\dots , k \\},\n$$\n\nwhere  $\\mathbf{X}_{2\\mathrm{D}}^{l,i} \\in \\mathbb{R}^{p_i \\times f_i \\times d_{\\mathrm{model}}}$  is the  $i$ -th transformed 2D tensor. After the transformation, we process the 2D tensor by a parameter-efficient inception block (Szegedy et al., 2015) as Inception $(\\cdot)$ , which involves multi-scale 2D kernels and is one of the most well-acknowledged vision backbones. Then we transform the learned 2D representations  $\\widehat{\\mathbf{X}}_{2\\mathrm{D}}^{l,i}$  back to 1D space  $\\widehat{\\mathbf{X}}_{1\\mathrm{D}}^{l,i} \\in \\mathbb{R}^{T \\times d_{\\mathrm{model}}}$  for aggregation, where we employ Trunc $(\\cdot)$  to truncate the padded series with length  $(p_i \\times f_i)$  into original length  $T$ .\n\nNote that benefiting from the transformation of 1D time series, the 2D kernels in the inception block can aggregate the multi-scale intraperiod-variation (columns) and interperiod-variation (rows) simultaneously, covering both adjacent time points and adjacent periods. Besides, we adopt a shared inception block for different reshaped 2D tensors  $\\{\\mathbf{X}_{2\\mathrm{D}}^{l,1},\\dots ,\\mathbf{X}_{2\\mathrm{D}}^{l,k}\\}$  to improve parameter efficiency, which can make the model size invariant to the selection of hyper-parameter  $k$\n\nAdaptive aggregation Finally, we need to fuse  $k$  different 1D-representations  $\\{\\widehat{\\mathbf{X}}_{\\mathrm{1D}}^{l,1},\\dots ,\\widehat{\\mathbf{X}}_{\\mathrm{1D}}^{l,k}\\}$  for the next layer. Inspired by Auto-Correlation (Wu et al., 2021), the amplitudes  $\\mathbf{A}$  can reflect the relative importance of selected frequencies and periods, thereby corresponding to the importance of each transformed 2D tensor. Thus, we aggregate the 1D-representations based on the amplitudes:\n\n$$\n\\widehat {\\mathbf {A}} _ {f _ {1}} ^ {l - 1}, \\dots , \\widehat {\\mathbf {A}} _ {f _ {k}} ^ {l - 1} = \\operatorname {S o f t m a x} \\left(\\mathbf {A} _ {f _ {1}} ^ {l - 1}, \\dots , \\mathbf {A} _ {f _ {k}} ^ {l - 1}\\right)\n$$\n\n$$\n\\mathbf {X} _ {\\mathrm {1 D}} ^ {l} = \\sum_ {i = 1} ^ {k} \\widehat {\\mathbf {A}} _ {f _ {i}} ^ {l - 1} \\times \\widehat {\\mathbf {X}} _ {\\mathrm {1 D}} ^ {l, i}. \\tag {6}\n$$\n\nSince the variations within and between periods are already involved in multiple highly-structured 2D tensors, TimesBlock can fully capture multi-scale temporal 2D-variations simultaneously. Thus, TimesNet can achieve a more effective representation learning than directly from 1D time series.\n\nGenerality in 2D vision backbones Benefiting from the transformation of 1D time series into temporal 2D-variations, we can choose various computer vision backbones to replace the inception block for representation learning, such as the widely-used ResNet (He et al., 2016) and ResNeXt (Xie et al., 2017), advanced ConvNeXt (Liu et al., 2022b) and attention-based models (Liu et al., 2021b). Thus, our temporal 2D-variation design also bridges the 1D time series to the booming 2D vision backbones, making the time series analysis take advantage of the development of computer vision community. In general, more powerful 2D backbones for representation learning will bring better performance. Considering both performance and efficiency (Figure 4 right), we conduct the main experiments based on the parameter-efficient inception block as shown in Equation 5.\n",
  "experiments": "# 4 EXPERIMENTS\n\nTo verify the generality of TimesNet, we extensively experiment on five mainstream analysis tasks, including short- and long-term forecasting, imputation, classification and anomaly detection.\n\nImplementation Table 1 is a summary of benchmarks. More details about the dataset, experiment implementation and model configuration can be found in Appendix A.\n\nTable 1: Summary of experiment benchmarks.  \n\n<table><tr><td>Tasks</td><td>Benchmarks</td><td>Metrics</td><td>Series Length</td></tr><tr><td rowspan=\"2\">Forecasting</td><td>Long-term: ETT (4 subsets), Electricity, Traffic, Weather, Exchange, ILI</td><td>MSE, MAE</td><td>96~720 (ILI: 24~60)</td></tr><tr><td>Short-term: M4 (6 subsets)</td><td>SMAPE, MASE, OWA</td><td>6~48</td></tr><tr><td>Imputation</td><td>ETT (4 subsets), Electricity, Weather</td><td>MSE, MAE</td><td>96</td></tr><tr><td>Classification</td><td>UEA (10 subsets)</td><td>Accuracy</td><td>29~1751</td></tr><tr><td>Anomaly Detection</td><td>SMD, MSL, SMAP, SWaT, PSM</td><td>Precision, Recall, F1-Socre</td><td>100</td></tr></table>\n\nBaselines Since we attempt to propose a foundation model for time series analysis, we extensively compare the well-acknowledged and advanced models in all five tasks, including the RNN-based models: LSTM (1997), LSTM (2018) and LSSL (2022); CNN-based Model: TCN (2019); MLP-based models: LightTS (2022) and DLinear (2023); Transformer-based models: Reformer (2020), Informer (2021), Pyraformer (2021a), Autoformer (2021), FEDformer (2022), Non-stationary Transformer (2022a) and ETSformer (2022). Besides, we also compare the state-of-the-art models for each specific task, such as N-HiTS (2022) and N-BEATS (2019) for short-term forecasting, Anomaly Transformer (2021) for anomaly detection, Rocket (2020) and Flowformer (2022) for classification and etc. Overall, more than 15 baselines are included for a comprehensive comparison.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/5aa607e211a56dcac4c70da7b2e79b21274e049e42fd6603bd27ac28631d4da0.jpg)  \nFigure 4: Model performance comparison (left) and generality in different vision backbones (right).\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/5ee553462d0188889195f408ebfadc7ac21a4d6f066f1d0aa1c48f0f5ab8b381.jpg)\n\n# 4.1 MAIN RESULTS\n\nAs a foundation model, TimesNet achieves consistent state-of-the-art performance on five mainstream analysis tasks compared with other customized models (Figure 4 left). The full efficiency comparison is provided in Table 11 of Appendix. Besides, by replacing the inception block with more powerful vision backbones, we can further promote the performance of TimesNet (Figure 4 right), confirming that our design can make time series analysis take advantage of booming vision backbones.\n\n# 4.2 SHORT- AND LONG-TERM FORECASTING\n\n**Setup** Time series forecasting is essential in weather forecasting, traffic and energy consumption planning. To fully evaluate the model performance in forecasting, we adopt two types of benchmarks, including long-term and short-term forecasting. Especially for the long-term setting, we follow the benchmarks used in Autoformer (2021), including ETT (Zhou et al., 2021), Electricity (UCI), Traffic (PeMS), Weather (Wetterstation), Exchange (Lai et al., 2018) and ILI (CDC), covering five real-world applications. For the short-term dataset, we adopt the M4 (Spyros Makridakis, 2018), which contains the yearly, quarterly and monthly collected univariate marketing data. Note that each dataset in the long-term setting only contains one continuous time series, where we obtain samples by sliding window, while M4 involves 100,000 different time series collected in different frequencies.\n\nTable 2: Long-term forecasting task. The past sequence length is set as 36 for ILI and 96 for the others. All the results are averaged from 4 different prediction lengths, that is  $\\{24, 36, 48, 60\\}$  for ILI and  $\\{96, 192, 336, 720\\}$  for the others. See Table 13 in Appendix for the full results.  \n\n<table><tr><td>Models</td><td>TimesNet (Ours)</td><td>ETSformer (2022)</td><td>LightTS (2022)</td><td>DLinear (2023)</td><td>FEDformer (2022)</td><td>Stationary (2022a)</td><td>Autoformer (2021)</td><td>Pyraformer (2021a)</td><td>Informer (2021)</td><td>LogTrans (2019)</td><td>Reformer (2020)</td></tr><tr><td>Metric</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td></tr><tr><td>ETTm1</td><td>0.400 0.406</td><td>0.429 0.425</td><td>0.435 0.437</td><td>0.403 0.407</td><td>0.448 0.452</td><td>0.481 0.456</td><td>0.588 0.517</td><td>0.691 0.607</td><td>0.961 0.734</td><td>0.929 0.725</td><td>0.799 0.671</td></tr><tr><td>ETTm2</td><td>0.291 0.333</td><td>0.293 0.342</td><td>0.409 0.436</td><td>0.350 0.401</td><td>0.305 0.349</td><td>0.306 0.347</td><td>0.327 0.371</td><td>1.498 0.869</td><td>1.410 0.810</td><td>1.535 0.900</td><td>1.479 0.915</td></tr><tr><td>ETTh1</td><td>0.458 0.450</td><td>0.542 0.510</td><td>0.491 0.479</td><td>0.456 0.452</td><td>0.440 0.460</td><td>0.570 0.537</td><td>0.496 0.487</td><td>0.827 0.703</td><td>1.040 0.795</td><td>1.072 0.837</td><td>1.029 0.805</td></tr><tr><td>ETTh2</td><td>0.414 0.427</td><td>0.439 0.452</td><td>0.602 0.543</td><td>0.559 0.515</td><td>0.437 0.449</td><td>0.526 0.516</td><td>0.450 0.459</td><td>0.826 0.703</td><td>4.431 1.729</td><td>2.686 1.494</td><td>6.736 2.191</td></tr><tr><td>Electricity</td><td>0.192 0.295</td><td>0.208 0.323</td><td>0.229 0.329</td><td>0.212 0.300</td><td>0.214 0.327</td><td>0.193 0.296</td><td>0.227 0.338</td><td>0.379 0.445</td><td>0.311 0.397</td><td>0.272 0.370</td><td>0.338 0.422</td></tr><tr><td>Traffic</td><td>0.620 0.336</td><td>0.621 0.396</td><td>0.622 0.392</td><td>0.625 0.383</td><td>0.610 0.376</td><td>0.624 0.340</td><td>0.628 0.379</td><td>0.878 0.469</td><td>0.764 0.416</td><td>0.705 0.395</td><td>0.741 0.422</td></tr><tr><td>Weather</td><td>0.259 0.287</td><td>0.271 0.334</td><td>0.261 0.312</td><td>0.265 0.317</td><td>0.309 0.360</td><td>0.288 0.314</td><td>0.338 0.382</td><td>0.946 0.717</td><td>0.634 0.548</td><td>0.696 0.602</td><td>0.803 0.656</td></tr><tr><td>Exchange</td><td>0.416 0.443</td><td>0.410 0.427</td><td>0.385 0.447</td><td>0.354 0.414</td><td>0.519 0.500</td><td>0.461 0.454</td><td>0.613 0.539</td><td>1.913 1.159</td><td>1.550 0.998</td><td>1.402 0.968</td><td>1.280 0.932</td></tr><tr><td>ILI</td><td>2.139 0.931</td><td>2.497 1.004</td><td>7.382 2.003</td><td>2.616 1.090</td><td>2.847 1.144</td><td>2.077 0.914</td><td>3.006 1.161</td><td>7.635 2.050</td><td>5.137 1.544</td><td>4.839 1.485</td><td>4.724 1.445</td></tr></table>\n\nTable 3: Short-term forecasting task on M4. The prediction lengths are in [6, 48] and results are weighted averaged from several datasets under different sample intervals. See Table 14 for full results.  \n\n<table><tr><td>Models</td><td>TimesNet (Ours)</td><td>N-HiTS (2022)</td><td>N-BEATS (2019)</td><td>ETSformer (2022)</td><td>LightTS (2022)</td><td>DLinear (2023)</td><td>FEDformer (2022a)</td><td>Stationary (2021)</td><td>Autoformer (2021a)</td><td>Pyraformer (2021)</td><td>Informer (2021)</td><td>LogTrans (2019)</td><td>Reformer (2020)</td></tr><tr><td>SMAPE</td><td>11.829</td><td>11.927</td><td>11.851</td><td>14.718</td><td>13.525</td><td>13.639</td><td>12.840</td><td>12.780</td><td>12.909</td><td>16.987</td><td>14.086</td><td>16.018</td><td>18.200</td></tr><tr><td>MASE</td><td>1.585</td><td>1.613</td><td>1.599</td><td>2.408</td><td>2.111</td><td>2.095</td><td>1.701</td><td>1.756</td><td>1.771</td><td>3.265</td><td>2.718</td><td>3.010</td><td>4.223</td></tr><tr><td>OWA</td><td>0.851</td><td>0.861</td><td>0.855</td><td>1.172</td><td>1.051</td><td>1.051</td><td>0.918</td><td>0.930</td><td>0.939</td><td>1.480</td><td>1.230</td><td>1.378</td><td>1.775</td></tr></table>\n\nResults TimesNet shows great performance in both long-term and short-term settings (Table 2-3). Concretely, TimesNet achieves state-of-the-art in more than  $80\\%$  of cases in long-term forecasting (Table 13). For the M4 dataset, since the time series are collected from different sources, the temporal variations can be quite diverse, making forecasting much more challenging. Our model still performs best in this task, surpassing extensive advanced MLP-based and Transformer-based models.\n\n# 4.3 IMPUTATION\n\n**Setup** Real-world systems always work continuously and are monitored by automatic observation equipment. However, due to malfunctions, the collected time series can be partially missing, making the downstream analysis difficult. Thus, imputation is widely-used in practical applications. In this paper, we select the datasets from the electricity and weather scenarios as our benchmarks, including ETT (Zhou et al., 2021), Electricity (UCI) and Weather (Wetterstation), where the data-missing problem happens commonly. To compare the model capacity under different proportions of missing data, we randomly mask the time points in the ratio of  $\\{12.5\\%, 25\\%, 37.5\\%, 50\\}$ .\n\nResults Due to the missing time points, the imputation task requires the model to discover underlying temporal patterns from the irregular and partially observed time series. As shown in Table 4, our proposed TimesNet still achieves the consistent state-of-the-art in this difficult task, verifying the model capacity in capturing temporal variation from extremely complicated time series.\n\n# 4.4 CLASSIFICATION\n\n**Setup** Time series classification can be used in recognition and medical diagnosis (Moody et al., 2011). We adopt the sequence-level classification to verify the model capacity in high-level representation learning. Concretely, we select 10 multivariate datasets from UEA Time Series Classification Archive (Bagnall et al., 2018), covering the gesture, action and audio recognition, medical diagnosis by heartbeat monitoring and other practical tasks. Then, we pre-process the datasets following the descriptions in (Zerveas et al., 2021), where different subsets have different sequence lengths.\n\nTable 4: Imputation task. We randomly mask  $\\{12.5\\%, 25\\%, 37.5\\%, 50\\% \\}$  time points in length-96 time series. The results are averaged from 4 different mask ratios. See Table 16 for full results.  \n\n<table><tr><td>Models</td><td>TimesNet (Ours)</td><td>ETSformer (2022)</td><td>LightTS (2022)</td><td>DLinear (2023)</td><td>FEDformer (2022)</td><td>Stationary (2022a)</td><td>Autoformer (2021)</td><td>Pyraformer (2021a)</td><td>Informer (2021)</td><td>LogTrans (2019)</td><td>Reformer (2020)</td></tr><tr><td>Mask Ratio</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td><td>MSE MAE</td></tr><tr><td>ETTm1</td><td>0.027 0.107</td><td>0.120 0.253</td><td>0.104 0.218</td><td>0.093 0.206</td><td>0.062 0.177</td><td>0.036 0.126</td><td>0.051 0.150</td><td>0.717 0.570</td><td>0.071 0.188</td><td>0.050 0.154</td><td>0.055 0.166</td></tr><tr><td>ETTm2</td><td>0.022 0.088</td><td>0.208 0.327</td><td>0.046 0.151</td><td>0.096 0.208</td><td>0.101 0.215</td><td>0.026 0.099</td><td>0.029 0.105</td><td>0.465 0.508</td><td>0.156 0.292</td><td>0.119 0.246</td><td>0.157 0.280</td></tr><tr><td>ETTh1</td><td>0.078 0.187</td><td>0.202 0.329</td><td>0.284 0.373</td><td>0.201 0.306</td><td>0.117 0.246</td><td>0.094 0.201</td><td>0.103 0.214</td><td>0.842 0.682</td><td>0.161 0.279</td><td>0.219 0.332</td><td>0.122 0.245</td></tr><tr><td>ETTh2</td><td>0.049 0.146</td><td>0.367 0.436</td><td>0.119 0.250</td><td>0.142 0.259</td><td>0.163 0.279</td><td>0.053 0.152</td><td>0.055 0.156</td><td>1.079 0.792</td><td>0.337 0.452</td><td>0.186 0.318</td><td>0.234 0.352</td></tr><tr><td>Electricity</td><td>0.092 0.210</td><td>0.214 0.339</td><td>0.131 0.262</td><td>0.132 0.260</td><td>0.130 0.259</td><td>0.100 0.218</td><td>0.101 0.225</td><td>0.297 0.382</td><td>0.222 0.328</td><td>0.175 0.303</td><td>0.200 0.313</td></tr><tr><td>Weather</td><td>0.030 0.054</td><td>0.076 0.171</td><td>0.055 0.117</td><td>0.052 0.110</td><td>0.099 0.203</td><td>0.032 0.059</td><td>0.031 0.057</td><td>0.152 0.235</td><td>0.045 0.104</td><td>0.039 0.076</td><td>0.038 0.087</td></tr></table>\n\nResults As shown in Figure 5, TimesNet achieves the best performance with an average accuracy of  $73.6\\%$ , surpassing the previous state-of-the-art classical method Rocket  $(72.5\\%)$  and deep model Flowformer  $(73.0\\%)$ . It is also notable that the MLP-based model DLinear fails in this classification task  $(67.5\\%)$ , which performs well in some time series forecasting datasets. This is because DLinear only adopts a one-layer MLP model on the temporal dimension, which might be suitable for some autoregressive tasks with fixed temporal\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/1705aa745a870c1c0b4f0c6bdc600b56dc1cf428699c62fea4459a28b762b04e.jpg)  \nFigure 5: Model comparison in classification. “*.” in the Transformers indicates the name of *former. The results are averaged from 10 subsets of UEA. See Table 17 in Appendix for full results.\n\ndependencies but will degenerate a lot in learning high-level representations. In contrast, TimesNet unifies the temporal 2D-variation in 2D space, which is convenient to learn informative representation by 2D kernels, thereby benefiting the classification task that requires hierarchical representations.\n\n# 4.5 ANOMALY DETECTION\n\n**Setup** Detecting anomalies from monitoring data is vital to industrial maintenance. Since the anomalies are usually hidden in the large-scale data, making the data labeling hard, we focus on unsupervised time series anomaly detection, which is to detect the abnormal time points. We compare models on five widely-used anomaly detection benchmarks: SMD (Su et al., 2019), MSL (Hundman et al., 2018), SMAP (Hundman et al., 2018), SWaT (Mathur & Tippenhauer, 2016), PSM (Abdulaal et al., 2021), covering service monitoring, space & earth exploration, and water treatment applications. Following the pre-processing methods in Anomaly Transformer (2021), we split the dataset into consecutive non-overlapping segments by sliding window. In previous works, the reconstruction is a classical task for unsupervised point-wise representation learning, where the reconstruction error is a natural anomaly criterion. For a fair comparison, we only change the base models for reconstruction and use the classical reconstruction error as the shared anomaly criterion for all experiments.\n\nResults Table 5 demonstrates that TimesNet still achieves the best performance in anomaly detection, outperforming the advanced Transformer-based models FEDformer (2022) and Autoformer (2021). The canonical Transformer performs worse in this task (averaged F1-score  $76.88\\%$ ). This may come from that anomaly detection requires the model to find out the rare abnormal temporal patterns (Lai et al., 2021), while the vanilla attention mechanism calculates the similarity between each pair of time points, which can be distracted by the dominant normal time points. Besides, by taking the periodicity into consideration, TimesNet, FEDformer and Autoformer all achieve great performance. Thus, these results also demonstrate the importance of periodicity analysis, which can highlight variations that violate the periodicity implicitly, further benefiting the anomaly detection.\n\nTable 5: Anomaly detection task. We calculate the F1-score (as %) for each dataset. *. means the *former. A higher value of F1-score indicates a better performance. See Table 15 for full results.  \n\n<table><tr><td>Models</td><td>TimesNet (ResNeXt)</td><td>TimesNet (Inception)</td><td>ETS. (2022)</td><td>FED. (2022)</td><td>LightTS (2022)</td><td>DLinear (2023)</td><td>Stationary (2022a)</td><td>Auto. (2021)</td><td>Pyra. (2021a)</td><td>Anomaly* (2021)</td><td>In. (2021)</td><td>Re. (2020)</td><td>LogTrans (2019)</td><td>Trans. (2017)</td></tr><tr><td>SMD</td><td>85.81</td><td>85.12</td><td>83.13</td><td>85.08</td><td>82.53</td><td>77.10</td><td>84.72</td><td>85.11</td><td>83.04</td><td>85.49</td><td>81.65</td><td>75.32</td><td>76.21</td><td>79.56</td></tr><tr><td>MSL</td><td>85.15</td><td>84.18</td><td>85.03</td><td>78.57</td><td>78.95</td><td>84.88</td><td>77.50</td><td>79.05</td><td>84.86</td><td>83.31</td><td>84.06</td><td>84.40</td><td>79.57</td><td>78.68</td></tr><tr><td>SMAP</td><td>71.52</td><td>70.85</td><td>69.50</td><td>70.76</td><td>69.21</td><td>69.26</td><td>71.09</td><td>71.12</td><td>71.09</td><td>71.18</td><td>69.92</td><td>70.40</td><td>69.97</td><td>69.70</td></tr><tr><td>SWaT</td><td>91.74</td><td>92.10</td><td>84.91</td><td>93.19</td><td>93.33</td><td>87.52</td><td>79.88</td><td>92.74</td><td>91.78</td><td>83.10</td><td>81.43</td><td>82.80</td><td>80.52</td><td>80.37</td></tr><tr><td>PSM</td><td>97.47</td><td>95.21</td><td>91.76</td><td>97.23</td><td>97.15</td><td>93.55</td><td>97.29</td><td>93.29</td><td>82.08</td><td>79.40</td><td>77.10</td><td>73.61</td><td>76.74</td><td>76.07</td></tr><tr><td>Avg F1</td><td>86.34</td><td>85.49</td><td>82.87</td><td>84.97</td><td>84.23</td><td>82.46</td><td>82.08</td><td>84.26</td><td>82.57</td><td>80.50</td><td>78.83</td><td>77.31</td><td>76.60</td><td>76.88</td></tr></table>\n\n* We replace the joint criterion in Anomaly Transformer (2021) with reconstruction error for fair comparison.\n\n# 4.6 MODEL ANALYSIS\n\nRepresentation analysis We attempt to explain model performance from the representation learning aspect. From Figure 6, we can find that the better performance in forecasting and anomaly detection corresponds to the higher CKA similarity (2019), which is opposite to the imputation and classification tasks. Note that the lower CKA similarity means that the representations are distinguishing among different layers, namely hierarchical representations. Thus, these results also indicate the property of representations that each task requires. As shown in Figure 6, TimesNet can learn appropriate representations for different tasks, such as low-level representations for forecasting and reconstruction in anomaly detection, and hierarchical representations for imputation and classification. In contrast, FEDformer (2022) performs well in forecasting and anomaly detection tasks but fails in learning hierarchical representations, resulting in poor performance in imputation and classification. These results also verify the task-generality of our proposed TimesNet as a foundation model.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/be582da8995b94ad650932f6f35d4f3eba6ebdf79285389a8517cb5d60ce0763.jpg)  \n(a) Forecasting (Weather input-96-predict-336)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/a302d9e3916516b2a218e4081a74f59bdbd574799096ee420528a0118ac71737.jpg)  \n(b) Imputation (Electricity Mask  $37.5\\%$ )\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/7157592eac188e678fb08aaaae58db8857a1270dcf926594bbfdada868bb909c.jpg)  \n(c) Classification (PEMS-SF)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-04/431aed6a-3162-43b8-ac20-bb85d3d3b7a5/97932e5d92bad86f6ce59cad52142496fe87ad1d2945b503fcad809c8657a7c5.jpg)  \n(d) Anomaly Detection (SMD)\n\nTemporal 2D-variations We provide a case study of temporal 2D-variations in Figure 7. We can find that TimesNet can capture the multi-periodicities precisely. Besides, the transformed 2D tensor is highly structured and informative, where the columns and rows can reflect the localities between time points and periods respectively, supporting our motivation in adopting 2D kernels for representation learning. See Appendix D for more visualizations.\n",
  "hyperparameter": "k (number of selected top frequencies/periods): key hyperparameter controlling how many periods to consider; d_model: hidden dimension for deep features after embedding layer; Number of TimesBlock layers: stacked in residual manner; Input sequence length T: 96 for most long-term forecasting (36 for ILI), 96 for imputation, varies 29-1751 for classification, 100 for anomaly detection; Prediction lengths: {96, 192, 336, 720} for long-term forecasting (except ILI: {24, 36, 48, 60}), {6-48} for short-term M4; Mask ratios for imputation: {12.5%, 25%, 37.5%, 50%}; Vision backbone: Inception block (parameter-efficient choice), with alternatives including ResNet, ResNeXt, ConvNeXt for better performance-efficiency tradeoffs"
}