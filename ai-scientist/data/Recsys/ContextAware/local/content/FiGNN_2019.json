{
  "id": "FiGNN_2019",
  "paper_title": "FiGNN: Modeling Feature Interactions via Graph Neural Networks for CTR Prediction",
  "alias": "FiGNN",
  "year": 2019,
  "domain": "Recsys",
  "task": "ContextAwareRecommendation",
  "idea": "FiGNN represents multi-field categorical features as a fully-connected feature graph where nodes are feature fields and models feature interactions through Graph Neural Networks. The core innovations are: (1) Edge-wise interactions via attentional edge weights (learned through attention mechanism) and edge-wise transformation functions (using separate input/output matrices per node to achieve unique transformations per edge with O(m) parameters instead of O(m²)); (2) State updates combining GRU with residual connections to preserve low-order interactions while modeling high-order interactions through T propagation steps.",
  "introduction": "# 1 INTRODUCTION\n\nThe goal of click-through rate prediction is to predict the probabilities of users clicking ads or items, which is critical to many web applications such as online advertising and recommender systems. Modeling sophisticated feature interactions plays a central role in the success of CTR prediction. Distinct from continuous features which can be naturally found in images and audios, the features for web applications are mostly in multi-field categorical form. For example, the four-fields categorical features for movies may be: (1) Language = {English, Chinese, Japanese, ...}, (2) Genre = {action, fiction, ...}, (3) Director = {Ang Lee, Christopher Nolan, ...}, and (4) Starring = {Bruce Lee, Leonardo DiCaprio, ...} (noted that there are much more feature fields in real applications). These multi-field categorical features are usually converted to sparse one-hot encoding vectors, and then embedded to dense real-value vectors, which can be used to model feature interactions.\n\nFactorization machine (FM) [23] is a well-known model proposed to learn second-order feature interactions from vector inner products. Field-aware factorization machine (FFM) [9] further considers the field information and introduces field-aware embedding. Regrettably, these FM-based models can only model second-order interaction and the linearity modeling limits its representative power. Recently, many deep learning based models have been proposed\n\nto learn high-order feature interactions, which follow a general paradigm: simply concatenate the field embedding vectors together and feed them into DNN or other specifically designed models to learn interactions. For example, Factorisation-machine supported Neural Networks (FNN) [35], Neural Factorization Machine (NFM) [8], Wide&Deep [2] and DeepFM [6] utilize DNN to model interactions. However, these model based on DNN learn high-order feature interactions in a bit-wise, implicit fashion, which lacks good model explanations. Some models try to learn high order interactions explicitly by introducing specifically designed networks. For example, Deep&Cross [31] introduces Cross Network (CrossNet) and xDeepFM [15] introduces Compressed Interaction Network (CIN). Nevertheless, we argue that they are still not sufficiently effective and explicit, since they still follow the general paradigm of combining feature fields together to model their interactions. The simple unstructured combination will inevitably limit the capability to model sophisticated interactions among different feature fields in a flexible and explicit fashion.\n\nIn this work, we take the structure of multi-field features into consideration. Specifically, we represent the multi-field features in a graph structure named feature graph. Intuitively, each node in the graph corresponds to a feature field and different fields can interact through edges. The task of modeling sophisticated interactions among feature fields can be thus converted to modeling node interactions on the feature graph. To this end, we design a novel model Feature interaction Graph Neural Networks (Fi-GNN) based on Graph Neural Networks (GNN), which is able to model sophisticated node (feature) interactions in a flexible and explicit fashion. In Fi-GNN, the nodes will interact by communicating the node states with neighbors and update themselves in a recurrent fashion. At every time step, the model interact with neighbors at one hop deeper. Therefore, the number of interaction steps equals to the order of feature interactions. Moreover, the edge weights reflecting importances of different feature interactions and node weights reflecting importances of each feature field on the final CTR prediction can be learnt by Fi-GNN, which can provide good explanations. Overall, our proposed model can model sophisticated feature interactions in an explicit, flexible fashion and also provide good model explanations.\n\nOur contributions can be summarized in threefold:\n\n- We point out the limitation of the existing works which consider multi-field features as an unstructured combination of feature fields. To this end, we propose to represent the multi-field features in a graph structure for the first time.  \n- We design a novel model Feature Interaction Graph Neural Networks (Fi-GNN) to model sophisticated interactions among feature fields on the graph-structured features in a more flexible and explicit fashion.  \n- Extensive experiments on two real-world datasets show that our proposed method can not only outperform the state-of-the-arts but also provide good model explanations.\n\nThe rest of this paper is organized as follows. Section 2 summarizes the related work. Section 3 provides an elaborative description of our proposed method. The extensive experiments and detailed analysis are presented in Section 4, followed by the conclusion in Section 5.",
  "method": "# 3 OUR PROPOSED METHOD\n\nWe first formulate the problem and then introduce the overview of our proposed method, followed by the elaborate detail of each component.\n\n# 3.1 Problem Formulation\n\nSuppose the training dataset consists of  $m$ -fields categorical features ( $m$  is the number of feature fields) and the associated labels  $y \\in \\{0,1\\}$  which indicate user click behaviors. The task of CTR prediction is to predict  $\\hat{y}$  for the input  $m$ -fields features, which estimates the probability of a user clicking. The key of the task is to model the sophisticated interactions among different feature fields.\n\n# 3.2 Overview\n\nFigure 1 is the overview of our proposed method ( $m = 4$ ). The input sparse  $m$ -field feature vector is first mapped into sparse one-hot embedding vectors and then embedded to dense field embedding vectors via the embedding layer and the multi-head self-attention layer. The field embedding vectors are then represented as a feature graph, where each node corresponds to a feature field and different feature fields can interact through edges. The task of modeling interaction can be thus converted to modeling node interactions on the feature graph. Therefore, the feature graph is feed into our proposed Fi-GNN to model node interactions. An attention scoring layer is applied on the output of Fi-GNN to estimate the click-through rate  $\\hat{y}$ . In the following, we will introduce the details of our proposed method.\n\n# 3.3 Embedding Layer\n\nThe multi-field categorical feature  $\\mathbf{x}$  is usually sparse and of huge dimension. Following previous works [6, 21, 22, 31, 35], we represent each field as a one-hot encoding vector and then embed it to a dense vector, noted as field embedding vector. Let us consider the example in Section 1, a movie {Language: English, Genre: fiction, Director: Christopher Nolan, Starring: Leonardo DiCaprio} is first transformed into a high-dimensional sparse features via one-hot encoding:\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/b15ad793-1881-4f14-93d1-04e554cb4f98/1b81201659cb57b7847f16c0875fd3c6d1bc1412fe69a5a427ebfc015a94d179.jpg)\n\nA field-aware embedding layer is then applied upon the one-hot vectors to embed them to low dimensional, dense real-value field embedding vectors as shown in Figure ??. Likewise, the field embedding vectors of  $m$ -field feature can be obtained:\n\n$$\n\\mathbf {E} = \\left[ \\mathbf {e} _ {1}, \\mathbf {e} _ {2}, \\mathbf {e} _ {3}, \\dots , \\mathbf {e} _ {m} \\right],\n$$\n\nwhere  $\\mathbf{e}_i\\in \\mathbb{R}^d$  denotes the embedding vector of field  $i$  and  $d$  denotes the dimension of field embedding vectors.\n\n# 3.4 Multi-head Self-attention Layer\n\nTransformer [29] is prevalent in NLP and has achieved great success in many tasks. At the core of Transformer, the multi-head self-attention mechanism is able to model complicated dependencies between word pairs in multiple semantic subspaces. In the literature of CTR prediction, we take advantage of the multi-head self-attention mechanism to capture the complex dependencies between feature field pairs, i.e., pairwise feature interactions, in different semantic subspaces.\n\nFollowing [26], given the feature embeddings  $\\mathbf{E}$ , we obtain the feature representation of features that cover the pairwise interactions of an attention head  $i$  via scaled dot-product:\n\n$$\n\\mathbf {H} _ {i} = \\operatorname {s o f t m a x} _ {i} \\left(\\frac {\\mathbf {Q K} ^ {T}}{\\sqrt {d _ {K}}}\\right) \\mathbf {V},\n$$\n\n$$\n\\mathbf {Q} = \\mathbf {W} _ {i} ^ {(Q)} \\mathbf {E}, \\mathbf {K} = \\mathbf {W} _ {i} ^ {(K)} \\mathbf {E}, \\mathbf {V} = \\mathbf {W} _ {i} ^ {(V)} \\mathbf {E}.\n$$\n\nThe matrices  $\\mathbf{W}_i^{(Q)}\\in \\mathbb{R}^{d_i\\times d}$ ,  $\\mathbf{W}_i^{(K)}\\in \\mathbb{R}^{d_i\\times d}$ ,  $\\mathbf{W}_i^{(V)}\\in \\mathbb{R}^{d_i\\times d}$  are three weight parameters for attention head  $i$ ,  $d_{i}$  is the dimension size of head  $i$ , and  $\\mathbf{H}_i\\in \\mathbb{R}^{m\\times d_i}$ .\n\nThen we combine the learnt feature representations of each head to preserve the pairwise feature interactions in each semantic subspace:\n\n$$\n\\mathbf {H} ^ {1} = \\operatorname {R e L U} \\left(\\mathbf {H} _ {1} \\oplus \\mathbf {H} _ {2} \\oplus \\dots \\oplus \\mathbf {H} _ {h}\\right),\n$$\n\nwhere  $\\oplus$  denotes the concatenation operation and  $h$  denotes the number of attention heads. The learnt feature representations  $\\mathbf{H}^1\\in \\mathbb{R}^{m\\times d'}$  are used for the initial node states of the graph neural network, where  $d^{\\prime} = \\sum_{i = 1}^{h}d_{i}$\n\n# 3.5 Feature Graph\n\nDistinguished from the previous works which simply concatenate the field embedding vectors together and feed them into designed models to learn feature interactions, we represent them in a graph structure. In particular, We represent each input multi-field feature as a feature graph  $\\mathcal{G} = (\\mathcal{N},\\mathcal{E})$ , where each node  $n_i\\in \\mathcal{N}$  corresponds to a feature field  $i$  and different fields can interact through the edges, so that  $|\\mathcal{N}| = m$ . Since each two fields ought to interact, it is a weighted fully connected graph while the edge weights reflect importances of different feature interactions. Accordingly, the task of modeling feature interactions can be converted to modeling node interactions on the feature graph.\n\n# 3.6 Feature Interaction Graph Neural Network\n\nFi-GNN is designed to model node interactions on the feature graph, which is based on GGNN [12]. It is able to model the interactions in a flexible and explicit fashion.\n\nPreliminaries. In Fi-GNN, each node  $n_i$  is associated with a hidden state vector  $\\mathbf{h}_i^t$  and the state of graph is composed of these node states\n\n$$\n\\mathbf {H} ^ {t} = \\left[ \\begin{array}{c} \\mathbf {h} _ {1} ^ {t}, \\mathbf {h} _ {2} ^ {t}, \\mathbf {h} _ {3} ^ {t}, \\dots , \\mathbf {h} _ {m} ^ {t} \\end{array} \\right],\n$$\n\nwhere  $t$  denote the interaction step. The learnt feature representations by the multi-head self-attention layer are used for their initial node states  $\\mathbf{H}^{1}$ . As shown in Figure 2, the nodes interact and update their states in a recurrent fashion. At each interaction step, the nodes aggregate the transformed state information with neighbors,\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/b15ad793-1881-4f14-93d1-04e554cb4f98/5b7788749fad8f90819247a6804e563b9617aeaf2e52136746e7966b68c63bda.jpg)  \nFigure 2: Framework of Fi-GNN. The nodes interact with neighbors and update their states in a recurrent fashion. At each interaction step, each node will first aggregate transformed state information from neighbors and then update its state according to the aggregated information and history via GRU and residual connection.\n\nand then update their node states according to the aggregated information and history via GRU and residual connection. Next, we will introduce the details of Fi-GNN elaborately.\n\nState Aggregation. At interaction step  $t$ , each node will aggregate the state information from neighbors. Formally, the aggregated information of node  $n_i$  is sum of its neighbors' transformed state information,\n\n$$\n\\mathbf {a} _ {i} ^ {t} = \\sum_ {n _ {j} \\rightarrow n _ {i} \\in \\mathcal {E}} \\mathbf {A} [ n _ {j}, n _ {i} ] \\mathbf {W} _ {p} \\mathbf {h} _ {j} ^ {t - 1}, \\tag {1}\n$$\n\nwhere  $\\mathbf{W}_p$  is the transformation function.  $\\mathbf{A} \\in \\mathbb{R}^{m \\times m}$  is the adjacency matrix containing the edge weights. For example,  $\\mathbf{A}[n_j, n_i]$  is the weight of edge from node  $n_j$  to  $n_i$ , which can reflect the importance of their interaction. Apparently, the transformation function and adjacency matrix decide on the node interactions. Since the interaction on each edge ought to differ, we aim to achieve edge-wise interaction, which requires a unique weight and transformation function for each edge.\n\n(1) Attentional Edge Weights. The adjacency matrix in the conventional GNN models is usually in the binary form, i.e., only contains 0 and 1. It can only reflect the connected relation of nodes but fails to reflect the importances of their relations. In order to infer the importances of interactions between different nodes, we propose to learn the edge weights via an attention mechanism. In particular, the weight of edge from node  $n_i$  to node  $n_j$  is calculated with their initial node states, i.e., the corresponding field embedding vectors. Formally,\n\n$$\nw \\left(n _ {i}, n _ {j}\\right) = \\frac {\\exp \\left(\\text {L e a k y R e l u} \\left(\\mathbf {W} _ {w} \\left[ \\mathbf {e} _ {i} \\mid \\mid \\mathbf {e} _ {j} \\right]\\right)\\right)}{\\sum_ {k} \\exp \\left(\\text {L e a k y R e l u} \\left(\\mathbf {W} _ {w} \\left[ \\mathbf {e} _ {i} \\mid \\mid \\mathbf {e} _ {k} \\right]\\right)\\right)}, \\tag {2}\n$$\n\nwhere  $\\mathbf{W}_w\\in \\mathbb{R}^{2d'}$  is a weight matrix,  $||$  is the concatenation operation. The softmax function is utilized to make weights easily comparable across different nodes. Therefore, the adjacency matrix is,\n\n$$\n\\mathrm {A} \\left[ n _ {i}, n _ {j} \\right] = \\left\\{ \\begin{array}{l l} & w \\left(n _ {i}, n _ {j}\\right), \\text {i f} i \\neq j, \\\\ & 0, \\text {e l s e}. \\end{array} \\right. \\tag {3}\n$$\n\nSince the edge weights reflects the importances of different interaction, Fi-GNN can provide good explanations on the relation of different feature fields of input instance, which will be further discussed in Section 4.5.\n\n(2) Edge-wise Transformation. As discussed before, a fixed transformed function on all the edges is unable to model the flexible interactions and a unique transformation for each edge is essential. Nevertheless, our graph is complete graph with a huge number of edges. Simply assigning a unique transformation weight to each edge will consuming too much parameter space and running time. To reduce the time and space complexity and also achieve edge-wise transformation, we assign an output matrix  $\\mathbf{W}_{out}^{i}$  and an input matrix  $\\mathbf{W}_{in}^{i}$  to each node  $n_i$  similar with [4]. As shown in Figure 2, when node  $n_i$  sends its state information to node  $n_j$ , the state information will first be transformed by its output matrix  $\\mathbf{W}_{out}^{i}$  and then transformed by node  $n_j$ 's input matrix  $\\mathbf{W}_{in}^{j}$  before  $n_j$  receives it. The transformation function of edge  $n_i \\rightarrow n_j$  from node  $n_i$  to node  $n_j$  thus could be written as,\n\n$$\n\\mathbf {W} _ {p} ^ {n _ {i} \\rightarrow n _ {j}} = \\mathbf {W} _ {\\text {o u t}} ^ {i} \\mathbf {W} _ {\\text {i n}} ^ {j}. \\tag {4}\n$$\n\nLikewise, the transformation function of edge  $n_j \\rightarrow n_i$  from node  $n_j$  to node  $n_j$  is\n\n$$\n\\mathbf {W} _ {p} ^ {n _ {j} \\rightarrow n _ {i}} = \\mathbf {W} _ {\\text {o u t}} ^ {j} \\mathbf {W} _ {\\text {i n}} ^ {i}. \\tag {5}\n$$\n\nAccordingly, the Equation 1 could be rewritten as,\n\n$$\n\\mathbf {a} _ {i} ^ {t} = \\sum_ {n _ {j} \\rightarrow n _ {i} \\in \\mathcal {E}} \\mathbf {A} [ n _ {j}, n _ {i} ] \\mathbf {W} _ {\\text {o u t}} ^ {j} \\mathbf {W} _ {\\text {i n}} ^ {i} \\mathbf {h} _ {j} ^ {t - 1} + \\mathbf {b} _ {p}. \\tag {6}\n$$\n\nIn this way, the number of parameters is proportional to the number of nodes rather than numerous edges, which greatly reduces the space and time complexity and meanwhile achieves edge-wise interaction.\n\nState Update. After aggregating state information, the nodes will update the state vectors via GRU and residual connections.\n\n(1) State update via GRU. In traditional GGNN, the state vector of node  $n_i$  is updated via GRU based on the aggregated state information  $\\mathbf{a}_i^t$  and its state at last step. Formally,\n\n$$\n\\mathbf {h} _ {i} ^ {t} = G R U \\left(\\mathbf {h} _ {i} ^ {t - 1}, \\mathbf {a} _ {i} ^ {t}\\right). \\tag {7}\n$$\n\nIt can be formalized in detail as:\n\n$$\n\\mathbf {z} _ {i} ^ {t} = \\sigma \\left(\\mathbf {W} _ {z} \\mathbf {a} _ {i} ^ {t} + \\mathbf {U} _ {z} \\mathbf {h} _ {i} ^ {t - 1} + \\mathbf {b} _ {z}\\right), \\tag {8}\n$$\n\n$$\n\\mathbf {r} _ {i} ^ {t} = \\sigma \\left(\\mathbf {W} _ {r} \\mathbf {a} _ {i} ^ {t} + \\mathbf {U} _ {r} \\mathbf {h} _ {i} ^ {t - 1} + \\mathbf {b} _ {r}\\right), \\tag {9}\n$$\n\n$$\n\\tilde {\\mathbf {h}} _ {i} ^ {t} = \\tanh  \\left(\\mathbf {W} _ {h} \\mathbf {a} _ {i} ^ {t} + \\mathbf {U} _ {h} \\left(\\mathbf {r} _ {i} ^ {t} \\odot \\mathbf {h} _ {i} ^ {t - 1}\\right) + \\mathbf {b} _ {h}\\right), \\tag {10}\n$$\n\n$$\n\\mathbf {h} _ {i} ^ {t} = \\tilde {\\mathbf {h}} _ {i} ^ {t} \\odot \\mathbf {z} _ {i} ^ {t} + \\mathbf {h} _ {i} ^ {t - 1} \\odot (1 - \\mathbf {z} _ {i} ^ {t}), \\tag {11}\n$$\n\nwhere,  $\\mathbf{W}_z,\\mathbf{W}_r,\\mathbf{W}_h,\\mathbf{b}_z,\\mathbf{b}_r,\\mathbf{b}_h$  are weights and biases of the updating function Gated Recurrent Unit (GRU) [12].  $\\mathbf{z}_i^t$  and  $\\mathbf{r}_i^t$  are update gate vector and reset gate vector, respectively.\n\n(2) State update via Residual Connections. Previous works [2, 25, 26] have proved that it's effective to combine the low-order and high-order interactions together. We thus introduce extra residual connections to update note states along with GRU, which can facilitate low-order feature reuse and gradients back-propagation. Therefore, the Eq. (7) can be rewritten as,\n\n$$\n\\mathbf {h} _ {i} ^ {t} = G R U \\left(\\mathbf {h} _ {i} ^ {t - 1}, \\mathbf {a} _ {i} ^ {t}\\right) + \\mathbf {h} _ {i} ^ {1}. \\tag {12}\n$$\n\n# 3.7 Attentional Scoring Layer\n\nAfter  $T$  propagation steps, we can obtain the node states\n\n$$\n\\mathbf {H} ^ {T} = \\left[ \\begin{array}{c} \\mathbf {h} _ {1} ^ {T}, \\mathbf {h} _ {2} ^ {T}, \\dots , \\mathbf {h} _ {m} ^ {T} \\end{array} \\right].\n$$\n\nSince the nodes have interacted with their  $T$ -order neighbors, the  $T$ -order feature interactions is modeled. We need a graph-level output to predict CTR.\n\nAttentional Node Weights The final state of each field node has captured the global information. In other words, these field nodes are neighborhood-aware. Here we predict a score on the final state of each field respectively and sum them up with an attention mechanism which measures their influences on the overall prediction. Formally, the prediction score of each node  $n_i$  and its attentional node weight can be estimated via two multiple layers perceptions respectively as,\n\n$$\n\\hat {y} _ {i} = M L P _ {1} \\left(\\mathbf {h} _ {i} ^ {P}\\right)), \\tag {13}\n$$\n\n$$\na _ {i} = M L P _ {2} \\left(\\mathbf {h} _ {i} ^ {P}\\right)). \\tag {14}\n$$\n\nThe overall prediction is a summation of all nodes:\n\n$$\n\\hat {y} = \\sum_ {i = 1} ^ {m} a _ {i} \\hat {y} _ {i}. \\tag {15}\n$$\n\nNote that it is actually same as the work [12]. Intuitively,  $MLP_{1}$  is used to model the prediction score of each field aware of the global information and  $MLP_{2}$  is used to model the weights of each field (i.e., importance of fields' influence on the overall prediction).\n\n# 3.8 Training\n\nOur loss function is Log loss, which is defined as follows:\n\n$$\n\\mathcal {L} = - \\frac {1}{N} \\sum_ {i = 1} ^ {N} \\left(y _ {i} \\log \\left(\\hat {y} _ {i}\\right) + \\left(1 - y _ {i}\\right) \\log \\left(1 - \\hat {y} _ {i}\\right)\\right), \\tag {16}\n$$\n\nwhere  $N$  is the total number of training samples and  $i$  indexes the training samples. The parameters are updated via minimizing the Log Loss using RMSProp [28]. Most CTR datasets have unbalanced proportion of positive and negative samples, which will mislead the predictions. To balance the proportion, we randomly select equal number of positive and negative samples in each batch during training process.\n\n3.8.1 Parameter Space. The parameter needed to be learnt mainly consists of the parameters correlated to nodes and the perception networks in attention mechanism. For each node  $n_i$ , we have an input matrix  $\\mathbf{W}_{in}^i$  and an output matrix  $\\mathbf{W}_{out}^i$  to transform state information. Totally we have  $2m$  matrices, which are proportional to the number of nodes  $m$ . Besides, the multi-head self-attention layer contains the following weight matrices  $\\left\\{\\mathbf{W}_i^{(Q)}, \\mathbf{W}_i^{(K)}, \\mathbf{W}_i^{(V)}\\right\\}$  for each head, and the number of parameters of the entire layer is  $(3dd' + hdd')$ . In addition, we have two matrices of perception networks in the self-attention mechanism and also parameters in GRU. Overall, there are  $O(2m + hdd')$  matrices.\n\n# 3.9 Model Analysis\n\n3.9.1 Comparison with Previous CTR Models. As discussed before, the previous deep learning based CTR models model high-order interactions in a general paradigm: raw sparse input multi-filed features are first mapped into dense field embedding vectors,\n\nthen simply concatenated together and feed into deep neural networks (DNN) or other specifically designed networks to learn high-order feature interactions. The simple unstructured combination of feature fields inevitably limits the capability to model sophisticated interactions among different fields in a sufficiently flexible and explicit fashion. In this way, the interaction between different fields is conducted in a fixed fashion, no matter how sophisticated the used network is. In addition, they lack good model explanation.\n\nSince we represent the multi-field features in a graph structure, our proposed model Fi-GNN is able to model interactions among different fields in the form of node interactions. Compared with the previous CTR models, Fi-GNN can model the sophisticated feature interaction via flexible edge-wise interaction function, which is more effective and explicit. Moreover, the edge weights reflecting importance of different interactions can be learnt in Fi-GNN, which provides good model explanations for CTR prediction. In fact, if the edge weight is all 1 and the transformation matrix on each edge is same, our model Fi-GNN collapses into FM. Taking advantage of the great power of GNN, we can apply flexible interactions on different feature fields.\n\n3.9.2 Comparison with Previous GNN Models. Our proposed model Fi-GNN is designed based on GGNN, upon which we mainly make two improvements: (1) we achieve edge-wise interaction via attentional edge weights and edge-wise transformation; (2) we introduce an extra residual connection along with GRU to update states, which can help regain the low-order information.\n\nAs discussed before, the node interaction on each edge in GNN depends on the edge weight and the transformation function on the edge. The conventional GGNN uses binary edge weights which fails to reflect the importance of the relations, and a fixed transformation function on all the edges. In contrast, our proposed Fi-GNN can model edge-wise interactions via attention edge weights and edge-wise transformation functions. When the interaction order is high, the node states tend to be smooth, i.e., the states of all the nodes tend to be similar. The residual connections can help identity the nodes by adding initial node states.\n\nTable 1: Statistics of evaluation datasets.  \n\n<table><tr><td>Dataset</td><td>#Instances</td><td>#Fields</td><td>#Features (sparse)</td></tr><tr><td>Criteo</td><td>45,840,617</td><td>39</td><td>998,960</td></tr><tr><td>Avazu</td><td>40,428,967</td><td>23</td><td>1,544,488</td></tr></table>",
  "experiments": "# 4 EXPERIMENTS\n\nIn this section, we conduct extensive experiments to answer the following questions:\n\nRQ1 How does our proposed Fi-GNN perform in modeling high-order feature interactions compared with the state-of-the-art models?  \nRQ2 Does our proposed Fi-GNN perform better than original GGNN in modeling high-order feature interactions?  \nRQ3 What are the influences of different model configurations?  \nRQ4 What are the relations between features of different fields? Is our proposed model explainable?\n\nWe first present some fundamental experimental settings before answering these questions.\n\n# 4.1 Experiment Setup\n\n4.1.1 Datasets. We evaluate our proposed models on the following two datasets, whose statistics are summarized in Table 1.\n\n1. Criteo<sup>1</sup>. This is a famous industry benchmark dataset for CTR prediction, which has 45 million users' click records in 39 anonymous feature fields on displayed ads. Given a user and the page he is visiting, the goal is to predict the probability that he will click on a given ad.  \n2. Avazu². This dataset contains users' click behaviors on displayed mobile ads. There are 23 feature fields including user/device features and ad attributes. The fields are partial anonymous.\n\nFor the two datasets, we remove the infrequent features appearing in less than 10, 5 times respectively and treat them as a single feature “<unknown>”. Since the numerical features may have large variance, we normalize numerical values by transforming a value  $z$  to  $\\log^2(z)$  if  $z > 2$ , which is proposed by the winner of Criteo Competition<sup>3</sup>. The instances are randomly split in 8:1:1 for training, validation and testing.\n\n4.1.2 Evaluation Metrics. We use the following two metrics for model evaluation: AUC (Area Under the ROC curve) and Logloss (cross entropy).\n\nAUC measures the probability that a positive instance will be ranked higher than a randomly chosen negative one. A higher AUC indicates a better performance.\n\nLogloss measures the distance between the predicted score and the true label for each instance. A lower Logloss indicates a better performance.\n\nRelative Improvement (RI). It should be noted that a small improvement with respect to AUC is regarded significant for real-world CTR tasks [2, 6, 15, 31]. In order to estimate the relative improvement of our model achieves over the compared models, we here measure RI-AUC and RI-Logloss, which can be formulated as,\n\n$$\nR I - X = \\frac {\\left| X (\\text {model}) - X (\\text {base}) \\right|}{X (\\text {base})} * 100 \\% , \\tag{17}\n$$\n\nwhere  $|x|$  returns the absolute value of  $x$ ,  $X$  can be either AUC or Logloss, model refers to our proposed model and base refers to the compared model.\n\n4.1.3 Baselines. As described in Section 2.1, the early approaches can be categorized into three types: (A) Logistic Regression (LR) which models first-order interaction; (B) Factorization Machine (FM) based linear models which model second-order interactions; (C) Deep learning based models which model high-order interactions on the concatenated field embedding vectors.\n\nWe select the following representative methods of three types to compare with ours.\n\nLR (A) models first-order interaction on the linear combination of raw individual features.\n\nFM [23] (B) models second-order feature interactions from vector inner products.\n\n<sup>1</sup>https://www.kaggle.com/c/criteo-display-ad-challenge  \n$^{2}$ https://www.kaggle.com/c/avazu-ctr-prediction  \n<sup>3</sup>https://www.csie.ntu.edu.tw/~r01922136/kaggle-2014-criteo.pdf\n\nTable 2: Performance Comparison of Different methods. The best performance on each dataset and metric are highlighted. Further analysis is provided in Section 4.2.  \n\n<table><tr><td rowspan=\"2\">Model Type</td><td rowspan=\"2\">Model</td><td colspan=\"4\">Criteo</td><td colspan=\"4\">Avazu</td></tr><tr><td>AUC</td><td>RI-AUC</td><td>Logloss</td><td>RI-Logloss</td><td>AUC</td><td>RI-AUC</td><td>Logloss</td><td>RI-Logloss</td></tr><tr><td>First-order</td><td>LR</td><td>0.7820</td><td>3.00%</td><td>0.4695</td><td>5.43%</td><td>0.7560</td><td>2.60%</td><td>0.3964</td><td>3.63%</td></tr><tr><td rowspan=\"2\">Second-order</td><td>FM [23]</td><td>0.7836</td><td>2.80%</td><td>0.4700</td><td>5.55%</td><td>0.7706</td><td>0.72%</td><td>0.3856</td><td>0.76%</td></tr><tr><td>AFM[34]</td><td>0.7938</td><td>1.54%</td><td>0.4584</td><td>2.94%</td><td>0.7718</td><td>0.57%</td><td>0.3854</td><td>0.81%</td></tr><tr><td rowspan=\"5\">High-order</td><td>DeepCrossing [25]</td><td>0.8009</td><td>0.66%</td><td>0.4513</td><td>1.35%</td><td>0.7643</td><td>1.53%</td><td>0.3889</td><td>1.67%</td></tr><tr><td>NFM [8]</td><td>0.7957</td><td>1.57%</td><td>0.4562</td><td>2.45%</td><td>0.7708</td><td>0.70%</td><td>0.3864</td><td>1.02%</td></tr><tr><td>CrossNet [31]</td><td>0.7907</td><td>1.92%</td><td>0.4591</td><td>3.10%</td><td>0.7667</td><td>1.22%</td><td>0.3868</td><td>1.12%</td></tr><tr><td>CIN [15]</td><td>0.8009</td><td>0.63%</td><td>0.4517</td><td>1.44%</td><td>0.7758</td><td>0.05%</td><td>0.3829</td><td>0.10%</td></tr><tr><td>Fi-GNN (ours)</td><td>0.8062</td><td>0.00%</td><td>0.4453</td><td>0.00%</td><td>0.7762</td><td>0.00%</td><td>0.3825</td><td>0.00%</td></tr></table>\n\nAFM [34] (B) is a extent of FM, which considers the weight of different second-order feature interactions by using attention mechanism. It is one of the state-of-the-art models that model second-order feature interactions.\n\nDeepCrossing [25] (C) utilizes DNN with residual connections to learn high-order feature interactions in an implicit fashion.\n\nNFM [8] (C) utilizes a Bi-Interaction Pooling layer to model the second-order interactions, and then feeds the concatenated second-order combinatorial features into DNNs to model high-order interactions.\n\nCrossNet (Deep&Cross) [31] (C) is the core of Deep&Cross model, which tries to model feature interactions explicitly by taking outer product of concatenated feature vector at the bit-wise level.\n\nCIN (xDeepFM) [15] (C) is the core of xDeepFM model, which takes outer product of stacked feature matrix at vector-wise level.\n\n4.1.4 Implementation Details. We implement our method using Tensorflow $^{4}$ . The optimal hyper-parameters are determined by the grid search strategy. Implementation of baselines follows [26]. Dimension of field embedding vectors is 16 and batch size is 1024 for all methods. DeepCrossing has four feed-forward layers, each with 100 hidden units. NFM has one hidden layer of size 200 on top of Bi-Interaction layer as recommended in the paper [8]. There are three interaction layers for both CrossNet and CIN. All the experiments were conducted over a sever equipped with 8 NVIDIA Titan X GPUs.\n\n# 4.2 Model Comparison (RQ1)\n\nThe performance of different methods is summarized in Table 2, from which we can obtain the following observations:\n\n(1) LR achieves the worst performance among these baselines, which proves that the individual features is insufficient in CTR prediction.  \n(2) FM and AFM, which model second-order feature interactions, outperform LR on all datasets, indicating that it's effective to model pair-wise interaction between feature fields. In addition, AFM achieves better performance than FM, which proves the effectiveness of attention on different interactions.  \n(3) The methods modeling high-order interaction mostly outperform the methods that model second-order interactions.\n\nThis indicates the second-order feature interactions is not sufficient.\n\n(4) DeepCrossing outperforms NFM, proving the effectiveness of residual connections in CTR prediction.  \n(5) Our proposed Fi-GNN achieves best performance among all these methods on two datasets. Considering the fact that previous improvements with respect to AUC at 0.001-level are regarded significant for CTR prediction task, our proposed method shows great superiority over these state-of-the-arts especially on Criteo dataset, owing to the great representative power of graph structure and the effectiveness of GNN on modeling node interactions.  \n(6) Compared with these baselines, the relative improvement of our model achieves on Criteo dataset is higher than that on Avazu dataset. This might be attributed to that there are more feature fields in Criteo dataset, which can take more advantage of the representative power of graph structure.\n\n# 4.3 Ablation Study (RQ2)\n\nOur proposed model Fi-GNN is based on GGNN, upon which we mainly make two improvements: (1) we achieve edge-wise node interactions via attentional edge weights and edge-wise transformation; (2) we introduce extra residual connections to update state along with GRU. To evaluate the effectiveness of the two improvements on modeling node interactions, we conduct ablation study and compare the following three variants of Fi-GNN:\n\nFi-GNN(-E/R): Fi-GNN without the two above mentioned improvements: edge-wise node interactions (E) and residual connections (R).\n\nFi-GNN(-E): Fi-GNN without edge-wise interactions (E).\n\nFi-GNN(-R): Fi-GNN without residual connections (R), which is also GGNN with edge-wise interactions.\n\nThe performance comparison is shown in Figure 3(a), from which we can obtain the following observations:\n\n(1) Compared with FiGNNijNthe performance of Fi-GNN(-E) drops by a large margin, suggesting that it's crucial to model the edge-wise interaction. Fi-GNN(-E) achieves better performance than Fi-GNN(-E/R), proving that the residual connections can indeed provide useful information.  \n(2) The full model Fi-GNN outperforms the three variants, indicating that the two improvements we make, i.e., residual\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/b15ad793-1881-4f14-93d1-04e554cb4f98/6c4b1f567648b57e3cc2c8cb6d4e29604303f64698d8a7c8c2365eb062c2bed6.jpg)  \n(a) edge-wise interaction (E) and residual connections (R)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/b15ad793-1881-4f14-93d1-04e554cb4f98/2c7d73b9d35b6d8f90a3c68361a681b45369d854f60a40b6fe0208d0c556571d.jpg)  \nFigure 3: Two groups of ablation studies on Fi-GNN.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/b15ad793-1881-4f14-93d1-04e554cb4f98/cf34a76e9e1e1a2fb942c4c5caa217456b549bf89a769afd8b6a4d53789da2b1.jpg)  \n(b) attentional edge weight (W) and edge-wise transformation (T)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/b15ad793-1881-4f14-93d1-04e554cb4f98/dee9e511136c981e126e65203032a4b5042b41630730ec883cfa2a9a8644baff.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/b15ad793-1881-4f14-93d1-04e554cb4f98/ac4575d627909cce34ffae5e991e8818a074c441fa131d444042bd028c9a7489.jpg)  \n(a) State Dimensionality  \nFigure 4: AUC performance with different state dimensionality  $D$  (left) and interaction step  $T$  (right) on Criteo and Avazu dataset.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/b15ad793-1881-4f14-93d1-04e554cb4f98/c997db543dd9a59078cf5712e3d7ea009e78e90f335c6fe39c9aa4797e4c6d1a.jpg)  \n(b) Interaction Step\n\nconnections and edge-wise interactions, can jointly boost the performance.\n\nWe take two measures to achieve edge-wise node interactions in Fi-GNN: attentional edge weight  $(\\mathbf{W})$  and edge-wise transformation  $(\\mathbf{T})$ . To further investigate where dose the great improvement comes from, we conduct another ablation study and compare the following three variants of Fi-GNN:\n\nFi-GNN(-W/T): Fi-GNN without self-adaptive adjacency matrix (W) and edge-wise transformation (T), i.e., uses binary adjacency matrix (all the edge weights are 1) and a shared transformation matrix on all the edges. It is also Fi-GNN-(E),\n\nFi-GNN(-W): FI-GNN without attentional edge weights, i.e., uses binary adjacency matrix.\n\nFi-GNN(-T): FI-GNN without edge-wise transformation, i.e., uses a shared transformation on all the edges.\n\nThe performance comparison is shown in Figure 3(a). We can see that Fi-GNN(-T) and Fi-GNN(-W) both outperform Fi-GNN(-W/T), which proves their effectiveness. Nevertheless, Fi-GNN(-W) achieves greater improvements than Fi-GNN(-T), suggesting that the edge-wise transformation is more effective than attentional edge weights in modeling edge-wise interaction. This is quite reasonable since the transformation matrix oughts to have stronger influence on interactions than a scalar attentional edge weight. In addition, Fi-GNN achieves the best performance demonstrates that it's crucial to take both the two measures to model edge-wise interaction.\n\n# 4.4 Hyper-Parameter Study (RQ3)\n\n4.4.1 Influence of different state dimensionality. We first investigate how the performance changes w.r.t. the dimension of the node states  $d'$ , which is also the output size of the initial multi-head self-attention layer. The results on Criteo and Avazu datasets are shown in Figure 4(a). On Avazu dataset, the performance first increases and then begins to decrease when the dimension size reaches 32, which indicates that state size of 32 has been represented enough information and the model is overfitted when too many parameters are used. Nevertheless, on Criteo dataset, the performance peaks with the dimension size of 64, which is reasonable since the dataset is more complexed which needs larger dimension size to carry out enough information.\n\n4.4.2 Influence of different interaction steps. We are interested in what the optimal highest order of feature interactions is. Our proposed Fi-GNN can answer the question, since the interaction step  $T$  equals to the highest order of feature interaction. Therefore, we conduct experiments on how the performance changes w.r.t. the highest order of feature interaction, i.e., the interaction step  $T$ . The results on Criteo and Avazu datasets are shown in Figure 4(b). On Avazu datasets, we can see that the performance increases along with the increasing of  $T$  until it reaches 2, after that the performance starts to decrease. By contrast, the performance peaks when  $T = 3$  on Criteo dataset. This finding suggests 2-order and 3-order interactions are enough for Avazu and Criteo dataset, respectively. It is reasonable since the Avazu and Criteo datasets have 23 and 39 feature fields, respectively. Thus the Criteo dataset needs more interaction steps for the field nodes to fully interact with other nodes in the feature graphs.\n\n# 4.5 Model Explanation (RQ4)\n\nIn this section, we will answer the question that can Fi-GNN provide explanations. We apply attention mechanisms on the edges and nodes in the feature graphs and obtain attentional edge weights and attentional node weights respectively, which can provide explanations from different aspects.\n\n4.5.1 Attentional Edge weights. The attentional edge weight reflects the importance of interaction between the two connected field nodes, which can also reflect the relation of the two feature fields. Higher the weight is, stronger the relation is. Figure 5 presents the heat map of the globally averaged adjacency matrix\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/b15ad793-1881-4f14-93d1-04e554cb4f98/56540aceb905c0521ced8c6dd49f479d565143ca5ad6919562765cae1e149063.jpg)  \nFigure 5: Heat map of attentional edge weights at the global-level on Avazu, which reflects the importance of relations between different feature fields.\n\nof all the samples in Avazu dataset, which can reflect the relations between different fields in a global level. Since they are some anonymous feature fields, we only show the remaining 13 feature fields with real meanings.\n\nAs can be seen, some feature fields tend to have a strong relations with others, such as site_category and site_id. This makes sense since the two feature field both corresponds to the website where the impressions are put on. They contain the main contextual information of impressions. Hour is another feature which have close relations with others. It is reasonable since Avazu focuses on mobile scene, where user surfing online at any time of a day. The surfing time has strong influence on other advertising features. On the other hand, device_ip and device_id seem to have weak relations with other feature fields. This may due to that they nearly equal to user identity, which is relatively fixed and hard to be influenced by other features.\n\n4.5.2 Attentional Node weights. The attentional node weights reflect the importances of feature fields' influence on the overall prediction score. Figure 6 presents the heat map of global-level and case-level attentional node weights. The leftmost is an globally averaged one of all the samples in Avazu dataset. The left four are randomly selected, whose predicted scores are [0.97, 0.12, 0.91, 0.99], and labels are [1, 0, 1, 1] respectively. At the global level, we can see that the feature field app_category have the strongest influence on the clicking behaviors. It is reasonable since Avazu focuses on mobile scene, where the app is the most important factor. At the case level, we observe that the final clicking behavior mainly depends on one critical feature field in most cases.",
  "hyperparameter": "Embedding dimension d=16; Batch size=1024; State dimensionality d'=32 (Avazu), d'=64 (Criteo); Interaction steps T=2 (Avazu), T=3 (Criteo); Multi-head self-attention with h heads where d'=Σd_i; DeepCrossing baseline uses 4 feed-forward layers with 100 hidden units each; NFM baseline uses 1 hidden layer of size 200; CrossNet and CIN baselines use 3 interaction layers; Optimizer: RMSProp; Loss function: Log loss (cross entropy); Training uses balanced sampling with equal positive/negative samples per batch."
}