{
  "id": "FwFM_2018",
  "paper_title": "Field-weighted Factorization Machines for Click-Through Rate Prediction",
  "alias": "FwFM",
  "year": 2018,
  "domain": "Recsys",
  "task": "ContextAwareRecommendation",
  "idea": "Field-weighted Factorization Machines (FwFMs) explicitly model different interaction strengths between field pairs by introducing field-pair-specific weights r_{F(i),F(j)} to the feature interaction terms. This approach achieves comparable performance to FFMs while using significantly fewer parameters (O(mK + n²) vs O(mnK)), making it more memory-efficient and less prone to overfitting. The model also proposes enhanced linear terms using embedding vectors with either feature-wise or field-wise linear weight vectors instead of scalar weights.",
  "introduction": "# 1 INTRODUCTION\n\nOnline display advertising is a multi-billion dollar business nowadays, with an annual revenue of 31.7 billion US dollars in fiscal year\n\nThis paper is published under the Creative Commons Attribution 4.0 International (CC BY 4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.\n\nWWW 2018, April 23-27, 2018, Lyon, France\n\n© 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License.\n\nACM ISBN 978-1-4503-5639-8/18/04.\n\nhttps://doi.org/10.1145/3178876.3186040\n\n<table><tr><td>CLICK</td><td>User_ID</td><td>GENDER</td><td>ADVERTISER</td><td>PUBLISHER</td></tr><tr><td>1</td><td>29127394</td><td>Male</td><td>Nike</td><td>news.yahoo.com</td></tr><tr><td>-1</td><td>89283132</td><td>Female</td><td>Walmart</td><td>techcrunch.com</td></tr><tr><td>-1</td><td>91213212</td><td>Male</td><td>Gucci</td><td>nba.com</td></tr><tr><td>-1</td><td>71620391</td><td>Female</td><td>Uber</td><td>tripadviser.com</td></tr><tr><td>1</td><td>39102740</td><td>Male</td><td>Adidas</td><td>mlb.com</td></tr></table>\n\nTable 1: An example of multi-field categorical data for CTR prediction. Each row is an ad impression. Column Click is the label indicating whether there is a click associated with this impression. Each of the rest columns is a field. Features are all categorical, e.g., Male, Female, Nike, Walmart, and each of them belongs to one and only one field, e.g., Male belongs to field GENDER, and Nike belongs to field ADVERTISER.\n\n2016, up  $29\\%$  from fiscal year 2015 [2]. One of the core problems display advertising strives to solve is to deliver the right ads to the right people, in the right context, at the right time. Accurately predicting the click-through rate (CTR) is crucial to solve this problem and it has attracted much research attention in the past few years [4, 16, 21].\n\nThe data involved in CTR prediction are typically multi-field categorical data [26] which are also quite ubiquitous in many applications besides display advertising, such as recommender systems [18]. Such data possess the following properties. First, all the features are categorical and are very sparse since many of them are identifiers. Therefore, the total number of features can easily reach millions or tens of millions. Second, every feature belongs to one and only one field and there can be tens to hundreds of fields. Table 1 is an example of a real-world multi-field categorical data set used for CTR prediction.\n\nThe properties of multi-field categorical data pose several unique challenges to building effective machine learning models for CTR prediction:\n\n(1) Feature interactions are prevalent and need to be specifically modeled [3, 4]. Feature conjunctions usually associate with the labels differently from individual features do. For example, the CTR of Nike's ads shown on nba.com is usually much higher than the average CTR of Nike's ads or the average CTR of ads shown on nba.com. This phenomenon is usually referred to as feature interaction in the literature [12]. To avoid confusion and simplify discussion, in\n\nthe rest of the paper, we unify and abuse the terminology feature interaction strength to represent the level of association between feature conjunctions and labels.\n\n(2) Features from one field often interact differently with features from different other fields. For instance, we have observed that features from field GENDER usually have strong interactions with features from field ADVERTISER while their interactions with features from field DEVICE_TYPE are relatively weak. This might be attributed to the fact that users with a specific gender are more biased towards the ads they are viewing than towards the type of device they are using.  \n(3) Potentially high model complexity needs to be taken care of [12]. The model parameters such as weights and embedding vectors need to be stored in memory in real-world production systems to enable real-time ad serving. As there are typically millions of features in practice, the model complexity needs to be carefully designed and tuned to fit the model into memory.\n\nTo resolve part of these challenges, researchers have built several solutions. Factorization Machines (FMs) [18, 19] and Field-aware Factorization Machines (FFMs) [12, 13] are among the most successful ones. FMs tackle the first challenge by modeling the effect of pairwise feature interactions as the dot product of two embedding vectors. However, the field information is not leveraged in FMs at all. Recently, FFMs have been among the best performing models for CTR prediction and won two competitions hosted by Criteo and Avazu [13]. FFMs learn different embedding vectors for each feature when the feature interacts with features from different other fields. In this way, the second challenge is explicitly tackled. However, the number of parameters in FFMs is in the order of feature number times field number, which can easily reach tens of millions or even more. This is unacceptable in real-world production systems. In this paper, we introduce Field-weighted Factorization Machines (FwFMs) to resolve all these challenges simultaneously. The main contributions of this paper can be summarized as follows:\n\n(1) Empirically we show that the average interaction strength of feature pairs from one field pair tends to be quite different from that of other field pairs. In other words, different field pairs have significantly different levels of association with the labels (i.e. clicks in CTR prediction). Following the same convention, we call this field pair interactions.  \n(2) Based on the above observation, we propose Field-weighted Factorization Machines (FwFMs). By introducing and learning a field pair weight matrix, FwFMs can effectively capture the heterogeneity of field pair interactions. Moreover, parameters in FwFMs are magnitudes fewer than those in FFMs, which makes FwFMs a preferable choice in real-world production systems.  \n(3) FwFMs are further augmented by replacing the binary representations of the linear terms with embedding vector representations. This novel treatment can effectively help avoid over-fittings and enhance prediction performance.  \n(4) We conduct comprehensive experiments on two real-world CTR prediction data sets to evaluate the performance of FwFMs against existing models. The results show that FwFMs\n\ncan achieve competitive prediction performance with only as few as  $4\\%$  parameters of FFMs. When using the same number of parameters, FwFMs outperform FFMs by up to  $0.9\\%$  AUC lift.\n\nThe rest of the paper is organized as follows. Section 2 provides the preliminaries of existing CTR prediction models that handle multi-field categorical data. In Section 3, we show that the interaction strengths of different field pairs are quite different, followed by detailed discussion of the proposed model in Section 4. Our experimental evaluation results are presented in Section 5. In Section 6, we show that FwFMs learn the field pair interaction strengths even better than FFMs. Section 7 and Section 8 discuss the related work and concludes the paper respectively.",
  "method": "# 4 FIELD-WEIGHTED FACTORIZATION MACHINES (FWFMS)\n\nWe propose to explicitly model the different interaction strengths of different field pairs. More specifically, the interaction of a feature pair  $i$  and  $j$  in our proposed approach is modeled as\n\n$$\nx _ {i} x _ {j} \\langle \\pmb {v} _ {i}, \\pmb {v} _ {j} \\rangle r _ {F (i), F (j)}\n$$\n\nwhere  $\\pmb{v}_i, \\pmb{v}_j$  are the embedding vectors of  $i$  and  $j$ ,  $F(i), F(j)$  are the fields of feature  $i$  and  $j$ , respectively, and  $r_{F(i), F(j)} \\in \\mathbb{R}$  is a weight to model the interaction strength between field  $F(i)$  and  $F(j)$ . We refer to the resulting model as the Field-weighted Factorization Machines (FwFMs):\n\n$$\n\\Phi_ {F w F M s} ((\\boldsymbol {w}, \\boldsymbol {v}), \\boldsymbol {x}) = w _ {0} + \\sum_ {i = 1} ^ {m} x _ {i} w _ {i} + \\sum_ {i = 1} ^ {m} \\sum_ {j = i + 1} ^ {m} x _ {i} x _ {j} \\left\\langle \\boldsymbol {v} _ {i}, \\boldsymbol {v} _ {j} \\right\\rangle r _ {F (i), F (j)} \\tag {7}\n$$\n\nFwFMs are extensions of FMs in the sense that we use additional weight  $r_{F(i),F(j)}$  to explicitly capture different interaction strengths of different field pairs. FFMs can model this implicitly since they learn several embedding vectors for each feature  $i$ , each one  $\\pmb{v}_{i,F_k}$  corresponds to one of other fields  $F_{k} \\neq F(i)$ , to model its different interaction with features from different fields. However, the model complexity of FFMs is significantly higher than that of FMs and FwFMs.\n\n# 4.1 Model Complexity\n\nThe number of parameters in FMs is  $m + mK$ , where  $m$  accounts for the weights for each feature in the linear part  $\\{w_i | i = 1, \\dots, m\\}$  and  $mK$  accounts for the embedding vectors for all the features\n\n<table><tr><td>Model</td><td>Number of Parameters</td></tr><tr><td>LR</td><td>m</td></tr><tr><td>Poly2</td><td>m + H</td></tr><tr><td>FMs</td><td>m + mK</td></tr><tr><td>FFMs</td><td>m + m(n - 1)K</td></tr><tr><td>FwFMs</td><td>m + mK + n(n-1)/2</td></tr></table>\n\n$\\{\\pmb{v}_i|i = 1,\\dots,m\\}$ . FwFMs use  $n(n - 1) / 2$  additional parameters  $\\{r_{F_k,F_l}|k,l = 1,\\dots,n\\}$  for each field pair so that the total number of parameters of FwFMs is  $m + mK + n(n - 1) / 2$ . For FFMs, the number of parameters is  $m + m(n - 1)K$  since each feature has  $n - 1$  embedding vectors. Given that usually  $n\\ll m$ , the parameter number of FwFMs is comparable with that of FMs and significantly less than that of FFMs. In Table 2 we compare the model complexity of all models mentioned so far.\n\n# 4.2 Linear Terms\n\nIn the linear terms  $\\sum_{i=1}^{m} x_i w_i$  of equation (7), we learn a weight  $w_i$  for each feature to model its effect with the label, using binary variable  $x_i$  to represent feature  $i$ . However, the embedding vectors  $\\pmb{v}_i$  learned in the interaction terms should capture more information about feature  $i$ , therefore we propose to use  $x_i \\pmb{v}_i$  to represent each feature in the linear terms as well.\n\nWe can learn one linear weight vector  $\\boldsymbol{w}_i$  for each feature and the linear terms become:\n\n$$\n\\sum_ {i = 1} ^ {m} x _ {i} \\left\\langle \\boldsymbol {v} _ {i}, \\boldsymbol {w} _ {i} \\right\\rangle \\tag {8}\n$$\n\nThere are  $mK$  parameters in the feature-wise linear weight vectors, and the total number of parameters is  $2mK + \\frac{n(n - 1)}{2}$ . Alternatively, we can learn one linear weight vector  $w_{F(i)}$  for each field and all features from the same field  $F(i)$  use the same linear weight vector. Then the linear terms can be formulated as:\n\n$$\n\\sum_ {i = 1} ^ {m} x _ {i} \\left\\langle \\boldsymbol {v} _ {i}, \\boldsymbol {w} _ {F (i)} \\right\\rangle \\tag {9}\n$$\n\nThe parameter number of these kind of FwFMs is  $nK + mK + \\frac{n(n - 1)}{2}$ , which is almost the same as FwFMs with original linear weights since both  $K$  and  $n$  are usually in the order of tens.\n\nIn the rest of the paper, we denote FwFMs with original linear weights as FwFMs_LW, denote FwFMs with feature-wise linear weight vectors as FwFMs_FeLV, denote FwFMs with field-wise linear weight vectors as FwFMs_FiLV.",
  "experiments": "# 5 EXPERIMENTS\n\nIn this section we present our experimental evaluations results. We will first describe the data sets and implementation details in Section 5.1 and 5.2 respectively. In Section 5.3.1 we compare\n\nTable 2: A summary of model complexities (ignoring the bias term  $w_0$ ).  $m$  and  $n$  are feature number and field number respectively,  $K$  is the embedding vector dimension, and  $H$  is the hashing space size when hashing tricks are used for Poly2 models.  \n\n<table><tr><td colspan=\"2\">Data set</td><td>Samples</td><td>Fields</td><td>Features</td></tr><tr><td rowspan=\"3\">Criteo</td><td>Train</td><td>27,502,713</td><td>26</td><td>399,784</td></tr><tr><td>Validation</td><td>9,168,820</td><td>26</td><td>399,654</td></tr><tr><td>Test</td><td>9,169,084</td><td>26</td><td>399,688</td></tr><tr><td rowspan=\"3\">Oath</td><td>Train</td><td>24,885,731</td><td>15</td><td>156,401</td></tr><tr><td>Validation</td><td>7,990,874</td><td>15</td><td>101,217</td></tr><tr><td>Test</td><td>8,635,361</td><td>15</td><td>100,515</td></tr></table>\n\nTable 3: Statistics of training, validation and test sets of Criteo and Oath data sets respectively.\n\nFwFMs_LW, i.e., FwFMs using original linear weights, with LR, Poly2, FMs and FFMs. Then we further investigate the performance of FwFMs_LW and FFMs when they use the same number of parameters in Section 5.3.2. The enhancement brought by our novel linear term treatment is discussed in Section 5.3.3. Finally we show model hyper-parameter tuning details in Section 5.4.\n\n# 5.1 Data sets\n\nWe use the following two data sets in our experiments.\n\n(1) Criteo CTR data set: This is the data set used for the Criteo Display Advertising Challenge [15]. We split the data into training, validation and test sets randomly by  $60\\% :20\\% :20\\%$ .  \n(2) Oath CTR data set: We use two-week display advertising click log from our ad serving system as the training set and the log of next day and the day after next day as validation and test set respectively.\n\nThe Criteo data set is already label balanced. For the Oath CTR data set, the ratio of positive samples (clicks) is the overall CTR, which is typically smaller than  $1\\%$ . We downsample the negative examples so that the positive and negative samples are more balanced. The downsampling is not done for validation and test sets, since the evaluation should be applied to data sets reflecting the actual traffic distribution.\n\nThere are 26 anonymous categorical fields in Criteo data set. The Oath data set consists of 15 fields, which can be categorized into 4 groups: user side fields such as GENDER, AGE_BUCKET, USER_ID, publisher side fields such as PAGE_TLD, PUBLISHER_ID, SUBDOMAIN, advertiser side fields such as ADVERTISER_ID, AD_ID, CREATIVE_ID, LAYOUT_ID, LINE_ID and context side fields such as HOUR_OF_DAY, DAY_OF_WEEK, AD_POSITION_ID and DEVICE_TYPE_ID. The meanings of most fields are quite straightforward and we only explain some of them: PAGE_TLD denotes the top level domain of a web page and SUBDOMAIN denotes the sub domain of a web page. CREATIVE_ID denotes the identifier of a creative, while AD_ID identifies an ad that encapsulates a creative; the same creative may be assigned to different ads. DEVICE_TYPE_ID denotes whether this events happens on desktop, mobile or tablet. LAYOUT_ID denotes a specific ads size and AD_POSITION_ID denotes the position for ads in web page.\n\nFurthermore, for both data sets we filter out all features which appear less than  $\\tau$  times in the training set and replace them by a NULL feature, where  $\\tau$  is set to 20 for Criteo data set and 10 for Oath data set. The statistics of the two data sets are shown in Table 3.\n\n# 5.2 Implementations\n\nWe use LibLinear [7] to train Poly2 with hashing tricks [25] to hash feature conjunctions to a hashing space of  $10^{7}$ . All the other models are implemented in Tensorflow. We follow the implementation of LR and FMs in [17], and implement FFMs by ourselves. The architecture of FwFMs in Tensorflow is shown in Figure 2.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/309a9a1c-fb85-40e8-ae9a-ec83670e81ff/d1d65c1d3e40438b3a3217396a0d657acaa1548dd8797ad4b77a11c770b42714.jpg)  \nFigure 2: Implementation for FwFMs in Tensorflow.\n\nThe input is a sparse binary vector  $\\boldsymbol{x}_i \\in \\mathbb{R}^m$  with only  $n$  non-zero entries since there are  $n$  fields and each field has one and only one active feature for each sample. In the embedding layer, the input vector  $\\boldsymbol{x}_i$  is projected into  $n$  embedding vectors. In the next layer the linear terms and interaction terms are computed from these  $n$  latent vectors. The linear terms layer simply concatenates the latent vectors of all active features. The interaction terms layer calculates the dot product  $\\langle \\boldsymbol{v}_i, \\boldsymbol{v}_j \\rangle$  between embedding vectors of all pairs of active features. Then every node in the linear terms layer and interaction terms layer will be connected to the final output node, which will sum up the inputs from both linear terms layer and interaction terms layer with weights. Note that in FwFMs_FeLV, the weights between the linear terms layer and the final output is  $w_i$  while for FwFMs_FeLV and FwFM_FiLV the weights are  $w_i$  and  $w_{F(i)}$  respectively. The weights between the interaction terms layer and the output node are  $r_{F(i),F(j)}$ .\n\n# 5.3 Performance Comparisons\n\n5.3.1 Comparison of FwFMs with Existing Models. In this section we will conduct performance evaluation for FwFMs with original linear terms, i.e., FwFMs_LW. We will compare it with LR, Poly2, FMs and FFMs on two data sets mentioned above. For the parameters such as regularization coefficient  $\\lambda$ , and learning rate  $\\eta$  in all models, we select those which leads to the best performance on the validation set and then use them in the evaluation on test set. Experiment results can be found in Table 4.\n\nWe observe that FwFMs can achieve better performance than LR, Poly2 and FMs on both data sets. The improvement comes from the fact that FwFMs explicitly model the different interaction strengths of field pairs, which would be discussed in Section 6 in more details. FFMs can always get the best performance on training and validation sets. However, FwFMs' performance on the both test sets are quite competitive with that of FwFMs. It suggests that FFMs are more vulnerable to overfittings than FwFMs.\n\n5.3.2 Comparison of FwFMs and FFMs using the same number of parameters. One critical drawback of using FFMs is that their number of parameters is in the order of  $O(mnK)$ , which would be too large to fit in memory. There are two solutions to reduce the number of parameters in FFMs [12]: use a smaller  $K$  or use hashing tricks with a small hashing space  $H$ . Juan et. al. [12] proposed to use  $K_{FFMs} = 2$  for FFMs to get a good trade-off between prediction accuracy and the number of parameters. This reduces the number of parameters to  $(n - 1)mK_{FFMs}$ . Juan et. al. [12] also proposed to further reduce the number of parameters of FFMs by using hashing tricks with a small hashing space  $H_{FFMs}$  to reduce it to  $(n - 1)m_{FFMs}K_{FFMs}$ . In this section, we make a fair comparison of FwFMs with FFMs using the same number of parameters by choosing proper  $k_{FFMs}$  and  $H_{FFMs}$  so that the number of parameters of FFMs and FwFMs are the same, i.e.,  $(n - 1)H_{FFMs}K_{FFMs} = mK_{FwFMs}$ , we do not count the parameters from the linear terms since they are negligible compared with the number of interaction terms. We choose  $K_{FwFMs} = 10$  and  $K_{FFMs} = 2$  and  $K_{FFMs} = 4$  as described in [12]. The experimental results are shown in Table 5.\n\nWe observe that when using the same number of parameters, FwFMs get better performance on test sets of both Criteo and Oath data sets, with a lift of  $0.70\\%$  and  $0.45\\%$  respectively. We conclude that FFMs make lots of compromise on the prediction performance when reducing the feature numbers therefore FwFMs can outperform them significantly in such cases.\n\n5.3.3 FwFMs with Different Linear Terms. We conduct experiments to compare FwFMs with three different kinds of linear terms as mentioned in Section 4.2. Table 6 lists the performance comparison between them. We observe that, FwFMs_LW and FwFMs_FeLV can achieve better performance on the training and validation set than FwFMs_FiLV. The reason is that those two models have more number of parameters in the linear weights  $(m$  and  $mK)$  than FwFMs_FiLV  $(nK)$ , so they can fit the training and validation set better than FwFMs_FiLV. However, FwFMs_FiLV get the best results on the test set, which suggests that it has better generalization performance. Furthermore, when we compare FwFMs_FiLV with FFMs using the same number of parameters, the AUC lift on Oath data set and Criteo data set are  $0.92\\%$  and  $0.47\\%$  respectively.\n\n# 5.4 Hyper-parameter Tuning\n\nIn this section we will show the impact of regularization coefficient  $\\lambda$ , embedding vector dimension  $K$  and learning rate  $\\eta$  on FwFMs. All following evaluations are done for FwFMs_FiLV model on Oath validation set.\n\n5.4.1 Regularization. We add  $L_{2}$  regularizations of all parameters in FwFMs to the loss function to prevent over-fitting. Figure 3 shows the AUC on validation set using different  $\\lambda$ . We get the best performance on validation set using  $\\lambda = 1e - 5$ .  \n5.4.2 Learning Rate and Embedding Vector Dimension. We have done experiments to check the impact of learning rate  $\\eta$  to the performance of FwFMs, and the results are shown in Figure 4. It shows that by using a small  $\\eta$ , we can keep improving the performance on validation set slowly in the first 20 epochs, while using a large  $\\eta$  will improve the performance quickly and then lead to over-fitting. In all experiments on Oath data set we choose  $\\eta = 1e - 4$ .\n\n<table><tr><td rowspan=\"2\">Models</td><td rowspan=\"2\">Parameters</td><td colspan=\"3\">AUC</td></tr><tr><td>Training</td><td>Validation</td><td>Test</td></tr><tr><td>LR</td><td>η = 1e-4, λ = 1e-7, t = 15</td><td>0.8595</td><td>0.8503</td><td>0.8503</td></tr><tr><td>Poly2</td><td>s = 7, c = 2</td><td>0.8652</td><td>0.8542</td><td>0.8523</td></tr><tr><td>FMs</td><td>η = 5e-4, λ = 1e-6, k = 10, t = 10</td><td>0.8768</td><td>0.8628</td><td>0.8583</td></tr><tr><td>FFMs</td><td>η = 1e-4, λ = 1e-7, k = 10, t = 3</td><td>0.8833</td><td>0.8660</td><td>0.8624</td></tr><tr><td>FwFMs</td><td>η = 1e-4, λ = 1e-5, k = 10, t = 15</td><td>0.8827</td><td>0.8659</td><td>0.8614</td></tr></table>\n\n(a) Oath data set  \n\n<table><tr><td rowspan=\"2\">Models</td><td rowspan=\"2\">Parameters</td><td colspan=\"3\">AUC</td></tr><tr><td>Training</td><td>Validation</td><td>Test</td></tr><tr><td>LR</td><td>η = 5e-5, λ = 1e-6, t = 14</td><td>0.7716</td><td>0.7657</td><td>0.7654</td></tr><tr><td>Poly2</td><td>s = 7, c = 2</td><td>0.7847</td><td>0.7718</td><td>0.7710</td></tr><tr><td>FMs</td><td>η = 1e-4, λ = 1e-6, k = 10, t = 10</td><td>0.7925</td><td>0.7759</td><td>0.7761</td></tr><tr><td>FFMs</td><td>η = 5e-4, λ = 1e-7, k = 10, t = 3</td><td>0.7989</td><td>0.7781</td><td>0.7768</td></tr><tr><td>FwFMs</td><td>η = 1e-4, λ = 1e-6, k = 10, t = 8</td><td>0.7941</td><td>0.7772</td><td>0.7764</td></tr></table>\n\n(b) Criteo data set  \nTable 4: Comparison among models on Criteo and Oath CTR data sets.  \n\n<table><tr><td rowspan=\"2\">Model</td><td colspan=\"3\">Oath data set</td><td colspan=\"3\">Criteo data set</td></tr><tr><td>Training</td><td>Validation</td><td>Test</td><td>Training</td><td>Validation</td><td>Test</td></tr><tr><td>FFMs(K=2,H=10/14·2m)</td><td>0.8743</td><td>0.8589</td><td>0.8543</td><td>0.7817</td><td>0.7716</td><td>0.7719</td></tr><tr><td>FFMs(K=4,H=10/14·4m)</td><td>0.8708</td><td>0.8528</td><td>0.8418</td><td>0.7697</td><td>0.7643</td><td>0.7641</td></tr><tr><td>FwFMs</td><td>0.8827</td><td>0.8659</td><td>0.8614</td><td>0.7941</td><td>0.7772</td><td>0.7764</td></tr></table>\n\nTable 5: Comparison of FFMs with FwFMs using same number of parameters.  $K$  is embedding vector dimension and  $H$  is the hashing space for hashing tricks.  \n\n<table><tr><td rowspan=\"2\">Model</td><td colspan=\"3\">Oath data set</td><td colspan=\"3\">Criteo data set</td></tr><tr><td>Training</td><td>Validation</td><td>Test</td><td>Training</td><td>Validation</td><td>Test</td></tr><tr><td>FwFMs_LW</td><td>0.8827</td><td>0.8659</td><td>0.8614</td><td>0.7941</td><td>0.7772</td><td>0.7764</td></tr><tr><td>FwFMs_FeLV</td><td>0.8829</td><td>0.8665</td><td>0.8623</td><td>0.7945</td><td>0.7774</td><td>0.7763</td></tr><tr><td>FwFMs_FiLV</td><td>0.8799</td><td>0.8643</td><td>0.8635</td><td>0.7917</td><td>0.7766</td><td>0.7766</td></tr></table>\n\nTable 6: Performance of FwFMs with different linear terms.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/309a9a1c-fb85-40e8-ae9a-ec83670e81ff/0e6f97cba327aced7568d4d82c0a4549107470b71da07fe23d8a1eb1798112cf.jpg)  \nFigure 3: Impact of regularization coefficient  $\\lambda$  on FwFMs.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-15/309a9a1c-fb85-40e8-ae9a-ec83670e81ff/4bb4f0ceb01913c89336e44596beaf136c82f65492997b9f47f5597f6c1a3331.jpg)  \nFigure 4: Impact of learning rate  $\\eta$  on FwFMs.\n\n<table><tr><td>k</td><td>Train AUC</td><td>Validation AUC</td><td>Training time (s)</td></tr><tr><td>5</td><td>0.8794</td><td>0.8621</td><td>320</td></tr><tr><td>10</td><td>0.8827</td><td>0.8659</td><td>497</td></tr><tr><td>15</td><td>0.8820</td><td>0.8644</td><td>544</td></tr><tr><td>20</td><td>0.8822</td><td>0.8640</td><td>636</td></tr><tr><td>30</td><td>0.8818</td><td>0.8647</td><td>848</td></tr><tr><td>50</td><td>0.8830</td><td>0.8652</td><td>1113</td></tr><tr><td>100</td><td>0.8830</td><td>0.8646</td><td>1728</td></tr><tr><td>200</td><td>0.8825</td><td>0.8646</td><td>3250</td></tr></table>\n\nTable 7: Comparison of different embedding vector dimensions  $K$\n\nWe conduct experiments to investigate the impact of embedding vector dimension  $K$  on the performance of FwFMs. Table 7 shows that the AUC changes only a little when we use different  $K$ . We choose  $K = 10$  in FwFMs since it gets best trade-off between performance and training time.",
  "hyperparameter": "Learning rate η: 1e-4 (Oath), 1e-4 to 5e-4 (Criteo); L2 regularization λ: 1e-5 (Oath), 1e-6 (Criteo); Embedding dimension K: 10 (optimal trade-off between performance and training time, tested from 5 to 200); Number of epochs t: 15 (Oath), 8 (Criteo); Feature frequency threshold τ: 10 (Oath), 20 (Criteo); Hashing space for Poly2: 10^7; FFMs embedding dimension K_FFMs: 2 or 4 for parameter reduction"
}