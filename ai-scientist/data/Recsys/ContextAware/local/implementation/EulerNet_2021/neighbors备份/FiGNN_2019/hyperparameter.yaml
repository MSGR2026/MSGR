# SIMILAR: Both models use embedding_size for feature embeddings
embedding_size: 10              # (int) The embedding size of features.
attention_size: 16              # (int) The vector size in attention mechanism. 
n_layers: 2                     # (int) The number of layers.
num_heads: 2                    # (int) The number of attention heads.
# DIFFERENT: EulerNet uses drop_ex/drop_im for explicit/implicit interactions; FiGNN uses hidden/attn dropout
hidden_dropout_prob: 0.2        # (float) The dropout rate of hidden layer.
attn_dropout_prob: 0.2          # (float) The dropout rate of multi-head self-attention layer.
