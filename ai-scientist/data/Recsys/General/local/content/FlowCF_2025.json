{
    "id": "FlowCF_2025",
    "paper_title": "Flow Matching for Collaborative Filtering",
    "alias": "FlowCF",
    "year": 2025,
    "domain": "Recsys",
    "task": "GeneralRecommendation",
    "idea": "FlowCF adapts flow matching to collaborative filtering by (1) replacing the usual Gaussian prior with a behavior-guided Bernoulli prior that encodes global item popularity, and (2) introducing a discrete flow framework that keeps user-item matrices strictly binary via a Bernoulli-masked linear interpolation and an expectation-based vector field, enabling straight, two-step inference trajectories without ever leaving the discrete space.",
    "introduction": "# 1 Introduction\n\nCollaborative filtering (CF) [17, 34] - as the foundational component of model-based recommender systems [23, 24] - aims to\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/ba08c681cda67238f2fc4d0eebe3ec57ac00872022ee7185f46199942080526e.jpg)\n\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\n\nKDD '25, August 3-7, 2025, Toronto, ON, Canada\n\n© 2025 Copyright held by the owner/author(s).\n\nACM ISBN 979-8-4007-1454-2/2025/08\n\nhttps://doi.org/10.1145/3711896.3736967\n\nJames Caverlee\n\nTexas A&M University\n\nCollege Station, TX, USA\n\ncaverlee@cse.tamu.edu\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/1bb5f3d7c5724c8585bb66b0b020d47f7ae20fb7df5a212d5db1622272fad102.jpg)\n\n\n\nFigure 1: Illustration of VAE and diffusion-based CF models, the proposed FlowCF, along with a trajectory comparison between diffusion process and flow in FlowCF.\n\n\nrecommend items to users by leveraging the preferences of similar users based on their past interactions with items. One exciting thread is the rise of generative collaborative filtering, ranging from variational autoencoders (VAEs) [15] to more advanced diffusion models [12, 38]. These generative CF approaches model the distribution of user preferences to generate diverse and realistic interaction patterns, thus better handling challenges like noisy data [41] and cold-start scenarios [5], in comparison with non-generative methods that focus on learning user and item representations for prediction [10, 11].\n\nEarly generative CF methods like VAE-based methods [19, 28, 35] pioneered the approximation of user preference distributions, demonstrating the potential of generative modeling for recommendation (Figure 1(a)). However, these approaches often struggle with inaccurate posterior approximations. This inaccuracy can blur the reconstructed user preferences, ultimately hindering recommendation accuracy. Furthermore, their reliance on variational approximation and Kullback-Leibler (KL) divergence often leads to unstable training and slow convergence. DiffRec [42] is the leading example of using diffusion models in CF. Although it solves the aforementioned issues of VAE-based methods during training, the stochastic nature [38] of its underlying Gaussian diffusion processes [12, 36] results in computational inefficiency with multiple sampling steps during inference, as illustrated in Figure 1(b). More fundamentally, the discrete nature of user-item interactions and binary implicit feedback in recommendations poses a challenge. The reliance on a\n\ncontinuous diffusion process applying Gaussian noise to these discrete interactions within a continuous state space risks distorting personalized preferences. This mismatch can compromise diffusion models' ability to accurately capture sparse and heterogeneous patterns inherent in user-item interactions, thereby limiting their effectiveness in learning user preference distributions.\n\nTo address these limitations, we propose leveraging the flow matching framework [22] for generative CF. Flow matching learns continuous normalizing flows [6] by modeling the vector field that transforms a simple prior distribution into a complex target distribution, such as user preferences. Unlike stochastic diffusion processes with curved probability paths, flow matching enables the learning of deterministic, straight flow trajectories. These trajectories offer both stable training and efficient sampling, as fewer steps are needed for straight paths compared to curved paths. Furthermore, the framework's flexibility in designing makes flow matching particularly well-suited for designing advanced generative recommendation models. These models not only achieve superior recommendation performance but also meet the requirement of fast inference speed, which is essential for real-world recommender systems.\n\nDespite the advantages of flow matching, its application to collaborative filtering presents unique challenges. A key component of flow matching is the prior distribution, which defines the initial state of the generative process. While Gaussian priors are widely adopted in many generative tasks [1, 26], they may not be suitable for real-world recommendation data, which often exhibits sparsity and popularity bias. Additionally, the continuous normalizing flows used in flow matching struggle to naturally simulate the discrete transitions inherent in recommendation scenarios.\n\nTo this end, in this work, we introduce FlowCF, a novel flow-based recommendation model that adapts flow matching to the unique characteristics of collaborative filtering through two key innovations: a behavior-guided prior and a discrete flow framework. Firstly, to better capture user behavior patterns, we introduce a behavior-guided prior, which is designed to align closely with real-world interactions. This prior is a probability distribution derived from the global frequencies of interacted items, which inherently reflects underlying user preferences. By incorporating domain-specific knowledge into the learning process, the behavior-guided prior ensures that the flow training process is guided by realistic behavioral data, leading to more effective and meaningful model training. Secondly, we propose a discrete flow framework that explicitly models the binary nature of implicit feedback. While this framework respects the inherent discreteness of the data, it maintains a linear evolution of mathematical expectations between the source and target distributions, as illustrated in Figure 1(d). This design bridges the gap between discrete interactions and continuous state spaces, providing a robust theoretical foundation for our approach. Importantly, FlowCF retains the benefits of flow matching, such as training stability and efficient sampling. The straight flow trajectories of FlowCF (Figure 1(d)) enable faster inference speed with fewer sampling steps compared to the curved trajectories of diffusion-based CF models, ensuring that our discrete flow framework delivers superior recommendation performance with rapid inference capabilities.\n\nIn summary, our key contributions are as follows:\n\n- We propose FlowCF, a novel flow-based recommendation model using flow matching that advances the generative paradigm for collaborative filtering.\n\n- We adapt flow matching to recommendation scenarios via a behavior-guided prior capturing user behavior patterns and a discrete flow framework modeling binary implicit feedback.\n\n- We conduct comprehensive experiments on multiple datasets, demonstrating that FlowCF achieves state-of-the-art performance, with both stable training and fast inference speed, addressing the practical needs of real-world recommender systems.",
    "method": "# 3 Flow-Based Recommender - FlowCF\n\nFlow matching has shown promise in various domains due to its ability to learn complex data distributions with efficient sampling.\n\nHowever, applying flow matching to collaborative filtering presents several distinct challenges. Unlike conventional generative tasks, which assume a simple Gaussian prior, recommendation data is inherently sparse and heterogeneous, requiring a more expressive prior distribution for training. Furthermore, user-item interactions are inherently discrete, making it insufficient to directly apply continuous flow models without adaptation. Finally, practical recommender systems require both efficient training and fast inference. Therefore, we must ensure that our design leverages the benefits of flow matching without sacrificing training and inference efficiency. These challenges motivate our investigation into the following research questions:\n\n- RQ1: How can we design an appropriate prior distribution for flow matching in recommendations?\n\n- RQ2: How can we effectively adapt flow models to handle discrete and binary implicit feedback data?\n\n- RQ3: How can we train and optimize FlowCF and learn to predict the vector field effectively?\n\n- RQ4: What factors contribute to the fast inference speed and swift recommendation response of FlowCF?\n\n# 3.1 Overall Framework\n\nTo harness the generative capabilities and flexibility of flow matching, we propose FlowCF, a flow-based recommender system that models the evolution of user-item interactions from a noisy source distribution to a target preference distribution. FlowCF employs a flow model  $f_{\\theta}$ , implemented as a multi-layer perceptron (MLP), which learns the vector field governing the flow dynamics. Flow matching is utilized to facilitate the accurate approximation of the flow by aligning the learned transformations with the underlying user interaction patterns.\n\nAs illustrated in Figure 2(a), the overall process begins with sampling  $X_0$  from a selected prior distribution  $p$ . A set of interpolations  $X_{t}$  is then defined along the flow trajectory in Equation 4, connecting  $X_0$  to the historical user-item interactions  $\\bar{X}$ , which serve as the sample  $X_{1}$  from the target distribution. As shown in Figure 2(b), the flow model  $f_{\\theta}$  learns the vector field to transform  $X_0$  into  $X_{1}$ , producing an approximation of the true interaction distribution. The objective is to minimize the discrepancy between the predicted vector field  $v$  and the ground truth vector field  $u$  in Equation 7. Once trained, FlowCF can use the flow model to predict vector fields for inference, as depicted in Figure 2(c).\n\nSpecifically, to construct these interpolations  $X_{t}$  at different time steps for training, discretize the time interval into  $N$  steps:\n\n$$\nT = \\left\\{t _ {i} \\mid t _ {i} = \\frac {i}{N}, i = 0, 1, \\dots , N \\right\\}, \\tag {8}\n$$\n\nwhere  $t_i \\in [0,1]$ , starting from  $t_0 = 0$  to  $t_N = 1$ . This discretization allows for the numerical simulation of the flow using the Euler method with a constant step size of  $1/N$ . By encoding the step  $t$  and integrating step embeddings via concatenation into the flow model  $f_{\\theta}$ , the flow model learns step-dependent transformations and predicts the vector field  $v_t$  at each step  $t$ .\n\nA critical aspect of the FlowCF framework is the selection of an appropriate prior distribution  $p$  and the definition of flow dynamics tailored for recommendation tasks. These components are addressed in detail in the subsequent sections.\n\n# 3.2 Behavior-Guided Prior (RQ1)\n\nFlow matching typically relies on a prior distribution for training. In many generative tasks, such as image generation [22, 26], the Gaussian distribution  $p = \\mathcal{N}(0,I)$  is commonly employed due to its mathematical tractability and universality. However, in collaborative filtering (CF), the distribution of interactions exhibits distinct characteristics. Specifically, the user-item interactions are highly sparse and often follow a long-tailed popularity bias. Furthermore, the role of our FlowCF is to transform a noisy user behavior distribution – rather than a pure noise like a Gaussian distribution – into the target distribution. Consequently, a Gaussian prior is ill-suited for flow matching in CF, as it fails to capture the inherent sparsity of interactions and the dynamic evolution of user behaviors. This misalignment between the prior and the true requirements of CF can lead to insufficient learning and suboptimal performance.\n\nTo address this challenge, we hypothesize that using a prior distribution which is close to the true user behavior distribution is beneficial to effective training of flow matching models in recommendation tasks. Therefore, we propose that a prior distribution derived from real-world user behaviors can better guide the flow matching process. Such a behavior-guided prior enables the flow model to learn more meaningful transitions from the prior to the distribution of historical interactions. By incorporating the inherent sparsity of user-item interactions and global item popularity - a critical factor in recommendation - this approach ensures a more accurate representation of the underlying user behavior distribution.\n\nTo operationalize this idea, we design a Behavior-Guided Prior Distribution that leverages the global item frequency vector  $\\mathbf{f} \\in \\mathbb{R}^{|\\mathcal{I}|}$ . Let  $\\mathbf{f}_i$  denote the frequency of item  $i$  across all historical\n\nuser-item interactions  $\\tilde{X}$\n\n$$\n\\mathrm {f} _ {i} = \\frac {\\text {n u m b e r o f i n t e r a c t i o n s f o r i t e m} i}{\\text {t o t a l n u m b e r o f u s e r s} | \\mathcal {U} |}. \\tag {9}\n$$\n\nThis frequency vector  $\\mathbf{f}$  captures the global popularity of items across all historical user-item interactions, providing a meaningful foundation for constructing the behavior-guided prior distribution.\n\nTo model the prior, we employ the Bernoulli distribution, which is well-suited for binary outcomes. Specifically, the Bernoulli distribution models whether an event occurs (1) or does not occur (0) based on a given probability. This aligns with our goal of representing user-item interactions as binary implicit feedback, where 1 indicates positive feedback and 0 indicates the absence of such feedback. The behavior-guided prior distribution is then constructed by applying the Bernoulli distribution with expanded global item frequency  $\\mathbf{f}$ :\n\n$$\np = \\operatorname {B e r n o u l l i} \\left(\\mathbf {1} _ {| \\mathcal {U} |} \\otimes \\mathrm {f}\\right). \\tag {10}\n$$\n\nThis ensures that the behavior-guided prior distribution aligns with the historical item frequencies across all users, thereby providing a more suitable starting point for the flow matching training process. The starting point  $X_0$  for the flow matching training process is sampled from the behavior-guided prior distribution:\n\n$$\nX _ {0} \\sim \\operatorname {B e r n o u l l i} \\left(\\mathbf {1} _ {| \\mathcal {U} |} \\otimes \\mathbf {f}\\right) \\in \\{0, 1 \\} ^ {| \\mathcal {U} | \\times | I |}, \\tag {11}\n$$\n\nwhere  $X_0$  comprises only 0 and 1 values, representing negative and positive implicit feedback, respectively. The sample  $X_0$  remains behavior-guided, reflecting the global item frequencies, as well as the sparsity and popularity bias inherent in user-item interactions.\n\n# 3.3 Discrete Flow Framework (RQ2)\n\nTraditional flow matching and diffusion-based DiffRec operate in a continuous state space. In continuous flow matching, the flow trajectory between the source sample  $X_0$  and target sample  $X_{1}$  is often defined using linear interpolation [26]. This interpolation can be defined as:\n\n$$\nX _ {t} = t X _ {1} + (1 - t) X _ {0} \\sim p _ {t}, \\tag {12}\n$$\n\nwhere  $X_{t}$  represents a linear interpolation between  $X_{0}$  and  $X_{1}$ . This continuous linear interpolation ensures a smooth transition between the source and target distributions. While there are alternative interpolation methods, such as the sinusoidal interpolation [1], the straight flow trajectory achieved via linear interpolation aligns well with recommendation tasks and is more computationally efficient compared to nonlinear or stochastic interpolations.\n\nHowever, in collaborative filtering, we primarily model rich implicit feedback (e.g., clicks or purchases) from users, which is inherently binary and discrete, as opposed to the rarer explicit feedback. Given that both the historical interactions  $X_{1}$  and the sample  $X_{0}$  (Equation 11) from the behavior-guided prior are binary, preserving this binary structure poses a significant challenge. Continuous flow matching fails to preserve the discrete structure of interaction data because continuous interpolations, such as Equation 12, produce fractional values that do not align with valid binary interactions. Such approximations to discrete interactions can lead to inaccuracies in recommendations. To address this limitation, we propose a discrete flow framework that operates in a discrete state space [4, 8], explicitly modeling binary implicit feedback, along with a series of discretization strategies, to ensure the integrity of the interactions.\n\nDiscretized Linear Interpolation. To preserve the discrete nature of the data, we propose a discretized linear interpolation:\n\n$$\nX _ {t} = M _ {t} \\odot X _ {1} + \\left(\\mathbf {1} _ {| \\mathcal {U} | \\times | \\mathcal {I} |} - M _ {t}\\right) \\odot X _ {0}. \\tag {13}\n$$\n\nwhere  $M_t \\in \\{0,1\\}^{|U| \\times |I|}$  is a binary mask with each element  $M_t^i \\sim \\text{Bernoulli}(t)$  and  $\\odot$  denotes element-wise multiplication. This formulation ensures that each entry  $X_t^i$  is a mixture of the historical interaction  $X_1^i$  and the source sample  $X_0^i$ , with a probability  $t$ :\n\n$$\nX _ {t} ^ {i} = \\left\\{ \\begin{array}{l l} X _ {1} ^ {i} & \\text {w i t h p r o b a b i l i t y} t, \\\\ X _ {0} ^ {i} & \\text {w i t h p r o b a b i l i t y} 1 - t. \\end{array} \\right. \\tag {14}\n$$\n\nThis discretized linear interpolation maintains the binary structure of the interaction data, ensuring that  $X_{t}$  remains step-dependent for all steps  $t \\in T$ . Despite the discretization, which restricts transitions to binary values, the expectation of  $X_{t}$  still behaves like a smooth linear function:\n\n$$\n\\mathbb {E} \\left[ X _ {t} \\right] = t X _ {1} + (1 - t) X _ {0}. \\tag {15}\n$$\n\nTherefore, despite the use of discrete variables, the discrete flow framework maintains a theoretical alignment with continuous interpolation in expectation.\n\nVector Field of Expectation. The flow dynamics under the framework are governed by the vector field of expectation  $u_{t}(\\mathbb{E}[X_{t}] \\mid X_{1})$ , which describes the rate of change of the expectation  $\\mathbb{E}[X_t]$ . This vector field is derived from Equation 15 as an ODE:\n\n$$\nu _ {t} \\left(\\mathbb {E} \\left[ X _ {t} \\right] \\mid X _ {1}\\right) = \\frac {\\mathrm {d} \\mathbb {E} \\left[ X _ {t} \\right]}{\\mathrm {d} t} = X _ {1} - X _ {0}. \\tag {16}\n$$\n\nHere, the difference vector  $X_{1} - X_{0}$  represents the direction of the flow, guiding the transition from  $X_{0}$  to  $X_{1}$ . By substituting  $X_{0} = \\frac{\\mathbb{E}[X_{t}] - tX_{1}}{1 - t}$ , the vector field can be reformulated as:\n\n$$\nu _ {t} \\left(\\mathbb {E} \\left[ X _ {t} \\right] \\mid X _ {1}\\right) = \\frac {X _ {1} - \\mathbb {E} \\left[ X _ {t} \\right]}{1 - t}. \\tag {17}\n$$\n\nThis formulation mirrors the continuous flow vector field but is adapted for discrete data. While the vector field is defined in terms of the expectation  $\\mathbb{E}[X_t]$ , the actual updates are applied to the discrete  $X_{t}$ , ensuring that the binary structure of interactions is preserved. Similarly, the predicted vector field  $v_{t}(\\mathbb{E}[X_{t}])$  is computed as:\n\n$$\nv _ {t} \\left(\\mathbb {E} \\left[ X _ {t} \\right]\\right) = \\frac {\\hat {X} _ {1} - \\mathbb {E} \\left[ X _ {t} \\right]}{1 - t}, \\tag {18}\n$$\n\nwhere  $\\hat{X}_1$  is the predicted user interactions.\n\nIn summary, we propose a discrete flow framework designed for recommendations, incorporating the discrete sample from behavior-guided prior and discretized linear interpolation to preserve the binary nature of implicit feedback. By leveraging a vector field of expectation, we bridge the gap between discrete and continuous state spaces, ensuring theoretical consistency while maintaining the discrete structure of interactions. This framework enables smooth and interpretable transitions from source to target distributions, addressing the unique challenges of collaborative filtering.\n\n# 3.4 Training FlowCF (RQ3)\n\nThe training process for FlowCF focuses on optimizing the flow model to accurately approximate the vector field to transform user-item interactions. This optimization can be interpreted as aligning a predicted vector field of expectation with a ground truth vector\n\nfield of expectation. By substituting the ground truth vector field  $u$  and the predicted vector field  $v$  into Equation 7, we derive the following loss function:\n\n$$\n\\mathcal {L} _ {t} = \\mathbb {E} _ {t, X _ {1}, X _ {t}} \\left[ \\left\\| \\frac {\\hat {X} _ {1} - \\mathbb {E} [ X _ {t} ]}{1 - t} - \\frac {X _ {1} - \\mathbb {E} [ X _ {t} ]}{1 - t} \\right\\| ^ {2} \\right], \\tag {19}\n$$\n\nwhich encourages  $\\hat{X}_1$  to accurately predict the target interaction matrix  $X_1$ . Consequently, the flow model  $f_{\\theta}$  can be optimized to minimize the mean squared error between its predictions and the true interactions, leading to the following simplified loss:\n\n$$\n\\mathcal {L} _ {t} = \\mathbb {E} _ {t, X _ {1}, X _ {t}} \\left[ \\| \\hat {X} _ {1} - X _ {1} \\| ^ {2} \\right], \\tag {20}\n$$\n\nwhere  $X_{t}$  can be viewed as the noisy interaction matrix at step  $t$ , and  $X_{1}$  is the target interaction matrix. Through this formulation, the flow model  $f_{\\theta}$  can be used to directly predict the target interactions  $\\hat{X}_{1}$  and subsequently used to compute the predicted vector field  $v$  with  $\\hat{X}_{1}$ . This alternative approach, given by\n\n$$\n\\hat {X} _ {1} = f _ {\\theta} \\left(X _ {t}, t\\right), \\tag {21}\n$$\n\neliminates the need for explicit vector field estimation, which is often more challenging. Instead, it focuses on capturing the underlying structure of user-item interactions, thereby improving the ability to generate accurate recommendations.\n\nUnlike KL divergence-based approaches [19, 28, 35], which often suffer from issues such as mode collapse or over-penalization of low-density regions in the learned distribution, FlowCF directly optimizes the interaction predictions. This approach avoids reliance on distributional matching and better captures the structure of user-item relationships. The training process is detailed in Algorithm 1.\n\n# Algorithm 1 Training FlowCF\n\nInput: All user interactions  $\\bar{X}$  and the randomly initialized parameters  $\\theta$  of the flow model  $f_{\\theta}$\n\n1: repeat\n\n2: Sample a batch of users  $\\mathcal{U}_b$  and their interactions as  $X_{1}\\subset \\bar{X}$\n\n3: Create discrete steps  $T$  by Equation 8\n\n4: Sample a batch of steps  $t$  from  $T^{|\\mathcal{U}_b|}$\n\n5: Sample  $X_0$  from the behavior-guided prior\n\n6: Compute the interpolation  $X_{t}$  by Equation 13\n\n7: Predict  $\\hat{X}_1 = f_\\theta(X_t, t)$\n\n8: Compute loss  $\\mathcal{L}_t$  by Equation 20\n\n9: Update  $\\theta$  via gradient descent on  $\\nabla_{\\theta}\\mathcal{L}_t$\n\n10: until Converged\n\nOutput: Optimized parameters  $\\theta$  of the flow model  $f_{\\theta}$\n\n# Algorithm 2 Inference with FlowCF\n\nInput: Trained flow model  $f_{\\theta}$  with parameters  $\\theta$ , observed user interactions  $X$ , number of discretization steps  $N$\n\n1: Set the starting step s\n\n2: Initialize  $X_{t} \\gets X$\n\n3: for  $i = s$  to  $N - 2$  do\n\n4: Set the current step  $t \\gets t_i$\n\n5: Predict  $\\hat{X} = f_{\\theta}(X_t,t)$\n\n6: Compute the predicted  $v_{t} \\gets (\\hat{X} - X_{t}) / (1 - t)$\n\n7: Update  $X_{t}$  by Equation 22\n\n8: Preserve observed interactions  $X_{t} \\gets X_{t} \\lor X$\n\n9: end for\n\n10: Predict  $\\hat{X} = f_{\\hat{\\theta}}(X_t,t)$  in the last step  $t = t_{N - 1}$\n\nOutput: Predicted interactions  $\\hat{X}$\n\n# 3.5 Inference with FlowCF (RQ4)\n\nDuring the inference process, the observed user interactions  $X$  can be treated as a noisy interaction matrix, analogous to an interpolation  $X_{t}$  between prior sample  $X_0$  from the behavior-guided prior and the ground truth interactions  $X_{1}$ . To initiate the inference process, a starting sampling step needs to be selected. Since the starting point  $X$  is not purely noise but contains meaningful information about user historical behavior, it is unnecessary to begin at  $t = 0$ . Instead, the inference process can start from a later step, significantly reducing the number of sampling steps required. To preserve the binary nature of the interactions  $X_{t}$  throughout the inference process, FlowCF employs the following update rule, where each update corresponds to an element-wise argmax over the predicted field, to compute  $X_{t + \\frac{1}{N}}$  at the next step of  $t$ :\n\n$$\nX _ {t + \\frac {1}{N}} ^ {i} = \\left\\{ \\begin{array}{l l} 1 & \\text {i f} X _ {t} ^ {i} + \\frac {v _ {t} ^ {i}}{N} \\geq 0. 5, \\\\ 0 & \\text {o t h e r w i s e .} \\end{array} \\right. \\tag {22}\n$$\n\nwhere  $v_{t}$  is the predicted vector field, and  $1 / N$  is the step size that controls the granularity of the discrete steps. The complete inference process is described in Algorithm 2.\n\nIn practice, FlowCF achieves superior performance within just two sampling steps, starting from the second-to-last step during inference. Compared to diffusion models, FlowCF leverages flow matching, which benefits from straight flow trajectories and eliminates the need to start from  $t = 0$  with unnecessary sampling steps. This property enables efficient sampling and allows FlowCF to require much fewer sampling steps, resulting in faster inference speeds and facilitating quicker recommendations.",
    "experiments": "# 4 Experiments\n\n# 4.1 Experimental Setup\n\nDatasets. To evaluate our proposed model, we conduct our experiments on three public datasets in real-world scenarios: MovieLens1M [9], MovieLens-20M, and Amazon-Beauty [29]. These datasets vary in scale and density, which allows us to evaluate the performance of the models across different levels of sparsity. Although they consist of explicit ratings, we have intentionally chosen them to investigate the performance of learning from implicit feedback. To convert explicit ratings into implicit feedback, we binarize the\n\nratings by treating ratings of four and above as positive interactions and discarding ratings  $< 4$ . We split the dataset into training, validation, and test sets at a ratio of 8:1:1. To be consistent with the preprocessing in previous studies [19], we exclude users and items with fewer than five interactions from the datasets. Table 2 provides a summary of the statistics of the datasets after preprocessing.\n\nBaselines. We compare FlowCF with several baselines, including non-generative methods like MF-BPR [32], LightGCN [10], and SGL [44]; DAE-based methods like CDAE [45] and Mult-DAE [19]; VAE-based methods like Mult-VAE [19], MacridVAE [28], and RecVAE [35]; and the diffusion-based method DiffRec [42]. The detailed descriptions of baselines are in Appendix C.\n\nEvaluation Metrics. We use two standard metrics, Recall@K (R@K) and NDCG@K (N@K), following the all-ranking protocol [10], which ranks all non-interacted items for each user. For each metric, we evaluate the top-K items, with  $K \\in [10,20]$ .\n\nImplementation Details. We use 9 discretization steps for ML-1M and Amazon-Beauty, and 50 for ML-20M. The number of sampling steps is fixed at 2. Further details are provided in Appendix D.\n\n# 4.2 Performance Comparison\n\nTable 1 presents the overall performance comparison of FlowCF and the baselines across three datasets. The results highlight several key observations and insights for generative CF and our FlowCF:\n\n- The generative CF methods demonstrate competitive performance compared to non-generative baseline methods. This suggests that generative CF models are promising for collaborative filtering, as they can effectively capture complex user-item interactions and generate high-quality recommendations by modeling the underlying interaction distribution.\n\n- When compared to traditional generative models such as DAE and VAE-based methods, we observe that more advanced generative models, particularly the diffusion-based DiffRec and our proposed flow matching model, FlowCF, tend to achieve superior recommendation performance. This improvement can be attributed to the inherent strengths of diffusion models and flow matching techniques, which effectively capture intricate user behavior patterns and preference distributions, leading to more accurate and personalized recommendations.\n\n- Our proposed FlowCF consistently outperforms all baseline models across all datasets and metrics with notable improvements. This demonstrates that FlowCF effectively combines the strengths of flow matching with the specific requirements of recommendation tasks. By incorporating our behavior-guided prior and discrete flow design for collaborative filtering, FlowCF is able to model user preference distribution more accurately than VAE and diffusion-based baseline models.\n\nNoisy Training. In real-world scenarios, implicit feedback often contains false-positive interactions. To evaluate the robustness of FlowCF to such natural noise, we conduct experiments by randomly adding ratings below 4 as positive implicit feedback in training and validation sets. The results, illustrated in Figure 3, reveal that our approach not only consistently outperforms baseline models under conditions of natural noise but also exhibits a lower rate of performance degradation compared to VAE-based methods. Furthermore, Figure 4 presents the experimental results involving random noise,\n\n\nTable 1: Overall performance comparison. The best results of FlowCF are highlighted in bold, and the best baseline results are underlined. The relative improvements of FlowCF over the best baselines are indicated as Improve. The symbol * indicates the improvement over the best baseline is statistically significant with  $p$ -value  $< 0.05$ .\n\n\n<table><tr><td></td><td colspan=\"4\">MovieLens-1M</td><td colspan=\"4\">MovieLens-20M</td><td colspan=\"4\">Amazon-Beauty</td></tr><tr><td>Methods</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td></tr><tr><td>MF-BPR</td><td>0.1764</td><td>0.2672</td><td>0.1924</td><td>0.2124</td><td>0.1980</td><td>0.2918</td><td>0.1779</td><td>0.2023</td><td>0.0871</td><td>0.1259</td><td>0.0487</td><td>0.0588</td></tr><tr><td>LightGCN</td><td>0.1859</td><td>0.2753</td><td>0.1849</td><td>0.2158</td><td>0.2055</td><td>0.3020</td><td>0.1855</td><td>0.2103</td><td>0.1032</td><td>0.1482</td><td>0.0579</td><td>0.0696</td></tr><tr><td>SGL</td><td>0.1936</td><td>0.2900</td><td>0.2086</td><td>0.2301</td><td>0.2219</td><td>0.3180</td><td>0.1947</td><td>0.2247</td><td>0.1093</td><td>0.1566</td><td>0.0624</td><td>0.0746</td></tr><tr><td>CDAE</td><td>0.1703</td><td>0.2517</td><td>0.1870</td><td>0.2045</td><td>0.2047</td><td>0.2998</td><td>0.2180</td><td>0.1936</td><td>0.0844</td><td>0.1285</td><td>0.0511</td><td>0.0614</td></tr><tr><td>Mult-DAE</td><td>0.1797</td><td>0.2667</td><td>0.1899</td><td>0.2106</td><td>0.2431</td><td>0.3488</td><td>0.2114</td><td>0.2399</td><td>0.0949</td><td>0.1388</td><td>0.0551</td><td>0.0666</td></tr><tr><td>Mult-VAE</td><td>0.1855</td><td>0.2751</td><td>0.1952</td><td>0.2160</td><td>0.2472</td><td>0.3531</td><td>0.2134</td><td>0.2424</td><td>0.1009</td><td>0.1417</td><td>0.0583</td><td>0.0690</td></tr><tr><td>MacridVAE</td><td>0.1775</td><td>0.2593</td><td>0.1903</td><td>0.2082</td><td>0.2417</td><td>0.3399</td><td>0.2153</td><td>0.2408</td><td>0.1147</td><td>0.1524</td><td>0.0695</td><td>0.0794</td></tr><tr><td>RecVAE</td><td>0.2049</td><td>0.3047</td><td>0.2146</td><td>0.2368</td><td>0.2487</td><td>0.3538</td><td>0.2217</td><td>0.2491</td><td>0.1153</td><td>0.1584</td><td>0.0677</td><td>0.0790</td></tr><tr><td>DiffRec</td><td>0.2055</td><td>0.3030</td><td>0.2208</td><td>0.2423</td><td>0.2530</td><td>0.3516</td><td>0.2362</td><td>0.2594</td><td>0.1190</td><td>0.1570</td><td>0.0731</td><td>0.0832</td></tr><tr><td>FlowCF</td><td>0.2157*</td><td>0.3145*</td><td>0.2320*</td><td>0.2530*</td><td>0.2580*</td><td>0.3585*</td><td>0.2394*</td><td>0.2634*</td><td>0.1245*</td><td>0.1633*</td><td>0.0755*</td><td>0.0856*</td></tr><tr><td>% Improve.</td><td>4.96%</td><td>3.35%</td><td>5.07%</td><td>4.42%</td><td>1.98%</td><td>1.33%</td><td>1.02%</td><td>1.20%</td><td>4.62%</td><td>3.10%</td><td>3.28%</td><td>2.88%</td></tr></table>\n\n\nTable 2: Statistics of the experimented datasets.\n\n\n<table><tr><td>Dataset</td><td># Users</td><td># Items</td><td># Interactions</td><td>Density</td></tr><tr><td>MovieLens-1M</td><td>6,034</td><td>3,126</td><td>574,376</td><td>3.04%</td></tr><tr><td>MovieLens-20M</td><td>136,674</td><td>13,681</td><td>9,977,451</td><td>0.53%</td></tr><tr><td>Amazon-Beauty</td><td>10,553</td><td>6,087</td><td>94,148</td><td>0.15%</td></tr></table>\n\nwith noise proportions ranging from  $10\\%$  to  $50\\%$  on the MovieLens-1M dataset. These results indicate that FlowCF maintains superior performance over both VAE and diffusion-based baseline models, demonstrating its robustness to random noise. This robustness can be attributed to our training strategy, which leverages a set of interpolations that incorporate varying levels of noisy interactions between samples from prior and historical interactions. This approach enhances generalization by enabling the model to effectively transform between prior and historical interactions through carefully designed probability paths. These paths inherently accommodate noisy data, allowing FlowCF to learn more stable transformations and adapt effectively to noisy real-world conditions.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/428b3fe2448c51bf1e5334f66e69b7e9627b9b37a963790372da4e802b333c84.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/76f235dbff418e1112faee6041fe7853b302b07e8c3c33580b3b533b251c43be.jpg)\n\n\n\nFigure 3: Performance comparison under natural noise setting on MovieLens-20M and Amazon-Beauty.\n\n\n# 4.3 Ablation and Sensitivity Study\n\nEffect of Priors and Flows. To study the effect of different prior distributions on both continuous flow-based recommender (denoted as CFlowCF, further details in Appendix B) and discrete flow-based FlowCF, we compare uniform distribution between 0 and 1, Gaussian distribution  $\\mathcal{N}(0,I)$ , and our behavior-guided prior distribution.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/6326b8091b2fc96ad1ae1e88a64acd6080d1ef5183b1b243c938229bd4a7f480.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/f34711da51c07ddc26c7e01f286e4f50ff0a6951fc4cdffbc1d8c410068c6f3f.jpg)\n\n\n\nFigure 4: Performance of noisy training with different proportions of random noise on MovieLens-1M.\n\n\nFor discrete flow-based FlowCF, we discretize these priors to probability mass functions using a Bernoulli distribution and also include a random binary initialization (0 or 1) as a baseline.\n\nTable 3 presents the performance of different variants with various priors and flows. The behavior-guided prior consistently outperforms the other priors, indicating that incorporating user behavior information into the prior facilitates the training of FlowCF. This validates our previous hypothesis that a behavior-guided prior, which better approximates the true user behavior distribution, enhances the performance of flow matching in collaborative filtering. While CFlowCF with uniform and Gaussian priors still achieves decent performance, the discrete flow-based FlowCF relies more heavily on the behavior-guided prior for stable training. Notably, using random binary initialization, discretized uniform distribution, or discretized Gaussian distribution as the prior can lead to training failures, as evidenced in the Amazon-Beauty dataset.\n\nThese results indicate that although the discrete flow framework improves recommendation performance, it is more sensitive to the choice of prior. This sensitivity arises from the inherent discrete nature and the density of interaction data. In discrete flow framework, the sample  $X_0$  from prior is binary (only 0s and 1s). To learn effective transformations, the density of positives (1s) in  $X_0$  should closely match the true density of the dataset. Dense samples from uniform or Gaussian priors introduce many false positives, hindering the model to recover correct patterns. In contrast, CFlowCF uses non-binary continuous-valued samples, which are not affected by\n\n\nTable 3: Performance comparison of multiple variants of FlowCF with different prior distributions and flows. The best results are highlighted in bold, and the second-best results are underlined.\n\n\n<table><tr><td colspan=\"2\"></td><td colspan=\"4\">MovieLens-1M</td><td colspan=\"4\">MovieLens-20M</td><td colspan=\"4\">Amazon-Beauty</td></tr><tr><td>Methods</td><td>Priors</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td></tr><tr><td>CFlowCF</td><td>Uniform</td><td>0.2103</td><td>0.3048</td><td>0.2256</td><td>0.2457</td><td>0.2473</td><td>0.3437</td><td>0.2321</td><td>0.2546</td><td>0.1098</td><td>0.1447</td><td>0.0683</td><td>0.0775</td></tr><tr><td>CFlowCF</td><td>Gaussian</td><td>0.2116</td><td>0.3056</td><td>0.2276</td><td>0.2471</td><td>0.2523</td><td>0.3514</td><td>0.2341</td><td>0.2574</td><td>0.1189</td><td>0.1597</td><td>0.0728</td><td>0.0836</td></tr><tr><td>CFlowCF</td><td>Behavior-Guided</td><td>0.2132</td><td>0.3107</td><td>0.2287</td><td>0.2491</td><td>0.2549</td><td>0.3547</td><td>0.2375</td><td>0.2611</td><td>0.1202</td><td>0.1619</td><td>0.0751</td><td>0.0859</td></tr><tr><td>FlowCF</td><td>Random Binary</td><td>0.2035</td><td>0.2933</td><td>0.2214</td><td>0.2393</td><td>0.1888</td><td>0.2656</td><td>0.1724</td><td>0.1912</td><td>0.0018</td><td>0.0033</td><td>0.0009</td><td>0.0013</td></tr><tr><td>FlowCF</td><td>Uniform</td><td>0.2054</td><td>0.2942</td><td>0.2219</td><td>0.2394</td><td>0.0938</td><td>0.1511</td><td>0.0871</td><td>0.1021</td><td>0.0020</td><td>0.0032</td><td>0.0009</td><td>0.0012</td></tr><tr><td>FlowCF</td><td>Gaussian</td><td>0.2028</td><td>0.2937</td><td>0.2208</td><td>0.2392</td><td>0.1963</td><td>0.2699</td><td>0.1865</td><td>0.2039</td><td>0.0020</td><td>0.0031</td><td>0.0009</td><td>0.0011</td></tr><tr><td>FlowCF</td><td>Behavior-Guided</td><td>0.2157</td><td>0.3145</td><td>0.2320</td><td>0.2530</td><td>0.2580</td><td>0.3585</td><td>0.2394</td><td>0.2634</td><td>0.1245</td><td>0.1633</td><td>0.0755</td><td>0.0856</td></tr></table>\n\nthe density of positives in discrete modeling. This explains its lower sensitivity to prior design compared to FlowCF. Consequently, a customized behavior-guided prior for effective training. Additionally, we observe that the convergence speed is significantly slower when using priors other than the behavior-guided prior for FlowCF. Overall, these results highlight the importance of incorporating user behavior patterns into the prior distribution to effectively model implicit feedback and enhance recommendation performance in flow matching recommenders.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/07de001d3b6909d8871a43394b12ea499e924c8c31c7c3a18a3c9c750f9a52a9.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/d46089e56885347975b61b6660db04d82aaf10b122c6f0a5b3f8533843787cc4.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/672d11eaeb6b7f87607dabcee6d5ffc1852d5da09daafe6d51d2d69145114905.jpg)\n\n\n\nFigure 5: Effect of the number of discretization steps  $N$ .\n\n\nSensitivity to Discretization Step. The number of discretization steps  $N$  determines the granularity of the interpolation set. To study its impact, we conduct experiments with different values of  $N$ . The results in Figure 5 indicate that the optimal choice of  $N$  depends on the dataset size and its inherent sparsity. For example, MovieLens-1M and Amazon-Beauty achieve the peak results with  $N = 9$ , while MovieLens-20M performs best with  $N$  between 50 and 75. Larger datasets generally benefit from finer discretization. Unlike diffusion-based models that require tuning noise schedules, our approach has fewer sensitive hyperparameters, with the primary focus being the selection of  $N$  for interpolation.\n\n# 4.4 Efficiency Analysis\n\nTo evaluate the efficiency of FlowCF, we compare its performance with VAE-based models and diffusion-based DiffRec in terms of training speed, inference speed, and convergence rate using the MovieLens-20M dataset, which contains the highest number of interactions among the datasets. All experiments are conducted on a single NVIDIA A5000 GPU under a fair baseline setting.\n\nThe learning curves on the left side of Figure 6 illustrate that among generative collaborative filtering models, FlowCF and DiffRec\n\nachieve the fastest convergence, whereas VAE-based methods converge more slowly. Specifically, Mult-VAE demonstrates fast per-epoch training speed but suffers from a slow convergence rate, which limits its overall training efficiency. RecVAE addresses this limitation by improving the convergence rate but at the cost of increased training time per epoch due to architectural modifications introduced to enhance Mult-VAE. In contrast, FlowCF combines rapid per-epoch training with a fast convergence rate, showcasing its superiority in balancing these two critical aspects of model efficiency. The inference time per epoch, depicted on the right side of Figure 6, further highlights the advantages of FlowCF. It achieves the fastest inference speed comparable to Mult-VAE and RecVAE by leveraging efficient sampling with only two steps during inference. Compared to DiffRec, which requires a larger number of sampling steps during inference due to its diffusion process, FlowCF significantly reduces this requirement. Overall, FlowCF achieves both efficient training with rapid convergence and efficient inference, making it a highly competitive choice for recommendation systems.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/77ec836523643825659ffb69de8d651a9748661a386645107e025b20c27ec7b7.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/c790606b-abef-4ba3-8efd-1388bcecbdb9/3cde7b2f047ab97d683f9f08e65535dc9a26d0d44b2c8085cc05b323dee04ab6.jpg)\n\n\n\nFigure 6: Learning curves and running time per epoch comparison of different generative CF models on ML-20M. The proposed FlowCF converges significantly faster while achieving superior performance and efficient inference speed.",
    "hyperparameter": "Discretization steps $N$ are set to 9 for ML-1M; inference is efficiently conducted with only 2 sampling steps starting from the second-to-last step. Training employs the Adam optimizer with a learning rate of 0.001, a batch size of 4096, and no weight decay. The Flow model is implemented as an MLP with hidden dimensions of [300, 300] for ML-1M, with the dropout rate explicitly fixed at 0.1 to ensure effective flow matching. The time embedding dimension is set to 10, using sinusoidal embeddings with frequencies scaled by $2\\pi$ as described in the timestep_embedding_pi function."
  }