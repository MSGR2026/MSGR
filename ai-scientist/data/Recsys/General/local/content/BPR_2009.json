{
  "id": "BPR_2009",
  "paper_title": "Bayesian Personalized Ranking from Implicit Feedback",
  "alias": "BPR",
  "year": 2009,
  "domain": "Recsys",
  "task": "GeneralRecommendation",
  "idea": "BPR (Bayesian Personalized Ranking) introduces a novel optimization criterion specifically designed for implicit feedback by maximizing the posterior probability of pairwise item preferences. Instead of predicting absolute ratings, BPR constructs training data as triplets (user, preferred item, non-preferred item) from implicit feedback and optimizes the model to correctly rank observed items higher than unobserved ones. The method uses a stochastic gradient descent algorithm (LearnBPR) with bootstrap sampling of training triples, which is shown to converge faster than traditional user-wise gradient descent and can be applied to various recommender models including matrix factorization and k-nearest-neighbor.",
  "introduction": "# Introduction\nRecommending content is an important task in many information systems. For example, online shopping websites like Amazon give each customer personalized recommendations of products that the user might be interested in. Other examples are video portals like YouTube that recommend movies to customers. Personalization is attractive both for content providers, who can increase sales or views, and for customers, who can find interesting content more easily.\n\nIn this paper, we focus on item recommendation. The task of item recommendation is to create a user-specific ranking for a set of items. Preferences of users about items are learned from the user’s past interaction with the system – e.g. his buying history, viewing history, etc.\n\nRecommender systems are an active topic of research. Most recent work is on scenarios where users provide explicit feedback, e.g. in terms of ratings. Nevertheless, in real-world scenarios most feedback is not explicit but implicit. Implicit feedback is tracked automatically, like monitoring clicks, view times, purchases, etc. Thus it is much easier to collect, because the user has not to express his taste explicitly. In fact implicit feedback is already available in almost any information system – e.g. web servers record any page access in log files.\n\nIn this paper we present a generic method for learning models for personalized ranking. The contributions of this work are:\n1. We present the generic optimization criterion BPR-Opt derived from the maximum posterior estimator for optimal personalized ranking. We show the analogies of BPR-Opt to maximization of the area under ROC curve.\n2. For maximizing BPR-Opt, we propose the generic learning algorithm LearnBPR that is based on stochastic gradient descent with bootstrap sampling of training triples. We show that our algorithm is superior to standard gradient descent techniques for optimizing w.r.t. BPR-Opt.\n3. We show how to apply LearnBPR to two state-of-the-art recommender model classes.\n4. Our experiments empirically show that for the task of personalized ranking, learning a model with BPR outperforms other learning methods.",
  "method": "# Method\n## 1. Personalized Ranking\n### 1.1 Formalization\nLet \\( U \\) be the set of all users and \\( I \\) the set of all items. In our scenario implicit feedback \\( S \\subseteq U × I \\) is available. Examples for such feedback are purchases in an online shop, views in a video portal or clicks on a website. The task of the recommender system is now to provide the user with a personalized total ranking \\( >_{u} \\subset I^{2} \\) of all items, where \\( >_{u} \\) has to meet the properties of a total order:\n- Totality: \\( \\forall i,j\\in I:i\\neq j\\Rightarrow i>_{u} j\\vee j>_{u} i \\)\n- Antisymmetry: \\( \\forall i,j\\in I:i>_{u}j\\land j>_{u}i\\Rightarrow i=j \\)\n- Transitivity: \\( \\forall i,j,k\\in I:i>_{u} j\\Lambda j>_{u} k \\Rightarrow i>_{u} k \\)\n\nFor convenience we also define:\n- \\( I_{u}^{+}:=\\{i \\in I:(u, i) \\in S\\} \\)\n- \\( U_{i}^{+}:=\\{u \\in U:(u, i) \\in S\\} \\)\n\n### 1.2 Training Data Construction\nFrom \\( S \\) we create training data \\( D_{S}: U × I × I \\) by:\n\\[ D_{S}:=\\left\\{(u, i, j) | i \\in I_{u}^{+} \\Lambda j \\in I \\backslash I_{u}^{+}\\right\\} \\]\nThe semantics of \\( (u, i, j) \\in D_{S} \\) is that user \\( u \\) is assumed to prefer \\( i \\) over \\( j \\).\n\n## 2. Bayesian Personalized Ranking (BPR)\n### 2.1 BPR Optimization Criterion\nThe Bayesian formulation of finding the correct personalized ranking is to maximize the posterior probability:\n\\[ p(\\Theta |>_{u})\\propto p(>_{u} | \\Theta )\\, p(\\Theta ) \\]\nAll users are presumed to act independently, and the ordering of each pair of items for a specific user is independent of other pairs. The likelihood function can be simplified to:\n\\[ \\prod_{u \\in U} p\\left(>_{u} | \\Theta\\right)=\\prod_{(u, i, j) \\in D_{S}} p\\left(i>_{u} j | \\Theta\\right) \\]\n\nWe define the probability that a user prefers item \\( i \\) to item \\( j \\) as:\n\\[ p\\left(i>_{u} j | \\Theta\\right):=\\sigma\\left(\\hat{x}_{u i j}(\\Theta)\\right) \\]\nwhere \\( \\sigma(x):=\\frac{1}{1+e^{-x}} \\) is the logistic sigmoid, and \\( \\hat{x}_{u i j}(\\Theta) \\) is a real-valued function capturing the relationship between user \\( u \\), item \\( i \\) and item \\( j \\).\n\nIntroducing a normal prior \\( p(\\Theta) \\sim N\\left(0, \\lambda_{\\Theta} I\\right) \\), the maximum posterior estimator (BPR-Opt) is:\n\\[ BPR-OPT = \\sum_{(u, i, j) \\in D_{S}} ln \\sigma\\left(\\hat{x}_{u i j}\\right)-\\lambda_{\\Theta}\\| \\Theta\\| ^{2} \\]\nwhere \\( \\lambda_{\\Theta} \\) are model-specific regularization parameters.\n\n### 2.2 BPR Learning Algorithm\nThe gradient of BPR-Opt with respect to model parameters is:\n\\[ \\frac{\\partial BPR-Opt}{\\partial \\Theta} \\propto \\sum_{(u, i, j) \\in D_{S}} \\frac{-e^{-\\hat{x}_{u i j}}}{1+e^{-\\hat{x}_{u i j}}} \\cdot \\frac{\\partial}{\\partial \\Theta} \\hat{x}_{u i j}-\\lambda_{\\Theta} \\Theta \\]\n\nWe propose LearnBPR, a stochastic gradient-descent algorithm based on bootstrap sampling of training triples:\n1. Procedure LearnBPR(\\( D_S, \\Theta \\))\n2. Initialize \\( \\Theta \\)\n3. Repeat\n4. Draw \\( (u, i, j) \\) from \\( D_S \\)\n5. \\( \\Theta \\leftarrow \\Theta + \\alpha \\cdot \\frac{e^{-\\hat{x}_{uij}}}{1+e^{-\\hat{x}_{uij}}} \\cdot \\frac{\\partial}{\\partial \\Theta} \\hat{x}_{uij} + \\lambda_{\\Theta} \\cdot \\Theta \\)\n6. Until convergence\n7. Return \\( \\hat{\\Theta} \\)\n\nwhere \\( \\alpha \\) is the learning rate.\n\n### 2.3 Applying BPR to Recommender Models\nWe define \\( \\hat{x}_{u i j}:=\\hat{x}_{u i}-\\hat{x}_{u j} \\), where \\( \\hat{x}_{u l} \\) is the prediction of the underlying model for user \\( u \\) and item \\( l \\).\n\n#### 2.3.1 Matrix Factorization\nThe prediction formula for matrix factorization is:\n\\[ \\hat{x}_{u i}=\\left< w_{u}, h_{i}\\right>=\\sum_{f=1}^{k} w_{u f} \\cdot h_{i f} \\]\nwhere \\( w_{u} \\in \\mathbb{R}^k \\) is the user feature vector, \\( h_{i} \\in \\mathbb{R}^k \\) is the item feature vector, and \\( k \\) is the latent dimension.\n\nThe derivatives for LearnBPR are:\n\\[ \\frac {\\partial }{\\partial \\theta }\\hat {x}_{uij}= \\begin{cases}h_{i f}-h_{j f} & if \\theta =w_{u f}, \\\\ w_{u f} & if \\theta =h_{i f}, \\\\ -w_{u f} & if \\theta =h_{j f}, \\\\ 0 & else \\end{cases} \\]\n\n#### 2.3.2 Adaptive k-Nearest-Neighbor\nThe prediction formula for item-based kNN is:\n\\[ \\hat{x}_{u i}=\\sum_{l \\in I_{v}^{+} \\Lambda l \\neq i} c_{i l} \\]\nwhere \\( c_{i l} \\) is the item similarity between \\( i \\) and \\( l \\).\n\nThe derivatives for LearnBPR are:\n\\[ \\frac{\\partial}{\\partial \\theta} \\hat{x}_{u i j}= \\begin{cases}+1 & if \\theta \\in\\left\\{c_{i l}, c_{l i}\\right\\} \\Lambda l \\in I_{u}^{+} \\Lambda l \\neq i, \\\\ -1 & if \\theta \\in\\left\\{c_{j l}, c_{l j}\\right\\} \\Lambda l \\in I_{u}^{+} \\Lambda l \\neq j, \\\\ 0 & else \\end{cases} \\]",
  "experiments": "# Experiment\n## 1. Datasets\nWe use two datasets of two different applications:\n1. **Rossmann dataset**: From an online shop. Contains the buying history of 10,000 users on 4,000 items. In total 426,612 purchases are recorded. The task is to predict a personalized list of the items the user wants to buy next.\n2. **Netflix DVD rental dataset**: Contains the rating behavior of users (explicit ratings 1-5 stars removed for implicit feedback task). We use a subsample of 10,000 users, 5,000 items containing 565,738 rating actions. Each user and item has at least 10 interactions.\n\n## 2. Evaluation Methodology\nWe use the leave-one-out evaluation scheme:\n1. For each user, randomly remove one action from \\( I_{u}^{+} \\) to form a disjoint train set \\( S_{train} \\) and test set \\( S_{test} \\).\n2. Models are learned on \\( S_{train} \\) and evaluated on \\( S_{test} \\) using average AUC:\n\\[ AUC=\\frac{1}{|U|} \\sum_{u} \\frac{1}{|E(u)|} \\sum_{(i, j) \\in E(u)} \\delta\\left(\\hat{x}_{u i}>\\hat{x}_{u j}\\right) \\]\nwhere \\( E(u):=\\{ (i,j)|(u,i)\\in S_{test}\\land (u,j)\\notin (S_{test}\\cup S_{train})\\} \\).\n\n3. All experiments are repeated 10 times with new train/test splits. Hyperparameters are optimized via grid search in the first round and kept constant thereafter.\n\n## 3. Compared Models\n1. **Matrix Factorization variants**:\n   - SVD-MF: Singular value decomposition based matrix factorization.\n   - WR-MF: Weighted regularized matrix factorization [5, 10].\n   - BPR-MF: Matrix factorization optimized with BPR-Opt and LearnBPR.\n2. **k-Nearest-Neighbor variants**:\n   - Cosine-kNN: Item-based kNN with cosine similarity.\n   - BPR-kNN: kNN optimized with BPR-Opt and LearnBPR.\n3. **Baselines**:\n   - most-popular: User-independent ranking based on item popularity.\n   - \\( np_{max} \\): Theoretical upper bound for non-personalized ranking.\n\n## 4. Main Results\n### 4.1 AUC Performance\nFigure 6 shows the AUC quality of all models on the two datasets. Key observations:\n1. The two BPR-optimized methods (BPR-MF, BPR-kNN) outperform all other methods in prediction quality.\n2. For matrix factorization models, BPR-MF clearly outperforms SVD-MF and WR-MF on both datasets. For example, on Netflix, a BPR-MF model with 8 dimensions achieves comparable quality to a WR-MF model with 128 dimensions.\n3. For kNN models, BPR-kNN outperforms Cosine-kNN.\n4. All personalized methods outperform the non-personalized upper bound \\( np_{max} \\).\n\n### 4.2 Convergence\nFigure 5 shows that LearnBPR converges much faster than user-wise stochastic gradient descent for BPR-MF on the Rossmann dataset.",
  "hyperparameter": "Learning rate α (used in LearnBPR gradient update); Regularization parameters λ_Θ (model-specific, controls the normal prior N(0, λ_Θ I)); Latent dimension k for Matrix Factorization (experiments tested dimensions including 8, 16, 32, 64, 128, with BPR-MF achieving good results at k=8 on Netflix dataset); Number of k for k-Nearest-Neighbor models. The paper mentions hyperparameters were optimized via grid search in the first experimental round and kept constant for remaining rounds, but does not specify exact recommended values for α and λ_Θ."
}