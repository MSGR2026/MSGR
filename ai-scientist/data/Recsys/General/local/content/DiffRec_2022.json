{
  "id": "DiffRec_2022",
  "paper_title": "Diffusion Recommender Model",
  "alias": "DiffRec",
  "year": 2022,
  "domain": "Recsys",
  "task": "GeneralRecommendation",
  "idea": "",
  "introduction": "# 1 INTRODUCTION\n\nGenerative models such as Generative Adversarial Networks (GANs) and Variational Auto-Encoders (VAEs) have been broadly utilized for personalized recommendation [19, 37, 50]. Generally speaking, generative recommender models learn the generative process to infer the user interaction probabilities over all non-interacted items. Such generative process typically assumes that users' interaction behaviors with items (e.g., clicks) are determined by some latent factors (e.g., user preference). Due to aligning with the real-world interaction generation procedure, generative recommender models have achieved significant success [19, 37].\n\nGenerative recommender models mainly fall into two groups:\n\n- GAN-based models utilize a generator to estimate users' interaction probabilities and leverage adversarial training to optimize the parameters [13, 37]. However, adversarial training is typically unstable, leading to unsatisfactory performance.  \n- VAEs-based models use an encoder to approximate the posterior distribution over latent factors and maximize the likelihood of observed interactions (Figure 1(a)) [19, 24]. While VAEs typically outperform GANs in recommendation, VAEs suffer from the trade-off between tractability and representation ability [14, 34]. Tractable and simple encoders might not well capture heterogeneous user preference while the posterior distribution of complex models is likely to be intractable [34].\n\nDiffusion Models (DMs) [10, 34] have achieved state-of-the-art results in image synthesis tasks [31], which alleviate the trade-off by gradually corrupting the images in a tractable forward process and learning the reverse reconstruction iteratively. As shown in Figure 1(b), DMs forwardly corrupt  \\(x_0\\)  with random noises step by step, and recover  \\(x_0\\)  from corrupted  \\(x_{T}\\)  iteratively. This forward process leads to a tractable posterior [34], and also opens the door to iteratively modeling complex distributions by flexible neural networks in the reverse generation. The objectives of recommender models align well with DMs since recommender models essentially infer the future interaction probabilities based on corrupted historical interactions (Figure 1(c)), where corruption implies that the interactions are noisy due to false-positive and false-negative items [32, 38]. As such, exploring DMs for recommendation has\n\n![](images/7540eb69cc367b09f2ab30145248331b4482141135887c68b68e60670738d63c.jpg)  \n(a) Illustration of VAE.\n\n![](images/91101b6f7e027424bc7951d9746b65b1f7ab6c2e26dea075d92fb290d6151bbe.jpg)  \n(c) Objective of recommender systems.\n\n![](images/70f532b40cd300cfc1d7d7ae344bddeb6fda82d1675e39709d56f0a3e1b8fb0b.jpg)\n\n![](images/be1ef56ff05b60840beb5bac292c95c85765686ecfe3b413365b3e83623833d9.jpg)  \n(b) Illustration of DiffRec.  \n(d) Illustration of L-DiffRec.  \nFigure 1: Illustration of VAE, DiffRec, the objective of recommender systems, and L-DiffRec.\n\ngreat potential to model the complex interaction generation more accurately with strong representation ability.\n\nWe propose a Diffusion Recommender Model named DiffRec, which infers users' interaction probabilities in a denoising manner. Technically, DiffRec gradually corrupts users' interaction histories by injecting scheduled Gaussian noises in the forward process, and then recovers original interactions from the corrupted interactions iteratively via a parameterized neural network. Nevertheless, we cannot directly graft the forward process in the image domain due to the necessity of generating personalized recommendations. To retain personalized information in users' corrupted interactions, we should avoid corrupting users' interaction histories into pure noises like in image synthesis. We thus significantly decrease the added noise scales in the forward process (see Section 3.4).\n\nTaking one step further, we handle two essential challenges in building generative models for recommendation: large-scale item prediction and temporal modeling. In detail, 1) generative models require extensive resource costs as predicting the interaction probabilities of all items simultaneously [19], limiting their application to large-scale item recommendation; and 2) generative models have to capture the temporal information in the interaction sequence, which is crucial for handling user preference shifts [48]. To this end, we further extend DiffRec to Latent DiffRec (named L-DiffRec) and Temporal DiffRec (named T-DiffRec).\n\n- L-DiffRec clusters items into groups, compresses the interaction vector over each group into a low-dimensional latent vector via a group-specific VAE, and conducts the forward and reverse diffusion processes in the latent space (Figure 1(d)). Owing to the clustering and latent diffusion, L-DiffRec significantly reduces the model parameters and memory costs, enhancing the ability of large-scale item prediction (see Section 3.5 and 4.3).  \n- T-DiffRec models the interaction sequence via a simple yet effective time-aware reweighting strategy. Intuitively, users' later interactions are assigned with larger weights, and then fed into DiffRec for training and inference (see Section 3.6 and 4.4).\n\nWe conduct extensive experiments on three representative datasets and compare DiffRec with various baselines under multiple settings (e.g., clean training, noisy training with natural or random noises, and temporal training), validating the superiority of our proposed DiffRec and two extensions. We release our code and data at https://github.com/YiyanXu/DiffRec.\n\nTo sum up, the contributions of this work are as follows.\n\n- We propose a novel Diffusion Recommender Model, a totally new recommender paradigm that points out a promising future direction for generative recommender models.  \n- We extend conventional Diffusion Models to reduce the resource costs for high-dimensional categorical predictions and enable the time-sensitive modeling of interaction sequences.  \n- We conduct substantial experiments on three datasets under various settings, demonstrating remarkable improvements of DiffRec with two extensions over the baselines.\n",
  "method": "# 3 DIFFUSION RECOMMENDER MODEL\n\nTo take advantage of the strong generation ability of DMs, we propose a novel DiffRec to predict users' future interaction probabilities from corrupted interactions. Given users' historical interactions, DiffRec gradually corrupts them by adding noises in a forward process, and then learns to recover original interactions iteratively. By such iterative denoising training, DiffRec can model complex interaction generation procedures and mitigate the effects of noisy interactions. Eventually, the recovered interaction probabilities are used to rank and recommend non-interacted items. In addition, we present two extensions of DiffRec for large-scale item prediction and temporal modeling to facilitate the use of DiffRec in practical recommender systems.\n\n## 3.1 Forward and Reverse Processes\n\nAs shown in Figure 2, DiffRec has two critical processes: 1) a forward process corrupts users' interaction histories by adding Gaussian noises step by step, and 2) a reverse process gradually learns to denoise and output the interaction probabilities.\n\n- Forward process. Given a user  \\(u\\)  with the interaction history over an item set  \\(I\\) , i.e.,  \\(x_{u} = [x_{u}^{1}, x_{u}^{2}, \\ldots, x_{u}^{|I|}]\\)  where  \\(x_{u}^{i} = 1\\)  or 0 implies whether user  \\(u\\)  has interacted with item  \\(i\\)  or not, we can set  \\(x_{0} = x_{u}\\)  as the initial state and parameterize the transition by\n\n\\[\nq \\left(\\boldsymbol {x} _ {t} \\mid \\boldsymbol {x} _ {t - 1}\\right) = \\mathcal {N} \\left(\\boldsymbol {x} _ {t}; \\sqrt {1 - \\beta_ {t}} \\boldsymbol {x} _ {t - 1}, \\beta_ {t} \\boldsymbol {I}\\right), \\tag {2}\n\\]\n\nwhere  \\(\\beta_{t} \\in (0,1)\\)  controls the Gaussian noise scales added at each step  \\(t\\) . Thanks to the reparameterization trick [10] and the additivity of two independent Gaussian noises [10, 23], we can directly obtain  \\(\\pmb{x}_{t}\\)  from  \\(\\pmb{x}_0\\) . Formally,\n\n\\[\nq \\left(\\boldsymbol {x} _ {t} \\mid \\boldsymbol {x} _ {0}\\right) = \\mathcal {N} \\left(\\boldsymbol {x} _ {t}; \\sqrt {\\bar {\\alpha} _ {t}} \\boldsymbol {x} _ {0}, (1 - \\bar {\\alpha} _ {t}) \\boldsymbol {I}\\right), \\tag {3}\n\\]\n\nwhere  \\(\\alpha_{t} = 1 - \\beta_{t}\\) ,  \\(\\bar{\\alpha}_{t} = \\prod_{t^{\\prime} = 1}^{t}\\alpha_{t^{\\prime}}\\) , and then we can reparameterize  \\(x_{t} = \\sqrt{\\bar{\\alpha}_{t}} x_{0} + \\sqrt{1 - \\bar{\\alpha}_{t}}\\epsilon\\)  with  \\(\\epsilon \\sim \\mathcal{N}(0,I)\\) . To regulate the added noises in  \\(x_{1:T}\\) , we design a linear noise schedule for  \\(1 - \\bar{\\alpha}_{t}\\) , i.e.,\n\n\\[\n1 - \\bar {\\alpha} _ {t} = s \\cdot \\left[ \\alpha_ {\\min } + \\frac {t - 1}{T - 1} \\left(\\alpha_ {\\max } - \\alpha_ {\\min }\\right) \\right], \\quad t \\in \\{1, \\dots , T \\}, \\tag {4}\n\\]\n\nwhere a hyper-parameter  \\(s \\in [0,1]\\)  controls the noise scales, and two hyper-parameters  \\(\\alpha_{\\min} < \\alpha_{\\max} \\in (0,1)\\)  indicating the upper and lower bounds of the added noises.\n\n- **Reverse process.** Starting from  \\(x_{T}\\) , the reverse process gradually recovers users' interactions by the denoising transition step:\n\n\\[\np _ {\\theta} \\left(\\boldsymbol {x} _ {t - 1} \\mid \\boldsymbol {x} _ {t}\\right) = \\mathcal {N} \\left(\\boldsymbol {x} _ {t - 1}; \\boldsymbol {\\mu} _ {\\theta} \\left(\\boldsymbol {x} _ {t}, t\\right), \\Sigma_ {\\theta} \\left(\\boldsymbol {x} _ {t}, t\\right)\\right), \\tag {5}\n\\]\n\nwhere  \\(\\pmb{\\mu}_{\\theta}(\\pmb{x}_t,t)\\)  and  \\(\\Sigma_{\\theta}(\\pmb{x}_t,t)\\)  are the Gaussian parameters outputted by any neural networks with learnable parameters  \\(\\theta\\)\n\n## 3.2 DiffRec Training\n\nTo learn  \\(\\theta\\) , DiffRec aims to maximize the ELBO of observed user interactions  \\(x_0\\) :\n\n\\[\n\\begin{array}{l} \\log p \\left(\\boldsymbol {x} _ {0}\\right) \\geq \\underbrace {\\mathbb {E} _ {q \\left(\\boldsymbol {x} _ {1} \\mid \\boldsymbol {x} _ {0}\\right)} \\left[ \\log p _ {\\theta} \\left(\\boldsymbol {x} _ {0} \\mid \\boldsymbol {x} _ {1}\\right) \\right]} _ {\\text {(r e c o n s t r u c t i o n t e r m)}} \\\\ - \\sum_ {t = 2} ^ {T} \\underbrace {\\mathbb {E} _ {q \\left(\\boldsymbol {x} _ {t} \\mid \\boldsymbol {x} _ {0}\\right)} \\left[ D _ {\\mathrm {K L}} \\left(q \\left(\\boldsymbol {x} _ {t - 1} \\mid \\boldsymbol {x} _ {t}, \\boldsymbol {x} _ {0}\\right) \\| p _ {\\theta} \\left(\\boldsymbol {x} _ {t - 1} \\mid \\boldsymbol {x} _ {t}\\right)\\right) \\right]} _ {\\text {(d e n o i s i n g m a t c h i n g t e r m)}}. \\tag {6} \\\\ \\end{array}\n\\]\n\nNote that the prior matching term in Eq. (1) is omitted as it is a constant. Besides, the reconstruction term measures the recovery probability of  \\(x_0\\)  while denoising matching terms regulate the recovery of  \\(x_{t-1}\\)  with  \\(t\\)  varying from 2 to  \\(T\\)  in the reverse process. So far, the optimization lies in maximizing the reconstruction term and denoising matching terms.\n\n- Estimation of denoising matching terms. The denoising matching term forces  \\(p_{\\theta}(\\pmb{x}_{t - 1}|\\pmb{x}_t)\\)  to approximate the tractable distribution  \\(q(\\pmb{x}_{t - 1}|\\pmb{x}_t,\\pmb{x}_0)\\)  via KL divergence. Through Bayes rules,  \\(q(\\pmb{x}_{t - 1}|\\pmb{x}_t,\\pmb{x}_0)\\)  can be rewritten as the following closed form [23]:\n\n\\[\nq \\left(\\boldsymbol {x} _ {t - 1} \\mid \\boldsymbol {x} _ {t}, \\boldsymbol {x} _ {0}\\right) \\propto \\mathcal {N} \\left(\\boldsymbol {x} _ {t - 1}; \\tilde {\\boldsymbol {\\mu}} \\left(\\boldsymbol {x} _ {t}, \\boldsymbol {x} _ {0}, t\\right), \\sigma^ {2} (t) \\boldsymbol {I}\\right), \\text {w h e r e} \\tag {7}\n\\]\n\n\\[\n\\left\\{ \\begin{array}{l} \\tilde {\\mu} \\left(\\boldsymbol {x} _ {t}, \\boldsymbol {x} _ {0}, t\\right) = \\frac {\\sqrt {\\alpha_ {t}} \\left(1 - \\bar {\\alpha} _ {t - 1}\\right)}{1 - \\bar {\\alpha} _ {t}} \\boldsymbol {x} _ {t} + \\frac {\\sqrt {\\bar {\\alpha} _ {t - 1}} \\left(1 - \\alpha_ {t}\\right)}{1 - \\bar {\\alpha} _ {t}} \\boldsymbol {x} _ {0}, \\\\ \\sigma^ {2} (t) = \\frac {(1 - \\alpha_ {t}) (1 - \\bar {\\alpha} _ {t - 1})}{1 - \\bar {\\alpha} _ {t}}. \\end{array} \\right. \\tag {8}\n\\]\n\n\\(\\tilde{\\mu} (\\pmb {x}_t,\\pmb {x}_0,t)\\)  and  \\(\\sigma^2 (t)\\pmb{I}\\)  are the mean and covariance of  \\(q(\\pmb{x}_{t - 1}|\\pmb {x}_t,\\pmb {x}_0)\\)  derived from Eq. (2) and Eq. (3) [10]. Besides, to keep training stability and simplify the calculation, we ignore the learning of  \\(\\Sigma_{\\theta}(\\pmb {x}_t,t)\\)  in  \\(p_{\\theta}(\\pmb{x}_{t - 1}|\\pmb {x}_t)\\)  and directly set  \\(\\Sigma_{\\theta}(\\pmb {x}_t,t) = \\sigma^2 (t)\\pmb{I}\\)  by following [10]. Thereafter, the denoising matching term  \\(\\mathcal{L}_t\\)  at step  \\(t\\)  can be calculated by\n\n\\[\n\\begin{array}{l} \\mathcal {L} _ {t} \\triangleq \\mathbb {E} _ {q (\\boldsymbol {x} _ {t} | \\boldsymbol {x} _ {0})} \\left[ D _ {\\mathrm {K L}} \\left(q \\left(\\boldsymbol {x} _ {t - 1} | \\boldsymbol {x} _ {t}, \\boldsymbol {x} _ {0}\\right) \\parallel p _ {\\theta} \\left(\\boldsymbol {x} _ {t - 1} | \\boldsymbol {x} _ {t}\\right)\\right) \\right] \\\\ = \\mathbb {E} _ {q \\left(\\boldsymbol {x} _ {t} \\mid \\boldsymbol {x} _ {0}\\right)} \\left[ \\frac {1}{2 \\sigma^ {2} (t)} \\left[ \\| \\boldsymbol {\\mu} _ {\\theta} \\left(\\boldsymbol {x} _ {t}, t\\right) - \\tilde {\\boldsymbol {\\mu}} \\left(\\boldsymbol {x} _ {t}, \\boldsymbol {x} _ {0}, t\\right) \\| _ {2} ^ {2} \\right] \\right], \\tag {9} \\\\ \\end{array}\n\\]\n\nwhich pushes  \\(\\pmb{\\mu}_{\\theta}(\\pmb{x}_t,t)\\)  to be close to  \\(\\tilde{\\pmb{\\mu}} (\\pmb {x}_t,\\pmb {x}_0,t)\\) . Following Eq. (8), we can similarly factorize  \\(\\pmb{\\mu}_{\\theta}(\\pmb {x}_t,t)\\)  via\n\n\\[\n\\boldsymbol {\\mu} _ {\\theta} \\left(\\boldsymbol {x} _ {t}, t\\right) = \\frac {\\sqrt {\\alpha_ {t}} \\left(1 - \\bar {\\alpha} _ {t - 1}\\right)}{1 - \\bar {\\alpha} _ {t}} \\boldsymbol {x} _ {t} + \\frac {\\sqrt {\\bar {\\alpha} _ {t - 1}} \\left(1 - \\alpha_ {t}\\right)}{1 - \\bar {\\alpha} _ {t}} \\hat {\\boldsymbol {x}} _ {\\theta} \\left(\\boldsymbol {x} _ {t}, t\\right), \\tag {10}\n\\]\n\nwhere  \\(\\hat{\\pmb{x}}_{\\theta}(\\pmb{x}_t,t)\\)  is the predicted  \\(\\pmb{x}_0\\)  based on  \\(\\pmb{x}_t\\)  and  \\(t\\) . Furthermore, by substituting Eq. (10) and Eq. (8) into Eq. (9), we have\n\n\\[\n\\mathcal {L} _ {t} = \\mathbb {E} _ {q (\\boldsymbol {x} _ {t} | \\boldsymbol {x} _ {0})} \\left[ \\frac {1}{2} \\left(\\frac {\\bar {\\alpha} _ {t - 1}}{1 - \\bar {\\alpha} _ {t - 1}} - \\frac {\\bar {\\alpha} _ {t}}{1 - \\bar {\\alpha} _ {t}}\\right) \\| \\hat {\\boldsymbol {x}} _ {\\theta} (\\boldsymbol {x} _ {t}, t) - \\boldsymbol {x} _ {0} \\| _ {2} ^ {2} \\right], \\tag {11}\n\\]\n\nwhich regulates  \\(\\hat{x}_{\\theta}(\\pmb {x}_t,t)\\)  to predict  \\(\\pmb{x_0}\\)  accurately.\n\nTo summarize, for estimating denoising matching terms, we need to implement  \\(\\hat{x}_{\\theta}(\\pmb{x}_t,t)\\)  by neural networks and calculate Eq. (11). Following MultiVAE [19], we also instantiate  \\(\\hat{x}_{\\theta}(\\cdot)\\)  via a MultiLayer Perceptron (MLP) that takes  \\(\\pmb{x}_t\\)  and the step embedding of  \\(t\\)  as inputs to predict  \\(\\pmb{x}_0\\) .\n\n### Algorithm 1 DiffRec Training\n\nInput: all users' interactions  \\(\\bar{X}\\)  and randomly initialized  \\(\\theta\\) . 1: repeat\n\n2: Sample a batch of users' interactions  \\(X \\subset \\bar{X}\\) .  \n3: for all  \\(x_0 \\in X\\)  do  \n4: Sample  \\(t\\sim \\mathcal{U}(1,T)\\)  or  \\(t\\sim p_t,\\epsilon \\sim \\mathcal{N}(\\mathbf{0},I)\\)  \n5: Compute  \\(\\pmb{x}_t\\)  given  \\(\\pmb{x}_0, t\\) , and  \\(\\pmb{\\epsilon}\\)  via  \\(q(\\pmb{x}_t | \\pmb{x}_0)\\)  in Eq. (3);  \n6: Compute  \\(\\mathcal{L}_t\\)  by Eq. (11) if  \\(t > 1\\) , otherwise by Eq. (12);  \n7: Take gradient descent step on  \\(\\nabla_{\\theta}\\mathcal{L}_t\\)  to optimize  \\(\\theta\\)  \n8: until converged\n\nOutput: optimized  \\(\\theta\\)\n\n- Estimation of the reconstruction term. We define  \\(\\mathcal{L}_1\\)  as the negative of the reconstruction term in Eq. (6), and calculate  \\(\\mathcal{L}_1\\)  by\n\n\\[\n\\begin{array}{l} \\mathcal {L} _ {1} \\triangleq - \\mathbb {E} _ {q \\left(\\boldsymbol {x} _ {1} \\mid \\boldsymbol {x} _ {0}\\right)} \\left[ \\log p _ {\\theta} \\left(\\boldsymbol {x} _ {0} \\mid \\boldsymbol {x} _ {1}\\right) \\right] \\\\ = \\mathbb {E} _ {q \\left(\\boldsymbol {x} _ {1} \\mid \\boldsymbol {x} _ {0}\\right)} \\left[ \\| \\hat {\\boldsymbol {x}} _ {\\theta} (\\boldsymbol {x} _ {1}, 1) - \\boldsymbol {x} _ {0} \\| _ {2} ^ {2} \\right], \\tag {12} \\\\ \\end{array}\n\\]\n\nwhere we estimate the Gaussian log-likelihood  \\(\\log p(x_0|x_1)\\)  by unweighted  \\(-||\\hat{x}_{\\theta}(x_1,1) - x_0||_2^2\\)  as discussed in [19].\n\n- Optimization. According to Eq. (11) and Eq. (12), ELBO in Eq. (6) can be formulated as  \\(-\\mathcal{L}_1 - \\sum_{t=2}^{T}\\mathcal{L}_t\\) . Therefore, to maximize the ELBO, we can optimize  \\(\\theta\\)  in  \\(\\hat{x}_{\\theta}(x_t,t)\\)  by minimizing  \\(\\sum_{t=1}^{T}\\mathcal{L}_t\\) . In the practical implementation, we uniformly sample step  \\(t\\)  to optimize an expectation  \\(\\mathcal{L}(x_0,\\theta)\\)  over  \\(t \\sim \\mathcal{U}(1,T)\\) . Formally,\n\n\\[\n\\mathcal {L} \\left(\\boldsymbol {x} _ {0}, \\theta\\right) = \\mathbb {E} _ {t \\sim \\mathcal {U} (1, T)} \\mathcal {L} _ {t}. \\tag {13}\n\\]\n\nThe training procedure of DiffRec is presented in Algorithm 1.\n\n- Importance sampling. Since the optimization difficulty might vary across different steps, we consider using importance sampling [25] to emphasize the learning over the steps with large loss values of  \\(\\mathcal{L}_t\\) . Formally, we use a new sampling strategy for  \\(t\\) :\n\n\\[\n\\mathcal {L} ^ {\\triangle} \\left(\\boldsymbol {x} _ {0}, \\theta\\right) = \\mathbb {E} _ {t \\sim p t} \\left[ \\frac {\\mathcal {L} _ {t}}{p t} \\right], \\tag {14}\n\\]\n\nwhere  \\(p_t \\propto \\sqrt{\\mathbb{E}\\left[\\mathcal{L}_t^2\\right]} / \\sqrt{\\sum_{t'=1}^{T} \\mathbb{E}\\left[\\mathcal{L}_{t'}^2\\right]}\\)  denotes the sampling probability and  \\(\\sum_{t=1}^{T} p_t = 1\\) . We here calculate  \\(\\mathbb{E}\\left[\\mathcal{L}_t^2\\right]\\)  by collecting ten  \\(\\mathcal{L}_t\\)  values during training and taking the average. Before acquiring enough  \\(\\mathcal{L}_t\\) , we still adopt the uniform sampling. Intuitively, the steps with large  \\(\\mathcal{L}_t\\)  values will be more easily sampled.\n\n## 3.3 DiffRec Inference\n\nIn image synthesis tasks, DMs draw random Gaussian noises for reverse generation, possibly guided by the gradients from a pretrained classifier or other signals such as textual queries. However, corrupting interactions into pure noises will hurt personalized user preference in recommendation (see empirical evidence in Section 4.2.3). It is also non-trivial to design additional classifiers or guidance signals. As such, we propose a simple inference strategy to align with DiffRec training for interaction prediction.\n\nSpecifically, DiffRec firstly corrupts  \\(x_0\\)  by  \\(x_0 \\to x_1 \\to \\dots \\to x_{T'}\\)  for  \\(T'\\)  steps in the forward process, and then sets  \\(\\hat{x}_T = x_{T'}\\)  to execute reverse denoising  \\(\\hat{x}_T \\to \\hat{x}_{T-1} \\to \\dots \\to \\hat{x}_0\\)  for  \\(T\\)  steps. The reverse denoising ignores the variance (like in MultiVAE [19]) and utilize  \\(\\hat{x}_{t-1} = \\mu_\\theta(\\hat{x}_t, t)\\)  via Eq. (10) for deterministic inference. In particular, in considering 1) the collected user interactions are\n\n### Algorithm 2 DiffRec Inference\n\nInput:  \\(\\theta\\)  and the interaction history  \\(x_0\\)  of user  \\(u\\) .\n\n1: Sample  \\(\\epsilon \\sim \\mathcal{N}(0,I)\\)  \n2: Compute  \\(\\pmb{x}_{T'}\\)  given  \\(\\pmb{x}_0, T'\\) , and  \\(\\pmb{\\epsilon}\\)  via Eq. (3), and set  \\(\\hat{\\pmb{x}}_T = \\pmb{x}_{T'}\\) .  \n3: for  \\(t = T, \\dots, 1\\)  do  \n4:  \\(\\hat{\\pmb{x}}_{t - 1} = \\pmb{\\mu}_{\\theta}(\\hat{\\pmb{x}}_t,t)\\)  calculated from  \\(\\hat{\\pmb{x}}_t\\)  and  \\(\\hat{\\pmb{x}}_{\\theta}(\\cdot)\\)  via Eq. (10);\n\nOutput: the interaction probabilities  \\(\\hat{x}_0\\)  for user  \\(u\\) .\n\nnaturally noisy due to false-positive and false-negative interactions [38, 39, 41] and 2) retaining personalized information, we reduce the added noises in the forward process by setting  \\(T' < T\\) . Finally, we use  \\(\\hat{x}_0\\)  for item ranking and recommend top-ranked items. The inference procedure is summarized in Algorithm 2.\n\n## 3.4 Discussion\n\nUnlike image synthesis, we highlight two special points of DiffRec.\n\n- Personalized recommendation. 1) During training, we do not corrupt users' interactions into pure noises for retaining some personalized information; that is, the latent variable  \\(x_{T}\\)  does not approach the standard Gaussian noises that lose extensive personalized characteristics. It is similar to the selection of  \\(\\beta\\)  in MultiVAE to control the strength of the prior constraint, i.e., the KL divergence (see Section 2.2.2 in [19]). In practice, We reduce  \\(s\\)  and  \\(\\alpha_{\\mathrm{max}}\\)  in the noise schedule of Eq. (4) to lessen the noises. And 2) we also decrease the added noises for inference by controlling  \\(T' < T\\)  by considering the natural noises in user interactions.  \n-  \\(x_0\\) -ELBO. DiffRec is optimized by predicting  \\(x_0\\)  instead of  \\(\\epsilon\\)  like in Section 2 because: 1) the key objective of recommendation is to predict  \\(\\hat{x}_0\\)  for item ranking, and thus  \\(x_0\\) -ELBO is intuitively more appropriate for our task; and 2) randomly sampled  \\(\\epsilon \\sim \\mathcal{N}(0, I)\\)  is unsteady and forcing an MLP to estimate such a  \\(\\epsilon\\)  is more challenging (see empirical analysis in Section 4.2.3).\n\n## 3.5 Latent Diffusion\n\nGenerative models, such as MultiVAE and DiffRec, predict the interaction probabilities  \\(\\hat{x}_0\\)  over all items simultaneously, requiring extensive resources and limiting large-scale item prediction in industry. To reduce the costs, we offer L-DiffRec, which clusters items for dimension compression via multiple VAEs and conducts diffusion processes in the latent space as shown in Figure 3.\n\n- Encoding for compression. Given an item set  \\(I\\) , L-DiffRec first adopts  \\(k\\) -means to cluster items into  \\(C\\)  categories  \\(\\{\\mathcal{I}_1, \\mathcal{I}_2, \\dots, \\mathcal{I}_C\\}\\)  based on item representations (e.g., trained item embeddings from LightGCN). L-DiffRec then divides user interaction vector  \\(\\boldsymbol{x}_0\\)  into  \\(C\\)  parts according to the clusters, i.e.,  \\(\\boldsymbol{x}_0 \\rightarrow \\{\\boldsymbol{x}_0^c\\}_{c=1}^C\\) , where  \\(\\boldsymbol{x}_0^c\\)  represents the interactions of user  \\(u\\)  over  \\(\\mathcal{I}_c\\) . Afterwards, we use a variational encoder parameterized by  \\(\\phi_c\\)  to compress each  \\(\\boldsymbol{x}_0^c\\)  to a low-dimensional vector  \\(\\boldsymbol{z}_0^c\\) , where the encoder predicts  \\(\\mu_{\\phi_c}\\)  and  \\(\\sigma_{\\phi_c}^2 \\boldsymbol{I}\\)  as the mean and covariance of the variational distribution  \\(q_{\\phi_c}(z_0^c | \\boldsymbol{x}_0^c) = \\mathcal{N}(z_0^c; \\mu_{\\phi_c}(\\boldsymbol{x}_0^c), \\sigma_{\\phi_c}^2(\\boldsymbol{x}_0^c) \\boldsymbol{I})\\) . The clustering can lessen resource costs since it can 1) achieve parallel calculation of different categories and 2) break the full connections among the multiple encoders to save parameters compared to vanilla VAE [19].  \n- Latent diffusion. By concatenating  \\(\\{z_0^c\\}_{c=1}^C\\) , we can obtain the compressed  \\(z_0\\)  for diffusion. Like DiffRec training, we replace  \\(x_0\\)\n\n![](images/744e1dc10890256455a2e0fb97b7e0df1857751036dd3ec416a2c35dc1af2ff5.jpg)  \nFigure 3: Illustration of L-DiffRec.  \\(z_0 = \\mu + \\sigma \\odot \\epsilon\\) , where  \\(\\epsilon \\sim \\mathcal{N}(0, I)\\) . L-DiffRec clusters items for compression via multiple VAEs and conducts latent diffusion.\n\nwith  \\(z_0\\)  to do the forward and reverse processes in the latent space. Similar to Eq. (13), we have the optimization loss as  \\(\\mathcal{L}(z_0,\\theta) = \\mathbb{E}_{t\\sim \\mathcal{U}(1,T)}\\mathcal{L}_t\\) , where  \\(\\theta\\)  marks the parameters of the denoising MLP.\n\n- Decoding. As shown in Figure 3, we split the reconstructed  \\(\\hat{z}_0\\)  from the reverse process into  \\(\\{\\hat{z}_0^c\\}_{c=1}^C\\)  according to item clusters. Each  \\(\\hat{z}_0^c\\)  is then fed into a separate decoder parameterized by  \\(\\psi_c\\)  to predict  \\(\\hat{x}_0\\)  via  \\(p_{\\psi_c}(\\hat{x}_0^c|\\hat{z}_0^c)\\) , which is similar to MultiVAE [19].  \n- Training. Intuitively, the encoder  \\(q_{\\phi_c}\\)  and decoder  \\(p_{\\psi_c}\\)  jointly constitute a VAE that bridges the interaction space and the latent space. Following MultiVAE [19], the set of VAEs with  \\(\\phi = \\{\\phi_c\\}_{c=1}^C\\)  and  \\(\\psi = \\{\\psi_c\\}_{c=1}^C\\)  could be optimized by:\n\n\\[\n\\begin{array}{l} \\mathcal {L} _ {v} \\left(\\boldsymbol {x} _ {0}, \\phi , \\psi\\right) = \\sum_ {c = 1} ^ {C} \\left[ \\mathbb {E} _ {\\boldsymbol {q} _ {\\phi_ {c}} \\left(\\boldsymbol {z} _ {0} ^ {c} \\mid \\boldsymbol {x} _ {0} ^ {c}\\right)} \\left[ \\log p _ {\\psi_ {c}} \\left(\\boldsymbol {x} _ {0} ^ {c} \\mid \\boldsymbol {z} _ {0} ^ {c}\\right) \\right] \\right. \\tag {15} \\\\ - \\gamma \\cdot D _ {\\mathrm {K L}} \\left(q _ {\\phi_ {c}} \\left(\\boldsymbol {z} _ {0} ^ {c} | \\boldsymbol {x} _ {0} ^ {c}\\right) | | p \\left(\\boldsymbol {z} _ {0} ^ {c}\\right)\\right), \\\\ \\end{array}\n\\]\n\nwhere  \\(\\gamma\\)  is to control the strength of KL regularization. Subsequently, combining the loss of diffusion and VAEs, we have  \\(\\mathcal{L}_v(x_0,\\phi ,\\psi) + \\lambda \\cdot \\mathcal{L}(z_0,\\theta)\\)  for L-DiffRec optimization, where the hyper-parameter  \\(\\lambda\\)  ensures the two terms in the same magnitude.\n\n- Inference. For inference, L-DiffRec first splits  \\(\\pmb{x}_0\\)  into  \\(\\{x_0^c\\}_{c=1}^C\\) , and then compresses each  \\(x_0^c\\)  into a deterministic variable  \\(z_0^c = \\mu_{\\phi_c}(x_0^c)\\)  without considering variance [19]. After that, L-DiffRec concatenates  \\(\\{z_0^c\\}_{c=1}^C\\)  into  \\(z_0\\)  for diffusion like DiffRec. Finally, by feeding the reconstructed  \\(\\hat{z}_0\\)  into the decoders, we will obtain  \\(\\hat{x}_0\\)  for item ranking and generate top-K recommendations.\n\n## 3.6 Temporal Diffusion\n\nSince user preference might shift over time, it is crucial to capture temporal information during DiffRec learning. Assuming that more recent interactions can better represent users' current preferences, we propose a time-aware reweighting strategy to assign larger weights to users' later interactions.\n\nFormally, for user  \\(u\\)  with  \\(M\\)  interacted items, the interaction time is available and the interaction sequence is formulated as  \\(S = \\{i_1, i_2, \\ldots, i_M\\}\\) , where  \\(i_m\\)  denotes the ID of the  \\(m\\) -th interacted item. We define the weights of interacted items  \\(w = [w_1, w_2, \\ldots, w_M]\\)  via a time-aware linear schedule:  \\(w_m = w_{\\min} + \\frac{m - 1}{M - 1} (w_{\\max} - w_{\\min})\\) , where the two hyper-parameters  \\(w_{\\min} < w_{\\max} \\in (0, 1]\\)  represent the lower and upper bounds of interaction weights. Thereafter, the interaction history  \\(x_0\\)  of user  \\(u\\)  is reweighted as  \\(\\bar{x}_0 = x_0 \\odot \\bar{w}\\) , where\n\nTable 1: Statistics of three datasets under two different settings, where \"C\" and \"N\" represent clean training and natural noise training, respectively. \"Int.\" denotes interactions.  \n\n<table><tr><td></td><td>#User</td><td>#Item (C)</td><td>#Int. (C)</td><td>#Item (N)</td><td>#Int. (N)</td></tr><tr><td>Amazon-book</td><td>108,822</td><td>94,949</td><td>3,146,256</td><td>178,181</td><td>3,145,223</td></tr><tr><td>Yelp</td><td>54,574</td><td>34,395</td><td>1,402,736</td><td>77,405</td><td>1,471,675</td></tr><tr><td>ML-1M</td><td>5,949</td><td>2,810</td><td>571,531</td><td>3,494</td><td>618,297</td></tr></table>\n\n\\(\\bar{\\pmb{w}}\\in \\mathbb{R}^{|\\mathcal{T}|}\\)  is the weight vector calculated by  \\(\\pmb{w}\\) , i.e.,\n\n\\[\n\\bar {\\boldsymbol {w}} [ i ] = \\left\\{ \\begin{array}{l l} \\boldsymbol {w} [ \\operatorname {I d x} (i) ], & \\text {i f} i \\in S \\\\ 0, & \\text {e l s e} \\end{array} \\right. \\tag {16}\n\\]\n\nwhere  \\(\\mathrm{Idx}(i)\\)  denotes the index of item  \\(i\\)  in the interaction sequence  \\(S\\)  of user  \\(u\\) . By feeding the reweighted interaction history  \\(\\bar{x}_0\\)  into DiffRec and L-DiffRec, we will obtain T-DiffRec and LT-DiffRec using temporal information, respectively.\n",
  "experiments": "# 4 EXPERIMENTS\n\nIn this section, we conduct extensive experiments on three real-world datasets to answer the following research questions:\n\n- RQ1: How does our DiffRec perform compared to the baselines under various experimental settings and how do the designs of DiffRec (e.g., importance sampling, the inference step  \\(T'\\) , and the reduced noise scales) affect the performance?  \n- RQ2: How does L-DiffRec perform regarding the recommendation accuracy and resource costs?  \n- RQ3: Can T-DiffRec surpass sequential recommender models when interaction timestamps are available for training?\n\n## 4.1 Experimental Settings\n\n4.1.1 Datasets. We conduct experiments on three publicly available datasets in different scenarios. 1) Amazon-book \\(^3\\)  is from the Amazon review datasets, which covers rich user interactions with extensive books. 2) Yelp \\(^4\\)  is a representative business dataset containing user reviews for different restaurants. 3) ML-1M \\(^5\\)  is a popular benchmark dataset with user ratings on movies.\n\nFor all datasets, we first sort all interactions chronologically according to the timestamps. Thereafter, we consider three different training settings as follows. 1) Clean training discards user interactions with ratings  \\(< 4\\) , and then splits the sorted interactions into training, validation, and testing sets with the ratio of 7:2:1. 2) Noisy training keeps the same testing set of clean training, but adds some noisy interactions, including natural noises (i.e., the interactions with ratings  \\(< 4\\) ) and randomly sampled interactions into the training and validation sets. Note that we keep the numbers of noisy training and validation interactions on a similar scale as clean training for a fair comparison. 3) Temporal training: to evaluate the effectiveness of temporal modeling, we additionally consider using timestamps for training, i.e., modeling the user interaction sequences like sequential recommender models. The testing set is also the same as clean and noisy training for a fair comparison. The dataset statistics are summarized in Table 1.\n\nTable 2: Overall performance comparison between the baselines and DiffRec under clean training on three datasets. The best results are highlighted in bold and the second-best results are underlined. % Improve. represents the relative improvements of DiffRec over the best baseline results. * implies the improvements over the best baseline are statistically significant (p-value < 0.05) under one-sample t-tests.  \n\n<table><tr><td rowspan=\"2\">Methods</td><td colspan=\"4\">Amazon-book</td><td colspan=\"4\">Yelp</td><td colspan=\"4\">ML-1M</td></tr><tr><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td></tr><tr><td>MF</td><td>0.0437</td><td>0.0689</td><td>0.0264</td><td>0.0339</td><td>0.0341</td><td>0.0560</td><td>0.0210</td><td>0.0276</td><td>0.0876</td><td>0.1503</td><td>0.0749</td><td>0.0966</td></tr><tr><td>LightGCN</td><td>0.0534</td><td>0.0822</td><td>0.0325</td><td>0.0411</td><td>0.0540</td><td>0.0904</td><td>0.0325</td><td>0.0436</td><td>0.0987</td><td>0.1707</td><td>0.0833</td><td>0.1083</td></tr><tr><td>CDAE</td><td>0.0538</td><td>0.0737</td><td>0.0361</td><td>0.0422</td><td>0.0444</td><td>0.0703</td><td>0.0280</td><td>0.0360</td><td>0.0991</td><td>0.1705</td><td>0.0829</td><td>0.1078</td></tr><tr><td>MultiDAE</td><td>0.0571</td><td>0.0855</td><td>0.0357</td><td>0.0442</td><td>0.0522</td><td>0.0864</td><td>0.0316</td><td>0.0419</td><td>0.0995</td><td>0.1753</td><td>0.0803</td><td>0.1067</td></tr><tr><td>MultiDAE++</td><td>0.0580</td><td>0.0864</td><td>0.0363</td><td>0.0448</td><td>0.0544</td><td>0.0909</td><td>0.0328</td><td>0.0438</td><td>0.1009</td><td>0.1771</td><td>0.0815</td><td>0.1079</td></tr><tr><td>MultiVAE</td><td>0.0628</td><td>0.0935</td><td>0.0393</td><td>0.0485</td><td>0.0567</td><td>0.0945</td><td>0.0344</td><td>0.0458</td><td>0.1007</td><td>0.1726</td><td>0.0825</td><td>0.1076</td></tr><tr><td>CODIGEM6</td><td>0.0300</td><td>0.0478</td><td>0.0192</td><td>0.0245</td><td>0.0470</td><td>0.0775</td><td>0.0292</td><td>0.0385</td><td>0.0972</td><td>0.1699</td><td>0.0837</td><td>0.1087</td></tr><tr><td>DiffRec</td><td>0.0695*</td><td>0.1010*</td><td>0.0451*</td><td>0.0547*</td><td>0.0581*</td><td>0.0960*</td><td>0.0363*</td><td>0.0478*</td><td>0.1058*</td><td>0.1787*</td><td>0.0901*</td><td>0.1148*</td></tr><tr><td>% Improve.</td><td>10.67%</td><td>8.02%</td><td>14.76%</td><td>12.78%</td><td>2.47%</td><td>1.59%</td><td>5.52%</td><td>4.37%</td><td>4.86%</td><td>0.90%</td><td>9.21%</td><td>6.69%</td></tr></table>\n\n4.1.2 Baselines. We compare DiffRec with competitive baselines, including generative methods, and non-generative methods.\n\n- MF [30] is one of the most representative collaborative filtering methods based on matrix factorization.  \n- LightGCN [7] learns user and item representations via the linear neighborhood aggregation on graph convolution networks.  \n- CDAE [47] trains an Auto-Encoder (AE) to recover the original user interactions from the randomly corrupted interactions.  \n- MultiDAE [19] uses dropout to corrupt the interactions and recover them via an AE with the multinomial likelihood.  \n- MultiDAE++ is designed by us by adding noises to corrupt interactions similar to DiffRec and training a MultiDAE to recover clean interactions in a single decoding step. The added noises in MultiDAE++ are the same as DiffRec while DiffRec learns to denoise little by little in the reverse process.  \n- MultiVAE [19] utilizes VAEs to model the interaction generation process, where the posterior is approximated by an encoder.  \n- CODIGEM [36] is a generative model using the diffusion process, which adopts multiple AEs to model the reverse generation yet only utilizes the first AE for interaction prediction.\n\nEvaluation. We follow the full-ranking protocol [7] by ranking all the non-interacted items for each user. For performance comparison, we adopt two widely used metrics Recall@K (R@K) and NDCG@K (N@K) over the top-K items, where  \\(K\\)  is set as 10 or 20.\n\n4.1.3 Hyper-parameters Settings. We select the best hyperparameters according to Recall@20 on the validation set. We tune the learning rates of all models in  \\(\\{1e^{-5}, 1e^{-4}, 1e^{-3}, 1e^{-2}\\}\\) . As to model-specific hyper-parameters, the search scopes are as follows.\n\n- MF & LightGCN. The dropout ratio is selected from  \\(\\{0.1, 0.2, 0.3, 0.4, 0.5\\}\\) . The weight decay is chosen from  \\(\\{1e^{-6}, 1e^{-5}, 1e^{-4}\\}\\)  and the number of propagation layers is searched in  \\(\\{1, 2, 3\\}\\) .\n\n- CDAE & MultiDAE & MultiDAE++ & MultVAE. We tune the weight decay and dropout ratio in the scopes of  \\(\\{0,1e^{-3},1e^{-1}\\}\\)  and  \\(\\{0.1,0.3,0.5\\}\\) , respectively. Besides, we choose the activation function of CDAE from {sigmoid,relu, tanh}. As to MultVAE, the regularization strength  \\(\\beta\\)  and the annealing step are searched in  \\(\\{0,0.3,0.5,0.7\\}\\)  and  \\(\\{0,200,500\\}\\) , respectively. The noises for\n\nMultiDAE++ are fixed consistently with DiffRec. The hidden size is set to the default value of [200, 600].\n\n- CODIGEM. The diffusion step is chosen from  \\(\\{2, 5, 10, 40, 50, 100\\}\\)  and the noise  \\(\\beta\\)  at each step is tuned in range of  \\(\\{5e^{-5}, 1e^{-4}, 5e^{-4}\\}\\) . The hidden sizes of the multiple five-layer AEs are set to the default value of 200.\n\n- DiffRec & L-DiffRec & T-DiffRec. The step embedding size is fixed at 10. We choose the hidden size of the MLP of  \\(p_{\\theta}(\\boldsymbol{x}_{t - 1}|\\boldsymbol{x}_t)\\)  in  \\(\\{[300], [200, 600], [1000]\\}\\) . The diffusion step  \\(T\\)  and the inference step  \\(T'\\)  are tuned in  \\(\\{2, 5, 10, 40, 50, 100\\}\\)  and  \\(\\{0, \\frac{T}{4}, \\frac{T}{2}\\}\\) , respectively. Besides, the noise scale  \\(s\\) , the noise lower bound  \\(\\alpha_{\\mathrm{min}}\\) , the noise upper bound  \\(\\alpha_{\\mathrm{max}}\\)  are searched in  \\(\\{0, 1e^{-5}, 1e^{-4}, 5e^{-3}, 1e^{-2}, 1e^{-1}, 5e^{-1}\\}\\) ,  \\(\\{5e^{-4}, 1e^{-3}, 5e^{-3}\\}\\) , and  \\(\\{5e^{-3}, 1e^{-2}, 2e^{-2}\\}\\) , respectively. As to L-DiffRec, the dimension of  \\(z_0\\)  is set to 300 and the category number  \\(C\\)  is chosen from  \\(\\{1, 2, 3, 4, 5\\}\\) . For T-DiffRec,  \\(w_{\\mathrm{min}}\\)  is tuned in  \\(\\{0.1, 0.3, 0.5\\}\\)  and  \\(w_{\\mathrm{max}}\\)  is set to 1. More details are included in our released code.\n\nAll experiments are done using a single Tesla-V100 GPU, except for ACVAE in Table 7 using A40 due to high computing costs.\n\n### 4.2 Analysis of DiffRec (RQ1)\n\n4.2.1 Clean Training. We first present the comparison between DiffRec and the baselines under clean training without using timestamps in Table 2, from which we have the following observations.\n\n- Most generative methods (i.e., MultiVAE, MultiDAE, Multi-DAE++, CDAE) usually yield better performance than MF and LightGCN. These superior results are possibly attributed to the alignment between the generative modeling and the real-world interaction generation procedure. Among all generative methods, MultiVAE reveals impressive performance, especially on Amazonbook and Yelp. This is because it utilizes variational inference and multinomial likelihood [19], leading to stronger generation modeling.  \n- In all cases, our revised MultiDAE++ consistently outperforms MultiDAE. This implies the effectiveness of denoising training on enhancing the representation abilities of generative models. Besides, CODIGEM performs worse compared to LightGCN and other generative methods. This is fair because although multiple AEs are trained to model the forward and reverse processes, CODIGEM only uses the first AE for inference, and thus it is\n\nTable 3: Performance comparison between DiffRec, the best generative baseline (MultiVAE), and the best non-generative baseline (LightGCN) under noisy training with natural noises.  \n\n<table><tr><td rowspan=\"2\"></td><td colspan=\"4\">Amazon-book</td><td colspan=\"4\">Yelp</td><td colspan=\"4\">ML-1M</td></tr><tr><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td></tr><tr><td>LightGCN</td><td>0.0400</td><td>0.0659</td><td>0.0231</td><td>0.0308</td><td>0.0466</td><td>0.0803</td><td>0.0278</td><td>0.0379</td><td>0.0648</td><td>0.1226</td><td>0.0470</td><td>0.0679</td></tr><tr><td>MultiVAE</td><td>0.0536</td><td>0.0820</td><td>0.0316</td><td>0.0401</td><td>0.0494</td><td>0.0834</td><td>0.0293</td><td>0.0396</td><td>0.0653</td><td>0.1247</td><td>0.0469</td><td>0.0680</td></tr><tr><td>DiffRec</td><td>0.0546</td><td>0.0822</td><td>0.0335</td><td>0.0419</td><td>0.0507</td><td>0.0853</td><td>0.0309</td><td>0.0414</td><td>0.0658</td><td>0.1236</td><td>0.0488</td><td>0.0703</td></tr></table>\n\n![](images/445b57da23323e843c23d6c70e5df7ee2c58969be33388e1df6cc34638bccdb8.jpg)  \nFigure 4: Performance comparison of noisy training with random noises on Amazon-book.\n\n![](images/b44b6016b9771f86f2a5804ddbe1e8c7f1887573b82783dc9acf53d4555a21ab.jpg)\n\nessentially learning a MultiDAE with the noises at a small scale. The inferior performance of CODIGEM than MultiVAE is also consistent with the results in Table 2 of [36].\n\n- DiffRec significantly achieves superior performance on three datasets. The large improvements over VAE-based methods validate the superiority of applying DMs for recommender systems. Such improvements result from that 1) DiffRec is capable of modeling complex distributions via gradually learning each denoising transition step from  \\(t\\)  to  \\(t - 1\\)  with shared neural networks [31]; 2) DiffRec utilizes simple forward corruption for tractable posterior distribution, alleviating the intrinsic trade-off between the tractability and representation ability of VAE-based methods; and 3) notably, the scheduled noises for corruption in Eq. (4) ensure personalized preference modeling (cf. Section 3.4).\n\n4.2.2 Noisy Training. In real-world recommender systems, collected user interactions in implicit feedback naturally contain false-positive and false-negative items. To analyze the performance of DiffRec on learning from noisy interactions, we compare DiffRec with the best non-generative method LightGCN and the best generative method MultiVAE under two noisy settings: 1) natural noises, where we randomly add some false-positive interactions with ratings  \\(< 4\\)  as positive ones to the training and validation sets (see Section 4.1.1); and 2) random noises, where we randomly add a proportion of non-interacted items as positive interactions for each user. We summarize the performance of natural noises in Table 3 and the results of random noises with the noise proportion ranging from  \\(10\\%\\)  to  \\(50\\%\\)  in Figure 4. In Figure 4, we only show the results on Amazon-book to save space as we have similar observations on Yelp and ML-1M.\n\nFrom Table 3, we can observe that DiffRec usually surpasses MultiVAE and LightGCN, verifying the strong robustness of DiffRec against natural noises. This is reasonable since such false-positive interactions are essentially corrupted interactions and DiffRec is intrinsically optimized to recover clean interactions iteratively from the corruption. By contrast, LightGCN is vulnerable to noisy interactions because it might amplify the negative effect of noises by emphasizing high-order propagation, thus leading to poor\n\n![](images/5cd06ce00c96ccbdd419e0d6b90775a20c48833a58cb9c34beb198139e3b7365.jpg)  \nFigure 5: Effects of  \\(\\mathcal{L}^{\\Delta}(\\cdot),\\mathcal{L}(\\cdot)\\)  , and  \\(T^{\\prime}\\)  , where  \\(\\mathcal{L}^{\\Delta}(\\cdot)\\)  and  \\(\\mathcal{L}(\\cdot)\\)  mean importance sampling in Eq. (14) and uniform sampling in Eq. (13), respectively.  \\(T^{\\prime}\\)  is the inference step.\n\n![](images/6819a3a1e6f4949b70d0dad2ba7f4711db2d39dd57f27aad35a4c858619c7c0f.jpg)\n\n![](images/b0213e1910ffd706e7f1b2359bbace56be7f0dbe8af74b94a4be96e67ff669d7.jpg)  \nFigure 6: Effects of the noise scale  \\(s\\)  and diffusion step  \\(T\\) .\n\n![](images/384871ffcca2c757e4b7157ca57000978e1a141aa5a5c3aaacb3d0f2be099c8a.jpg)\n\nperformance. In addition, the comparable results on ML-1M are because this dense dataset is relatively easier for prediction.\n\nFrom the results in Figure 4, we can find: 1) from adding  \\(10\\%\\)  to  \\(50\\%\\)  random noises, the performance of LightGCN, MultiVAE, and DiffRec gradually declines. This observation makes sense because it is harder to predict user preference as noises increase. Nevertheless, 2) DiffRec still outperforms MultiVAE and LightGCN even under a large scale of noises. The reason is that DiffRec is trained under different noise scales at each step, facilitating the recovery of real interactions from heavily corrupted interactions.\n\n4.2.3 In-depth Analysis. We further explore the effects of different designs in DiffRec such as importance sampling,  \\(x_0\\) -ELBO, inference step  \\(T'\\) , and noise scales. The results on Amazon-book are reported in Figure 5 while the results on Yelp and ML-1M with similar observations are omitted to save space.\n\n- Importance sampling. We compare the performance between importance sampling  \\((\\mathcal{L}^{\\Delta}(\\cdot)\\)  in Eq. (14)) and uniform sampling  \\((\\mathcal{L}(\\cdot)\\)  in Eq. (13)) in Figure 5(a). The declined performance of  \\(\\mathcal{L}(\\cdot)\\)  validates the effectiveness of importance sampling, which assigns large sampling probabilities to the large-loss steps and thus focuses on \"hard\" denoising steps for optimization.  \n- Effect of inference step  \\(T'\\) . We vary  \\(T'\\)  from 0 to  \\(T\\)  during inference and show the results in Figure 5(b), from which we can find that using  \\(T' = 0\\)  achieves better performance. It makes sense because collected interactions from real-world data naturally contain noises, and too much corruption might hurt personalization.\n\nTable 4: Performance comparison between L-DiffRec and DiffRec under natural noise training on three datasets.  \n\n<table><tr><td rowspan=\"2\"></td><td colspan=\"4\">Amazon-book</td><td colspan=\"4\">Yelp</td><td colspan=\"4\">ML-1M</td></tr><tr><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td></tr><tr><td>DiffRec</td><td>0.0546</td><td>0.0822</td><td>0.0335</td><td>0.0419</td><td>0.0507</td><td>0.0853</td><td>0.0309</td><td>0.0414</td><td>0.0658</td><td>0.1236</td><td>0.0488</td><td>0.0703</td></tr><tr><td>L-DiffRec</td><td>0.0586+7.3%</td><td>0.0876+6.6%</td><td>0.0347+3.6%</td><td>0.0434+3.6%</td><td>0.0521+2.8%</td><td>0.0876+2.7%</td><td>0.0311+0.7%</td><td>0.0419+1.2%</td><td>0.0665+1.1%</td><td>0.1272+2.9%</td><td>0.0493+1.0%</td><td>0.0710+1.0%</td></tr></table>\n\nTable 5: Performance of  \\(\\epsilon\\)  -ELBO on ML-1M.  \n\n<table><tr><td>Variants</td><td>R@10</td><td>R@20</td><td>N@10</td><td>N@20</td></tr><tr><td>DiffRec (x0-ELBO)</td><td>0.1058</td><td>0.1787</td><td>0.0901</td><td>0.1148</td></tr><tr><td>Îµ-ELBO</td><td>0.0157</td><td>0.0266</td><td>0.0170</td><td>0.0204</td></tr></table>\n\nIn addition, the results are comparable when  \\(T'\\)  changes from  \\(T / 4\\)  to  \\(T\\) , possibly because the scheduled noise scale is relatively small, leading to minor changes in the ranking positions of top-  \\(K\\)  items.\n\n- Effects of noise scale  \\(s\\)  and step  \\(T\\) . In DiffRec, there are two important hyper-parameters: diffusion step  \\(T\\)  and noise scale  \\(s\\) . To analyze their effect, we vary  \\(s\\)  at different scales and change  \\(T\\)  from 2 to 100, respectively. From the results in Figure 6, we can observe that: 1) as the noise scale increases, the performance first rises compared to training without noise ( \\(s = 0\\) ), verifying the effectiveness of denoising training. However, enlarging noise scales degrades the performance due to corrupting the personalization. Hence, we should carefully choose a relatively small noise scale (e.g.,  \\(1e^{-4}\\) ) as discussed in Section 3.4. And 2) the performance fluctuation w.r.t.  \\(T\\)  indicates that increasing diffusion steps has little effects on accuracy due to the relatively small noises in the forward process. Considering  \\(T\\)  being too large will cause high computing burdens, we choose  \\(T = 5\\)  for good performance as well as low costs.\n\n-  \\(x_0\\) -ELBO vs.  \\(\\epsilon\\) -ELBO. The comparison between predicting  \\(x_0\\)  and  \\(\\epsilon\\)  ( \\(\\epsilon\\) -ELBO, introduced in Section 3.4) on ML-1M is in Table 5. The results of  \\(\\epsilon\\) -ELBO on Amazon-book and Yelp are close to zero due to severer data sparsity, and thus are omitted to save space. We attribute the worse results of  \\(\\epsilon\\) -ELBO to the difficulty of predicting randomly sampled noises via an MLP. Besides, the reduced noise scales  \\(s\\)  may also enhance the prediction difficulty because the noises of different steps are becoming small with minor differences. We leave the further theoretical analysis to future work.\n\n### 4.3 Analysis of L-DiffRec (RQ2)\n\nTo analyze L-DiffRec performance w.r.t. accuracy and resource costs, we evaluate L-DiffRec on three datasets under clean and noisy training. Moreover, we examine the effect of clustering category numbers to facilitate the future application of L-DiffRec.\n\n4.3.1 Clean Training. From Table 6, we can find that L-DiffRec significantly outperforms MultiVAE with fewer resource costs (38.39% parameters and 10.61% GPU memory reduced on average), justifying the superiority of L-DiffRec. Meanwhile, it drastically lowers the costs of DiffRec with comparable accuracy, i.e., reducing 56.17% parameters and 24.64% GPU usage on average. The comparable accuracy might be attributed to that the diffusion in the interaction space has redundant information and the dimension compression via clustering does not lose key information. The remarkable decline of resources is due to that 1) item clustering reduces the parameters of the encoder and decoder; 2) the latent diffusion lessens the parameters of the denoising MLP with  \\(\\theta\\) . With significantly fewer resource costs, L-DiffRec has the potential to enable large-scale item prediction in industrial scenarios.\n\nTable 6: Performance of L-DiffRec with  \\(C = 2\\) , DiffRec, and MultiVAE under clean training. \"par\" denotes parameters.  \n\n<table><tr><td>Datasets</td><td>Method</td><td>R@10â</td><td>R@20â</td><td>N@10â</td><td>N@20â</td><td>#par.(M)â</td><td>GPU(MB)â</td></tr><tr><td rowspan=\"3\">Amazon -book</td><td>MultiVAE</td><td>0.0628</td><td>0.0935</td><td>0.0393</td><td>0.0485</td><td>114</td><td>3,711</td></tr><tr><td>DiffRec</td><td>0.0695</td><td>0.1010</td><td>0.0451</td><td>0.0547</td><td>190</td><td>5,049</td></tr><tr><td>L-DiffRec</td><td>0.0694</td><td>0.1028</td><td>0.0440</td><td>0.0540</td><td>75</td><td>3,077</td></tr><tr><td rowspan=\"3\">Yelp</td><td>MultiVAE</td><td>0.0567</td><td>0.0945</td><td>0.0344</td><td>0.0458</td><td>42</td><td>1,615</td></tr><tr><td>DiffRec</td><td>0.0581</td><td>0.0960</td><td>0.0363</td><td>0.0478</td><td>69</td><td>2,103</td></tr><tr><td>L-DiffRec</td><td>0.0585</td><td>0.0970</td><td>0.0353</td><td>0.0469</td><td>29</td><td>1,429</td></tr><tr><td rowspan=\"3\">ML-1M</td><td>MultiVAE</td><td>0.1007</td><td>0.1726</td><td>0.0825</td><td>0.1076</td><td>4</td><td>497</td></tr><tr><td>DiffRec</td><td>0.1058</td><td>0.1787</td><td>0.0901</td><td>0.1148</td><td>4</td><td>495</td></tr><tr><td>L-DiffRec</td><td>0.1060</td><td>0.1809</td><td>0.0868</td><td>0.1122</td><td>2</td><td>481</td></tr></table>\n\n4.3.2 Noisy Training. The resource costs of noisy training are the same as clean training while we observe that L-DiffRec consistently outperforms DiffRec under noisy training as shown in Table 4. One possible reason is that some clustered categories have few interactions, which are more likely to be false-positive interactions. The effect of such noises is weakened after representation compression via item clustering.\n\n4.3.3 Effect of category number. To inspect the effect of category number on L-DiffRec, we compare the results with clustering category numbers changing from 1 to 5 on Amazon-book. We omitted similar results on Yelp and ML-1M to save space. From Figure 7, we can find that: 1) the Recall, NDCG, GPU usage, and parameters decline as the category number  \\(C\\)  increases as shown in Figure 7(a) and (b). This is reasonable since increasing  \\(C\\)  will reduce the parameters, hurting the representation ability. 2) The resource costs are substantially reduced compared to DiffRec and MultiVAE even if clustering is disabled ( \\(C = 1\\) ). This is due to the significant parameter reduction of the denoising MLP via latent diffusion. And 3) L-DiffRec is comparable with DiffRec when  \\(C = 1\\)  or 2 while L-DiffRec consistently outperforms MultiVAE when  \\(C = 1, 2\\) , or 3. As such, L-DiffRec can save extensive resources with comparable or superior accuracy by carefully choosing  \\(C\\) .\n\n### 4.4 Analysis of T-DiffRec (RQ3)\n\nTo verify the effectiveness of T-DiffRec on temporal modeling, we compare T-DiffRec and LT-DiffRec with a SOTA sequential recommender model ACVAE [48], which employs VAE with contrastive learning and adversarial training for recommendation.\n\nFrom Table 7, we have the following observations: 1) T-DiffRec and LT-DiffRec perform better than DiffRec and L-DiffRec by a large margin, justifying the effectiveness of the proposed time-aware reweighting strategy on temporal modeling; 2) the superior performance of T-DiffRec and LT-DiffRec than ACVAE is attributed to both capturing temporal shifts and conducting diffusion processes, leading to more accurate and robust user representations; 3) despite more parameters, DiffRec-based methods consume much less GPU memory than ACVAE, thus reducing computing costs; 4) it is highlighted that LT-DiffRec yields comparable performance to T-DiffRec with fewer parameters, which is consistent with observations in Section 4.3; and 5) the relatively small improvements of T-DiffRec\n\n![](images/9ae6327934c97ad8530d867a1dea4f8b1c469a2eb8c7e999e61119814b5730b4.jpg)  \nFigure 7: Effects of the clustering category number of L-DiffRec on Amazon-book under clean training.\n\n![](images/d9ab60a61f27f79ce77b393c6c5d727c71dd6c67ae2e9cc008c505cea35835a6.jpg)\n\n![](images/6c8ec64b3b7090303f73af01f0a94f7d2719a1c97c8c7c7b39b4fd074d94e232.jpg)\n\n![](images/508595a963fbf789cf849decfc320df303e63beb41d0fc2e7ecf5acbe769e436.jpg)\n\nTable 7: Performance comparison between DiffRec variants and a SOTA sequential baseline ACVAE. The models are trained using timestamps. The results on ML-1M are similar to Amazon-Book and omitted to save space. \"par\" denotes parameters.  \n\n<table><tr><td rowspan=\"2\"></td><td colspan=\"6\">Amazon-book</td><td colspan=\"6\">Yelp</td></tr><tr><td>R@10â</td><td>R@20â</td><td>N@10â</td><td>N@20â</td><td>#par. (M)â</td><td>GPU (MB)â</td><td>R@10â</td><td>R@20â</td><td>N@10â</td><td>N@20â</td><td>#par. (M)â</td><td>GPU (MB)â</td></tr><tr><td>ACVAE</td><td>0.0770</td><td>0.1107</td><td>0.0547</td><td>0.0647</td><td>13</td><td>37,711</td><td>0.0567</td><td>0.0947</td><td>0.0342</td><td>0.0456</td><td>5</td><td>14,697</td></tr><tr><td>DiffRec</td><td>0.0695</td><td>0.1010</td><td>0.0451</td><td>0.0547</td><td>190</td><td>5,049</td><td>0.0581</td><td>0.0960</td><td>0.0363</td><td>0.0478</td><td>69</td><td>2,107</td></tr><tr><td>T-DiffRec</td><td>0.0819</td><td>0.1139</td><td>0.0565</td><td>0.0661</td><td>190</td><td>5,049</td><td>0.0601</td><td>0.0987</td><td>0.0377</td><td>0.0494</td><td>69</td><td>2,107</td></tr><tr><td>L-DiffRec</td><td>0.0694</td><td>0.1028</td><td>0.0440</td><td>0.0540</td><td>75</td><td>3,077</td><td>0.0585</td><td>0.0970</td><td>0.0353</td><td>0.0469</td><td>29</td><td>1,429</td></tr><tr><td>LT-DiffRec</td><td>0.0838</td><td>0.1188</td><td>0.0560</td><td>0.0665</td><td>75</td><td>3,077</td><td>0.0604</td><td>0.0982</td><td>0.0369</td><td>0.0484</td><td>29</td><td>1,429</td></tr></table>\n\nover DiffRec on Yelp and the inferior results of ACVAE than DiffRec on Yelp are because user preference over food is relatively stable and the temporal shifts are limited. As such, considering temporal information receives minor benefits.\n",
  "hyperparameter": ""
}