{
  "id": "SelfCF_2023",
  "paper_title": "SelfCF: A Simple Framework for Self-supervised Collaborative Filtering",
  "alias": "SelfCF",
  "year": 2023,
  "domain": "Recsys",
  "task": "MultiModalRecommendation",
  "introduction": "",
  "method": "# SelfCF: A Simple Framework for Self-supervised Collaborative Filtering\n\nXIN ZHOU, Nanyang Technological University, Singapore AIXIN SUN, Nanyang Technological University, Singapore YONG LIU, Nanyang Technological University, Singapore JIE ZHANG, Nanyang Technological University, Singapore CHUNYAN MIAO, Nanyang Technological University, Singapore\n\nCollaborative filtering (CF) is widely used to learn informative latent representations of users and items from observed interactions. Existing CF-based methods commonly adopt negative sampling to discriminate different items. That is, observed user-item pairs are treated as positive instances; unobserved pairs are considered as negative instances and are sampled under a defined distribution for training. Training with negative sampling on large datasets is computationally expensive. Further, negative items should be carefully sampled under the defined distribution, in order to avoid selecting an observed positive item in the training dataset. Unavoidably, some negative items sampled from the training dataset could be positive in the test set. Recently, self-supervised learning (SSL) has emerged as a powerful tool to learn a model without negative samples. In this paper, we propose a self-supervised collaborative filtering framework (SelfCF), that is specially designed for recommender scenario with implicit feedback. The proposed SelfCF framework simplifies Siamese networks and can be easily applied to existing deep-learning based CF models, which we refer to as backbone networks. The main idea of SelfCF is to augment the latent embeddings generated by backbone networks instead of the raw input of user/item ids. We propose and study three embedding perturbation techniques that can be applied to different types of backbone networks including both traditional CF models and graph-based models. The framework enables learning informative representations of users and items without negative samples, and is agnostic to the encapsulated backbones. We conduct experimental comparisons on four datasets, one self-supervised framework and eight baselines to show that our framework may achieve even better recommendation accuracy than the encapsulated supervised counterpart with a $2 \\times - 4 \\times$ faster training speed. The results also demonstrate that SelfCF can boost up the accuracy of a self-supervised framework BUIR by $1 7 . 7 9 \\%$ on average and shows competitive performance with baselines.\n\n# CCS Concepts: $\\bullet$ Information systems Recommender systems.\n\nAdditional Key Words and Phrases: Collaborative Filtering, Self-supervised Learning, Recommender Systems, Siamese Networks\n\n# 1 INTRODUCTION\n\nRecommender systems aim to provide users with personalized products or services. They help to handle the increasing information overload problem and improve customer relationship management. In Fig. 1, we present an illustration of recommendation under implicit feedback. Recommender systems are designed to infer the missing values of the matrix (right) transformed from the user-item interactions (left). In top- $K$ scenario, the inferred values are further ranked with each user for personalized recommendation. Collaborative Filtering (CF)\n\n![](images/1b7ee9617325db2b6d381a5a7bf3c6f4c5aa300e56b4d98998ddf33e871dba0e.jpg)  \nFig. 1. An illustration of the recommendation scenario under implicit feedback. Only positive samples can be captured for training recommender systems.\n\nis a canonical recommendation technique, which predicts interests of a user by aggregating information from similar users or items. In detail, existing CF-based methods [20, 21, 26, 38] learn latent representations of users and items, by first factorizing the observed interaction matrix, then predicting the potential interests of user-item pairs based on the dot-product of learned embeddings. However, existing CF models rely heavily on negative sampling techniques to discriminate against different items, because negative samples are not naturally available.\n\nNevertheless, the negative sampling techniques suffer from a few limitations. Firstly, they introduce additional computation and memory costs. In existing CF-based methods, the negative sampling algorithm need be carefully designed in order to not select the observed positive user-item pairs. Specifically, to sample one negative user-item pair for a specific user, the algorithm checks its conflicts with all the observed positive items interacted with this user. As a result, much computation is needed for users who have a large number of interactions. Secondly, even if non-conflicted negative samples are selected for a user, the samples may fall into future positive items of the user. The reason is that the unobserved user-item pairs can be either true negative instances (i.e., the user is not interested in these items) or missing values (e.g., interaction pairs not observed in the training set but the test set) [28, 36]. We denote the sampled pairs that fall in the test set as false negative samples [6]. Although another line of work [7–9] has get rid of negative sampling and takes the full unobserved interactions as negative samples, they may still treat a future positive sample as negative.\n\nTo uncover the negative sampling problem in current models, we employ uniform sampling (UniS) and Dynamic Negative Sampling (DNS) [57] in LightGCN [20] to study the aforementioned issues. Uniform sampling is a widely used and classical solution in the item recommendation domain with implicit feedback [6]. DNS improves uniform sampling by selecting a set of negative candidates and ranking the candidates based on learned user/item embeddings. The top-ranked item is used as a hard instance. As a result, DNS is model-sensitive. We plot the percentage of sampled false negative pairs in the test set along with the training progress of LightGCN under uniform sampling and DNS in Fig. 2. We test the negative sampling methods on two diverse datasets, MOOC and Amazon Video Games (Games). MOOC contains 458,453 interactions collected from 82,535 learners on 1,302 courses. Games has 50,677 users, 16,897 items and 454,529 interactions. The sparsity of MOOC and Games are $9 9 . 4 0 3 9 \\%$ and $9 9 . 9 4 6 9 \\%$ , respectively. From Fig. 2, we observe the percentage of false negative pairs sampled by DNS is over $5 0 \\%$ when LightGCN early stops on the MOOC dataset. Here, we use the original early stopping setting in LightGCN[20]. The sparse dataset, Games, has a relatively small number of sampled false negative instances under $1 0 \\%$ . However, the overhead to sample a negative instance increases with the number of candidates, as shown in Table 1. Although DNS can sample hard negative instances, its overhead on sampling is 2-3 times of uniform sampling in Table 1. From the above observations, it is promising to train the model without negative sampling.\n\n![](images/51a37fc74c1311f0bdca5ea270ed4c5a3415a719cf14c6b375452900fae4f8d2.jpg)  \nFig. 2. Percentage of false negative pairs sampled with different sampling methods of LightGCN. The percentage is calculated by dividing the number of sampled false negative pairs by the number of instances in the test set and multiplying the result by 100.\n\nTable 1. Negative sampling time under various sampling methods and datasets. Overhead is calculated as the percentage of sampling time over training time per epoch. UniS denotes uniform sampling. DNS denotes dynamic negative sampling.   \n\n<table><tr><td rowspan=\"2\">Dataset Method</td><td colspan=\"3\">Time (s)</td><td rowspan=\"2\">Overhead</td></tr><tr><td></td><td>Sampling</td><td>Training</td></tr><tr><td>MOOC</td><td>UniS</td><td>2.32</td><td>8.89</td><td>26.1%</td></tr><tr><td>MOOC</td><td>DNS</td><td>32.38</td><td>40.33</td><td>80.3%</td></tr><tr><td>Games</td><td>UniS</td><td>3.47</td><td>8.22</td><td>42.2%</td></tr><tr><td>Games</td><td>DNS</td><td>39.15</td><td>43.68</td><td>89.6%</td></tr></table>\n\nSelf-supervised learning (SSL) models [13, 17, 51] provide us a possible solution to tackle the aforementioned limitations. SSL enables training a model by iteratively updating network parameters without using negative samples. Research in various domains ranging from Computer Vision (CV) to Natural Language Processing (NLP), has shown that SSL is possible to achieve competitive or even better results than supervised learning [12, 17, 51]. The underlying idea is to maximize the similarity of representations obtained from different distorted versions of a sample using a variant of Siamese networks [18]. Siamese networks usually include two symmetric networks (i.e., online network and target network) for inputs comparing. The problem with only positive sampling in model training is that, the Siamese networks collapse to a trivial constant solution [13]. Thus, in recent work, BYOL [17] and SimSiam [13] introduce asymmetry to the network architecture by adding parameter update technique. Specifically, in the network architecture, an additional “predictor” network is stacked onto the online encoder. For parameter update, a special “stop gradient” operation is highlighted to prevent solution collapsing. SimSiam simplifies BYOL by removing its “momentum update”, which updates the parameters of target networks based on online networks. We will illustrate the architectures in detail in the related work section.\n\nTo the best of our knowledge, BUIR [28] is the only recommendation framework to learn user and item latent representations without negative samples. BUIR is derived from BYOL [17]. Similar to BYOL, BUIR employs two distinct encoder networks (i.e., online and target networks) to address the recurring of trivial constant solutions in SSL. In BUIR, the parameters of the online network are optimized towards that of the target network. At the same time, parameters of the target network are updated based on momentum-based moving average [17, 19, 42] to slowly approximate the online network [28]. As BUIR is built upon BYOL, which stems from vision domain, its architecture is redundant and suffers from slow convergence, because of the design of the momentum-based parameter updating. The SimSiam network is originally proposed in vision domain as well. The input is an image, and techniques for data augmentation on images are relatively mature [39], such as random cropping, resizing, horizontal flipping, color jittering, converting to grayscale, Gaussian blurring, and solarization. As for a pair of user id and item id that is observed in implicit feedback, there is no standard solution on how to distort it while keep its representation invariant.\n\nThe learning paradigm of SSL without negative samples differs slightly from existing paradigms that use negative samples to learn representations. SSL without negative samples intends to learn an encoder with augmentation-invariant representation [13, 17]. That is, they minimize the representation distance between two positive samples based on a Siamese network architecture [3]. By using negative samples in SSL, solutions are prevented from collapsing because of their repulsivity. Our proposed framework can achieve competitive performance without harnessing this repulsive force.\n\nIn this paper, we propose a Self-supervised Collaborative Filtering (SelfCF) framework, which performs posterior perturbation on user and item latent embeddings, to obtain a contrastive pair. On architecture design, our framework uses only one encoder instead of two encoders, which simplifies BYOL and SimSiam. Besides, instead of perturbing inputs ahead of encoding, we generate different but invariant contrastive views with posterior embedding perturbations. An additional benefit of posterior embedding perturbation is that the framework can take the internal implementation of the encapsulated backbones as black-box. Conversely, BUIR adds momentumbased parameter updating to encoders in order to generate different views. Our experiments on four real-world datasets validate that the proposed SelfCF framework is able to learn informative representation solely based on positive user-item pairs. In our experiments, we encapsulate two popular CF-based models into the framework, and the results on Top- $K$ item recommendation are competitive or even better than their supervised counterparts.\n\nWe summarize our contributions as follows:\n\n• We propose a novel framework, SelfCF, that learns latent representations of users/items solely based on positively observed interactions. The framework uses posterior output perturbation to generate different augmented views of the same user/item embeddings for contrastive learning.   \n• We design three output perturbation techniques: historical embedding, embedding dropout, and edge pruning to distort the output of the backbone. The techniques are applicable to all existing CF-based models as long as their outputs are embedding-like.   \n• We investigate the underlying mechanisms of the framework by performing ablation study on each component. We find the presentations of user/item can be learnt even without the “stop gradient” operator, which shows different behaviors from previous SSL frameworks (e.g., BYOL [17] and SimSiam [13]).   \n• Finally, we conduct experiments on four public datasets by encapsulating two popular backbones. Results show SelfCF is competitive or better than their supervised counterpart and outperforms existing SSL framework by up to $1 7 . 7 9 \\%$ on average.\n\n# 2 RELATED WORK\n\nIn this section, we first review the CF technique, then summarize the current progress of SSL.\n\n# 2.1 Collaborative Filtering\n\nCF is a typical and prevalent technique adopted in modern recommender systems [48]. The core concept is that similar users tend to have similar tastes on items. To tackle the data sparsity and scalability of CF, more advanced method, Matrix Factorization (MF), decomposes the original sparse matrix to low-dimensional matrices with latent factors/features and less sparsity. To learn informative and compressed latent features, deep learning based models are further proposed for recommendation [21, 43, 56].\n\nWith the emerge of graph convolutional networks (GCNs), which generalize convolutional neural networks (CNNs) on graph-structured data [31, 54, 63], GCN-based CF is widely researched recently [2, 45, 48, 60–62]. The user-item interaction matrix naturally can be treated as a bipartite graph. GCN-based CF takes advantage of fusing both high-order information and the inherent graph structure. GCNs are used to propagate information using the normalized adjacency matrix and aggregate information from neighbors via the nonlinear activation and linear transformation layers. He et al. [20] simplify the GCNs architecture by removing the feature transformation as well as nonlinear activation layers as they impose negative effect on recommendation performance. In [11], the authors add a residual preference learning on GCN and obtain better recommendation performance.\n\n# 2.2 Self-supervised Learning\n\nSSL has achieved competitive results on various tasks in vision and natural language processing domains. We review two lines of work on SSL.\n\nContrastive learning. Contrastive approaches learn representations by attracting the positive sample pairs and repulsing the negative sample pairs [18]. A line of work [12, 19, 22, 23, 47, 53, 55] is developed based on this concept. These work benefits from a large number of negative samples, which require a memory bank [47] or a queue [19] to store negative samples. In [46], the authors integrate supplemental signal into supervised baselines for contrastive learning, and show that it performs better than their baselines. Following the line, Yu et al. propose a graph-augmentation free recommendation model [49] to enforce the learning of uniform representations for users and items. The uniform representations can mitigate the popularity bias and achieve better recommendation accuracy. Liu et al. summarize the contrastive learning applied on a broad fields, e.g., NLP, Computer Vision, in [32].\n\nSiamese networks. Siamese networks [3] are general models for comparing entities. BYOL [17] and SimSiam [13] are two specializations of the Siamese network that achieve remarkable results by only using positive samples. BYOL proposes two coupled networks (i.e., online and target networks) that are optimized and updated iteratively. In detail, the online network is optimized towards the target network, while the target network is updated with a moving average of the online network to avoid collapse. On the contrary, SimSiam verifies that a “stop gradient” operator is crucial in preventing collapse. As a result, it removes the dashed “momentum update” line in Fig. 3a.\n\nDerived from BYOL, the recently proposed self-supervised framework, BUIR, learns the representation of users and items solely on positive interactions. It introduces different views by differentiating parameters of online and target networks. However, the framework modifies the underlying logic of the encapsulated graph-based CF models for the sake of introducing contrastive user-item pairs. In our solution, we choose to augment the output of encoder $f$ to generate two different but related embeddings for representation learning. For comparison, we present our proposed framework specialized for CF, SelfCF, in Fig. 3b. The framework shares the same encoder between online and target networks, thus reduces the unnecessary memory and computational resources for storing and executing an additional encoder of the target network. We elaborate our framework in the following section.\n\n# 3 THE SELFCF FRAMEWORK\n\nOur framework (shown in Fig. 3b ) partially inherits the Siamese network architecture of SimSiam, as shown in Fig. 3. In our framework, SelfCF, the goal is to learn informative representations of users and items based on positive user-item interactions only. The latent embeddings of users and items are learnt from the online network. Analogous to convolutions [27], which is a successful inductive bias via weight-sharing for modeling translation-invariance, the weight-sharing Siamese networks can model invariance with regard to more complicated transformations (??.??., data augmentations) [13]. The online and target networks in SelfCF use a same copy of the parameters as well as the backbone for modeling representation invariance. In addition, we drop the momentum encoder as used in BYOL and BUIR. As a result, with the same input, the online and target networks will generate the same output which makes the loss totally vanished. We will discuss how to tackle this issue in the following section.\n\n![](images/d9fcfc5455fa17871f4a0e22f7df223fd79659392b3c394ba4e73868ea2cf84e.jpg)  \nFig. 3. Comparison of Siamese network architectures. Input $x$ is an image. The input to SelfCF is the interaction pairs of users $( u )$ and items (??).\n\n![](images/508e4f58c9fac2baa12a1de0e4e0eedb67bde8db9820910e66b761c0c0905fab.jpg)  \nFig. 4. Illustration of output perturbation performed on a batch. The perturbed embedding is denoted as E˜ .\n\nWhen considering data augmentations of input in CF, it is not a trivial task to distort the positive samples. In vision domain, where SSL is popularly applied, images can be easily distorted under a wide range of transformations. However, positive user-item pairs are difficult to be distorted while preserving their representation invariance. We use the following embedding perturbation techniques to achieve the same effect. For reasons of clarity, we denote bold value E as the embedding matrix of users and items within a batch, and differentiate the embedding matrix of users with $\\mathbf { E } _ { u }$ , vice visa. The value $e$ in lowercase denotes the embedding of a user or item, specified as $e _ { u }$ or $e _ { i }$ .\n\n# 3.1 Data Augmentation via Output Perturbation\n\nIn vision, researchers use image transformations to augment input data and generate two different but relative reviews. Instead, our framework augments the output embeddings of users and items to generate two contrastive views. We propose three methods to introduce embedding perturbation in our framework, shown in Fig. 4. The historical embedding and embedding dropout are general techniques for output augmentation in our framework, while the edge pruning is specially designed for graph-based CF models.\n\nHistorical embedding. We introduce embedding perturbation by utilizing historical embeddings [10, 15] from prior training iterations. Specifically, we use a momentum update to generate the contrastive embeddings in the target network. Suppose $\\mathbf { E } ^ { t }$ is the embeddings generated by a backbone encoder $f$ in a batch $\\mathbb { B } ^ { t }$ . The perturbed embeddings $\\tilde { \\mathbf { E } } ^ { t }$ is calculated by combining of the output embeddings $\\mathbf { E } ^ { t }$ with the historical embedding $\\mathbf { E } ^ { t - 1 }$ :\n\n$$\n\\tilde { \\boldsymbol { \\mathbf { E } } } ^ { t } = \\boldsymbol { \\mathbf { E } } ^ { t - 1 } \\tau + \\boldsymbol { \\mathbf { E } } ^ { t } ( 1 - \\tau )\n$$\n\nwhere $\\tau$ is a parameter controls the proportion of information preserved from a prior iteration.\n\nEmbedding dropout. We apply the embedding dropout scheme to perturb the embeddings of users and items from the target network. In classical CF models, the parameters are not modified until the loss is backpropagated. With the same input, to avoid null loss resulted from these models, our framework adopts embedding dropout on the resulted users’ and items’ vectors, which is analogous to node dropout [40]. In this way, the framework is able to generate two different but related views on the output, which are then feed into the loss function for optimization. The resulted embeddings under a dropout ratio $\\boldsymbol { p }$ is calculated as:\n\n$$\n\\tilde { \\boldsymbol { \\mathbf { E } } } ^ { t } = \\boldsymbol { \\mathbf { E } } ^ { t } \\cdot B e r n o u l l i ( p )\n$$\n\nEdge pruning. As for graph-based CF models, the edge pruning method used in [34, 37] provides an alternative way to augment the output embeddings. With the user-item bipartite graph, we randomly prune a certain proportion of edges from the graph in each batch. The output embeddings are updated by aggregating the embeddings of neighbors. With the same positive user-item pair, the output is distorted with different adjacency matrix (neighbors). Let $A _ { p r u n e d }$ be the pruned adjacency matrix, then the resulted embeddings with edge pruning denote as:\n\n$$\n\\tilde { \\mathbf { E } } ^ { t } = \\mathbf { E } ^ { t } \\cdot A _ { p r u n e d }\n$$\n\nNote that, in implementation, edge pruning would require to calculate the adjacency matrix of users and items, which is more expensive in computation than the embedding dropout technique.\n\nTo summarize, our framework augments the output via embedding perturbation in the target network instead of distorting the input directly as commonly used in vision domain. It is worth noting that the historical embedding perturbation performs on embeddings from prior and current iteration, the embedding dropout perturbs the current embedding with noise, and the edge pruning method operates on future embeddings generated by stacking one more convolutional layer on current embeddings. Both historical embedding perturbation and embedding dropout perturbation remove the requirements of auxiliary graphs to generate a contrastive view as in [28, 46, 49]. We will discuss their performance with regard to this perspective in experiments section.\n\n# 3.2 The Loss Function\n\nOur framework, as shown in Fig. 3b, takes a positive user-item pair $( u , i )$ as input. The $( u , i )$ pair is initially processed by an encoder network $f$ in a backbone (??.??. LightGCN [20]). The output of the encoder $f$ is then copied to the target network for embedding perturbation. Formally, we denote the output of the encoder from the online network as $( e _ { u } , e _ { i } ) = f ( u , i )$ . Finally, the linear predictor in our framework transforms the output $( e _ { u } , e _ { i } )$ with $( { \\dot { e } } _ { u } , { \\dot { e } } _ { i } ) = h ( e _ { u } , e _ { i } )$ and matches it to the perturbed embeddings $( { \\tilde { e } _ { u } } , { \\tilde { e } _ { i } } ) = g ( e _ { u } , { e _ { i } } )$ in other view like in BYOL [17] and SimSiam [13].\n\nWe define a symmetrized loss function as the negative cosine similarity between $( \\dot { e } _ { u } , \\tilde { e } _ { i } )$ and $( \\tilde { e } _ { u } , \\dot { e } _ { i } )$ :\n\n$$\n\\mathcal { L } = \\frac { 1 } { 2 } C ( \\dot { e } _ { u } , \\tilde { e } _ { i } ) + \\frac { 1 } { 2 } C ( \\tilde { e } _ { u } , \\dot { e } _ { i } )\n$$\n\nFunction $C ( \\cdot , \\cdot )$ in the above equation is defined as:\n\n$$\nC ( e _ { u } , e _ { i } ) = - \\frac { ( e _ { u } ) ^ { T } e _ { i } } { | | e _ { u } | | _ { 2 } | | e _ { i } | | _ { 2 } } ,\n$$\n\nwhere $| | \\cdot | | _ { 2 }$ is $\\ell _ { 2 }$ -norm. The total loss is averaged over all user-item pairs in a batch. The intuition behind this is that we intend to maximize the prediction of the perturbed item $i$ given a user $u$ , and vice versa. The minimized possible value for this loss is $- 1$ .\n\nFinally, we stop gradient on the target network and force the backpropagation of loss over the online network only. We follow the stop gradient $( s g )$ operator as in [13, 17], and implement the operator by updating Equation 4 as:\n\n$$\n\\mathcal { L } = \\frac { 1 } { 2 } \\left( C ( \\dot { e } _ { u } , s g ( \\tilde { e } _ { i } ) ) + C ( s g ( \\tilde { e } _ { u } ) , \\dot { e } _ { i } ) \\right) .\n$$\n\nWith the stop gradient operator, the target network receives no gradient from $( \\tilde { e } _ { u } , \\tilde { e } _ { i } )$ . However, the encoder $f$ in the online network receives gradients from user-item pair $( \\dot { e } _ { u } , \\dot { e } _ { i } )$ , and optimizes its parameters towards the global optimum. Conversely, the removal of this operator can cause instability in online network learning, which we will verify this through ablation study. The reason is that the online and target networks simulate the student-teacher-like network [42] in which only the online network is optimized to predict the positively interacted item (user) presented by the target network. Additionally, we add regularization penalty on the online embeddings (i.e., $e _ { u }$ and $e _ { i }$ ) and the predictor $h$ . The final loss function is:\n\n$$\n\\mathcal { L } = \\frac { 1 } { 2 } \\left( C ( \\dot { e } _ { u } , s g ( \\tilde { e } _ { i } ) ) + C ( s g ( \\tilde { e } _ { u } ) , \\dot { e } _ { i } ) \\right) + \\lambda _ { 1 } \\cdot \\left( | | e _ { u } | | _ { 2 } ^ { 2 } + | | e _ { i } | | _ { 2 } ^ { 2 } \\right) + \\lambda _ { 2 } \\cdot \\left( | | h | | _ { 1 } ^ { 2 } \\right) ,\n$$\n\nwhere $| | \\cdot | | _ { 1 }$ is $\\ell _ { 1 }$ -norm. The pseudo-code of SelfCF is in Algorithm 1.\n\n# Algorithm 1 PyTorch-style pseudo-code for SelfCF.\n\n<table><tr><td colspan=\"2\">Require: user-item interaction set B</td></tr><tr><td colspan=\"2\">Require: f,h,g encoder, predictor, output perturbation</td></tr><tr><td colspan=\"2\">1: for Bt in B do</td></tr><tr><td colspan=\"2\">2: (E,E)=f(Bt) V output of encoder</td></tr><tr><td colspan=\"2\" rowspan=\"2\">（E,E）=h(E,E） 3: &gt;output of predictor</td></tr><tr><td colspan=\"2\">（EE）=g(E,E） &gt; output of perturbation Eq.7</td></tr><tr><td colspan=\"2\">4: L=(C(Esg(E))+C(sg(E),E))+λ·(IE²+|E2)+2·(/l²) 5:</td></tr><tr><td colspan=\"2\">6: L.backward()</td></tr><tr><td colspan=\"2\">back-propagate 7: update(f,h) parameters update</td></tr><tr><td colspan=\"2\">8: end for</td></tr><tr><td colspan=\"2\">9:</td></tr><tr><td colspan=\"2\">10: def predict(eu, ei):</td></tr><tr><td colspan=\"2\">calculate recommendation score 11: return s(eu, ei)</td></tr></table>\n\nTable 2. Statistics of the experimented data.   \n\n<table><tr><td>Dataset</td><td># of Users</td><td># of Items</td><td># of Interactions</td><td>Sparsity</td></tr><tr><td>Arts</td><td>45,624</td><td>21,104</td><td>396,556</td><td>99.9588%</td></tr><tr><td>Games</td><td>50,677</td><td>16,897</td><td>454,529</td><td>99.9469%</td></tr><tr><td>Food</td><td>115,144</td><td>39,688</td><td>1,025,169</td><td>99.9776%</td></tr><tr><td>COCO</td><td>144,773</td><td>20,969</td><td>1,204,697</td><td>99.9603%</td></tr></table>\n\n# 3.3 Top- $K$ Recommendation\n\nClassical CF methods recommend top- $K$ items by ranking scores of the inner product of a user embedding with all candidate item embeddings. However, in SSL, we minimize the predicted loss between $u$ and $i$ for each positive interaction $( u , i )$ . Intuitively, we predict the future interaction score based on a cross-prediction task [28]. That is, we both predict the interaction probability of item $i$ with $u$ and the probability of user $u$ with $i .$ . Given $( e _ { u } , e _ { i } )$ being the output of the encoder $f$ , the recommendation score is calculated as:\n\n$$\ns ( e _ { u } , e _ { i } ) = h ( e _ { u } ) \\cdot ( e _ { i } ) ^ { T } + e _ { u } \\cdot h ( e _ { i } ) ^ { T }\n$$\n\nIt is worth noting that since the encoder $f$ is shared between both online and target networks, we use the representations obtained from the online network to predict top- $K$ items for each user.",
  "experiments": "",
  "hyperparameter": "- **embedding_size**: Dimensionality of the latent user and item embeddings produced by the backbone encoder (e.g., BPR or LightGCN). Controls the representation capacity of the model. In this paper it is fixed to 64 for all methods.\n- **num_layers**: Number of propagation layers in the LightGCN backbone when encapsulated by SelfCF, determining how many hops of the user–item graph are exploited. Tuned mainly in {1, 2, 3, 4} (and analyzed up to 8 layers in sensitivity studies) to balance capturing high-order structure and avoiding over-smoothing.\n- **tau_momentum**: Momentum coefficient \\(\\tau\\) used in the historical-embedding perturbation, which linearly combines current and previous iteration embeddings to form a perturbed view. Typical search values are {0.1, 0.2, 0.5}; larger values retain more historical information.\n- **dropout_ratio**: Embedding dropout probability \\(p\\) used in SelfCF_ed to randomly zero out dimensions (or nodes) in user/item embeddings when generating the perturbed view. For LightGCN backbones, \\(p\\) is tuned in {0.1, 0.2, 0.5}; for the BPR backbone a smaller fixed dropout such as 0.05 is used.\n- **lambda_1**: L2 regularization coefficient on user and item embeddings in the loss, controlling the norm of latent factors and helping prevent overfitting. Searched over {0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1}.\n- **lambda_2**: Regularization coefficient applied to the predictor network \\(h\\) (L1 when the backbone is BPR, L2 otherwise), encouraging a sparse or small-norm predictor so that the encoder learns more informative representations. Typically set to small values such as 0 or 1e-2 depending on the backbone.\n- **early_stopping_epochs**: Number of epochs without improvement on validation Recall@20 before stopping training, controlling when to terminate optimization to avoid overfitting. Fixed to 50 in the experiments.\n- **max_epochs**: Maximum number of training epochs allowed. Used as an upper bound on training duration; fixed to 1000 in this paper."
}
