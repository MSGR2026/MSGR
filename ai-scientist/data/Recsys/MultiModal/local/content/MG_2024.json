{
  "id": "MG_2024",
  "paper_title": "Mirror Gradient: Towards Robust Multimodal Recommender Systems via Exploring Flat Local Minima",
  "alias": "MG",
  "year": 2024,
  "domain": "Recsys",
  "task": "MultiModalRecommendation",
  "introduction": "",
  "method": "# 3 METHODOLOGY\n\nIn this section, we first elaborate on the algorithm of the proposed MG. Then, we introduce the theoretical insight of MG.\n\n# 3.1 Mirror Gradient\n\nMG is a concise and easily implementable approach that enhances the gradient of the model during the optimization process of recommender systems. This enhancement is equivalent to adding a regularization term to improve the system’s robustness on input. The proposed MG consists of two phases in each training epoch: Normal Training and Mirror Training.\n\nDuring Normal Training, the conventional gradient descent is applied to the loss function $\\boldsymbol { L } _ { \\mathrm { R } } ( \\cdot )$ with the current learnable parameters $\\Theta _ { t - 1 }$ , as follows:\n\n$$\n\\Theta _ { t } = \\Theta _ { t - 1 } - \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } \\big ( \\Theta _ { t - 1 } \\big ) ,\n$$\n\nwhere $\\eta$ represents the learning rate. As shown in the Algorithm 1, we use an interval $\\beta$ to control the effect of MG on each training epoch. After updating per $\\beta - 1$ iterations using Eq. (2), we employ the Mirror Training strategy to update the parameter $\\Theta _ { t - 1 }$ as follows:\n\n$$\n\\left\\{ \\begin{array} { l l } { \\Theta _ { t } ^ { ' } = \\Theta _ { t - 1 } - \\alpha _ { 1 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) , } \\\\ { \\Theta _ { t } = \\Theta _ { t } ^ { ' } + \\alpha _ { 2 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t } ^ { ' } ) . } \\end{array} \\right.\n$$\n\nHere, in order to control the relative size of updates introduced by mirror training, we introduce two positive scaling coefficients, $\\alpha _ { 1 }$ and $\\alpha _ { 2 }$ , with $\\alpha _ { 1 } > \\alpha _ { 2 }$ .\n\nAlthough the MG we proposed is highly simple, it possesses a strong theoretical insight and remarkable versatility. This enables consistent performance improvements across a wide array of experimental scenarios. Furthermore, in Section 5, we demonstrate the compatibility of MG with various optimizers and existing robust recommender system techniques. Moreover, it can achieve superior performance compared to some conventional optimization strategies about flat local minima.\n\n# 3.2 Theoretical Insight of MG\n\nIn this part, we introduce Lemma 3.1 and Theorem 3.2 which can help us analyze how MG helps the model’s parameters tend towards flat local minima from a theoretical perspective, thereby enhancing the input robustness of the recommender system.\n\nLemma 3.1. [6, 24] Consider a neural network $f ( x )$ with $L$ layers and learnable parameters ?? . $h _ { i } , 1 \\leq i \\leq L$ , denotes the feature map from ?? th layer. For any scalar function $g$ of ${ \\bf \\ddot { } } h _ { L }$ , we have\n\n$$\n\\| \\nabla _ { \\boldsymbol { x } } g _ { \\boldsymbol { \\theta } } ( \\boldsymbol { x } ) \\| _ { 2 } ^ { 2 } \\cdot \\sum _ { j = 1 } ^ { L } O \\big ( \\frac { 1 + \\| h _ { i } \\| _ { 2 } ^ { 2 } } { \\| \\nabla _ { \\boldsymbol { x } } h _ { i } \\| _ { 2 } ^ { 2 } } \\big ) \\leq \\| \\nabla _ { \\boldsymbol { \\theta } } g _ { \\boldsymbol { \\theta } } ( \\boldsymbol { x } ) \\| _ { 2 } ^ { 2 } .\n$$\n\nAlgorithm 1 The training algorithm of Mirror Gradient\n\nInput: The recommendation model $\\mathbf { R } ( \\cdot )$ ; learning rate $\\eta$ ; the number of iteration $T$ ; The scaling coefficients $\\alpha _ { 1 } , \\alpha _ { 2 } \\in \\mathbb { R } ^ { + }$ and $\\alpha _ { 1 } > \\alpha _ { 2 }$ . The interval $\\beta \\in \\mathbb { N } ^ { + }$ of mirror training.\n\nOutput: Model parameters $\\Theta$ .\n\n1: for $t$ from 1 to $T$ do   \n2: if $t$ mod $\\beta = = 0$ do ⊲ Mirror Training   \n3: $\\begin{array} { r l } & { \\Theta _ { t } ^ { ' } = \\Theta _ { t - 1 } - \\alpha _ { 1 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) ; } \\\\ & { \\Theta _ { t } = \\Theta _ { t } ^ { ' } + \\alpha _ { 2 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t } ^ { ' } ) ; } \\end{array}$   \n4:   \n5: else do ⊲ Normal Training   \n6: $\\Theta _ { t } = \\Theta _ { t - 1 } - \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) ;$   \n7: end if   \n8: end for   \n9: return Θ\n\nTheorem 3.2. Mirror Training in Eq. (3) is equal to introducing an implicit regularization term $\\lVert \\nabla _ { \\Theta } L _ { R } ( \\Theta ) \\rVert _ { 2 } ^ { 2 }$ to the original optimization objective $L _ { R } ( \\Theta )$ .\n\nProof. In Mirror Training, we have\n\n$$\n\\begin{array} { r l } & { \\Theta _ { t } = \\Theta _ { t } ^ { ' } + \\alpha _ { 2 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t } ^ { ' } ) } \\\\ & { \\qquad = \\Theta _ { t - 1 } - \\alpha _ { 1 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) } \\\\ & { \\qquad + \\alpha _ { 2 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } - \\alpha _ { 1 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) ) . } \\end{array}\n$$\n\nNext, since $\\eta$ is small, we can use Taylor expansion for estimating $\\nabla _ { \\Theta } L _ { \\mathrm { R } } \\big ( \\Theta _ { t - 1 } - \\alpha _ { 1 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } \\big ( \\Theta _ { t - 1 } \\big ) \\big )$ , and we have\n\n$$\n\\begin{array} { r l } & { \\Theta _ { t } \\approx \\Theta _ { t - 1 } - \\alpha _ { 1 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) + \\alpha _ { 2 } \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) } \\\\ & { \\qquad - \\alpha _ { 1 } \\alpha _ { 2 } \\eta ^ { 2 } \\nabla _ { \\Theta } ^ { 2 } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) ^ { \\top } \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) } \\\\ & { \\qquad = \\Theta _ { t - 1 } - ( \\alpha _ { 1 } - \\alpha _ { 2 } ) \\eta \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) } \\\\ & { \\qquad - \\frac { 1 } { 2 } \\cdot \\alpha _ { 1 } \\alpha _ { 2 } \\eta ^ { 2 } \\nabla _ { \\Theta } \\Vert \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) \\Vert _ { 2 } ^ { 2 } . } \\end{array}\n$$\n\nTherefore, from Eq. (6), we can find that the equivalent objective function for Mirror Training $L _ { M }$ is\n\n$$\n\\begin{array} { r } { L _ { M } = ( \\alpha _ { 1 } - \\alpha _ { 2 } ) \\underbrace { L _ { \\mathrm { R } } ( \\Theta ) } _ { \\mathrm { m a i n t e r m } } + \\alpha _ { 1 } \\alpha _ { 2 } \\eta \\cdot \\underbrace { \\| \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) \\| _ { 2 } ^ { 2 } } _ { \\mathrm { r e g u l a r i z a t i o n t e r m } } , } \\end{array}\n$$\n\nwhere $\\alpha _ { 1 } \\alpha _ { 2 } \\eta > 0$ and $\\alpha _ { 1 } - \\alpha _ { 2 } > 0$ .\n\nThe essence of MG, as revealed in Theorem 3.2, lies in the addition of a regularization term concerning gradient magnitude to the original objective function $L _ { \\mathrm { R } } ( \\Theta )$ implicitly. It’s worth noting that the magnitude of gradients near flat local minima is quite small. And since $\\alpha _ { 1 } \\alpha _ { 2 } \\eta > 0$ , Eq. (6) requires that the norm of gradient $\\lVert \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta ) \\rVert _ { 2 } ^ { 2 }$ should be sufficiently small, i.e., MG will lead the model’s parameters towards flatter minima. Furthermore, from Lemma 3.1 and Eq.(7), let the scalar function is $L _ { \\mathrm { R } }$ in recommender system, we have\n\n$$\n\\begin{array} { r l } { { \\cal L } _ { \\cal M } \\ge \\alpha _ { 1 } \\alpha _ { 2 } \\eta \\cdot \\| \\nabla _ { \\Theta } { \\cal L } _ { \\mathrm { R } } ( \\Theta _ { t - 1 } ) \\| _ { 2 } ^ { 2 } } & { } \\\\ { \\ge \\alpha _ { 1 } \\alpha _ { 2 } \\eta \\cdot \\displaystyle \\sum _ { j = 1 } ^ { L } O \\big ( \\frac { 1 + \\| h _ { i } \\| _ { 2 } ^ { 2 } } { \\| \\nabla _ { x } h _ { i } \\| _ { 2 } ^ { 2 } } \\big ) \\cdot } & { \\underbrace { \\| \\nabla _ { x } { \\cal L } _ { \\mathrm { R } } \\| _ { 2 } ^ { 2 } } _ { \\mathrm { ~ . ~ } } } \\end{array}\n$$\n\nrobustness term\n\nIn general, $\\left( 1 + \\| h _ { i } \\| _ { 2 } ^ { 2 } \\right) / ( \\| \\nabla _ { x } h _ { i } \\| _ { 2 } ^ { 2 } )$ is bounded and positive. Taking BM3 [66] on the Baby as an example, its value is bounded [24, 25] and around 96.16 with the well-trained system. Therefore, from Eq. (8) and Eq. (7), we can infer that MG also aims to minimize the impact of inputs on the loss, $\\| \\nabla _ { x } L _ { \\mathrm { R } } \\| _ { 2 } ^ { 2 }$ , while enhancing the model’s robustness against input perturbations.\n\nFurthermore, although Eq. (7) reveals that our proposed MG is equivalent to adding a regularization term $\\lVert \\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\bar { \\Theta } _ { t - 1 } ) \\rVert _ { 2 } ^ { 2 }$ during the optimization process of recommender systems, we do not recommend directly including this term in the loss function. On one hand, computing this term requires the prior calculation of the gradient $\\nabla _ { \\Theta } L _ { \\mathrm { R } } ( \\Theta _ { t - 1 } )$ , implying additional computational overhead during inference and not easy to implement. On the other hand, this kind of explicit loss term is not conducive to optimization and generally results in relatively poor performance [10]. In fact, our proposed MG is an implicit optimization of the additional regularization term shown in Eq. (7). It is also straightforward to implement. Hence, MG possesses greater practical applicability and potential.",
  "experiments": "",
  "hyperparameter": "- β: The interval for applying mirror training (e.g., every β iterations). Typical value: 3.\n- α₁: Scaling factor for the first gradient step in mirror training. Controls the step size in the initial update. Positive real number, typically greater than α₂.\n- α₂: Scaling factor for the second gradient step in mirror training. Controls the step size in the corrective update. Positive real number, typically less than α₁.\n- η: Learning rate used in the optimization process. Not specific to MG but involved in the gradient steps. Typical values depend on the base model and dataset."
}
