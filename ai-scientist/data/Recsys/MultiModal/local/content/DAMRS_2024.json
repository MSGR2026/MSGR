{
  "id": "DAMRS_2024",
  "paper_title": "Improving Multi-modal Recommender Systems by Denoising and Aligning Multi-modal Content and User Feedback",
  "alias": "DAMRS",
  "year": 2024,
  "domain": "Recsys",
  "task": "MultiModalRecommendation",
  "introduction": "",
  "method": "# 3 Methodology\n\nAs shown in Figure 2, DAMRS consists of three modules. Following structure-based methods [14, 34, 35], DAMRS extracts item-item graphs from multi-modal content that reflect static semantic relations among items. Since the multi-modal content is noisy, we propose Denoising Item-item Graph (Section 3.2) to accurately capture item-item semantic relations and build multiple modalityspecific item-item semantic graphs. To further utilize dynamic behavior information, we build an item-item behavior graph. Then, the representations of users and items are derived from item-item graphs and the backbone CF model, and the user feedback is utilized as supervised signals to optimize the representations. Due to the noisy nature of user feedback, we propose Denoising User Feedback (Section 3.3) to eliminate the impact of erroneous feedback signals and derive the objective based on the well-known BPR loss. Finally, we align the multi-modal content and user feedback through two aligning methods (Section 3.4) guided by the user preference and the graded item relations.\n\n# 3.1 Preliminaries\n\nLet $\\boldsymbol { \\mathcal U }$ and $\\boldsymbol { \\mathcal { T } }$ denote the user and item sets. $| \\mathcal { U } |$ and $| { \\cal T } |$ denote the number of users and items, respectively. The user-item interaction matrix is $\\mathbf { O } \\in \\mathbb { R } ^ { | \\mathcal { U } | \\times | \\mathcal { I } | }$ , where $\\mathbf { O } _ { u i } = 1$ suggests the user $u$ interacts (e.g., clicks, views, etc.) with item $i$ , otherwise $\\mathbf { O } _ { u i } = 0$ . The content of each item ?? for each modality $\\mathfrak { m } \\in { \\mathcal { M } }$ is pre-processed (e.g., by a pre-trained model), and the feature vector is denoted as $\\mathbf { e } _ { i } ^ { \\mathfrak { m } } \\in \\mathbb { R } ^ { d _ { \\mathfrak { m } } }$ , where $d _ { \\mathfrak { m } }$ is the embedding dimension, e.g., $\\mathcal { M } = \\{ \\mathsf { v } , \\mathsf { t } , \\mathsf { a } \\}$ for visual, textual, and acoustic modalities, respectively. Given O and $\\mathbf { e } ^ { \\mathfrak { m } }$ , ${ \\mathfrak { m } } \\in$ $M$ , the task of multi-modal recommender systems (MRSs) is to deliver a ranking list of possible recommendations that each user $u$ may prefer, according to the predicted user-item preference score $\\widehat { y } _ { u i }$ .\n\n# 3.2 Denoising Item-item Graph\n\nGiven the user feedback and the multi-modal content, existing structure-based methods [14, 34, 35] typically create item-item graphs by connecting each item to its top- $k$ most similar items in each modality. Their construction strategies have two problems. (1) Most studies [14, 34, 38] merge similar items in each modality into one item-item graph. If the similarity is mistakenly amplified based on noisy content, false positive links are introduced into the graph. For example, \"carpet\" and \"painting\" in Figure 1(b) can be falsely connected since their noisy visual attributes are similar. (2) They focus on semantic relations extracted from multi-modal content while neglecting behavior relations extracted from user feedback. Thus, they can not fully reveal the collaborative relations among items.\n\nTo address these problems, instead of constructing one graph, we construct multiple item-item graphs, namely Item-item Semantic Graph (IIS-Graph) and Item-item Behavior Graph (IIB-Graph). Each IIS-Graph is constructed in one modality to distinguish modality specific semantic relations, and the construction is based on consistent similarity across modalities to avoid false positive links. The IIB-Graph is constructed from user feedback to represent cooccurrence behaviors. IIS-Graph and IIB-Graph are complementary, i.e., they mitigate the noise and sparsity problems of each other. By using them together, a more comprehensive item-item collaborative relationship can be established.\n\n3.2.1 Item-item Semantic Graph. We initialize a dense matrix $\\mathsf { S } ^ { \\mathsf { m } } , \\mathsf { m } \\in { \\mathcal { M } }$ , where each element $\\mathsf { S } _ { i , j } ^ { \\mathsf { m } }$ measures the similarity between the two items ?? and $j$ in modality m. We employ cosine similarity as the similarity metric due to its parameter independence and lower computational complexity, i.e., $\\mathbf { \\widetilde { S } } _ { i , j } ^ { \\mathtt { m } } = \\big ( ( \\mathbf { e } _ { i } ^ { \\mathtt { m } } ) ^ { T } \\mathbf { e } _ { j } ^ { \\mathtt { m } } \\big ) / \\big ( \\lVert \\mathbf { e } _ { i } ^ { \\mathtt { m } } \\rVert \\lVert \\mathbf { e } _ { j } ^ { \\mathtt { m } } \\rVert \\big )$ .\n\nTo prune false positive links, we first discard entries with smaller similarities in the dense matrix $\\mathtt { S } ^ { \\mathtt { m } }$ . This step avoids the impact of amplified similarity in certain modalities. For example, in Ecommerce platforms, since most retailers use verbose descriptions, the textual similarities tend to be higher than visual similarities. Specifically, let $\\overline { { \\mathbf { S } ^ { \\mathfrak { m } } } } = \\bigl ( \\sum _ { i } \\sum _ { j } \\mathbf { S } _ { i , j } ^ { \\mathfrak { m } } \\bigr ) / \\bigl ( | \\mathcal { I } | ^ { 2 } \\bigr )$ represents the average similarity in modality $\\mathsf { m }$ , if $\\mathsf { S } _ { i , j } ^ { \\mathtt { m } } \\ < \\ \\overline { { \\mathsf { S } ^ { \\mathtt { m } } } }$ , we set $\\mathsf { S } _ { i , j } ^ { \\mathsf { m } } = 0$ . Then, we discard entries that exhibit inconsistency across modalities. This step prevents semantic relations from being mistakenly added due to noisy content. For example, if two irrelevant items are assigned identical pictures due to a system error, they may be similar in visual modality but dissimilar in textual modality. Specifically, entries with small similarities in other modalities are deleted, i.e., $\\mathsf { S } _ { i , j } ^ { \\mathsf { m } } = 0$ if $\\exists \\mathrm { m } ^ { \\prime } , \\boldsymbol { \\mathrm { \\sf { S } } } _ { i , j } ^ { \\mathrm { m ^ { \\prime } } } = 0 .$\n\nNext, we use the $k$ -Nearest Neighbors method to construct the IIS-Graph’s adjacency matrix $\\mathbf { A } ^ { \\mathfrak { m } }$ . For each item $i \\in \\mathcal { I }$ , we retrieve the top $K$ items with the highest similarity and generate a list of elements called top- $\\mathbf { \\cdot k } ( \\mathbf { S } _ { i , : } ^ { \\mathfrak { m } } )$ . To enhance computational efficiency, we set the non-zero elements in top- $\\operatorname { k } ( \\mathbb { S } _ { i , : } ^ { \\mathfrak { m } } )$ to 1. The adjacency matrix of the IIS-Graph $\\mathbf { G } ^ { \\mathfrak { m } }$ is defined as\n\n$$\n\\begin{array} { r } { \\mathbf { A } _ { i , j } ^ { \\mathtt { m } } = \\left\\{ \\begin{array} { l l } { 1 , } & { \\mathbf { S } _ { i , j } ^ { \\mathtt { m } } \\in \\mathrm { t o p - k } ( \\mathbf { S } _ { i , : } ^ { \\mathtt { m } } ) \\& \\mathbf { S } _ { i , j } ^ { \\mathtt { m } } > 0 , } \\\\ { 0 , } & { \\mathrm { o t h e r w i s e } . } \\end{array} \\right. } \\end{array}\n$$\n\n3.2.2 Item-item Behavior Graph. We initialize an item-item cooccurrence matrix $\\mathsf { S } ^ { \\mathsf { c } }$ , where each element ${ \\tt S } _ { i , j } ^ { \\tt c }$ records the frequency of two items $i$ and $j$ clicked by a same user. The idea is that if two items appear together in the user’s clicked lists, they are likely to be semantically relevant. Then, we prune infrequent elements, i.e., $\\mathsf { S } _ { i , j } ^ { \\mathsf { c } } \\ < \\ \\xi _ { B }$ , where $\\xi _ { B }$ is the pruning threshold. The pruning step avoids the impact of random behaviors, e.g., co-occurrence caused by the user randomly clicking an item. Next, we employ the $k$ -Nearest Neighbors method to process the matrix. For each item $i \\in \\mathcal { I }$ , we retrieve the top $K$ items with the highest similarity and generate top- $\\mathbf { \\cdot k } ( \\mathbf { S } _ { i , : } ^ { \\mathsf { c } } )$ . The adjacency matrix of Item-item Behavior Graph $\\mathbf { G } ^ { \\mathsf { c } }$ is defined as\n\n$$\n\\begin{array} { r } { \\mathbf { A } _ { i , j } ^ { \\mathrm { c } } = \\left\\{ \\begin{array} { l l } { \\mathrm { S } _ { i , j } ^ { \\mathrm { c } } , \\quad \\mathrm { S } _ { i , j } ^ { \\mathrm { c } } \\in \\mathrm { t o p - k } ( \\mathrm { S } _ { i , : } ^ { \\mathrm { c } } ) \\ \\& \\ i \\neq j \\ \\& \\ \\mathrm { S } _ { i , j } ^ { \\mathrm { c } } \\geq \\xi _ { B } , } \\\\ { 1 , \\quad i = j , } \\\\ { 0 , \\quad \\mathrm { o t h e r w i s e } . } \\end{array} \\right. } \\end{array}\n$$\n\n3.2.3 User and Item Representation. We can treat the co-occurrence as another modality and add IIB-Graph to the modality-specific item-item graphs, i.e., $M = M \\cup \\{ { \\mathsf { c } } \\}$ . We perform graph convolutions on each item-item graph. Among the various graph convolution methods, we select LightGCN [10] as the convolution kernel for message propagation and aggregation because of its simplicity in computation and widespread adoption. We stack $l$ layers and obtain the last layer’s representations as the embeddings for each modality, i.e., $\\mathbf { h } _ { i } ^ { \\mathsf { v } }$ , ${ \\bf h } _ { i } ^ { \\mathrm { t } }$ and $\\mathbf { h } _ { i } ^ { \\mathsf { c } }$ are item representations learned on IIS-Graph $\\mathbf { G } ^ { \\mathsf { v } }$ , IIS-Graph $\\mathbf { G } ^ { \\mathrm { t } }$ and IIB-Graph $\\mathbf { G } ^ { \\mathtt { C } }$ , respectively.\n\nFollowing other structure-based methods [14, 34, 35], DAMRS can plug in various collaborative filtering (CF) methods that model user-item interactions. We feed the user ID embeddings, item ID embeddings, and user observed feedback O to the backbone CF method and obtain the user embeddings $\\mathbf { u } _ { u }$ for user $u$ and item embeddings $\\mathbf { h } _ { i } ^ { \\mathrm { i d } }$ for item ??. Note that the user representation is obtained solely by the backbone CF method. We use the item embeddings learned from IIS-Graph, IIB-Graph, and the backbone CF method to obtain the item representation:\n\n$$\n\\mathbf { t } _ { i } = \\mathrm { M e a n p o o l i n g } \\big ( \\mathbf { h } _ { i } ^ { \\mathrm { i d } } , \\mathrm { M e a n p o o l i n g } ( \\mathbf { h } _ { i } ^ { \\mathrm { v } } , \\mathbf { h } _ { i } ^ { \\mathrm { t } } , \\mathbf { h } _ { i } ^ { \\mathrm { c } } ) \\big ) .\n$$\n\n# 3.3 Denoising User Feedback\n\nAfter obtaining the user embeddings $\\mathbf { u }$ and item embeddings t, conventional RSs usually use Bayesian Personalized Ranking [17] (BPR) loss. Let $y$ denotes the true user behavior; the probability a user $u$ prefers item ?? over item $j$ (i.e., $y _ { u i } > y _ { u j }$ ) is determined by the model parameters $\\Theta$ .\n\n$$\n\\begin{array} { r } { p ( y _ { u i } > y _ { u j } | \\Theta ) = \\sigma ( \\widehat { y } _ { u i } - \\widehat { y } _ { u j } ) , } \\end{array}\n$$\n\nwhere $\\widehat { y } _ { u i }$ is the predicted user-item preference score. It is combmonly defined as $\\bar { \\widehat { y } } _ { u i } = \\mathbf { u } _ { u } ^ { \\textit { T } } \\mathbf { t } _ { i }$ , where the user and item representations are part of the model parameters $\\mathbf { u } \\in \\Theta , \\mathbf { t } \\in \\Theta , \\sigma ( )$ represents the sigmoid function.\n\nA training set $\\mathcal { D } = \\{ \\langle u , i , j \\rangle \\}$ is constructed from the observations $\\mathbf { O }$ [17]. Each triple in the training set $\\langle u , i , j \\rangle$ contains a positive observation $\\mathbf { O } _ { u i } = 1$ , and a randomly sampled negative observation $\\mathbf { O } _ { u j } = 0$ . The BPR loss assumes a triple $\\langle u , i , j \\rangle$ implies $y _ { u i } > y _ { u j }$ . The model parameters are optimized via the BPR loss:\n\n$$\n\\begin{array} { r l } & { \\mathcal { L } _ { B P R } = l n \\big ( \\boldsymbol { \\rho } ( \\boldsymbol { \\Theta } | \\mathcal { D } ) \\big ) } \\\\ & { \\qquad \\propto l n \\big ( \\boldsymbol { \\rho } ( \\mathcal { D } | \\boldsymbol { \\Theta } ) \\times \\boldsymbol { \\mathcal { p } } ( \\boldsymbol { \\Theta } ) \\big ) } \\\\ & { \\qquad = \\displaystyle \\sum _ { \\langle u , i , j \\rangle \\in \\mathcal { D } } l n \\big ( \\boldsymbol { \\rho } ( y _ { u i } > y _ { u j } | \\boldsymbol { \\Theta } ) \\big ) + \\lambda _ { \\boldsymbol { \\Theta } } | | \\boldsymbol { \\Theta } | | ^ { 2 } , } \\end{array}\n$$\n\nwhere $\\lambda _ { \\Theta }$ is the regularization coefficient.\n\nHowever, due to the presence of noisy feedback [3, 13, 29, 30], the observation triple $\\langle u , i , j \\rangle$ is not equivalent to true user behavior $y _ { u i } ~ > ~ y _ { u j }$ . Our basic idea is to treat the observation triple as a random variable, and the probability of the observation triple is conditioned on the true user behavior. Inspired by the BPR loss [17], we assume the true user behavior is a ranked list, and the pair-wise rank is either $y _ { u i } > y _ { u j }$ or $y _ { u i } < y _ { u j }$ 1 .\n\nWhen the true user behavior $y _ { u i } > y _ { u j }$ , we assume that the observation triple is drawn from a Bernoulli distribution2 parameterized by $f ( u , i )$ , i.e., $\\begin{array} { r } { p \\big ( \\langle u , i , j \\rangle \\in \\mathcal { D } | y _ { u i } > y _ { u j } , \\Theta \\big ) = B e r n o u l l i ( f ( u , i ) ) . } \\end{array}$ . If the observation is correct and reliable, then $f ( u , i ) = 1$ . In other words, the value of $f ( u , i )$ measures the reliability of the observation $\\langle u , i , j \\rangle \\in \\mathcal { D }$ . Intuitively, since users respond to their preferred multi-modal content, e.g., a fashion-goer prefers trending elements in the displayed image, we can use the estimated preference score on multi-modal content to define $f ( u , i )$ . That is, the stronger a user is attracted to the item’s multi-modal content, the more reliable the observation triple is. Furthermore, the more consistent the user is attracted across different modalities, the more possible the triple can be observed. Specifically, we estimate the user-item preference score on each modality and calculate the mean and variance across different modalities.\n\n$$\n\\begin{array} { r l r } & { } & { \\boldsymbol { f } ( u , i ) = ( \\mu _ { u i } ) ^ { \\alpha } \\times ( e ^ { - s _ { u i } ^ { 2 } } ) ^ { \\beta } , ~ } \\\\ & { } & { \\mu _ { u i } = \\frac { \\sum _ { \\mathfrak { m } \\in \\mathcal { M } } \\sigma \\left( \\widehat { y } _ { u i } ^ { \\mathfrak { m } } \\right) } { \\left| \\mathcal { M } \\right| } , ~ s _ { u i } ^ { 2 } = \\frac { \\sum _ { \\mathfrak { m } \\in \\mathcal { M } } \\left( \\mu _ { u i } - \\sigma ( \\widehat { y } _ { u i } ^ { \\mathfrak { m } } ) \\right) ^ { 2 } } { \\left| \\mathcal { M } \\right| } , } \\\\ & { } & { \\widehat { y } _ { u i } ^ { \\mathfrak { m } } = ( \\mathbf { u } _ { u } ) ^ { T } \\mathbf { h } _ { i } ^ { \\mathfrak { m } } , ~ } \\end{array}\n$$\n\nwhere $\\mu _ { u i }$ denotes the average estimated preference score of user $u$ on item $i$ across all modalities. We employ the sigmoid function $\\sigma ( )$ to ensure that $\\mu \\in ( 0 , 1 ) . s _ { u i } ^ { 2 }$ denotes the variance of the estimated preference scores of user $u$ for item $i$ across all modalities. Since $s _ { u i } ^ { 2 } > 0 , e ^ { - s _ { u i } ^ { 2 } } \\in ( 0 , 1 ) . \\alpha , \\beta > 0$ are two hyper-parameters. Therefore, the function $f ( u , i ) \\in ( 0 , 1 )$ ensures a Bernoulli probability. In Equation 6, the more the user prefers the multi-modal content (i.e., larger $\\mu _ { u i }$ ) and the more consistent the user preference is across modalities (i.e., smaller $s _ { u i } ^ { 2 } )$ , the more reliable the observation triple is (i.e., larger $f ( u , i ) )$ .\n\nIf the true user behavior $y _ { u i } < y _ { u j }$ , we define another Bernoulli distribution $\\begin{array} { r } { p \\big ( \\langle u , i , j \\rangle \\in \\mathcal { D } | y _ { u i } < y _ { u j } , \\Theta \\big ) = B e r n o u l l i ( g ( u , i ) ) } \\end{array}$ to be parameterized by $g ( u , i )$ . The value of $g ( u , i )$ quantifies the probability of incidents that the observation contradicts the user’s true behavior. Intuitively, one possible cause of such incidents is when a user is influenced by a certain modality of an item and interacts with it. For example, a user is attracted by an item’s high-quality product image and clicks it, although afterward, he finds the item is not what he seeks. Another possible cause is when there are no comparable products on the market. For example, a user does not like the item, but since there is no substitute, he clicks it and attempts to evaluate it with an open mind. To model such phenomena, we can define $g ( u , i )$ based on the maximal estimated preference score on the target item ?? in any single modality and the estimated preference score on competitors.\n\n$$\n\\begin{array} { c } { \\displaystyle g ( u , i ) = \\left. \\sigma \\big ( \\mathrm { m a x } _ { \\mathrm { m } } \\big ( \\widehat { y } _ { u i } ^ { \\mathrm { m } } \\big ) - \\widehat { y } _ { n } \\big ) ^ { \\gamma } , \\quad \\widehat { y } _ { n } > \\mu _ { u i } , \\right. } \\\\ { \\displaystyle 0 , \\quad \\mathrm { o t h e r w i s e } , } \\\\ { \\displaystyle \\widehat { \\overline { { y } } _ { n } } = \\frac { \\sum _ { \\langle u , j \\rangle \\in \\mathcal { B } } \\sigma ( \\widehat { y } _ { u j } ) } { | \\mathcal { B } | } , } \\end{array}\n$$\n\nwhere $\\operatorname* { m a x } _ { \\mathfrak { m } } ( \\widehat { y } _ { u i } ^ { \\mathfrak { m } } )$ represents the maximal estimated preference score of user $u$ on item $i$ in any modality. $\\overline { { \\widehat { y } _ { n } } }$ represents the average user preference score of negative samples within the mini-batch $\\mathcal { B }$ $\\gamma > 0$ is a hyper-parameter. We employ the sigmoid function $\\sigma ( )$ to ensure $g ( u , i ) \\in ( 0 , 1 )$ . Thus, when the user does not like the item (i.e., $\\overline { { \\widehat { y _ { n } } } } > \\mu _ { u i } )$ , the more the user is attracted by a certain modality (i.e., larger $\\operatorname* { m a x } ( \\widehat { y } _ { u i } ^ { \\mathfrak { m } } ) )$ and the less the user prefers other products (i.e., smaller $\\overline { { { \\widehat { y } } _ { n } } } .$ ), the more possible the observation triple appears (i.e., larger $g ( u , i ) )$ .\n\nBased on the above reasoning, we derive the objective for denoised user feedback $\\mathsf { a s } ^ { 3 }$ ,\n\n$$\n\\begin{array} { r l r } { \\mathcal { L } _ { D \\cdot B P R } = \\displaystyle \\sum _ { \\langle u , i , j \\rangle \\in \\mathcal { D } } l n \\bigg ( f ( u , i ) \\sigma \\big ( \\mathbf { u } _ { u } ^ { \\textit { T } } ( \\mathbf { t } _ { i } - \\mathbf { t } _ { j } ) \\big ) + g ( u , i ) \\Big ( 1 - \\sigma \\big ( \\mathbf { u } _ { u } ^ { \\textit { T } } ( \\mathbf { t } _ { i } - \\mathbf { t } _ { j } ) \\big ) \\Big ) \\bigg ) } & { } & \\\\ { + \\lambda _ { \\Theta } | | \\Theta | | ^ { 2 } . } & { } & { { \\mathrm { ( 8 ) } } } \\end{array}\n$$\n\n# 3.4 Aligning Multi-modal Content and User Feedback\n\nAlignment between multi-modal content and user feedback is underexplored in current MRSs. The recommendation performance is damaged because the embeddings learned from multi-modal content and user feedback usually reside in different regions of the feature space. To better integrate multi-modal content and user feedback, we align them. The recommender system consists of items and users. Naturally, our alignment is split into two parts.\n\n3.4.1 Alignment guided by user perference. The item-level alignment can be seen as instance-level alignment on parallel corpora in traditional multi-modal systems. We believe that only instancelevel alignment is insufficient in MRSs because the goal of recommender systems is essentially to predict user preference instead of understanding multi-modal content. Our motivation is to use the user preference to orient multi-modal content. For example, if a user prefers a pen over a pencil, then the estimated preference from multi-modal content for the pen should be larger than the estimated preference for the pencil.\n\nSpecifically, we extract distinct users from the mini-batch $\\mathcal { B }$ and form $\\mathcal { B } _ { \\mathrm { u } }$ . For each user $u \\in \\mathcal { B } _ { \\mathsf { U } }$ , we compute preference scores on multi-modal content with respect to all $i \\in \\mathcal { I }$ by $\\widehat { y } _ { u i } ^ { \\mathrm { m m } } = ( \\mathbf { u } _ { u } ) ^ { T } \\mathbf { h } _ { i } ^ { \\mathrm { m m } }$ where $\\mathbf { h } ^ { \\mathsf { m m } } = \\mathrm { M e a n P o o l i n g } ( \\mathbf { h } ^ { \\mathsf { v } } , \\mathbf { h } ^ { \\mathsf { t } } , \\mathbf { h } ^ { \\mathsf { c } } )$ . Then, we compute the preference distribution of the user $u$ over items based on multi-modal content,\n\n$$\nP _ { u } ^ { \\mathfrak { m } \\mathfrak { m } } = \\mathrm { s o f t m a x } ( [ \\widehat { y } _ { u 1 } ^ { \\mathfrak { m } \\mathfrak { m } } , . . . , \\widehat { y } _ { u | \\mathcal { I } | } ^ { \\mathfrak { m } \\mathfrak { m } } ] ) ,\n$$\n\nwhere $| { \\cal T } |$ represents the number of items, softmax() represents the softmax function.\n\nSimilarly, we can compute the preference distribution $P _ { u } ^ { \\mathrm { i d } }$ of $u$ over the itemset based on user feedback by $\\widehat { y } _ { u i } ^ { \\mathrm { i d } } = ( \\mathbf { u } _ { u } ) ^ { T } \\mathbf { h } _ { i } ^ { \\mathrm { i d } }$ . $\\mathcal { L } _ { A U }$ aligns the two preference distributions,\n\n$$\n\\mathcal { L } _ { A U } = \\sum _ { u \\in \\mathcal { B } _ { \\mathsf { u } } } K L [ P _ { u } ^ { \\mathsf { m m } } | | P _ { u } ^ { \\mathrm { i d } } ] + K L [ P _ { u } ^ { \\mathrm { i d } } | | P _ { u } ^ { \\mathsf { m m } } ] ,\n$$\n\nwhere $K L [ ]$ represents the KL divergence.\n\n3.4.2 Alignment guided by item graded relations. Contrastive learning is an efficient alignment method that aligns the positive samples and makes the negative samples more distinguishable. In defining positive and negative samples, current MRSs [35, 39] simplify the multi-modal relation as a binary relation, which is sub-optimal. (1) Considering similar items within a single modality as positive samples can result in false positives, impeding item representation learning. (2) Treating dissimilar items within a single modality as negative samples may overlook some potentially useful samples.\n\nWe believe the relations extracted from multi-modal content are graded in nature, i.e., items can be similar in multiple modalities, similar in a single modality, and dissimilar. Exploiting the graded relation is beneficial for finer-grained alignment. For example, when a user wants to purchase a jacket with a similar style to a previously bought shirt, similar shirts (visually similar to the jacket but textually dissimilar) and similar jackets (visually and textually similar) can improve our understanding of the preferred jackets.\n\nTo represent the similarity grades, we construct two types of positive samples for each modality, i.e., multi-modal similar items and single-modal similar items. Note that the multi-modal similar items and single-modal similar items differ in each modality m. For each modality m, we first compute a similarity matrix, $\\mathbf { T } _ { i , j } ^ { \\mathfrak { m } } =$ $\\left( ( \\mathbf { h } _ { i } ^ { \\mathsf { m } } ) ^ { T } \\mathbf { h } _ { j } ^ { \\mathsf { m } } \\right) / \\left( \\| \\mathbf { h } _ { i } ^ { \\mathsf { m } } \\| \\| \\mathbf { h } _ { j } ^ { \\mathsf { m } } \\| \\right)$ . Then, for each item $i \\in \\mathcal { I }$ , we use the softmax function softmax() to normalize the similarity scores, i.e., $\\widetilde { \\mathbf { T } } _ { i , : } ^ { \\mathfrak { m } } = \\operatorname { s o f t m a x } ( \\mathbf { T } _ { i , : } ^ { \\mathfrak { m } } )$ . Next, we modify the modal-aware multi-modal similarity by adding the aggregated multi-modal similarity, ${ \\bf R } _ { i , : } ^ { \\mathfrak { m } } =$ $\\begin{array} { r } { \\widetilde { \\mathbf { T } } _ { i , : } ^ { \\mathfrak { m } } + \\sum _ { \\mathfrak { m } } \\widetilde { \\mathbf { T } } _ { i , : } ^ { \\mathfrak { m } } } \\end{array}$ , i.e., incorporating the multi-modal similarity while highlighting the current modality. Thus, the multi-modal similar items are defined as the top $k$ similar items with largest $\\mathbf { R } _ { i , : } ^ { \\mathfrak { m } }$ , denoted as $\\mathcal { R } _ { i } ^ { \\mathfrak { m } }$ . To obtain single-modal similar items, we first remove the items in $\\mathcal { R } _ { i } ^ { \\mathfrak { m } }$ , i.e, $\\widetilde { \\mathbf { T } } _ { i , j } ^ { \\mathfrak { m } } = 0 , \\forall j \\in \\mathcal { R } _ { i } ^ { \\mathfrak { m } }$ . Then we retrieve top $k$ similar items with largest $\\widetilde { \\mathbf { T } } _ { i , j } ^ { \\mathfrak { m } }$ , and build the single-modal similar itemset $\\mathcal { T } _ { i } ^ { \\mathfrak { m } }$ . Consequently, we construct the dissimilar itemset ${ \\cal N } _ { i } ^ { \\mathfrak { m } }$ . For each $j \\in \\mathcal { T } _ { i } ^ { \\mathfrak { m } }$ , we set $\\widetilde { \\mathbf { T } } _ { i , j } ^ { \\mathfrak { m } } = 0$ . Then, the dissimilar itemset contains item in mini-batch $\\mathcal { B }$ , i.e., $N _ { i } ^ { \\mathfrak { m } } = \\{ j | j \\in \\mathcal { B } \\& \\mathbf { T } _ { i , j } ^ { \\mathfrak { m } } > 0 \\}$ .\n\nWe believe multi-modal similar items should be closer in the representation space than single-modal similar items, and single-modal similar items should be closer than dissimilar items. Accordingly, we propose the contrastive learning loss,\n\n$$\n\\mathcal { L } _ { A I - M M } = \\sum _ { \\mathfrak { m } } - l o g \\frac { \\sum _ { j \\in \\mathcal { R } _ { i } ^ { \\mathfrak { m } } } \\varphi ( \\mathbf { h } _ { i } ^ { \\mathfrak { m } } , \\mathbf { h } _ { j } ^ { \\mathfrak { m } } ) } { \\sum _ { j \\in \\mathcal { R } _ { i } ^ { \\mathfrak { m } } } \\varphi ( \\mathbf { h } _ { i } ^ { \\mathfrak { m } } , \\mathbf { h } _ { j } ^ { \\mathfrak { m } } ) + \\sum _ { k \\in \\mathcal { T } _ { i } ^ { \\mathfrak { m } } } \\varphi ( \\mathbf { h } _ { i } ^ { \\mathfrak { m } } , \\mathbf { h } _ { k } ^ { \\mathfrak { m } } ) + \\sum _ { l \\in \\mathcal { N } _ { i } ^ { \\mathfrak { m } } } \\varphi ( \\mathbf { h } _ { i } ^ { \\mathfrak { m } } , \\mathbf { h } _ { l } ^ { \\mathfrak { m } } ) } ,\n$$\n\nTable 1: Statistics of the datasets. $| \\mathcal { D } |$ , $| \\mathcal { U } |$ , $| { \\cal T } |$ represents the number of observations, users, and items. $\\overline { { \\mathsf { S } ^ { \\vee } } }$ , $\\overline { { \\mathsf { S } ^ { \\mathrm { t } } } }$ and $\\overline { { \\mathsf { S } ^ { \\mathsf { a } } } }$ represents the average visual, textual and acoustic similarity.   \n\n<table><tr><td>Datasets</td><td>|D</td><td>u</td><td></td><td>Sparsity</td><td>sv</td><td>st</td><td>sa</td></tr><tr><td>Baby</td><td>160,792</td><td>19,445</td><td>7,050</td><td>0.9988</td><td>0.2240</td><td>0.2627</td><td>-</td></tr><tr><td>Sports</td><td>296,337</td><td>35,598</td><td>18,357</td><td>0.9995</td><td>0.2085</td><td>0.2184</td><td>-</td></tr><tr><td>Clothing</td><td>278,677</td><td>39,387</td><td>23.033</td><td>0.9997</td><td>0.2239</td><td>0.3880</td><td>-</td></tr><tr><td>TikTok</td><td>68,722</td><td>9,308</td><td>6,710</td><td>0.9989</td><td>0.8556</td><td>0.7113</td><td>0.1245</td></tr></table>\n\n$$\n\\mathcal { L } _ { A I - S } = \\sum _ { \\mathfrak { m } } - l o g \\frac { \\sum _ { k \\in \\mathcal { T } _ { i } ^ { \\mathfrak { m } } } \\varphi ( \\mathbf { h } _ { i } ^ { \\mathfrak { m } } , \\mathbf { h } _ { k } ^ { \\mathfrak { m } } ) } { \\sum _ { k \\in \\mathcal { T } _ { i } ^ { \\mathfrak { m } } } \\varphi ( \\mathbf { h } _ { i } ^ { \\mathfrak { m } } , \\mathbf { h } _ { k } ^ { \\mathfrak { m } } ) + \\sum _ { l \\in { \\cal N } _ { i } ^ { \\mathfrak { m } } } \\varphi ( \\mathbf { h } _ { i } ^ { \\mathfrak { m } } , \\mathbf { h } _ { l } ^ { \\mathfrak { m } } ) } ,\n$$\n\nwhere $\\varphi ( \\mathbf { h } _ { i } ^ { \\mathfrak { m } } , \\mathbf { h } _ { j } ^ { \\mathfrak { m } } ) = e x p \\big ( s i m ( \\mathbf { h } _ { i } ^ { \\mathfrak { m } } , \\mathbf { h } _ { j } ^ { \\mathfrak { m } } ) / \\tau \\big )$ , $\\tau$ is the temperature, $s i m ( )$ is the cosine similarity.\n\nThe final loss consists of the denoised BPR loss, the aligning user preference loss, and the aligning graded item relations loss.\n\n$$\n\\mathcal { L } = \\mathcal { L } _ { D - B P R } + \\lambda _ { 1 } \\mathcal { L } _ { A U } + \\lambda _ { 2 } ( \\mathcal { L } _ { A I - M M } + \\mathcal { L } _ { A I - S } ) ,\n$$\n\nwhere $\\lambda _ { 1 } , \\lambda _ { 2 }$ are two hyper-parameters.",
  "experiments": "",
  "hyperparameter": "- k: Number of neighbors in k-NN for graph construction. Typical value: 10.\n- ξ_B: Pruning threshold for Item-item Behavior Graph. Typical value: 2.\n- α: Exponent for mean preference in f(u,i) function. Typical values: 1.5 (Baby, Clothing) or 3 (Sports).\n- β: Exponent for variance in f(u,i) function. Typical values: 1.5 (Baby, Clothing) or 3 (Sports).\n- γ: Exponent in g(u,i) function. Tuned amongst {2.0, 1.0}.\n- λ_1: Weight for alignment loss L_AU. Tuned amongst {10, 1, 0.1, 0.01}.\n- λ_2: Weight for alignment loss L_AI. Tuned amongst {1, 0.1, 0.01, 1e-3, 1e-4}.\n- learning_rate: Learning rate for optimizer. Tuned amongst {1e-4, 1e-3, 1e-2}."
}
