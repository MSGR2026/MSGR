{
  "id": "FREEDOM_2023",
  "paper_title": "A Tale of Two Graphs: Freezing and Denoising Graph Structures for Multimodal Recommendation",
  "alias": "FREEDOM",
  "year": 2023,
  "domain": "Recsys",
  "task": "MultiModalRecommendation",
  "introduction": "",
  "method": "# 3 FREEZING AND DENOISING GRAPH STRUCTURES\n\nIn this section, we elaborate on each component of FREEDOM from graph construction to item recommendation. Fig. 1 shows the overall architecture compared with LATTICE.\n\n![](images/65026ae70a010245f5135527d77ee1ef060f1ed693ed82f602ae74cb7a2fbb41.jpg)  \nFigure 1: Comparison of our proposed a) FREEDOM and b) LATTICE [28]. FREEDOM freezes the item-item graph and denoises the user-item graph simultaneously for multimodal recommendation.\n\n# 3.1 Constructing Frozen Item-Item Graph\n\nFollowing [28], FREEDOM also uses $k \\mathbf { N N }$ to construct an initial modalityaware item-item graph $s ^ { m }$ using raw features from each modality $m$ . Considering $N$ items, we calculate the similarity score $s _ { i j } ^ { m }$ between item pair ?? and $j$ with a cosine similarity function on their raw features $( \\boldsymbol { x } _ { i } ^ { m }$ and $\\pmb { x } _ { j } ^ { m }$ ) of modality $m$ . That is:\n\n$$\nS _ { i j } ^ { m } = \\frac { ( \\pmb { x } _ { i } ^ { m } ) ^ { \\top } \\pmb { x } _ { j } ^ { m } } { \\| \\pmb { x } _ { i } ^ { m } \\| \\| \\pmb { x } _ { j } ^ { m } \\| } ,\n$$\n\nwhere $s _ { i j } ^ { m }$ is the $i$ -th row, $j$ -th column element of matrix $s ^ { m } \\in$ $\\mathbb { R } ^ { N \\times N }$ . We further employ $k \\mathbf { N N }$ sparsification [1] and convert the weighted $s ^ { m }$ into an unweighted matrix. That is, for each item $i$ we only retain the connection relations of its top- $k$ similar edges:\n\n$$\n\\begin{array} { r } { \\widehat { S } _ { i j } ^ { m } = \\left\\{ \\begin{array} { l l } { 1 , \\ } & { S _ { i j } ^ { m } \\in \\mathrm { t o p } ^ { - } k ( S _ { i } ^ { m } ) , } \\\\ { 0 , \\ } & { \\mathrm { o t h e r w i s e } . } \\end{array} \\right. } \\end{array}\n$$\n\nEach element in ${ \\widehat { s } } ^ { m }$ is either 0 or 1, with 1 denoting a latent connection between the two items. We empirically fixed the value of $k$ at 10. Note that ${ \\widehat { S } } ^ { m }$ is different from the weighted similarity matrix of LATTICE, which uses the affinity values between items as its elements. We normalize the discretized adjacency matrix ${ \\widehat { s } } ^ { m }$ as $\\widetilde { S } ^ { m } = ( D ^ { m } ) ^ { - \\frac { 1 } { 2 } } \\widehat { S } ^ { m } ( D ^ { m } ) ^ { - \\frac { 1 } { 2 } }$ , where $D ^ { m } \\in \\mathbb { R } ^ { N \\times N }$ is the diagonal degree matrix of aware adjacency ${ \\widehat { s } } ^ { m }$ and trice $\\begin{array} { r } { D _ { i i } ^ { m } = \\sum _ { j } \\widehat { S } _ { i j } ^ { m } } \\end{array}$ . With the resulted modality-ct the latent item-item graph by aggregating the structures from each modality:\n\n$$\nS = \\sum _ { m \\in { \\cal M } } \\alpha _ { m } \\widetilde { S } ^ { m } ,\n$$\n\nwhere $S \\in \\mathbb { R } ^ { N \\times N }$ , $\\alpha _ { m }$ is the importance score of modality $m$ and $\\mathcal { M }$ is the set of modalities. Same as other studies [13, 28], we consider visual and textual modalities denoted by $\\boldsymbol { \\mathcal { M } } = \\{ \\boldsymbol { v } , t \\}$ in this paper. The importance score can be learned via parametric functions. Here, we reduce the model parameters by introducing a hyperparameter $\\alpha _ { v }$ denoting the importance of visual modality in constructing ??. We let $\\alpha _ { t } = 1 - \\alpha _ { v }$ .\n\nFinally, we freeze the latent item-item graph, which can greatly improve the efficiency of FREEDOM. To be specific, the construction of the similarity matrix under modality $m$ in Eq. (1) requires computational complexity of $O ( N ^ { 2 } d _ { m } )$ , where $d _ { m }$ is the dimension of raw features. As shown in Fig. 1, FREEDOM pre-calculates (dotted lines) the item-item graph before training and freezes it during model training. As a result, it removes the computational burden of $O ( N ^ { 2 } d _ { m } )$ for graph construction in training.\n\n# 3.2 Denoising User-Item Bipartite Graph\n\nIn this section, we introduce a degree-sensitive edge pruning to denoise the user-item bipartite graph. The idea is derived from recent researches on model sparsification [19] and simplification [3]. Specifically, DropEdge [19] randomly drops a certain ratio of edges in training. In [3], the authors verify that popular nodes are more likely to suffer from over-smoothing. Inspired by the finding, we sparsify the graph by pruning superfluous edges following a degreesensitive probability.\n\nFormally, we denote a user-item graph as $\\mathcal { G } = ( \\mathcal { V } , \\mathcal { E } )$ , where $_ \\mathrm { c } { } _ { V }$ is the set of nodes and $\\varepsilon$ is the set of edges. The number of users and items in the user-item graph is $M$ and $N$ , respectively. We have $M + N = | \\mathcal { V } |$ , where $| \\cdot |$ denotes the cardinality of a set. We construct a symmetric adjacency matrix $\\pmb { A } \\in \\mathbb { R } ^ { | \\mathcal { V } | \\times | \\mathcal { V } | }$ from the user-item interaction matrix $\\pmb { R } \\in \\mathbb { R } ^ { M \\times N }$\n\n$$\nA = \\left( \\begin{array} { l l l } { { { \\bf 0 } } } & { { R } } \\\\ { { R ^ { \\top } } } & { { { \\bf 0 } } } \\end{array} \\right) ,\n$$\n\nand each entry $A _ { u i }$ of $A$ is set to 1, if user $u$ has interacted with item $i$ , otherwise, $A _ { u i }$ is set to 0.\n\nGiven a specific edge $\\begin{array} { r } { e _ { k } \\in \\mathcal { E } , ( 0 \\le k < | \\mathcal { E } | ) } \\end{array}$ which connects node ?? and ??, we calculate its probability as ???? = 1 √???? √???? , where $\\omega _ { i }$ and $\\omega _ { j }$ are the degrees of nodes $i$ and $j$ in graph $\\mathcal { G }$ , respectively. Usually, we prune a certain proportion $\\rho$ of edges of the graph. That is, the number of edges should be pruned is $\\lfloor \\rho \\vert \\mathcal { E } \\vert \\rfloor$ , where $\\lfloor \\cdot \\rfloor$ is the floor function. As a result, the number of retained edges is $n = \\lceil \\lvert \\mathcal { E } \\rvert ( 1 - \\rho ) \\rceil$ . Thus, we sample edges from the multinomial distribution with index $n$ and parameter vector $\\pmb { p } = \\langle p _ { 0 } , p _ { 1 } , \\cdots , p _ { | \\mathcal { E } | - 1 } \\rangle$ In this way, edges connecting high-degree nodes have a low probability to be sampled from the graph. That is, these edges are more likely to be pruned in $\\mathcal { G }$ . We then construct a symmetric adjacency matrix $A _ { \\rho }$ based on the sampled edges following Eq. (4). In line with prior latent item-item graph, we also perform the re-normalization trick on $A _ { \\rho }$ , resulting as $\\widehat { A } _ { \\rho }$ . Same as DropEdge, FREEDOM prunes the user-item graph and normalizes the sampled adjacency matrix iteratively in each training epoch. However, we resort to the original normalized adjacency matrix $\\widehat { A } = D ^ { - 1 / 2 } A D ^ { - 1 / 2 }$ in model inference.\n\n# 3.3 Integration of Two Graphs for Learning\n\nWe perform graph convolutions on both graphs, that is, we employ a light-weighted GCN [10] for information propagation and aggregation on ?? and $\\widehat { A } _ { \\rho }$ . Specifically, the graph convolution over the item-item graph is defined as:\n\n$$\n\\widetilde { \\pmb { h } } _ { i } ^ { l } = \\sum _ { j \\in N ( i ) } S _ { i j } \\widetilde { \\pmb { h } } _ { j } ^ { l - 1 } ,\n$$\n\nwhere $N ( i )$ is the neighbor items of $i , \\widetilde { \\pmb { h } } _ { i } ^ { l } \\in \\mathbb { R } ^ { d }$ is the $l$ -th layer item representation of item $i , \\widetilde { \\pmb { h } } _ { i } ^ { 0 }$ denotes its corresponding ID embedding vector and $d$ is the dimension of an item or user ID embedding. We stack $L _ { i i }$ convolutional layers on the item-item graph $s$ and obtain the last layer representation $\\widetilde { \\pmb { h } } _ { i } ^ { L _ { i i } }$ as the representation $\\widetilde { \\pmb { h } } _ { i } \\in \\mathbb { R } ^ { d }$ of $i$ from the multimodal view:\n\n$$\n\\widetilde { \\pmb { h } } _ { i } = \\widetilde { \\pmb { h } } _ { i } ^ { L _ { i i } } .\n$$\n\nAnalogously, in the user-item graph, we perform $L _ { u i }$ convolutional operations on $\\widehat { A } _ { \\rho }$ and obtain embedding of a user $\\widehat { \\pmb { h } } _ { u } \\in \\mathbb { R } ^ { d }$ or an item $\\widehat { \\pmb { h } } _ { i } \\in \\mathbb { R } ^ { d }$ with a readout function on all the hidden representations resulted in each layer:\n\n$$\n\\begin{array} { r l } & { \\widehat { \\pmb { h } } _ { u } = \\mathrm { R E A D O U T } ( \\widehat { \\pmb { h } } _ { u } ^ { 0 } , \\widehat { \\pmb { h } } _ { u } ^ { 1 } , \\cdots , \\widehat { \\pmb { h } } _ { u } ^ { L _ { u i } } ) , } \\\\ & { \\widehat { \\pmb { h } } _ { i } = \\mathrm { R E A D O U T } ( \\widehat { \\pmb { h } } _ { i } ^ { 0 } , \\widehat { \\pmb { h } } _ { i } ^ { 1 } , \\cdots , \\widehat { \\pmb { h } } _ { i } ^ { L _ { u i } } ) , } \\end{array}\n$$\n\nwhere the READOUT function can be any differentiable function, $\\widehat { \\pmb { h } } _ { u } ^ { 0 }$ and $\\widehat { \\pmb { h } } _ { i } ^ { 0 } = \\widetilde { \\pmb { h } } _ { i } ^ { 0 }$ denotes the $\\mathrm { I D }$ embeddings of user $u$ and item $i$ respectively. We use the default mean function of LightGCN [10] for embedding readout.\n\nFinally, we use the user representation output by the user-item graph as its final representation. For the item, we sum up the representations obtained from the two graphs as its final representation.\n\n$$\n\\begin{array} { l } { { \\pmb { h } } _ { u } = \\widehat { \\pmb { h } } _ { u } , } \\\\ { { \\pmb { h } } _ { i } = \\widetilde { \\pmb { h } } _ { i } + \\widehat { \\pmb { h } } _ { i } . } \\end{array}\n$$\n\nTo fully explore the raw features, we project multimodal features of item $i$ in each modality via MLPs.\n\n$$\n\\pmb { h } _ { i } ^ { m } = \\pmb { x } _ { i } ^ { m } \\pmb { W } _ { m } + \\pmb { b } _ { m } ,\n$$\n\nwhere $W _ { m } \\in \\mathbb { R } ^ { d _ { m } \\times d } , b _ { m } \\in \\mathbb { R } ^ { d }$ denote the linear transformation matrix and bias in the MLP. In this way, each uni-modal representation $\\pmb { h } _ { i } ^ { m }$ shares the same latent space with its $\\mathrm { I D }$ embedding $\\mathbf { \\delta } _  \\mathbf { \\} } h _ { i }$ .\n\nFor model optimization, we adopt the pairwise Bayesian personalized ranking (BPR) loss [18], which encourages the prediction of a positive user-item pair to be scored higher than its negative pair:\n\n$$\n\\begin{array} { r l } { \\mathcal { L } _ { b p r } = \\displaystyle \\sum _ { ( u , i , j ) \\in \\mathcal { D } } \\Big ( - \\log \\sigma ( \\pmb { h } _ { u } ^ { \\top } \\pmb { h } _ { i } - \\pmb { h } _ { u } ^ { \\top } \\pmb { h } _ { j } ) + } & { } \\\\ { \\lambda \\displaystyle \\sum _ { m \\in \\mathcal { M } } - \\log \\sigma ( \\pmb { h } _ { u } ^ { \\top } \\pmb { h } _ { i } ^ { m } - \\pmb { h } _ { u } ^ { \\top } \\pmb { h } _ { j } ^ { m } ) \\Big ) , } \\end{array}\n$$\n\nwhere $\\mathcal { D }$ is the set of training instances, and each triple $( u , i , j )$ satisfies $A _ { u i } = 1$ and $A _ { u j } = 0 . \\sigma ( \\cdot )$ is the sigmoid function and $\\lambda$ is a hyperparameter of FREEDOM to weigh the reconstruction losses between user-item ID embeddings and projected multimodal features.\n\n# 3.4 Top- $K$ Recommendation\n\nTo generate item recommendations for a user, we first predict the interaction scores between the user and candidate items. Then, we rank candidate items based on the predicted interaction scores in descending order, and choose $K$ top-ranked items as recommendations to the user. The interaction score is calculated as:\n\n$$\n\\begin{array} { r } { r ( \\pmb { h } _ { u } , \\pmb { h } _ { i } ) = \\pmb { h } _ { u } ^ { \\top } \\pmb { h } _ { i } . } \\end{array}\n$$\n\nA high score suggests that the user prefers the item. Note that we only use user and item $\\mathrm { I D }$ embeddings for prediction, because we empirically find the adding of projected item multimodal features in prediction does not show improvement on performance. However, the item multimodal representations can partially benefit the learning of user representations in FREEDOM via Eq. (10).",
  "experiments": "",
  "hyperparameter": "- alpha_v: The importance of the visual modality in constructing the item-item graph, typically set between {0, 1}.\n- rho: The edge pruning ratio used in denoising the user-item graph, common values range from {0.8, 0.9}.\n- lambda: The regularization coefficient for balancing the loss terms, typically set to {1e-3}.\n- k: The number of nearest neighbors for constructing the item-item graph, typical value is {10}.\n- epochs: The number of training epochs, typically set to {1000}.\n- batch_size: The batch size for training, common values are {2048}.\n- learning_rate: The learning rate for optimization, common values are {0.0001, 0.001, 0.01}."
}
