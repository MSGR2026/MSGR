{
  "id": "KTUP_2020",
  "paper_title": "Unifying Knowledge Graph Learning and Recommendation:Towards a Better Understanding of User Preferences",
  "alias": "KTUP",
  "year": 2020,
  "domain": "Recsys",
  "task": "KnowledgeAwareRecommendation",
  "idea": "",
  "introduction": "# 1 INTRODUCTION\n\nKnowledge Graph (KG) is a heterogeneous structure that stores the world's knowledge in the form of machine-readable graphs, where nodes denote entities, and edges denote the relations between entities. Since proposed, KG has attracted much attention in many fields, ranging from recommendation [40], dialogue system [18, 21], to information extraction [3]. Focusing on recommendation, the structural knowledge has shown great potential in providing rich information about the items, offers a promising solution to improving the accuracy and explainability of recommender systems.\n\nNevertheless, existing KGs (e.g., DBPedia [20]) are far from complete, which limits the benefits of the transferred knowledge. As illustrated in Figure 1, the red dashed line between Robert Zemeckis and Death Becomes Her indicates a missing relation isDirectorOf. Assuming that the user has chosen movies Back to The Future I & II and Forrest Gump, by using the KG, we can attribute the reason of user's choices to the director Robert Zemeckis. In this case, although we have accurately captured the user's preference on movies, we may still fail to recommend Death Becomes Her (which is also of interest to the user), due to the missing relation in the KG (cf. the red dashed line). As such, we believe that it is critical to consider the incomplete nature of KG when using it for recommendation, and more interestingly, can the completion of KG benefit from the improved modeling of user-item interactions?\n\nIn this paper, we propose to unify the two tasks of recommendation and KG completion in a joint model for mutually enhancements. The basic idea is twofold: 1) utilizing the facts in KG as auxiliary data to augment the modeling of user-item interaction, and 2) completing the missing facts in KG based on the enhanced user-item modeling. For example, we are able to understand the user's preference on director via the related entities and relations; meanwhile we can predict that Robert Zemeckis is the director of Death Becomes Her, if there exist some users who like the movie also have a preference of other movies directed by Robert Zemeckis.\n\nAlthough many prior efforts have leveraged KG in recommender systems [16, 29, 30, 44, 46, 48], there are few works that jointly\n\n![](images/1ec1057a8c1d88d032f96c113e9426b108a79d49dfcca08ab33016432ac7f8fe.jpg)  \nFigure 1: An illustrative example on the necessity of considering the missing relations in KG for recommendation.\n\nmodel the two tasks of knowledge graph learning and recommendation. CoFM [31] is the most similar work that aligns the two latent vector spaces in each task together by regularizing or sharing entity and item embeddings if they refer to the same thing. However, it ignores the important role of entity relations in user-item modeling, and fails to offer interpretation ability.\n\nIn this work, we propose a Translation-based User Preference model (TUP) to integrate with KG learning seamlessly. The key idea is that there exists multiple (implicit) relations between users and items, which reveal the preferences (i.e., reasons) of users on consuming items. An example of the \"preference\" is the director information in Figure 1 that drives the user to watch the movies Back to Future I & II and Forest Gump. While we can pre-define the number of preferences and train TUP from user-item interaction data, the preferences are expressed as latent vectors that are opaque to deeper understanding. To endow the preferences with explicit semantics, we align them with the relations in KG, capturing the intuition that the type of item attributes plays a crucial role in user decision-making process. Technically speaking, we transfer the relation embeddings as well as entity embeddings learned from KG to TUP, simultaneously training the KG completion and recommendation tasks. We term the method as Knowledge-enhanced TUP (KTUP) that jointly learns the representations of users, items, entities, and relations. The main contributions are summarized:\n\n- We propose a new translation-based model, which exploits the implicit preference representations to capture the relations between users and items.  \n- We emphasize the importance of jointly modeling item recommendation and KG completion to couple the preference representations with the knowledge-aware relations, thus empowering the model with explainability.  \n- We perform extensive experiments on two datasets for top- \\(N\\)  recommendation and KG completion tasks, which verify the rationality of joint learning. Experimental results demonstrate the effectiveness and explainability of our model.\n",
  "method": "# 5 JOINT LEARNING VIA KTUP FOR TWO TASKS\n\nKTUP extends the translation-based recommendation model, TUP, by incorporating KG knowledge of entities as well as relations. Intuitively, the auxiliary knowledge supplements the connectivity among items as constraints to model user-item pairs. On the other hand, the understanding of users' preferences to items shall reveal their commonality related to some relation types and entities, which may be missing in the given KG.\n\n## 5.1 KTUP\n\nFigure 3 presents the overall framework of KTUP. On the left side is the inputs: user-item interactions, knowledge graph and the alignments between items and entities. At the top-right corner is TUP for item recommendation, while TransH for knowledge graph completion is at the bottom-right corner. KTUP jointly learns the two tasks by enhancing the embeddings of items and preferences with that of entities and relations. We define the knowledge enhanced TUP translation function as follows:\n\n\\[\ng (u, i; p) = \\left\\| \\mathbf {u} ^ {\\perp} + \\hat {\\mathbf {p}} - \\hat {\\mathbf {i}} ^ {\\perp} \\right\\| \\tag {16}\n\\]\n\nwhere  \\(\\hat{\\mathbf{i}}^{\\perp}\\)  is the projected vector for the enhanced item embedding  \\(\\hat{\\mathbf{i}}\\)  by the corresponding entity embedding  \\(\\mathbf{e}\\) :\n\n\\[\n\\hat {\\mathbf {i}} ^ {\\perp} = \\hat {\\mathbf {i}} - \\hat {\\mathbf {w}} _ {p} ^ {\\mathrm {T}} \\hat {\\mathbf {i}} \\hat {\\mathbf {w}} _ {p} \\tag {17}\n\\]\n\n\\[\n\\hat {\\mathbf {i}} = \\mathbf {i} + \\mathbf {e}, (i, e) \\in \\mathcal {A} \\tag {18}\n\\]\n\nAnd  \\(\\hat{\\mathbf{p}}\\)  and  \\(\\hat{\\mathbf{w}}_p\\)  are the translation vector and the projection vector enhanced by those of the corresponding relation embedding according a predefined one-to-one mapping  \\(\\mathcal{R} \\to \\mathcal{P}\\) . We obtain these two vectors as follows:\n\n\\[\n\\hat {\\mathbf {p}} = \\mathbf {p} + \\mathbf {r} \\tag {19}\n\\]\n\n\\[\n\\hat {\\mathbf {w}} _ {p} = \\mathbf {w} _ {p} + \\mathbf {w} _ {r} \\tag {20}\n\\]\n\nThus, for entities and items, the enhanced item embeddings contain the relational knowledge among items that is complementary to user-item interactions, and improves item recommendation, since the entity embedding e perserves the structural knowledge in KG. Meanwhile, the entity embedding e shall be fine tuned by the additional connectivity through users and items during backpropagation. Note that we don't use the combined embeddings for both tasks, because it makes the embeddings of items the same as corresponding entities in two tasks, which actually degrades our model to share embeddings between items and entities.\n\nFor relations and preferences, the usage of relations not only offers explicit interpretation of explainability, but also further combines the two tasks more sufficiently at model level. On one hand, through the one-to-one mapping, the meaning of each preference is revealed by the relation label. For instance, the relation isDirectorOf reveals a preference to director, or starring for a preference to movie stars. On the other hand, many items have no aligned entities due to the incompleteness of KG, which limits the mutual impacts to the alignments between entities and items in the models that only transfer knowledge of entities. Considering that each user-item pair\n\n![](images/1c384ac062d21f4631cebc3ce9758c336275c123eb49c61c098e91ebda4e4a0f.jpg)  \nFigure 3: Framework of KTUP. At the top is TUP for item recommendation including two components: preference induction and hyperplane-based translation. KTUP jointly learns TUP and TransH to enhance the item and preference modeling by transferring knowledge of entities as well as relations.\n\nhas a preference and so does the relations between two entities, KTUP optimizes all users, items and entities more thoroughly.\n\n## 5.2 Training\n\nWe train KTUP using the overall objective function as follows:\n\n\\[\n\\mathcal {L} = \\lambda \\mathcal {L} _ {p} + (1 - \\lambda) \\mathcal {L} _ {k} \\tag {21}\n\\]\n\nwhere  \\(\\lambda\\)  is a hyperparameter to balance the two tasks.\n\n## 5.3 Relationship to SOTA Models\n\nIn this section, we give a discussion on the relationship between KTUP and the other state-of-the-art KG-based recommendation methods to facilitate a deep understanding between two tasks in Section 6. We choose three typical models that transfer knowledge of entities at data level (CFKG [46]), at embedding level (CKE [44]) and in both directions (CoFM [31]). We summarize the main differences and similarities from the following aspects:\n\nImplicitly of User Preference CKE and CoFM can be regarded as extensions of collaborative filtering. This type of methods consider the preferences from users to items implicitly and rely on their embeddings to compute a score (i.e., dot product) indicating in which degree the user likes the item. CFKG and KTUP model the preferences explicitly and learn the vectoral representations instead of scalars to capture more comprehensive semantics.\n\nVariety of User Preference CFKG defines the only buy preference between users and items, which obviously suffers from the serious N-to-N issue and fails to deal with it through the TransE-like scoring function. TKUP distinguishes different user preferences and introduces hyperplanes for each preference as well as each relation to learn the various representations of items and entities.\n\nTransferred Knowledge from KG CKE and CoFM only focus on transferring knowledge of entities. CFKG also transfers relations in the way of data integration through a unified graph. Except for entities and items, KTUP combines the embeddings of relations and preferences according to the predefined one-to-one mapping,\n\nwhich brings another byproduct of the explainable ability to recommendation mechanism.\n",
  "experiments": "# 6 EXPERIMENTS\n\nIn this section, we conduct quantitative experiments on separate tasks of item recommendation and KG completion. For each task, we use two datasets in different domains and give further evaluations on the influence of data sparsity as well as the N-to-N issue. We then investigate the mutual impacts between the two tasks during joint training. Finally, we highlight real examples for qualitative analysis to give an intuitive impression of explainability. We publish our project at https://github.com/TaoMiner/joint-kg-recommendender.\n\n## 6.1 Datasets\n\nFollowing CoFM [31], we use two publicly available datasets in the movie and book domains: MovieLens-1m [28] and DBbook2014. Both datasets consist of users and their ratings on movies or books, which are then refined for LODRecSys [15, 28, 29] by mapping items into DBPedia entities if there is a mapping available. Following most item recommendation work that models implicit feedback [40], we treat existing ratings as positive interactions, and generate negative ones by randomly corrupting items.\n\nTo collect the related facts from DBPedia, we only consider those triplets that are directly related to the entities with mapped items, no matter which role (i.e. subject or object) the entity serves as. We then preprocess the two datasets by: filtering out low frequency users and items (i.e., lower than 10 in MovieLens and 5 in DBbook), filtering out infrequent entities (i.e., lower than 10 in both datasets), cutting off unrelated relations and merging similar relations manually.\n\nTable 1 shows the statistics of MovieLens-1m and DBbook2014 datasets<sup>3</sup>. After preprocessing, there are 6,040 users and 3,230 items with 998,539 ratings in Movielens-1m, the average number of ratings per user is 165 and the sparisity rate is  \\(94.9\\%\\) . The data sparisity\n\nTable 1: Statistics of MovieLens-1m and DBbook2014  \n\n<table><tr><td></td><td></td><td>MovieLens-1m</td><td>DBbook2014</td></tr><tr><td rowspan=\"5\">User-Item Interactions</td><td># Users</td><td>6,040</td><td>5,576</td></tr><tr><td># Items</td><td>3,240</td><td>2,680</td></tr><tr><td># Ratings</td><td>998,539</td><td>65,961</td></tr><tr><td># Avg. ratings</td><td>165</td><td>12</td></tr><tr><td>Sparsity</td><td>94.9%</td><td>99.6%</td></tr><tr><td rowspan=\"3\">KG</td><td># Entity</td><td>14,708</td><td>13,882</td></tr><tr><td># Relation</td><td>20</td><td>13</td></tr><tr><td># Triple</td><td>434,189</td><td>334,511</td></tr><tr><td rowspan=\"2\">Multi-Tasks</td><td># Item-Entity Alignments</td><td>2,934</td><td>2,534</td></tr><tr><td>Coverage</td><td>90.6%</td><td>94.6%</td></tr></table>\n\nissue is more severe in DBbook2014. It consists of 5,576 users and 2,680 items with 65,961 ratings, where the average number of ratings per user is 12 and the sparsity rate reaches up to  \\(99.6\\%\\) . The triplets used in the two datasets are at the same scale, where the subgraph for MovieLens-1m composes of 434,189 triplets with 14,708 entities and 20 relations, while the subgraph of DBbook has 334,511 triplets with 13,882 entities and 13 relations. Note that the alignments between items and entities for transferring are fewer in MovieLens-1m than that in DBbook2014.\n\n## 6.2Baselines\n\nFor item recommendation, we compare our proposed models with the following state-of-the-art baselines involving typical similarity-based methods and KG-based methods.\n\n- Typical similarity-based methods: we choose the widely used collaborative filtering models, FM [33] and BPRMF [34], because they are the foundations of other baselines and also achieve the state-of-the-art performance on many benchmark datasets.  \n- CFKG [46] that integrates the data of two sources and applies TransE on a unified graph including users, items, entities and relations;  \n- CKE [44] that combines various item embeddings from different sources including TransR on KG;  \n- CoFM [31] that jointly trains FM and TransE by sharing parameters or regularization of aligned items and entities. We mark the two schemes as CoFM (share) and CoFM (reg), respectively.\n\nFor KG completion, we choose the typical methods TransE [2], TransH [42] and TransR [23] that are widely used in this field. Also, we evaluate the above KG-based methods even if they have not been done so in the original papers to investigate the impacts of different transfer schemes.\n\nFor fair comparison, we carefully reimplement them in our released codes because they did not report the results on the same datasets and we cannot find their released codes. Note that we remove the components of side information modeling like reviews and visual information, since they are not available in the datasets and are out of the scope of this paper.\n\n### 6.3 Training Details\n\nWe construct training set, validation set and test set by randomly splitting the dataset with the ratio of  \\(7:1:2\\) . For item recommendation, we split the items for each user and ensure at least one item exist in the test set.\n\nFor hyperparameters, we apply a grid search on BPRMF and TransE to find the best settings for each task, and use them for all of the other models since they share the basic learning ideas<sup>4</sup>. The learning rate is searched in  \\(\\{0.0005, 0.005, 0.001, 0.05, 0.01\\}\\) , the coefficient of  \\(L_{2}\\)  regularization is in  \\(\\{10^{-5}, 10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}, 0\\}\\) , and the optimization methods include Adaptive Moment Estimation (Adam), Adagrad and SGD. Finally, we set the learning rate as 0.005 and 0.001 for item recommendation and KG completion, respectively,  \\(L_{2}\\)  coefficient is set to  \\(10^{-5}\\)  and 0, and the optimization methods is set to Adagrad and Adam. Particularly, for the models involving two tasks, we have tried both sets of parameters, and pick up the latter set of parameters due to its superior performance.\n\nOther hypermeters are empirically set as follows: the batch size is 256, the embedding size is 100 and we perform early stopping strategy on the validation sets.\n\nWe predefine the number of preferences in TUP as 20 and 13 for MovieLens-1m and DBbook2014, respectively, which are set according to the relations of the collected triplets. For the models involving two tasks (i.e., CFKG, CKE, CoFM and KTUP), we set the joint hyperparameter  \\(\\lambda\\)  as 0.5 and 0.7 on the two datasets after searching in  \\(\\{0.7, 0.5, 0.3\\}\\) , so as to balance their impacts, and use the pretrained embeddings of the basic model (i.e., BPRMF and TransE).\n\nThe main goal in this paper is to investigate the mutual impacts on each task during jointly training, rather than achieving best performance by tuning parameters. Thus, our proposed models as well as baseline methods are trained once for each dataset and evaluate for both tasks of item recommendation and KG completion.\n\n## 6.4 Item Recommendation\n\nIn this section, we evaluate our models as well as the baseline methods on the task of item recommendation. Given a user, we take all items in test sets as candidates and rank them according to the scores computed based on the embeddings of users and items. Thus, the N items ranked at top are the recommended items.\n\n6.4.1 Metrics. We use five evaluation metrics that have been widely used in previous work:\n\n- Precision@N: It is the fraction of the items recommended that are relevant to the user. We compute the mean of all users as the final precision.  \n- Recall@N: It is the proportion of items relevant to the user that have been successfully recommended. We compute the mean of all users as the final recall.  \n- F1 score@N: It is the harmonic mean of precision at rank N and recall at rank N.  \n- Hit ratio@N: It is 1 if any gold items are recommended within the top N items, otherwise 0. We compute the mean of all users as the final hit ratio score.\n\nTable 2: Overall performance on Item Recommendation  \n\n<table><tr><td rowspan=\"2\"></td><td colspan=\"5\">MovieLens-1m (@10, %)</td><td colspan=\"5\">DBbook2014 (@10, %)</td></tr><tr><td>Precision</td><td>Recall</td><td>F1</td><td>Hit</td><td>NDCG</td><td>Precision</td><td>Recall</td><td>F1</td><td>Hit</td><td>NDCG</td></tr><tr><td>FM</td><td>29.28</td><td>11.92</td><td>13.81</td><td>81.06</td><td>59.48</td><td>3.44</td><td>21.55</td><td>5.75</td><td>30.15</td><td>20.10</td></tr><tr><td>BPRMF</td><td>30.81</td><td>12.95</td><td>14.84</td><td>83.18</td><td>61.02</td><td>3.56</td><td>22.46</td><td>5.96</td><td>31.26</td><td>21.01</td></tr><tr><td>CFKG</td><td>29.45</td><td>12.49</td><td>14.23</td><td>82.24</td><td>58.97</td><td>3.17</td><td>19.69</td><td>5.30</td><td>28.09</td><td>19.87</td></tr><tr><td>CKE</td><td>38.67</td><td>16.65</td><td>18.94</td><td>88.36</td><td>67.05</td><td>3.92</td><td>23.41</td><td>6.51</td><td>33.18</td><td>27.78</td></tr><tr><td>CoFM (share)</td><td>32.08</td><td>13.02</td><td>15.12</td><td>83.30</td><td>58.69</td><td>3.41</td><td>20.78</td><td>5.67</td><td>29.84</td><td>20.92</td></tr><tr><td>CoFM (reg)</td><td>31.74</td><td>12.74</td><td>14.87</td><td>82.67</td><td>58.66</td><td>3.32</td><td>20.54</td><td>5.54</td><td>28.96</td><td>20.53</td></tr><tr><td>TUP (hard)</td><td>37.29</td><td>17.07</td><td>18.98</td><td>89.60</td><td>67.40</td><td>3.40</td><td>21.11</td><td>5.67</td><td>29.56</td><td>20.19</td></tr><tr><td>TUP (soft)</td><td>37.00</td><td>16.79</td><td>18.76</td><td>89.47</td><td>67.02</td><td>3.62</td><td>22.81</td><td>6.06</td><td>31.42</td><td>21.54</td></tr><tr><td>KTUP (hard)</td><td>40.87</td><td>17.24</td><td>19.79</td><td>88.97</td><td>69.65</td><td>4.04</td><td>24.48</td><td>6.71</td><td>34.49</td><td>27.38</td></tr><tr><td>KTUP (soft)</td><td>41.03</td><td>17.25</td><td>19.82</td><td>89.03</td><td>69.92</td><td>4.05</td><td>24.51</td><td>6.73</td><td>34.61</td><td>27.62</td></tr></table>\n\n- nDCG@N: Normalized Discounted Cumulative Gain (nDCG) is a standard measure of ranking quality, considering the graded relevance among positive and negative items within the top  \\(N\\)  of the ranking list.\n\n6.4.2 Overall Results. Table 2 shows the overall performance of our proposed models as well as the baseline methods, where hard and soft denote the two preference induction strategies in Section 4.1. We can observe that:\n\n- Our proposed methods perform the best compared with the baseline methods on the two datasets. Particularly, TUP performs competitively to other KG-based models, while it doesn't require any additional information. This is because TUP automatically infers the knowledge of preferences from the user-item interactions, and performs much better especially when the amount of interaction data is sufficient, like MovieLens-1m. By incorporating KG, KTUP further presents more promising improvements on DBbook than MovieLens (i.e.,  \\(11.06\\%\\)  v.s.  \\(4.43\\%\\)  gains in F1), which implies that the knowledge is more helpful for sparse data.  \n- The hard strategy performs better than the soft strategy only when it is used for TUP on MovieLens-1m, which implies that to induce a deterministic user preference requires sufficient data, and the soft strategy is more robust.  \n- CFKG and CoFM perform slightly better than the typical models (i.e., FM and BPRMF) on MovieLens-1m, but perform worse on the sparse dataset of DBbook2014. One possible reason is that they both transfer entities by forcing their embeddings to be similar with the aligned items, leading to the loss of knowledge that has been perserved in the embeddings, and the loss becomes more serious when there is insufficient training data.  \n- CKE achieves pretty good performance on the two datasets mainly because it combines the embeddings of items and entities that persevere the information from both sources, instead of aligning them with similar positions in the latent space.  \n- All models preform much better on MovieLens-1m than on DBbook2014 due to the relatively sufficient training data and an easier test (a higher value even using random initializations). Interestingly, the improvement by utilizing KG is larger on dense dataset of MovieLens than that on the sparse\n\ndataset of DBbook. This goes against our intuitions that the more sparse the dataset is, the more potentials it shall have in absorbing richer knowledge. Thus, we further split the test set according to different sparsity levels of training data, and investigate the impacts from KG on each subset in the next section.\n\n![](images/9a858d123e99dd295c4b915bb79db05e1f2773a445a99c7d1b004225461c8b4f.jpg)  \nFigure 4: Influence of Different Sparsity on MovieLens-1m. The x-axis shows 10 user groups splited according to interaction number, the left y-axis corresponds to the bars indicating the number of interactions in each user group, and the right y-axis denotes F1-score of curves.\n\n6.4.3 Influence of Training Data Sparsity. To investigate the influence of data sparsity on knowledge transfer, we split the test set of MovieLens-1m into 10 subsets according to the rating number of each user for training; meanwhile we also try to balance the number of users as well as ratings in each subset. The detailed results of F1 score are shown in Figure 4. Green bars represent the average rating number per user ranging from 17 to  \\(563^{5}\\) . We denote the models without KG knowledge as dashed lines, and other models as solid lines.\n\nTable 3: Performance on MovieLens by Relation Category  \n\n<table><tr><td>Task</td><td colspan=\"4\">Prediction Head (Hits@10, %)</td><td colspan=\"4\">Prediction Tail (Hits@10, %)</td></tr><tr><td>Relation Category</td><td>1-to-1</td><td>1-to-N</td><td>N-to-1</td><td>N-to-N</td><td>1-to-1</td><td>1-to-N</td><td>N-to-1</td><td>N-to-N</td></tr><tr><td>TransE</td><td>59.62</td><td>56.76</td><td>64.55</td><td>24.56</td><td>65.38</td><td>62.16</td><td>78.52</td><td>46.25</td></tr><tr><td>TransH</td><td>61.54</td><td>48.65</td><td>65.73</td><td>25.51</td><td>57.69</td><td>78.38</td><td>75.62</td><td>46.73</td></tr><tr><td>TransR</td><td>17.31</td><td>29.73</td><td>32.88</td><td>18.50</td><td>17.31</td><td>43.24</td><td>53.12</td><td>38.88</td></tr><tr><td>CFKG</td><td>59.62</td><td>51.35</td><td>63.31</td><td>20.30</td><td>57.69</td><td>70.27</td><td>78.56</td><td>41.22</td></tr><tr><td>CKE</td><td>19.23</td><td>21.62</td><td>24.16</td><td>14.81</td><td>7.69</td><td>24.32</td><td>37.83</td><td>34.82</td></tr><tr><td>CoFM (share)</td><td>65.38</td><td>59.46</td><td>66.13</td><td>24.42</td><td>61.54</td><td>72.97</td><td>81.05</td><td>45.99</td></tr><tr><td>CoFM (reg)</td><td>69.23</td><td>70.27</td><td>66.09</td><td>24.30</td><td>48.08</td><td>86.49</td><td>80.72</td><td>45.79</td></tr><tr><td>KTUP (hard)</td><td>67.31</td><td>59.46</td><td>66.42</td><td>25.67</td><td>57.69</td><td>81.08</td><td>79.22</td><td>47.24</td></tr><tr><td>KTUP (soft)</td><td>75.00</td><td>56.76</td><td>67.16</td><td>26.09</td><td>63.46</td><td>81.08</td><td>78.34</td><td>47.65</td></tr></table>\n\nWe can see that (1) KG-based methods (i.e., CKE and KTUP) outperform the other models the most when the average number of ratings per user ranges from 100 to 200. (2) The gap between the two types of models is getting closer as the amount of the training data decreases, and the improvements become similar with that on DBbook when their training data is at the similar sparisity level. (3) Meanwhile, the gap almost disappears when the average ratings are 563 (the left most bar), which implies that the impacts of KG become negligible if there is sufficient training data. Note that the performance of all models are getting worse when the average ratings are larger than 89. The possible reason is the user likes so many items that the preferences are too general to capture. (4) TUP outperforms KTUP when user preferences are relative simple to model (i.e., #rating<50), showing the effectiveness and necessity to fully utilize user-item interactions for preference modeling.\n\nTable 4: Overall performance on KG Completion  \n\n<table><tr><td></td><td colspan=\"2\">MovieLens-1m</td><td colspan=\"2\">DBbook2014</td></tr><tr><td></td><td>Hit@10 (%)</td><td>Mean Rank</td><td>Hit@10 (%)</td><td>Mean Rank</td></tr><tr><td>TransE</td><td>46.95</td><td>537</td><td>60.71</td><td>531</td></tr><tr><td>TransH</td><td>47.63</td><td>537</td><td>60.06</td><td>556</td></tr><tr><td>TransR</td><td>38.93</td><td>609</td><td>56.33</td><td>563</td></tr><tr><td>CFKG</td><td>41.56</td><td>523</td><td>58.83</td><td>547</td></tr><tr><td>CKE</td><td>34.37</td><td>585</td><td>54.66</td><td>593</td></tr><tr><td>CoFM (share)</td><td>46.62</td><td>515</td><td>57.01</td><td>529</td></tr><tr><td>CoFM (reg)</td><td>46.51</td><td>506</td><td>60.81</td><td>521</td></tr><tr><td>KTUP (hard)</td><td>48.39</td><td>525</td><td>60.53</td><td>501</td></tr><tr><td>KTUP (soft)</td><td>48.90</td><td>527</td><td>60.75</td><td>499</td></tr></table>\n\n## 6.5 Knowledge Graph Completion\n\nIn this section, we evaluate on the task of KG completion. It is to predict the missing entity  \\(e_h\\)  or  \\(e_t\\)  for a given triplet  \\((e_h, e_t, r)\\) . For each missing entity, we take all entities as candidates and rank them according to the scores computed based on entity and relation embeddings.\n\n6.5.1 Metrics. We use two evaluation metrics that have been widely used in previous work [42]:\n\n- Hit ratio@N: It is 1 if the miss entity are ranked within the top N candidates, otherwise 0. We compute the mean of all triplets as the final hit ratio score.\n\n- Mean Rank : It is the averaged rank of the missing entities, the smaller the better.\n\n6.5.2 Overall Results. Table 4 shows the overall performance. We can see that KTUP almost outperforms all the other models on both datasets except the mean rank value on MovieLens-1m. We argue this metric is less important since it is easily reduced by an obstinate triple with a low rank [41]. Compared with TransH, it achieves a larger improvement on Hit Ratio for MovieLens-1m as compared to that for DBbook2014 (2.67% vs. 1.15%), because Movielens-1m contains more connectivities between users and items that are helpful for modeling structural knowledge between entities. We also observe that CFKG, CKE and CoFM show a performance drop as compared to their basic KG components: TransE and TransR. One reason may be that these methods force the embeddings of aligned entities to satisfy the other task of item recommendation, while the aligned entities are only a small portion (i.e. 19.95% and 18.25% on the two datasets), which actually degrades the learning for KG completion. Another reason is that the N-to-N issues of user preferences have negative impacts on the representation learning of entities and relations, especially for the buy relation in CFKG. CKE takes this issue into account but TransR contains a lot of trainable parameters and does not work well on such a small training set.\n\n6.5.3 Capability to Handle N-to-N Relations. Table 3 shows the separate evaluation results on each relation category. Following [2], we divide relations into four types: 1-to-1, 1-to-N, N-to-1 and N-to-N. We can see that (1) TransR and its related models (i.e., CKE) perform the worst which is consistent with the above overall performance. (2) KTUP achieves the best performance on N-to-N issues, and also performs competitively with TransE and CoFM on 1-to-1, 1-to-N and N-to-1 problems, which indicates the capability of our methods in hanling complex relations and improves both tasks. (3) CFKG presents a lower value on N-to-N relations than TransE, which implies that the unified graph may have introduced more confusing relational semantics. (4) CoFM performs competitively in KG completion task while worse in item recommendation, because their knowledge transferring schemes lead to unstable joint training. That is, it is difficult to control the positive impacts of knowledge transfer on which task, and different parameters for separately training CoFM on each task is required, which is also concluded in the original paper [31].\n\n![](images/546471b8ee00efc3212098a48586dabba3f11201048dfbc3c629c32595bd6bc6.jpg)  \n(a) KTUP  \\((\\rho = 0.97)\\)\n\n![](images/692743120a48e41ce5c556231b85390253a444b3d057b5d3ce7d247b7b808fbb.jpg)  \n(b) CoFM  \\((\\rho = 0.81)\\)\n\n![](images/5b8a41e9ecd1ceb7ebfdf40e3416a4bc2f710687b8041d7bed16c09bef0c8d10.jpg)  \n(c) CFKG  \\((\\rho = 0.97)\\)\n\n![](images/74d67a119dbe795033fc84a0d8022630f104404771b80d69bcb3ee6e8099e82c.jpg)  \n(d) CKE  \\((\\rho = 0.94)\\)\n\n![](images/32ec8cd506ddf6d89f1f801c4b990d6393d05d3485c4ce912ab12bf8bc7a70c4.jpg)  \nFigure 5: Correlation of Training Curves between Two Tasks on DBbook2014, which is denoted by the Pearson's correlation coefficient  \\(\\rho\\) . The x-axis is training epoch, the left y-axis corresponds to KG completion via hit ratio, and the right y-axis is for item recommendation through F1. (Note that we scale the values of both F1 and Hit Ratio to the same magnitude.)  \nFigure 6: Real Example from MovieLens-1m\n\n## 6.6 Mutual Benefits of Two Tasks\n\nAlthough the evaluations on separate tasks have been conducted, it is still unclear how different transfer schemes take effect. We thus investigate the correlations between the training curves of two tasks. Intuitively, a strong correlation implies a more complete transfer learning, and a better utilization of the complementary information from each other. Because KG completion has no F1 measures, so we present its hit ratio corresponds to left y-axis, and item recommendation through F1 is presented on right y-axis.\n\nAs shown in Figure 5, we can see that KTUP and CFKG present the strongest correlations between their curves, that is, the increase and decrease of one curve shall be reflected on the other curve simultaneously. This implies that the transfer of relations plays an important role in training the two tasks together. However, CFKG does not perform well on both tasks (as shown in Table 2 and Table 4) mainly because of 2 reasons. First, it cannot deal with complex relations; second, it only increases the connectivity in the unified graph through the integration of relations and preferences, which are actually not transitional. Instead, KTUP combines the embeddings of relations and preferences that persevere two types of structural knowledge, and meanwhile introduces hyperplanes for the N-to-N issue. The curves of CoFM and CKE are obviously not\n\ncorrelated strongly due to the small portion of transferred entities. Concretely, CoFM forces the embeddings of aligned entities and items to be similar which may result in unstable training. CKE focuses on unidirectional enhancements by combining their embeddings, and thus performs well in item recommendation but worse in KG completion.\n\n## 6.7 Case Study\n\nIn this section, we present an example of Movielens-1m to give an intuitive impression of our explainability. On the left is a user who has interacted with 7 movies. KTUP first induces user preferences to these movies, and finds that what the user is concerned is the relations of isDirectorOf and starring (the preferences having highest attention in Section 4.1). Thus, it searches the nearest items according to Equation 16 based on the induced preferences. We present the recommended four movies on the right side. In particular, Batman Forever and Batman & Robin (film) are recommended because the user shows preference with their director Joel Schumacher. Similarly, the preference to director also helps to induce the movie Say Anything ... directed by Cameron Crowe. Besides, the user also has preferences on starring, such as James Dean in East of Eden (film) and Natalie Wood in Gypsy (1962 film); together, the system suggests another movie Rebel Without a Cause.\n",
  "hyperparameter": ""
}