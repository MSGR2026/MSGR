{
    "id": "FAME_2025",
    "paper_title": "Facet-Aware Multi-Head Mixture-of-Experts Model for Sequential Recommendation",
    "alias": "FAME",
    "year": 2025,
    "domain": "Recsys",
    "task": "SequentialRecommendation",
    "idea": "FAME introduces two key innovations: (1) a Facet-Aware Multi-Head Prediction Mechanism that splits each item into multiple sub-embeddings (heads), each capturing a distinct facet (e.g., genre vs. actor), and learns a gating score to weight head-specific predictions; (2) a Mixture-of-Experts Self-Attention Layer that replaces the single query transformation in each head with N expert-specific query transformations plus a router that softly combines the resulting attention representations, enabling fine-grained preference modeling within every facet.",
    "introduction": "# 1 Introduction\n\nThe explosion of information online presents users with a vast and ever-growing sea of items, from products [11] and apps [4] to videos [7, 40]. With limited time to explore everything, recommender systems (RS) have become crucial tools for helping users make efficient and satisfying choices. However, user interests are inherently dynamic, evolving over time and making it challenging for platforms to deliver consistently relevant recommendations [29]. To address these challenges, sequential recommendation (SR) has emerged as a powerful technique. This approach leverages the sequential nature of user interactions, typically captured as sessions containing a series of recent item interactions, to predict the user's next action [9, 30].\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/736067fc861a7872cb2e5c0ddbf921e0a140685566dc8ffce8f2026b6c65efdd.jpg)\n\n\n\nFigure 1: A motivation example.\n\n\nMainstream SR systems assign a single embedding vector to each item, capturing its features. Recurrent neural networks (RNNs) [14, 15], attention-based models [17, 24, 25, 39], graph-based models [2, 12, 32, 35], and others combine these item embeddings into a sequence representation vector to capture the user intent. This representation is used to predict the next item (e.g., selecting the item with the highest inner product with the sequence representation vector). However, a single embedding cannot well capture an item's multifaceted nature (e.g., movie genres and starring) [6, 38]. This is particularly problematic when different facets of an item can influence user intent. As illustrated in Figure 1, User 1's watch history suggests a strong preference for action movies. In this case, recommending another action movie might be appropriate. Conversely, User 2's movie choices range across genres but all feature Hugh Jackman. In this case, recommending another movie starring\n\nHugh Jackman might be more relevant. These examples highlight how user interests can be dominated by a single facet (genre or actor) within a category (movie). Furthermore, in more realistic scenarios, users can have multiple preferences within a single facet. For example, a user might enjoy both action and musical movies in the facet of genre. Recognizing and addressing these diverse preferences within a sequence is crucial for generating more effective recommendations that cater to specific user interests [6]. Failing to capture the dominant facet and the specific preferences within each facet can lead to suboptimal recommendations. This highlights the need for recommender systems that can effectively model the dynamic and multi-faceted nature of user interests.\n\nExisting research addresses user intent complexity by using hierarchical windows [12, 37] to capture multi-level user intents from recent items, or by utilizing item representations from multiple items in the sequence instead of using the last item's representation only to recommend the next interacted item [6]. However, these methods still neglect the multi-faceted nature of items themselves.\n\nTo solve the aforementioned issues, we propose a novel structure called Facet-Aware Multi-Head Mixture-of-Experts Model for Sequential Recommendation (FAME). We utilize the sub-embeddings from each head in the final multi-head attention layer to independently predict the next item, with each head capturing a distinct facet of the items. A gating mechanism integrates recommendations from each head and dynamically determines their importance. Furthermore, we introduce a Mixture-of-Experts (MoE) network: this network replaces the query matrix in the self-attention layer, enabling the model to disentangle various user preferences within each facet. Each expert within the MoE focuses on a specific preference within each facet. A learnable router network is adopted to compute the importance weight for each expert and aggregate them. (e.g., whether action or musical movies are the stronger preference in genre).\n\nTo summarize, our contributions in this paper are as follows:\n\n- We propose a Multi-Head Prediction Mechanism to enhance the recommendation quality. This design facilitates capturing the potential multi-facet features of the items.\n\n- We propose a Mixture-of-Experts (MoE) network that improves user preference modeling by disentangling multiple preferences in each facet within a sequence. This module seamlessly integrates with existing attention-based models.\n\n- Our model demonstrates significant effectiveness compared to various baseline categories (sequential, pre-trained, multi-intent) on four public datasets.",
    "method": "# 4 Methods\n\n# 4.1 Overview\n\nThis section introduces our proposed framework with a high-level overview, which is displayed in Figure 2. The framework incorporates two key components: the Facet-Aware Multi-Head Prediction Mechanism (detailed in Section. 4.2), which learns to represent each item with multiple sub-embedding vectors, each capturing a specific facet of the item; and the Mixture-of-Experts Self-Attention Layer (detailed in Section. 4.3), which employs a Mixture-of-Experts (MoE) network within each subspace to capture the users' specific preferences within each facet. Our framework can be seamlessly integrated to any attention-based recommendation model. In this paper, we incorporate our framework to SASRec for illustration.\n\n# 4.2 Facet-Aware Multi-Head Prediction Mechanism\n\n4.2.1 Original SASRec Prediction Process. In the original SASRec model, the final prediction for the next item is based on the last item's representation ( $f_{t}$ , calculated by Equation 4, which can also be regarded as the sequence representation) obtained from the last self-attention layer. This representation is processed through a feed-forward network (FFN) with ReLU activation for non-linearity, followed by layer normalization, dropout, and a residual connection:\n\n$$\n\\operatorname {F F N} \\left(f _ {t}\\right) = \\operatorname {R E L U} \\left(f _ {t} ^ {T} \\cdot W _ {1} + b _ {1}\\right) ^ {T} \\cdot W _ {2} + b _ {2}, \\tag {5}\n$$\n\n$$\nF _ {t} = \\operatorname {L a y e r N o r m} \\left(f _ {t} + \\operatorname {D r o p o u t} (\\operatorname {F F N} (f _ {t}))\\right),\n$$\n\nHere,  $W_{1}, W_{2} \\in \\mathbb{R}^{d \\times d}, b_{1}, b_{2} \\in \\mathbb{R}^{d}$  are all learnable parameters. The final user preference score for item  $v$  at step  $(t + 1)$  is then\n\ncalculated as the dot product between the item embedding  $(x_{v})$  and the sequence representation  $(F_{t})$ :\n\n$$\nP \\left(v _ {t + 1} = v \\mid S _ {u}\\right) = x _ {v} ^ {T} \\cdot F _ {t}, \\tag {6}\n$$\n\nTop-  $k$  items with the highest preference scores are recommended to the user.\n\n4.2.2 Motivation for Our Approach. The multi-head self-attention mechanism splits the sequence representation and item embeddings into multiple subspaces (heads). Research suggests that these heads can allocate different attention distributions so as to perform different tasks [27]. We hypothesize that these heads could also capture different facets of items (e.g., genre and starring actors in the context of movie recommendation). This ability to capture multifaceted information has the potential to improve recommendation quality.\n\n4.2.3 Proposed Multi-Head Recommendation. Instead of performing a single attention function with  $d$ -dimensional keys, values and queries, it is found beneficial to linearly project the queries, keys and values  $H$  times with different, learned linear projections to  $d_{k}$ ,  $d_{k}$  and  $d_{v}$  dimensions, respectively [27]. Here,  $H$  is the number of heads, and  $d_{k}, d_{k}$  and  $d_{v}$  are typically set to  $d' = \\frac{d}{H}$ .\n\nLeveraging the multi-head attention mechanism, we propose a novel approach where each head independently generates recommendations. The final item embedding from head  $h$  is denoted as  $f_{t}^{(h)} \\in \\mathbb{R}^{d^{\\prime}}$ . We then process this embedding similarly as we do for the original model:\n\n$$\n\\mathrm {F F N} ^ {\\prime} (f _ {t} ^ {(h)}) = \\mathrm {R E L U} (f _ {t} ^ {(h) T} \\cdot W _ {1} ^ {\\prime} + b _ {1} ^ {\\prime}) ^ {T} \\cdot W _ {2} ^ {\\prime} + b _ {2} ^ {\\prime},\n$$\n\n$$\nF _ {t} ^ {(h)} = \\operatorname {L a y e r N o r m} \\left(f _ {t} ^ {(h)} + \\operatorname {D r o p o u t} \\left(\\operatorname {F F N} ^ {\\prime} \\left(f _ {t} ^ {(h)}\\right)\\right)\\right),\n$$\n\nUnlike the original FFN (Equation 5), the feed-forward network applied to each head  $(\\mathrm{FFN}^{\\prime})$  operates on a reduced dimension of  $d^{\\prime}$ . The learnable parameters for  $\\mathrm{FFN}^{\\prime}$  are therefore adjusted accordingly:  $W_1^{\\prime}, W_2^{\\prime} \\in \\mathbb{R}^{d^{\\prime} \\times d^{\\prime}}, b_1^{\\prime}, b_2^{\\prime} \\in \\mathbb{R}^{d^{\\prime}}$ . This adaptation aligns with the dimensionality of sub-embeddings within each head. To enhance parameter efficiency and improve performance, we adopt a shared feed-forward network  $(\\mathrm{FFN}^{\\prime})$  across all attention heads. Each head generates the preference score for each item independently, i.e.,\n\n$$\nP ^ {(h)} (v _ {t + 1} = v | \\mathcal {S} _ {u}) = x _ {v} ^ {(h) T} \\cdot F _ {t} ^ {(h)}, \\tag {8}\n$$\n\nwhere  $x_{v}^{(h)} \\in \\mathbb{R}^{d^{\\prime}}$  is the sub-embedding of the item  $v$ , reflecting the features of the specific facet corresponding to the attention head  $h$ . Specifically, it is calculated by a linear transformation from its original embedding:\n\n$$\nx _ {v} ^ {(h)} = x _ {v} ^ {T} \\cdot W _ {f} ^ {(h)}, \\tag {9}\n$$\n\nwith  $W_{f}^{(h)}\\in \\mathbb{R}^{d\\times d^{\\prime}}$  being a learnable matrix.\n\nIn order to integrate the recommendation results from each head, we employ a gate mechanism to determine the relative importance of each head's recommendations:\n\n$$\ng = \\left[ F _ {t} ^ {(1)} | \\dots | F _ {t} ^ {(H)} \\right] ^ {T} \\cdot W _ {g} + b _ {g}, \\tag {10}\n$$\n\n$$\n\\tilde {g} = \\operatorname {s o f t m a x} (g)\n$$\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/7c50db7aa086c18a4bc8255b0294d1b430d0a5ae4b84f065dfc462d43bbaadf4.jpg)\n\n\n\n(a) Original Transformer Block\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/74958460563693ccd545b6f7274d92b2b1b0a1ffc9c094af480f65b76e911f35.jpg)\n\n\n\n(b) FAME's Transformer Block\n\n\n\nFigure 2: Overview of the proposed model: (a) illustrates the original Transformer block, while (b) depicts the architecture of our proposed FAME model. For simplicity, the LayerNorm and Dropout operations following the FFN (FFN') are omitted from the Figure\n\n\nHere,  $[\\cdot \\cdot ]$  denotes the concatenation operation. Each element  $\\tilde{g}^{(h)}\\in [0,1]$  within the vector  $\\tilde{g}$  represents the importance of head  $h$  in determining the user's dominant interest or preference. For instance, a higher  $\\tilde{g}^{(h)}$  for a genre-focused head indicates a stronger preference for specific movie genres, while a higher value for an actor-focused head suggests a preference for movies starring particular actors. The gate mechanism, parameterized by  $W_{g}\\in \\mathbb{R}^{d\\times H}$  and  $b_{g}\\in \\mathbb{R}^{H}$ , learns to assign appropriate weights to each head based on the user's current context. Finally, we compute a unified preference score for each item by weighting the recommendations from each head:\n\n$$\nP \\left(v _ {t + 1} = v \\mid \\mathcal {S} _ {u}\\right) = \\sum_ {i = 1} ^ {H} \\tilde {g} ^ {(h)} \\cdot P ^ {(h)} \\left(v _ {t + 1} = v \\mid \\mathcal {S} _ {u}\\right) \\tag {11}\n$$\n\nThis approach allows the model to exploit the strengths of each head while assigning appropriate weights based on their importance in the specific context.\n\n# 4.3 Mixture-of-Experts Self-Attention Layer\n\nWhile the Facet-Aware Multi-Head mechanism effectively captures item facets, users often exhibit more granular and diverse preferences within these facets. To address this, we introduce the Mixture-of-Experts Self-Attention Layer (MoE-Attention), as illustrated in Figure 3.\n\nWe assume that each facet can be decomposed into  $N$  distinct preferences. For instance, a genre facet might include preferences for action, comedy, musicals, etc. To capture the nuanced preferences within each facet of a sequence, we replace the standard query generation mechanism in self-attention (Equation 2) with a Mixture-of-Experts (MoE) network in each head. This network consists of  $N$  experts, each represented by a trainable matrix  $W_{Q(n)}^{(h)} \\in \\mathbb{R}^{d \\times d'}$  (where  $n \\in [1, N]$ ). Each expert within a head is designed to capture one of these preferences by transforming an item embedding  $x_i$  (i.e., the embedding of the  $i^{th}$  item in the sequence) into an expert\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/f5f12e907ff20cfd666bc8c947d5afbbe64cc486674b637d915623bb4df34698.jpg)\n\n\n\nFigure 3: MoE Self-Attention Network: Integrated Item Representation Calculation. This diagram visualizes the computational process for determining the integrated item representation of the final item  $(f_t^{(h)})$  within a specific head  $(h)$  of our proposed model.\n\n\nquery vector  $q_{i(n)}^{(h)}\\in \\mathbb{R}^{d^{\\prime}}$  as follows:\n\n$$\nq _ {i (n)} ^ {(h)} = x _ {i} ^ {T} \\cdot W _ {Q (n)} ^ {(h)} \\tag {12}\n$$\n\nThe key vector  $(k_j^{(h)})$  and value vector  $(v_j^{(h)})$  of the  $j^{th}$  sequence item in head  $h$  are computed using the same linear transformations as in the original SASRec model:\n\n$$\nk _ {j} ^ {(h)} = x _ {j} ^ {T} \\cdot W _ {K} ^ {(h)}, \\quad v _ {j} ^ {(h)} = x _ {j} ^ {T} \\cdot W _ {V} ^ {(h)} \\tag {13}\n$$\n\nThen the attention score for the  $i^{th}$  item relative to the  $j^{th}$  item in head  $h$  by expert  $n$  is computed as:\n\n$$\n\\alpha_ {i j (n)} ^ {(h)} = \\frac {q _ {i (n)} ^ {(h) T} \\cdot k _ {j} ^ {(h) T}}{\\sqrt {d ^ {\\prime}}}, \\tag {14}\n$$\n\n$$\n\\tilde {\\alpha} _ {i j (n)} ^ {(h)} = \\operatorname {s o f t m a x} \\left(\\alpha_ {i 1 (n)} ^ {(h)}, \\dots , \\alpha_ {i t (n)} ^ {(h)}\\right)\n$$\n\nThe item representation of the  $i^{th}$  item for head  $h$  and expert  $n$ $(f_{i(n)}^{(h)})$  is then calculated as a weighted sum of value vectors, where the weights are the corresponding attention scores:\n\n$$\nf _ {i (n)} ^ {(h)} = \\sum_ {j = 1} ^ {t} \\tilde {\\alpha} _ {i j (n)} ^ {(h)} \\cdot v _ {j} ^ {(h)} \\tag {15}\n$$\n\nAs illustrated in Figure 4, consider a genre-focused head with two experts: one for action movies and another for musical movies. As detailed in Section 4.2.1, the standard SASRec model treats the representation of the final item in a sequence as the overall sequence representation. To illustrate our MoE attention mechanism, we focus on the attention scores associated with the  $4^{th}$  (and final) item in the sequence. The first expert's query vector of the  $4^{th}$  item  $(q_{4(1)}^{(h)})$  would assign higher attention scores to action movies (items 1 and 3), while the second expert's query vector  $(q_{4(2)}^{(h)})$  would focus on musical movies (items 2 and 4). Consequently, the final item's representation  $(f_{4(1)}^{(h)})$  generated by the first expert would lean towards recommending action movies, whereas the representation  $(f_{4(2)}^{(h)})$  from the second expert would favor musical movies.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/9ecb4bb7fa564c86873672280a0150cc7525f3ee6c2e0b5abcbf496ee0387628.jpg)\n\n\n\nFigure 4: An example on attention scores distribution and recommendation results among different experts on genre-focused head\n\n\nTo dynamically determine the importance of each preference within a facet (e.g., whether action or musical is the preferred genre), we introduce a router network parameterized by  $W_{exp}^{(h)} \\in \\mathbb{R}^{(n \\cdot d') \\times n}$ . This network assigns an importance score  $\\beta_{i(n)}^{(h)} \\in (0,1)$  to each item representation generated by each expert  $f_{i(n)}^{(h)}$ . The importance scores are computed as follows:\n\n$$\n\\beta_ {i \\cdot} ^ {(h)} = \\operatorname {s o f t m a x} \\left(\\left[ f _ {i (1)} ^ {(h)} \\right| \\dots \\left| f _ {i (n)} ^ {(h)} \\right] ^ {T} \\cdot W _ {e x p} ^ {(h)}\\right) \\tag {16}\n$$\n\nThe integrated item representation  $f_{i}^{(h)}$  for the  $i^{th}$  item in head  $h$  is then computed as a weighted sum of the expert query vectors:\n\n$$\nf _ {i} ^ {(h)} = \\sum_ {n = 1} ^ {N} \\beta_ {i (n)} ^ {(h)} \\cdot f _ {i (n)} ^ {(h)} \\tag {17}\n$$\n\nThe integrated item representation  $(f_i^{(h)})$  represents the overall preference at the  $i^{th}$  timestamp within head  $h$ . For instance, for the\n\n\nTable 1: Dataset statistic\n\n\n<table><tr><td>Dataset</td><td>#users</td><td>#items</td><td>#actions</td><td>avg.length</td><td>density</td></tr><tr><td>Beauty</td><td>22,363</td><td>12,101</td><td>198,502</td><td>8.8</td><td>0.07%</td></tr><tr><td>Sports</td><td>25,598</td><td>18,357</td><td>296,337</td><td>8.3</td><td>0.05%</td></tr><tr><td>Toys</td><td>19,412</td><td>19,392</td><td>167,597</td><td>8.6</td><td>0.04%</td></tr><tr><td>ML-20m</td><td>96,726</td><td>16,297</td><td>185,6746</td><td>19.2</td><td>0.11%</td></tr></table>\n\ncase in Figure 4, a higher weight for  $f_{4(1)}^{(h)}$  (resp.  $f_{4(2)}^{(h)}$ ) would push the model towards recommending action (resp. musical) movies.\n\n# 4.4 Deployment and Training\n\n4.4.1 Model Deployment. Our FAME model is built upon the SAS-Rec (or any attention-based) framework, with the final Transformer layer replaced by our proposed architecture.\n\n4.4.2 Training Pipeline. We initiate our model by pre-training an attention-based sequential recommendation model (e.g., SASRec). Subsequently, we replace Transformer block's query matrix at the final layer with our proposed MoE network (Section 4.3) while retaining the original key and value matrices. The newly introduced components, including the head-specific  $\\mathrm{FFN^{\\prime}}$  (Equation 7), gate mechanism (Equation 10), and router (Equation 16), are randomly initialized. The entire model is then fine-tuned end-to-end.\n\n4.4.3 Training Objectives. A global cross-entropy loss function is employed to optimize the model during training:\n\n$$\n\\mathcal {L} _ {c e} = - \\sum_ {u \\in \\mathcal {U}} \\log \\left(\\frac {\\exp \\left(x _ {t + 1} ^ {(u) T} \\cdot f _ {t} ^ {(u)}\\right)}{\\sum_ {i} \\exp \\left(x _ {i} ^ {T} \\cdot f _ {t} ^ {(u)}\\right)}\\right) \\tag {18}\n$$\n",
    "hyperparameter": "embedding dimension d ∈ {64, 128}; number of attention heads H ∈ {1, 2, 4, 8, 16} (dataset-dependent, 4–8 optimal for most); number of experts per head N ∈ {2, 4, 8, 16, 32} (dataset-dependent, 4–16 optimal); head sub-dimension d′ = d / H; shared FFN′ hidden size = d′; Adam optimizer lr = 0.001, β1 = 0.9, β2 = 0.999; batch size = 256.",
    "experiments": "# 5 Experiments\n\n# 5.1 Datasets\n\nWe conduct experiments on four public datasets. Beauty, Sports and Toys are three subcategories of Amazon review data introduced in [19].  $ML - 20m$  is a subset of the MovieLens dataset [13], containing approximately 20 million ratings from 138,493 users on 27,278 movies. Following [33, 41], only \"5-core\" sequences are remained in the 4 datasets, in which all users and items have at least 5 interactions. The statistics of the prepared datasets are summarized in Table 1.\n\n# 5.2 Evaluation Metrics\n\nWe rank the prediction on the whole item set without negative sampling [18]. Performance is evaluated on a variety of evaluation metrics, including Hit Ratio@k (HR@k), and Normalized Discounted Cumulative Gain@k (NDCG@k) where  $k \\in \\{5, 10, 20\\}$ . Following standard practice in sequential recommendation [17, 22, 25, 41], we employ a leave-one-out evaluation strategy: for each user sequence, the final item serves as the test data, the penultimate item as the validation data, and the remaining items as the training data.\n\n# 5.3Baselines\n\nWe compare our proposed method against a set of baseline models as follows:\n\n\nTable 2: Performance comparison of different methods on top-  $k$  recommendation\n\n\n<table><tr><td>Dataset</td><td>Metric</td><td>GRU4Rec</td><td>SASRec</td><td>BERT4Rec</td><td>CORE</td><td>CL4SRec</td><td>ICLRec</td><td>DuoRec</td><td>A-Mixer</td><td>MSGIFSR</td><td>MiaSRac</td><td>FAME</td><td>Improv.</td></tr><tr><td rowspan=\"6\">Beauty</td><td>HR@5</td><td>0.0408</td><td>0.0508</td><td>0.0510</td><td>0.0331</td><td>0.0623</td><td>0.0664</td><td>0.0504</td><td>0.0507</td><td>0.0518</td><td>0.0524</td><td>0.0710</td><td>6.9%</td></tr><tr><td>HR@10</td><td>0.0623</td><td>0.0761</td><td>0.0745</td><td>0.0664</td><td>0.0877</td><td>0.0918</td><td>0.0691</td><td>0.0752</td><td>0.0771</td><td>0.0795</td><td>0.0978</td><td>6.2%</td></tr><tr><td>HR@20</td><td>0.0895</td><td>0.1057</td><td>0.1075</td><td>0.1071</td><td>0.1195</td><td>0.1252</td><td>0.0912</td><td>0.1033</td><td>0.1105</td><td>0.1125</td><td>0.1345</td><td>7.4%</td></tr><tr><td>NDCG@5</td><td>0.0273</td><td>0.0318</td><td>0.0343</td><td>0.0164</td><td>0.0440</td><td>0.0480</td><td>0.0363</td><td>0.0350</td><td>0.0344</td><td>0.0362</td><td>0.0508</td><td>5.8%</td></tr><tr><td>NDCG@10</td><td>0.0342</td><td>0.0400</td><td>0.0419</td><td>0.0271</td><td>0.0521</td><td>0.0562</td><td>0.0424</td><td>0.0421</td><td>0.0429</td><td>0.0449</td><td>0.0593</td><td>5.5%</td></tr><tr><td>NDCG@20</td><td>0.0410</td><td>0.0474</td><td>0.0502</td><td>0.0373</td><td>0.0601</td><td>0.0646</td><td>0.0479</td><td>0.0504</td><td>0.0508</td><td>0.0532</td><td>0.0687</td><td>6.3%</td></tr><tr><td rowspan=\"6\">Sports</td><td>HR@5</td><td>0.0210</td><td>0.0266</td><td>0.0252</td><td>0.0150</td><td>0.0338</td><td>0.0384</td><td>0.0225</td><td>0.0217</td><td>0.0268</td><td>0.0270</td><td>0.0400</td><td>4.2%</td></tr><tr><td>HR@10</td><td>0.0339</td><td>0.0412</td><td>0.0395</td><td>0.0342</td><td>0.0498</td><td>0.0543</td><td>0.0327</td><td>0.0321</td><td>0.0425</td><td>0.0435</td><td>0.0580</td><td>6.8%</td></tr><tr><td>HR@20</td><td>0.0527</td><td>0.0618</td><td>0.0607</td><td>0.0609</td><td>0.0723</td><td>0.0753</td><td>0.0476</td><td>0.0469</td><td>0.0634</td><td>0.0651</td><td>0.0820</td><td>8.9%</td></tr><tr><td>NDCG@5</td><td>0.0136</td><td>0.0158</td><td>0.0166</td><td>0.0072</td><td>0.0235</td><td>0.0266</td><td>0.0161</td><td>0.0165</td><td>0.0171</td><td>0.0180</td><td>0.0277</td><td>4.1%</td></tr><tr><td>NDCG@10</td><td>0.0178</td><td>0.0205</td><td>0.0212</td><td>0.0134</td><td>0.0287</td><td>0.0317</td><td>0.0193</td><td>0.0188</td><td>0.0221</td><td>0.0233</td><td>0.0337</td><td>6.3%</td></tr><tr><td>NDCG@20</td><td>0.0225</td><td>0.0256</td><td>0.0265</td><td>0.0201</td><td>0.0344</td><td>0.0370</td><td>0.0231</td><td>0.0235</td><td>0.0279</td><td>0.0288</td><td>0.0402</td><td>8.6%</td></tr><tr><td rowspan=\"6\">Toys</td><td>HR@5</td><td>0.0369</td><td>0.0489</td><td>0.0464</td><td>0.0338</td><td>0.0658</td><td>0.0792</td><td>0.0481</td><td>0.0565</td><td>0.0576</td><td>0.0581</td><td>0.0820</td><td>3.5%</td></tr><tr><td>HR@10</td><td>0.0524</td><td>0.0676</td><td>0.0677</td><td>0.0699</td><td>0.0912</td><td>0.1043</td><td>0.0666</td><td>0.0819</td><td>0.0831</td><td>0.0828</td><td>0.1065</td><td>2.1%</td></tr><tr><td>HR@20</td><td>0.076</td><td>0.0908</td><td>0.0968</td><td>0.1114</td><td>0.1209</td><td>0.1382</td><td>0.0879</td><td>0.1099</td><td>0.1150</td><td>0.1143</td><td>0.1409</td><td>1.9%</td></tr><tr><td>NDCG@5</td><td>0.0247</td><td>0.0329</td><td>0.0322</td><td>0.0158</td><td>0.047</td><td>0.0579</td><td>0.0356</td><td>0.403</td><td>0.0407</td><td>0.0408</td><td>0.0603</td><td>4.1%</td></tr><tr><td>NDCG@10</td><td>0.0296</td><td>0.0389</td><td>0.0391</td><td>0.0274</td><td>0.0552</td><td>0.0660</td><td>0.0415</td><td>0.481</td><td>0.0492</td><td>0.0488</td><td>0.0681</td><td>3.2%</td></tr><tr><td>NDCG@20</td><td>0.0356</td><td>0.0448</td><td>0.0464</td><td>0.0378</td><td>0.0627</td><td>0.0745</td><td>0.0469</td><td>0.574</td><td>0.0577</td><td>0.0567</td><td>0.0759</td><td>1.9%</td></tr><tr><td rowspan=\"6\">ML-20m</td><td>HR@5</td><td>0.1365</td><td>0.1305</td><td>0.1446</td><td>0.0655</td><td>0.1205</td><td>0.1380</td><td>0.1458</td><td>0.1325</td><td>0.1303</td><td>0.1367</td><td>0.1538</td><td>5.5%</td></tr><tr><td>HR@10</td><td>0.2052</td><td>0.2016</td><td>0.2172</td><td>0.1312</td><td>0.1853</td><td>0.2070</td><td>0.2164</td><td>0.2022</td><td>0.2013</td><td>0.2071</td><td>0.2246</td><td>3.4%</td></tr><tr><td>HR@20</td><td>0.2981</td><td>0.2996</td><td>0.3132</td><td>0.2251</td><td>0.2760</td><td>0.2997</td><td>0.3108</td><td>0.2994</td><td>0.2978</td><td>0.3021</td><td>0.3230</td><td>3.1%</td></tr><tr><td>NDCG@5</td><td>0.0927</td><td>0.0858</td><td>0.0964</td><td>0.0347</td><td>0.0804</td><td>0.0927</td><td>0.0986</td><td>0.0899</td><td>0.0844</td><td>0.0918</td><td>0.1046</td><td>6.1%</td></tr><tr><td>NDCG@10</td><td>0.1148</td><td>0.1086</td><td>0.1197</td><td>0.0558</td><td>0.1012</td><td>0.1149</td><td>0.1212</td><td>0.1121</td><td>0.1119</td><td>0.1144</td><td>0.1276</td><td>5.3%</td></tr><tr><td>NDCG@20</td><td>0.1382</td><td>0.1333</td><td>0.1438</td><td>0.0794</td><td>0.1240</td><td>0.1382</td><td>0.1450</td><td>0.1334</td><td>0.1357</td><td>0.1383</td><td>0.1513</td><td>4.3%</td></tr></table>\n\n- GRU4Rec [14]: it employs a GRU to encode sequences and incorporates a ranking-based loss.\n\n- SASRec [17]: this method is a pioneering work utilizing self-attention to capture dynamic user interests.\n\n- BERT4Rec [25]: this approach adapts the BERT architecture for sequential recommendation using a cloze task.\n\n- CORE [16]: it proposes a representation-consistent encoder based on linear combinations of item embeddings to ensure that sequence representations are in the same space with item embeddings.\n\n- CL4SRec [33]: this method combines contrastive learning with a Transformer-based model through data augmentation techniques (i.e., item crop, mask, and reorder).\n\n- ICLRec [3]: this approach improves sequential recommendation by conducting clustering and contrastive learning on user intentions represented by cluster centroids to enhance recommendation.\n\n- DuoRec [20]: this research investigates the representation degeneration issue in sequential recommendation and offers solutions based on contrastive learning techniques.\n\n- MSGIFSR [12]: it captures multi-level user intents using a Multi-granularity Intent Heterogeneous Session Graph.\n\n- Atten-Mixer [37]: this method leverages concept-view and instance-view readouts for multi-level intent reasoning instead of using the GNN propagation.\n\n- MiasRec [6]: this approach utilizes multiple item representations in the sequence instead of only using the last item's representation as the sequence representation to capture diverse user intents.\n\n# 5.4 Settings and Implementation Details\n\nWe employ original implementations for SASRec, ICLRec, MSGIFSR, Atten-Mixer, and MiasRec public in their papers. For GRU4Rec and CORE, we leverage the RecBole library [34], while BERT4Rec, CL4SRec, and DuoRec are implemented using the SSLRec library [23]. Hyperparameters for all models are set according to their respective papers. We experiment with embedding dimensions of 64 and 128 (as experimented, larger dimensions often lead to convergence issues) and select the configuration that yields the best performance for each model.\n\nOur method is implemented in PyTorch. The model is optimized by Adam optimizer with a learning rate of 0.001,  $\\beta_{1} = 0.9$ ,  $\\beta_{2} = 0.999$ . We employ a batch size of 256. For FAME hyperparameters,  $H$  and  $N$  are tuned within the ranges  $\\{1, 2, 4, 8, 16\\}$  and  $\\{2, 4, 8, 16, 32\\}$ , respectively. All experiments were conducted on a single NVIDIA RTX A5000 GPU.\n\n# 5.5 Overall Performance\n\nTable 2 presents a comprehensive comparison of FAME against various baseline models. Our experimental findings reveal several key observations:\n\n- Limitations of Traditional Models: While RNN and Transformer-based models have shown success in sequential tasks, their direct application to recommendation often yields suboptimal results due to a lack of consideration for real-world user and item complexities (e.g., GRU4Rec, BERT4Rec).\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/c2f214f0168fccbf682f9ddbf55e6a2d37815dbc8dc5bbaba28c5a6ee4d5e54e.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/fa6e9c4cdf1bd1b3a83711e0bee69d55baa03a52ae822f2edfceac94807b3f39.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/3dd866e15569e4adc8a65087e57e5f85e12f6fe5101ce3cdd42d61e61a620b14.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/d3d6b153b57aec717d27d01b0d958f02ca1f0d4507ccb962365ea6100684814c.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/db8b8beb540a36b61003a3c4a967de9ba5d5455ba52d89dcfdac8fa228a10f85.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/ac068d891a916e804b4c63ebbfc8606242ad470cd2654c765a92f29e214f986c.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/671ac5a09c7771772f1c81336f6c43ecbc70b33d86d657b791144feac4218b27.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/0929db8c445fd33ebc028139d03fb4d5b50cda66f1d4e938f8d4267769135084.jpg)\n\n\n\nFigure 5: The performances comparison varying the number of heads in each dataset. The metric in (a)-(d) is NDCG@20, and the metric in (e)-(h) is HR@20.\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/3078bb90c00c4e25498365091913401cd6681ce69b0a426e9d88664c7bc7b0e6.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/688ac030033c9502dc27da9660114beda47aa2afc3dbccd2e47d6b76eadf42a8.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/2e32400a225b97b84b4e0d33b1f981069d345edac05c2e8c4f800a49b56cd362.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/e717e16ab1f653ef384f5791fc80000978b5e5f008c79225e42d419d5bcc89e1.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/c9156f5c20405d8427e6411097dbe54956eb447dd83c9bdca777d807919e7fc1.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/d31feef00fe325e916f0c42a6cdb7af8e7649ae3f33d7750d79c3b6a34510cc6.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/34c6bfbb6c8058ca94c8692d5e004424c41b0aa95c33f2976dd2cad8510d15c1.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/32374de45fac5bb38e056989968edddd770f021fa6f4c9c23efe71f850ea51fa.jpg)\n\n\n\nFigure 6: The performances comparison varying the number of experts in each dataset. The metric in (a)-(d) is NDCG@20, and the metric in (e)-(h) is HR@20. The red horizontal line in each subfigure indicates the peak performance (NDCG@20 or HR@20) achieved by  $\\mathrm{FAME}_{w/oMoE}$  within that dataset, as shown in Figure 5.\n\n\n- Importance of Intent Modeling: Models that explicitly capture user intents significantly outperform traditional sequential models. This improvement is attributed to their ability to: 1) handle noisy user behavior by focusing on underlying preferences\n\nrather than superficial interactions (e.g., ICLRec), or 2) disentangle multiple co-existing user intents within a sequence (e.g., MiasRec).\n\n\nUser 230\n\n\n\nHistory Sequence: [1975,2018,1447,2019,2020,2021,518,2022,2023,1411,2024,2025,2026,509,2027,2028,523]\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-08/29a06dab-9dbc-4e81-9588-dc71672dad76/d76389a7cd4de223f104b4dab89b87031adb88980c20c4e5d7aa389490fdc699.jpg)\n\n\n\nFigure 7: Recommendation results for user 230 in the Sports dataset. User history is displayed at the top. The ground truth next item (item 2028) is highlighted.\n\n\n- Superiority of our model FAME: Our proposed FAME model consistently outperforms all baselines across datasets. This highlights the importance of considering item multi-faceted nature and disentangling user preferences within each facet for effective sequential recommendation.\n\n# 5.6 Ablation Study and Parameters Study\n\nThis subsection presents the ablation study to evaluate the contributions of our proposed components and conduct corresponding hyperparameter tuning. We begin by examining  $\\mathrm{FAME}_{w / o} \\, MoE$ , which excludes the MoE module, to assess the impact of the facet-aware multi-head prediction mechanism (introduced in Section. 4.2) and determine the optimal number of attention heads in Section. 5.6.1. Subsequently, using the optimized head configuration, we evaluate the complete FAME model to validate the effectiveness of the MoE module and identify the optimal number of experts in Section. 5.6.2.\n\n5.6.1 Impact of the number of heads. Figure 5 illustrates the performance variation with different numbers of heads  $(H)$ , treated as a hyperparameter. We compare the original SASRec model with  $\\mathrm{FAME}_{w / oMoE}$  to isolate the impact of our multi-head prediction mechanism. We experiment with  $H$  values of  $\\{1,2,4,8,16\\}$ . When  $H = 1$ , our  $\\mathrm{FAME}_{w / oMoE}$  is reduced to the original SASRec model with single head. As noted in [27], computational costs remain constant when varying the number of heads  $(H)$  while maintaining a fixed embedding dimension  $(d)$ .\n\nBenefits of multi-head attention: Both SASRec and  $\\mathrm{FAME}_{w / o}$  MoE exhibit performance improvements with multiple heads, however, excessive heads can lead to diminishing returns, aligning with findings in Transformer [27] and SASRec [17].\n\nSuperiority of facet-aware architecture:  $\\mathrm{FAME}_{w / o}$  MoE consistently outperforms SASRec, demonstrating the effectiveness of our facet-aware approach.\n\nDataset-specific optimal head count: The optimal number of heads varies across datasets. Beauty, Sports, and Toys benefit from fewer heads, suggesting simpler item facets, while ML-20m requires more heads to capture complex item characteristics.\n\n5.6.2 Impact of the number of experts. Figure 6 illustrates the influence of the number of experts  $(N)$  within each attention head on\n\nmodel performance. We set  $H$  to the optimal value determined for  $\\mathrm{FAME}_{w / oMoE}$  and compare its performance (red horizontal line in each subfigure) to that of FAME by varying  $N$  in  $\\{2,4,8,16,32\\}$ . FAME simplifies to  $\\mathrm{FAME}_{w / oMoE}$  when  $N$  is set to 1.\n\nFAME outperforms  $\\mathrm{FAME}_{w / oMoE}$  across all datasets. This improvement can be attributed to the effectiveness of the MoE component, as evidenced by the existence of an optimal  $N$  value in each subfigure that surpasses the performance of  $\\mathrm{FAME}_{w / oMoE}$ . While the Beauty dataset exhibits diminishing returns for  $N$  greater than 4, suggesting simpler user preferences, the other datasets benefit from a larger number of experts. In particular, ML-20m show performance gains with increasing  $N$ , indicating the presence of more complex and diverse user preferences. However, excessive experts ( $N = 32$ ) might lead to overfitting in the Sports and Toys dataset.\n\n# 5.7 Case Study\n\nTo illustrate the effectiveness of our facet-aware mechanism, Figure 7 presents recommendation results for user 230, along with corresponding head importance scores (calculated using Equation 10). For simplicity, we set the number of heads to two and focus on the Sports dataset.\n\nThe figure clearly demonstrates the diversity of recommendations across different heads, highlighting the ability of our model to capture distinct item facets. The calculated head importance scores reveal that head 2 better aligns with user 230's preferences (0.82 vs 0.18), as evidenced by the inclusion of the ground truth item (item 2028) in its recommendation list. The integrated recommendation, incorporating both heads with appropriate weights, successfully predicts the ground truth item.\n\nIn contrast, a traditional approach concatenating sub-embeddings from all heads without considering head importance fails to capture the user's dominant preference, resulting in the omission of the ground truth item in the recommendation list."
  }