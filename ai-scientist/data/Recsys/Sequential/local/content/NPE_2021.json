{
  "id": "NPE_2021",
  "paper_title": "Neural Personalized Embedding for Recommendation",
  "alias": "NPE",
  "year": 2021,
  "domain": "Recsys",
  "task": "SequentialRecommendation",
  "idea": "NPE (Neural Personalized Embedding) proposes a neural factor model that captures both user preferences for items and relationships between closely related items for top-N recommendation. The key innovation is modeling the conditional probability p(r_u,i=1|u,c_u,i) using two components: (1) user-item preference term h_u^T w_i and (2) item-context compatibility term w_i^T v_c_{u,i}, where items have dual representations (embedding vector w_i for attributes and context vector v_i for co-occurrence patterns). This allows NPE to leverage item co-occurrence patterns from user click history to improve recommendations, especially for cold users with limited historical data.",
  "introduction": "# 1 Introduction\n\nIn recent years, recommender systems have become a core component of online services. Given the \"historical activities\" of a particular user (e.g., product purchases, movie watching, and Web page views), a recommender system suggests other items that may be of interest to that user. Current domains for recommender systems include movie recommendation (Netflix and Hulu), product recommendation (Amazon), and application recommendation (Google Play and Apple Store).\n\nThe historical activities of users are often expressed in terms of a user-item preference matrix whose entries are either explicit feedback (e.g., ratings or like/dislike) or implicit feedback (e.g., clicks or purchases). Typically, only a small part of the potential user-item matrix is available, with the remaining entries not having been recorded. Predicting user preferences can be interpreted as filling in the missing entries of the user-item matrix. In this setting, matrix factorization (MF) is one of the most efficient approaches to find the latent representations of users and items [Hu et al., 2008; Salakhutdinov and Mnih, 2008; Koren, 2008]. To address the sparseness of the user-item matrix, additional data are integrated\n\ninto MF as \"side information.\" This might include textual information for article recommendations [Wang et al., 2015; Wang and Blei, 2011], product images in e-commerce [He and McAuley, 2016], or music signals for song recommendations [Oord et al., 2013]. However, there are two major issues with these MF-based algorithms. First, these models are poor at modeling cold-users (i.e., users who have only a short history of relevant activities). Second, because these models consider only user-item interactions, the item representations poorly capture the relationships among closely related items [Koren, 2010].\n\nOne approach to cold-user recommendation is to exploit user profiles. Such proposed models [Tang and Liu, 2017; Li et al., 2015b] can learn user representations from their profiles (e.g., gender and age). In this way, these models can make recommendations to new users who have no historical activities, provided their user profiles are available. However, user profiles are often very noisy, and in many cases, they are simply not available. Another approach is item-similarity based models [Sarwar et al., 2001; Linden et al., 2003], which recommends items based on item-item similarity. The main issue of this approach is that it considers only the most recent click when making a recommendation, ignoring previous clicks. In addition, these models are not personalized.\n\nIn item representations learning, Item2Vec [Barkan and Koenigstein, 2016] is an efficient model that borrows the idea behind word-embedding techniques [Mikolov et al., ] for learning item representations. However, the main goal of Item2Vec is to learn item representations and it cannot be used directly for predicting missing entries in a user-item matrix. Furthermore, in making recommendations, Item2Vec is not personalized: it recommends items based on the similarities between items, computed using item representations, and ignores users' historical activities.\n\nTo address these problems, this paper proposes a neural personalized embedding (NPE) model that fuses item relationships for learning effective item representations in addition to improving recommendation quality for cold-users. NPE models a user's click on an item by assuming that there are two signals driving the click: the personal preference of the user with respect to the item and the relationships between this item and other items that the user has clicked.\n\nTo model the personal preference term, we adopt the same\n\napproach as MF, which views the preference of a user for an item as the inner product of the corresponding factor vectors. To model the relationships among items, we propose an item-embedding model that generalizes the idea behind word-embedding techniques to click data. However, our item-embedding model differs from the word-embedding model in that the latter can only learn word representations. In contrast, our embedding model can both learn item representations and fill in the user-item matrix simultaneously.",
  "method": "# 3 NPE: Neural Personalized Embedding\n\nWe propose NPE, a factor model that explains users' clicks by capturing the preferences of users for items and the relationships between closely related items. We will describe the model and how to learn the model parameters.\n\n# 3.1 Problem Formulation\n\nEach entry  $r_{u,i}$  in the user-item preference matrix  $\\mathbf{R}$  has one of two values 0 or 1, such that  $r_{u,i} = 1$  if user  $u$  has clicked item  $i$  and  $r_{u,i} = 0$  otherwise. We assume that  $r_{u,i} = 1$  indicates that user  $u$  prefers  $i$ , whereas  $r_{u,i} = 0$  indicates that this entry is non-observed (i.e., a missing entry).\n\nGiven a user  $u$  and the set of items that  $u$  previously interacted, our goal is to predict a list of items that  $u$  may find interesting (top-N recommendations).\n\nThe notations used in this paper are defined in Table 1.\n\n# 3.2 Model Formulation\n\nWe denote the observations for user  $u$  as:\n\n$$\n\\mathbf {r} _ {u} = \\left(r _ {u, 1}, r _ {u, 2}, \\dots , r _ {u, M}\\right). \\tag {1}\n$$\n\nNPE models the probability of each observation conditioned on user  $u$  and its context items as:\n\n$$\np \\left(r _ {u, i} = 1 \\mid u, \\mathbf {c} _ {u, i}\\right), \\tag {2}\n$$\n\n# Notation | Meaning\n\n<table><tr><td>N,M</td><td>the number of users and items, respectively</td></tr><tr><td>R</td><td>the user-item matrix (e.g., click matrix)</td></tr><tr><td>ru</td><td>the observation data for user u (i.e., the row corresponding to user u of matrix R)</td></tr><tr><td>D</td><td>the dimensionality of the embedding space</td></tr><tr><td>H</td><td>the dimensionality of the user input vector</td></tr><tr><td>L</td><td>the dimensionality of the item input vector</td></tr><tr><td>xu</td><td>the input vector of user u, xu ∈ R^H</td></tr><tr><td>yi</td><td>the input vector of item i, yi ∈ RL</td></tr><tr><td>H</td><td>the user embedding matrix, H ∈ R^H×D</td></tr><tr><td>W</td><td>the item-embedding matrix, W ∈ RL×D</td></tr><tr><td>V</td><td>the item context matrix, V ∈ RL×D</td></tr><tr><td>hu</td><td>the embedding vector of user u, hu ∈ RD</td></tr><tr><td>wi</td><td>the embedding vector of item i, wi ∈ RD</td></tr><tr><td>vi</td><td>the context vector of item i, vi ∈ RD</td></tr><tr><td>Θ</td><td>The set of all model parameters</td></tr><tr><td>Ω(.)</td><td>The regularization term</td></tr><tr><td>cu,i</td><td>the set of items that user u clicked, excluding i (the context items)</td></tr><tr><td>D+</td><td>the set of positive examples, D+ = {(u,i)|ru,i=1}</td></tr><tr><td>D-</td><td>the set of negative examples, which is obtained by sampling from zero entries of matrix R</td></tr></table>\n\nTable 1: The notations used throughout the paper.\n\nThis equation captures the intuition behind the model, namely that the conditional distribution of whether user  $u$  clicks on item  $i$  is governed by two factors: (1) the personal preference of user  $u$  for item  $i$ , and (2) the set of items that  $u$  has clicked (i.e.,  $\\mathbf{c}_{u,i}$ ).\n\nThe likelihood function for the entire matrix  $\\mathbf{R}$  is then formulated as:\n\n$$\np (\\mathbf {R}) = \\prod_ {u = 1} ^ {N} \\prod_ {i = 1} ^ {M} p \\left(r _ {u, i} \\mid u, \\mathbf {c} _ {u, i}\\right). \\tag {3}\n$$\n\nThe conditional probability expressed in Eq. 2 is implemented by a neural network. This neural network connects the input vectors of user  $u$ , item  $i$ , and context items  $\\mathbf{c}_{u,i}$  to their hidden representations as:\n\n$$\n\\mathbf {h} _ {u} = \\mathbf {f} \\left(\\mathbf {x} _ {u} ^ {\\top} \\mathbf {H}\\right), \\tag {4}\n$$\n\n$$\n\\mathbf {w} _ {i} = \\mathbf {f} \\left(\\mathbf {y} _ {i} ^ {\\top} \\mathbf {W}\\right), \\tag {5}\n$$\n\n$$\n\\mathbf {v} _ {\\mathbf {c} _ {u, i}} = \\mathbf {f} \\left(\\sum_ {j \\in \\mathbf {c} _ {u, i}} \\mathbf {y} _ {i} ^ {\\top} \\mathbf {V}\\right), \\tag {6}\n$$\n\nwhere  $\\mathbf{f}(.)$  is an activation function such as ReLU.\n\nNote that there are two hidden representations associated with item  $i$ : the embedding vector  $\\mathbf{w}_i$  and the context vector  $\\mathbf{v}_i$ , which have different roles. Whereas  $\\mathbf{w}_i$  accounts for the attributes of item  $i$ ,  $\\mathbf{v}_i$  accounts for specifying the items that appear in its context.\n\nWe can then define the conditional probability in Eq. 2 via the hidden representations as:\n\n$$\np \\left(r _ {u, i} = 1 \\mid u, \\mathbf {c} _ {u, i}\\right) = \\sigma \\left(\\mathbf {h} _ {u} ^ {\\top} \\mathbf {w} _ {i} + \\mathbf {w} _ {i} ^ {\\top} \\mathbf {v} _ {\\mathbf {c} _ {u, i}}\\right). \\tag {7}\n$$\n\nNote that the  $\\sigma(.)$  function on the right side of Eq. 7 comprises two terms: the first term  $\\mathbf{h}_u^\\top \\mathbf{w}_i$  accounts for how user  $u$  prefers item  $i$ , whereas the second term  $\\mathbf{w}_i^\\top \\mathbf{v}_{\\mathbf{c}_{u,i}}$  accounts for the compatibility between item  $i$  and the items that  $u$  has already clicked.\n\nFrom Eq. 7, we can also obtain the probability that  $r_{u,i} = 0$  as:\n\n$$\np \\left(r _ {u, i} = 0 \\mid u, \\mathbf {c} _ {u, i}\\right) = 1 - \\sigma \\left(\\mathbf {h} _ {u} ^ {\\top} \\mathbf {w} _ {i} + \\mathbf {w} _ {i} ^ {\\top} \\mathbf {v} _ {\\mathbf {c} _ {u, i}}\\right) \\tag {8}\n$$\n\nThe conditional probability functions in Eqs. 7 and 8 can be summarized in a single conditional probability function as:\n\n$$\np \\left(r _ {u, i} = r \\mid u, \\mathbf {c} _ {u, i}\\right) = \\left\\{ \\begin{array}{l l} \\hat {\\mu} _ {u, i}, & \\text {i f} r = 1, \\\\ 1 - \\hat {\\mu} _ {u, i}, & \\text {i f} r = 0, \\end{array} \\right. \\tag {9}\n$$\n\nwhere  $\\hat{\\mu}_{u,i} = \\sigma (\\mathbf{h}_u^\\top \\mathbf{w}_i + \\mathbf{w}_i^\\top \\mathbf{v}_{\\mathbf{c}_{u,i}})$\n\n# 3.3 The Model Architecture\n\nThe architecture of NPE is shown in Fig. 1 as a multi-layer neural network. The first layer is the input layer which specifies the input vectors of (1) a user  $u$ , (2) a candidate item  $i$ , and (3) the context items. Above this is the second layer (the embedding layer), which connects to the input layer via connection matrices  $\\mathbf{H}$ ,  $\\mathbf{W}$ , and  $\\mathbf{V}$ . Above the embedding layer, two terms are calculated: the personal preference of user  $u$  for item  $i$  and the relationship between  $i$  and the context items. Finally, the model combines these two terms to compute the output, which is the probability that  $u$  will click  $i$ .\n\nNote that, the input layer accepts a wide range of vectors that describe users and items such as one-hot vector or content feature vectors obtained from side information. With such a generic input vectors, our method can address the cold-start problem by using content feature vectors as input vectors for users and items. Since this work focuses on the pure collaborative filtering setting, we use only the identities of users and items in the form of one-hot vectors as input vectors. Investigating the effectiveness of using content feature vectors, is left for future work.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/73ff3025-af8a-432d-bbbd-7ae79117bf4f/73c934b98c9f9888992e0a2fc72c923655d8338704cfed95ddeef749d490e599.jpg)  \nFigure 1: The architecture of NPE.\n\nAlgorithm 1: NPE(R, n). Backprop is the backpropagation procedure for updating network weights.  \nInput :  \n- R: User-item preference matrix  \n- n: number of negative samples per positive example  \nOutput: Θ = {H, W, V}  \n1 Initialization: sample H, W, V from Gaussian distributions  \n2 for epoch=1...T do  \n3 Sample negative examples D^-  \n4 D = D^+ ∪ D^-  \n5 O = Shuffle(D)  \n6 for t=1...# of mini-batches do  \n7 B = next-mini-batch(O)  \n8 Backprop(Θ, B)  \n9 end  \n10 end\n\n# 3.4 Objective Function\n\nGiven an observed matrix  $\\mathbf{R}$ , our goal is to learn the model parameters  $\\Theta$  that maximize the likelihood function in Eq. 3. However, instead of modeling all zero entries, we only model a small subset of such entries by picking them randomly (negative sampling). This gives:\n\n$$\np (\\mathbf {R}) = \\prod_ {(u, i) \\in \\mathcal {D} ^ {+}} p \\left(r _ {u, i} \\mid u, \\mathbf {c} _ {u, i}\\right) \\prod_ {(u, i) \\in \\mathcal {D} ^ {-}} p \\left(r _ {u, i} \\mid u, \\mathbf {c} _ {u, i}\\right). \\tag {10}\n$$\n\nMaximizing the likelihood in Eq. 10 is equivalent to minimizing the following loss function (its negative log function):\n\n$$\n\\begin{array}{l} \\mathcal {L} (\\Theta) = - \\sum_ {(u, i) \\in \\mathcal {D} ^ {+}} \\log \\hat {\\mu} _ {u i} - \\sum_ {(u, i) \\in \\mathcal {D} ^ {-}} \\log (1 - \\hat {\\mu} _ {u i}) \\tag {11} \\\\ + \\lambda \\Omega (\\Theta), \\\\ \\end{array}\n$$\n\nwhere  $\\hat{\\mu}_{u,i} = \\sigma (\\mathbf{h}_u^\\top \\mathbf{w}_i + \\mathbf{w}_i^\\top \\mathbf{v}_{\\mathbf{c}_{u,i}})$\n\nThis loss function is known as the binary cross-entropy.\n\n# 3.5 Model Training\n\nWe adopt the Adam technique (a mini-batch stochastic gradient descent approach) [Kingma and Ba, 2014]. We do not perform negative sampling in advance, which can only produce a fixed set of negative samples. Instead, we perform negative sampling with each epoch, which enables diverse sets of negative examples to be used. The algorithm is summarized in Algorithm 1.\n\n# 3.6 Connections with Previous Models\n\n# NPE vs. MF\n\nIn the conditional probability in Eq. 7, we can see that the  $\\sigma(.)$  function is a combination of two terms: (1) user preference and (2) item relationship. If the second term is removed, NPE will reduce to an original MF method.\n\n<table><tr><td></td><td>ML-10m</td><td>OnlineRetail</td><td>TasteProfile</td></tr><tr><td>#users</td><td>58,059</td><td>3,705</td><td>211,830</td></tr><tr><td>#items</td><td>8,484</td><td>3,644</td><td>22,781</td></tr><tr><td># clicks</td><td>3,502,733</td><td>235,472</td><td>10,054,204</td></tr><tr><td>% clicks</td><td>0.71%</td><td>1.74%</td><td>0.21%</td></tr></table>\n\nTable 2: Statistical information about the datasets.\n\n# NPE vs. Word Embedding\n\nSimilarly, if we remove the first element of  $\\sigma(.)$  in Eq. 7, NPE will model only the relationship among items. If we view each item as a word, and the set of items that a user clicked as a sentence, the model becomes similar to a word-embedding model. However, our embedding model differs in that word-embedding techniques can only learn word (item) representations and cannot fill the user-item matrix directly. In contrast, our embedding model can learn effective item representations while predicting the missing entries in the user-item matrix.",
  "experiments": "# 4 Empirical Study\n\nWe have studied the effectiveness of NPE both quantitatively and qualitatively. In our quantitative analysis, we compared NPE with state-of-the-art methods on top-N recommendation task, using real-world datasets. We also performed a qualitative analysis to show the effectiveness of the item representations.\n\n# 4.1 Datasets\n\nWe used three real-world datasets whose sizes varied from small to large-scale, from different domains. First, Movielens 10M (ML-10m) is a dataset of user-movie ratings, collected from MovieLens, an online film service. Next, Online Retail [Chen et al., 2012] is a dataset of online retail transactions that contains all transactions from Dec 1, 2010 to Dec 9, 2011 for an online retailer. Finally, TasteProfile is a dataset of counts of song plays by users, as collected by Echo Nest.\n\n# 4.2 Experiment Setup\n\n# Data Preparation\n\nFor the ML-10m, we binarized the ratings, thresholding at 4 or above; for TasteProfile and OnlineRetail, we binarized the data and interpreted them as implicit feedback. Statistical information about the datasets is given in Table 2.\n\nWe partitioned the data into three subsets, using  $70\\%$  of the data as the training set,  $10\\%$  as the validation set, and the remaining  $20\\%$  as the test set (ground truth).\n\n# Evaluation Metrics\n\nAfter training the models on the training set, we evaluated the accuracy of their top-N recommendations using the test set. We used the rank-based metrics Recall@n and nDCG@n, which are common metrics in information retrieval, for evaluating the accuracy of the top-N recommendations. (We did not use \"Precision\" because it is difficult to evaluate, given that a zero entry can imply either that the user does not like the item or does not know about the item).\n\n# Competing Methods\n\nWe compared NPE with the following competing methods:\n\n- Bayesian personalized ranking (BPR) [Rendle et al., 2009]: an algorithm that optimizes the MF model with a pair-wise ranking loss  \n- Neural collaborative filtering (NeuCF) [He et al., 2017]: a generalization of an MF method in which the inner product of user and item feature vectors are replaced by a deep neural network  \n- Sparse linear model (SLIM) [Ning and Karypis, 2011]: a state-of-the-art method for top-N recommendations, which is based on the similarities between items.\n\n# 4.3 Implementation Details\n\nSince neural networks are prone to overfitting, we apply a dropout after the hidden representation layer. The dropout rate is tuned for each dataset. We use early stopping to terminate the training process if the loss function does not decrease on the validation set for five epochs. The weights for the matrices  $\\mathbf{H}$ ,  $\\mathbf{W}$ , and  $\\mathbf{V}$  are initialized as normal distributions. The size of each mini-batch was 10,000.\n\n# 4.4 Experimental Results\n\n# Top-N Recommendations\n\nTable 3 summarizes the Recall@20 and nDCG@20 for each model. Note that NPE significantly outperforms the other competing methods across all datasets for both Recall and nDCG. We emphasize that all methods used the same data. However, NPE benefits from capturing the compatibility between each item and other items picked by the same users.\n\nIn Table 4, we summarize Recall@20 values for the four methods when different numbers of items were to be recommended. From these results, we can see that NPE consistently outperformed the other methods at all settings. The differences between NPE and the other methods are more pronounced for small numbers of recommended items. This is a desirable feature because we often only consider a small number of top items (e.g., top-5 or top-10).\n\n# The Performance on Cold-Users\n\nWe studied the performance of the models for users who had few historical activities. To this end, we partitioned the test cases into three groups, according to the number of clicks that each user had. The Low group's users had less than 10 clicks, the Medium group's users had  $10 \\sim 20$  clicks, and the High group's users had more than 20 clicks.\n\nFig. 2 shows the breakdown of Recall@20 in terms of user activity in the training set for the ML-10m and OnlineRetail. Although the details varied across datasets, the NPE model outperformed the other methods for all three groups of users. The differences between NPE and the other methods are much more pronounced for users who have fewest clicks. This is to be expected because, for such users, NPE captures the item relations when making recommendations.\n\n(a) ML-10m  \n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/73ff3025-af8a-432d-bbbd-7ae79117bf4f/cc5eff8f3506232d2f80b018e8fb6a2b5b6848a4f6c394b41b4efbb76c4e3c6b.jpg)  \nSLIM BPR NeuMF NPE\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/73ff3025-af8a-432d-bbbd-7ae79117bf4f/a44dec10cf46e4809d3d1eac04293cedb670f21c3284c342336ba41e2f3a4faa.jpg)  \n(b) OnlineRetail\n\nNeuMF NPE\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/73ff3025-af8a-432d-bbbd-7ae79117bf4f/9da8a26b185033624ac771cbdc39d94eba4631cdc2fa106a3940d93eb07141ed.jpg)  \nFigure 2: Recall@20 for different groups of users.  \nFigure 3: Top-5 similar items for a given item. In each row, the given item is at the left and the top-5 similar items are to its right.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/73ff3025-af8a-432d-bbbd-7ae79117bf4f/81d10788db2bccfa8c0099ee0a00a4dfd5c4fb106de5082405a4ba22fc6ac7eb.jpg)  \nFigure 4: Top-5 items that are likely to be bought together with a given item. The given item is at the left and its top-5 most similar items are to its right.\n\n# Effectiveness of the Item Representations\n\nWe evaluated the effectiveness of item representations by investigating how well the representations capture the item similarity and items that are often purchased together.\n\nSimilar items: The similarity between two items is defined as the cosine distance between their embedding vectors. Fig. 3 shows three examples of the top-5 most similar items to a given item in the OnlineRetail dataset. We can see that the items' embedding vectors effectively capture the similarity of the items. For example, in the first row, given a red alarm clock, four of its top-5 similar items are also alarm clocks.\n\nItems that are often purchased together: NPE can also identify items that are often purchased together. To assess if two items are often purchased together, we calculate the inner product of one item's embedding vector  $\\mathbf{w}_i$  and the other's context vector  $\\mathbf{v}_j$ . A high value of this inner product indicates that these two items are often purchased together. Fig. 4 shows an example of items that tend to be purchased together with the given item. Here, we see that buying a knitting Nancy, a child's toy, might accompany the purchase of other goods for children or for a household.\n\n<table><tr><td rowspan=\"2\">Methods</td><td colspan=\"2\">ML-10m</td><td colspan=\"2\">OnlineRetail</td><td colspan=\"2\">TasteProfile</td></tr><tr><td>Re@20</td><td>nDCG@20</td><td>Re@20</td><td>nDCG@20</td><td>Re@20</td><td>nDCG@20</td></tr><tr><td>SLIM</td><td>0.1342</td><td>0.1289</td><td>0.2085</td><td>0.1015</td><td>0.1513</td><td>0.1422</td></tr><tr><td>BPR</td><td>0.1314</td><td>0.1253</td><td>0.2137</td><td>0.0943</td><td>0.1598</td><td>0.1398</td></tr><tr><td>NeuCF</td><td>0.1388</td><td>0.1337</td><td>0.2199</td><td>0.0911</td><td>0.1609</td><td>0.1471</td></tr><tr><td>NPE (our)</td><td>0.1497</td><td>0.1449</td><td>0.2296</td><td>0.1742</td><td>0.1788</td><td>0.1594</td></tr></table>\n\nTable 3: Recall and nDCG for three datasets, with embedding size  $D = 64$  and negative sampling ratio  $n = 4$ .  \n\n<table><tr><td rowspan=\"2\">Methods</td><td colspan=\"3\">ML-10m</td><td colspan=\"3\">OnlineRetail</td><td colspan=\"3\">TasteProfile</td></tr><tr><td>Re@5</td><td>Re@10</td><td>Re@20</td><td>Re@5</td><td>Re@10</td><td>Re@20</td><td>Re@5</td><td>Re@10</td><td>Re@20</td></tr><tr><td>SLIM</td><td>0.1284</td><td>0.1298</td><td>0.1342</td><td>0.0952</td><td>0.1311</td><td>0.2085</td><td>0.1295</td><td>0.1304</td><td>0.1513</td></tr><tr><td>BPR</td><td>0.1254</td><td>0.1261</td><td>0.1314</td><td>0.0859</td><td>0.1222</td><td>0.2137</td><td>0.1307</td><td>0.1311</td><td>0.1598</td></tr><tr><td>NeuCF</td><td>0.1347</td><td>0.1363</td><td>0.1388</td><td>0.0871</td><td>0.1274</td><td>0.2199</td><td>0.1342</td><td>0.1356</td><td>0.1609</td></tr><tr><td>NPE (our)</td><td>0.1451</td><td>0.1487</td><td>0.1497</td><td>0.1392</td><td>0.1667</td><td>0.2296</td><td>0.1428</td><td>0.1523</td><td>0.1788</td></tr></table>\n\nTable 4: Recall for different numbers of items to be recommended, with embedding size  $D = {64}$  and negative sampling ratio  $n = 4$  .  \n\n<table><tr><td>D</td><td>ML-10m\nRe@20</td><td>OnlineRetail\nRe@20</td><td>TasteProfile\nRe@20</td></tr><tr><td>8</td><td>0.1428</td><td>0.1187</td><td>0.0987</td></tr><tr><td>16</td><td>0.1451</td><td>0.1596</td><td>0.1142</td></tr><tr><td>32</td><td>0.1441</td><td>0.1950</td><td>0.1509</td></tr><tr><td>64</td><td>0.1497</td><td>0.2296</td><td>0.1788</td></tr><tr><td>128</td><td>0.1482</td><td>0.2284</td><td>0.1992</td></tr><tr><td>256</td><td>0.1459</td><td>0.2248</td><td>0.1985</td></tr></table>\n\nTable 5: Recall@20 for various embedding sizes, with negative sampling ratio  $n = 4$ .  \n\n<table><tr><td>n</td><td>ML-10m\nRe@20</td><td>OnlineRetail\nRe@20</td><td>TasteProfile\nRe@20</td></tr><tr><td>1</td><td>0.1392</td><td>0.1608</td><td>0.1243</td></tr><tr><td>2</td><td>0.1418</td><td>0.1795</td><td>0.1451</td></tr><tr><td>4</td><td>0.1441</td><td>0.1950</td><td>0.1509</td></tr><tr><td>5</td><td>0.1478</td><td>0.1952</td><td>0.1585</td></tr><tr><td>8</td><td>0.1563</td><td>0.1941</td><td>0.1621</td></tr><tr><td>12</td><td>0.1531</td><td>0.1937</td><td>0.1615</td></tr><tr><td>16</td><td>0.1524</td><td>0.1925</td><td>0.1603</td></tr><tr><td>20</td><td>0.1496</td><td>0.1908</td><td>0.1598</td></tr></table>\n\nTable 6: Recall@20 for different negative sampling ratios, with a fixed embedding size  $D = 32$ .\n\n# Sensitivity Analysis\n\nWe also studied the effect of the hyper-parameters on the models' performance.\n\nImpact of the embedding size: To evaluate the effects of the dimensionality of the embedding space on the top-N recommendations, we varied the embedding dimension  $D$  while fixing the other parameters. Table 5 summarizes the Recall@20 for NPE on the three datasets for various embedding sizes:  $D = \\{8,16,32,64,128,256\\}$ . We can see that the larger embedding sizes seem to improve the performance of the models. The optimal embedding size for OnlineRetail is  $D = 64$  and, for ML-10m and TasteProfile is  $n = 128$ .\n\nImpact of the negative sampling ratio: During the training of NPE, we sampled negative examples. We studied the effect of the negative sampling ratio  $n$  on the performance of NPE by fixing the embedding size  $D = 32$  and evaluating Recall@20 for  $n = \\{1,2,4,5,8,12,16,20\\}$ . From Table 6, we note that when  $n$  increases, the performance also increases up to a certain value of  $n$ . The optimal negative sampling ratios are  $n = \\{4,5\\}$  for OnlineRetail and  $n = 8$  for ML-10m and TasteProfile. This is reasonable because ML-10m and TasteProfile, being larger than OnlineRetail, will need more negative examples.",
  "hyperparameter": "Embedding dimension D: optimal values are D=128 for ML-10m and TasteProfile, D=64 for OnlineRetail (tested range: 8, 16, 32, 64, 128, 256). Negative sampling ratio n: optimal values are n=8 for ML-10m and TasteProfile, n=4 or n=5 for OnlineRetail (tested range: 1, 2, 4, 5, 8, 12, 16, 20). Mini-batch size: 10,000. Optimization: Adam optimizer with early stopping (patience=5 epochs). Dropout is applied after hidden representation layer with dataset-specific rates. Weight initialization: normal distributions for matrices H, W, V. Regularization parameter λ is used in the loss function."
}