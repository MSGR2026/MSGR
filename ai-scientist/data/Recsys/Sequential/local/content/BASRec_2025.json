{
    "id": "BASRec_2025",
    "paper_title": "Popularity-based Recommendation Systems: A Baseline Approach",
    "alias": "BASRec",
    "year": 2025,
    "domain": "Recsys",
    "task": "SequentialRecommendation",
    "idea": "BASRec proposes a two-stage, model-agnostic data-augmentation plugin for sequential recommendation that balances relevance and diversity. It first augments each sequence with learnable reorder/substitute operators and adaptive mixup weights, then performs nonlinear item- and feature-wise mixup across users’ hidden representations to inject collaborative signals without extra parameters.",
    "introduction": "# Introduction\n\nAs an essential branch of recommender systems, sequential recommendation (SR) has received much attention due to its well-consistency with real-world recommendation situations. However, the widespread problem of data sparsity limits the SR model's performance (Jing et al. 2023). For this reason, researchers have proposed many data augmentation methods to mitigate this phenomenon (Dang et al. 2023b, 2024a). Earlier work used heuristic methods to directly augment sequences and mix them to the training process, such as Sliding Windows (Tang and Wang 2018) and Dropout\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/b9cd75e5-a8b1-43ad-9af5-397fb072fb8d/1ea9ae1ba2b82a12601e532216a3cd144ba4454fe7aac23c2d1c385a0aecfa55.jpg)\n\n\n\nFigure 1: An illustration of imbalanced relevance and diversity issues in sequential data augmentation.\n\n\n(Tan, Xu, and Liu 2016). Later, some researchers generated high-quality augmented data by counterfactual thinking (Wang et al. 2021), diffusion models (Liu et al. 2023) or bi-directional transformer (Jiang et al. 2021). With the success of self-supervised learning (Chen et al. 2020), many sequence-level augmentation operators have been proposed for contrastive learning (Liu et al. 2021; Xie et al. 2022).\n\nDespite the effectiveness, the imbalance between relevance and diversity for augmented data remains to be solved (Bian et al. 2022). 'Relevance' means that the augmented data should have transition patterns similar to the original data to avoid semantics drift problems. 'Diversity' means that the augmented data should contain sufficient variations to enable the model to explore more user preferences knowledge and improve its performance. However, these two factors are often conflicting and challenging to trade off. For example, as shown in Figure 1, heuristic augmentation and operators proposed in recent years perform cropping, masking, substitution, or shuffle to the original sequence. The new sequences may deviate from the original data, resulting in weak correlations. Model- and representation-level augmentation methods, while improving the correlation of the generated data through well-designed generation modules, fail to produce sufficient diversity. These conservative augmented data make it challenging to improve the model performance further. Intuitively, we can obtain suitable samples by directly merging the two augmented sequences in Figure 1. However, directly merging them will corrupt the original sequence patterns, and irrelevant or repeated items will be retained, resulting in inaccurate representation learning. In addition, existing methods focus on single-sequence\n\naugmentation and lack consideration for the cross-sequence preference patterns and semantic information.\n\nIn this paper, inspired by previous work based on mixup (Zhang et al. 2018; Bian et al. 2022), we propose BASRec, Balanced data Augmentation plugin for Sequential Recommendation. Our core idea is to generate new samples that balance relevance and diversity through representation-level fusion. The BASRec consists of two modules: Single-sequence Augmentation and Cross-sequence Augmentation. For Single-sequence Augmentation, we propose two new mixup-based data augmentation operators, M-Substitute and M-Reorder. On top of the traditional operator, we improve the diversity by sampling the operation weights from a uniform distribution, while the correlation is obtained by fusing the original and the augmented sequence representation. Further, we adaptively reweight the training loss with the operators' augmentation weights and mixup weights, allowing the model to learn based on the difference between the augmented and the original samples. So far, all augmentations are limited to a single sequence. For Cross-sequence Augmentation, we propose to explore the semantics of sequence and preferences knowledge among different users. The traditional mixup operation can only generate samples in the linear dimension for a pair of samples (Guo 2020). In order to further improve the space of synthetic samples and enable the model to discover the fine-grained knowledge among different users, we adopt a nonlinear mixup approach for fusion. However, assigning a weight to each parameter introduces a significant computational overhead. We decompose this process and further present the Item-wise and Feature-wise mixup. Our method generates new training samples in the representation space that relate to the original data but contain diverse transition patterns, balancing the two properties. Finally, we employ a two-stage learning strategy to avoid the noise and convergence instability introduced by the hybrid representation at the beginning of training.\n\nExtensive experiments on four real-world datasets with four base SR models demonstrate that our proposed BASRec achieves significant improvements. We compare BASRec with heuristic and training-required data augmentation methods to further validate its superiority. Besides, We experimentally demonstrate that the data generated by BASRec strikes a better balance between the two properties. The main contributions can be summarized follows:\n\n- We emphasize the unbalanced relevance and diversity of current data augmentation methods and propose a Balanced Data Augmentation Plugin for Sequential Recommendation, which can be seamlessly integrated into most existing sequential recommendation models.\n\n- We design two key modules, Single-sequence Augmentation and Cross-sequence Augmentation. They perform augmentation and fusion operations to synthesize new samples that balance relevance and diversity.\n\n- We conduct comprehensive experiments on real-world datasets to demonstrate the effectiveness of BASRec, showing significant improvements over various sequential models. Our approach also achieves competitive performance compared to the data augmentation baselines.",
    "method": "# Preliminaries\n\n# Problem Formulation\n\nSuppose we have user and item sets denoted by  $\\mathcal{U}$  and  $\\nu$ , respectively. Each user  $u \\in \\mathcal{U}$  is associated with a sequence of interacted items in chronological order  $s_u = [v_1, v_2, \\dots, v_{|s_u|}]$ , where  $v_j \\in \\mathcal{V}$  indicate the item that user  $u$  has interacted with at time step  $j$ . The  $|s_u|$  is the sequence length. Given the sequences of interacted items  $s_u$ , SR aims to accurately predict the possible item  $v^*$  that user  $u$  will interact with at time step  $|s_u| + 1$ , formulated as follows:\n\n$$\n\\underset {v ^ {*} \\in \\mathcal {V}} {\\arg \\max } P \\left(v _ {| s _ {u} | + 1} = v ^ {*} \\mid s _ {u}\\right). \\tag {1}\n$$\n\nThe model will calculate the probability of all candidate items and select the highest one for recommendation.\n\n# Mixup for Data Augmentation\n\nMixup (Zhang et al. 2018; Zhang, Yu, and Zhang 2020) is a simple yet effective data augmentation method. It implements linear interpolation in the input space to construct virtual training data. Given two input samples  $x_{i}, x_{j}$  along with the labels  $y_{i}, y_{j}$ , the mixup process can be formulated as:\n\n$$\n\\tilde {x} = \\lambda \\cdot x _ {i} + (1 - \\lambda) \\cdot x _ {j}, \\tag {2}\n$$\n\n$$\n\\tilde {y} = \\lambda \\cdot y _ {i} + (1 - \\lambda) \\cdot y _ {j}. \\tag {3}\n$$\n\nwhere  $\\lambda \\sim \\mathrm{Beta}(\\alpha, \\alpha)$  is the mixup coefficient from beta distribution. Some work in the recommendation field has explored the use of mixup to synthesize hard negative samples for training graph neural networks better (Huang et al. 2021) or to improve the representation of tail sessions (Yang et al. 2023a). However, these efforts failed to balance relevance and diversity when performing augmentation. They may generate harmful or overly conservative augmented data. Also, they are limited by the type of backbone network and have lower generalization capability (Bian et al. 2022).\n\n# Ours: BASRec\n\nIn this section, we present our proposed BASRec. The overall framework is illustrated in Figure 2. Our approach consists of two separate modules: Single-sequence Augmentation and Cross-sequence Augmentation. After that, we introduce the training and inference process of BASRec. Finally, we provide a discussion about our and existing methods.\n\n# Single-sequence Augmentation\n\nSingle-sequence Augmentation generates new samples by mixing the representations of items in the original sequence with those in the augmented sequence. Specifically, we propose two new operators, M-Reorder and M-Substitute, to accomplish this augmentation operation.\n\nThe standard SR paradigm (Kang and McAuley 2018; Bian et al. 2022) maintains an item embedding matrix  $\\mathbf{M}_{\\mathcal{V}} \\in \\mathbb{R}^{|\\mathcal{V}| \\times D}$ . The matrix project the high-dimensional one-hot representation of an item to low-dimensional dense representations. Given an original user sequence  $s_u = [v_1, v_2, \\dots, v_{|s_u|}]$ , the Look-up operation will be applied for  $\\mathbf{M}_{\\mathcal{V}}$  to get a sequence of item representation, i.e.,  $E_u =$\n\n$[m_{v_1}, m_{v_2}, \\ldots, m_{v_{|s_{u^i}}}]$ . Note that we omit the padding for short sequences and intercepting for long sequences.\n\nM-Reorder. Given an original sequence  $s_u$ , M-Reorder first selects a sub-sequence with length  $c = \\text{rate} \\cdot |s_u|$ . Unlike traditional operators that preform augmentation with a fixed rate, we further extend the augmentation possibilities by drawing rate from a uniform distribution:\n\n$$\n\\operatorname {r a t e} \\sim \\operatorname {U n i f o r m} (a, b), \\tag {4}\n$$\n\nwhere  $a$  and  $b$  are hyper-parameters and  $0 < a < b < 1$ . Then, we randomly shuffle this sub-sequence  $[v_i,\\dots ,v_{i + c - 1}]$  as  $\\left[v_i^{\\prime},\\ldots ,v_{i + c - 1}^{\\prime}\\right]$  and get the augmented item sequence  $s_u^\\prime$ :\n\n$$\ns _ {u} ^ {\\prime} = \\operatorname {R e o r d e r} \\left(s _ {u}\\right) = \\left[ v _ {1}, v _ {2}, \\dots , v _ {i} ^ {\\prime}, \\dots , v _ {i + r - 1} ^ {\\prime}, \\dots , v _ {n} \\right] \\tag {5}\n$$\n\nUnlike traditional operators that directly use  $s_u'$  as a new sample to participate in model training, we mix up the sequence of item representation corresponding to  $s_u$  and  $s_u'$  to generate new training samples in the representation space:\n\n$$\nE _ {u} ^ {\\prime} = \\text {L o o k - u p} \\left(\\mathbf {M} _ {\\mathcal {V}}, s _ {u} ^ {\\prime}\\right), \\tag {6}\n$$\n\n$$\nE _ {u} ^ {I n} = \\lambda \\cdot E _ {u} + (1 - \\lambda) \\cdot E _ {u} ^ {\\prime}, \\tag {7}\n$$\n\nwhere  $\\lambda \\sim \\mathrm{Beta}(\\alpha, \\alpha)$  is the mixup weight and  $E_u^{In}$  is augment representation used for model training.\n\nM-Substitute. This operator is similar to M-Reorder. Given an original sequence  $s_u$ , it first randomly selects  $c = rate \\cdot |s_u|$  different indices  $\\{\\mathrm{idx}_1, \\mathrm{idx}_2, \\dots, \\mathrm{idxc}\\}$ , where  $rate$  is sampled following Eq. 4. Then, we replace each with a correlated item based on the selected indices. We adopt the cosine similarity method as (Liu et al. 2021) to select the items to substitute. The above process can be formulated as:\n\n$$\ns _ {u} ^ {\\prime} = \\text {S u b s t i t u t e} \\left(s _ {u}\\right) = \\left[ v _ {1}, v _ {2}, \\dots , \\bar {v} _ {\\mathrm {i d x} _ {i}}, \\dots , v _ {| s _ {u} |} \\right]. \\tag {8}\n$$\n\nFollowing the same steps as in M-Reorder, through Eq. 6 and Eq. 7, we can obtain the augmented representation  $E_{u}^{In}$ .\n\nAdaptive Loss Weighting. The augmentation of the original representation by the two operators comes from two main dimensions: 1) The change of the operator to the original interaction sequence, i.e., the rate of operators. 2) The mixing of the new sequence representation with the original one, i.e., the  $\\lambda$  of mixup. To further measure this augmentation process so that the model can adaptively learn the preferences based on the relevance and diversity of the augmentation, we propose an adaptive loss weighting strategy. Inspired by previous work (Yang et al. 2023b), based on the rate from two operators and mixup coefficient  $\\lambda$  from  $\\mathrm{Beta}(\\alpha, \\alpha)$ , we define the transformation as follows:\n\n$$\n\\omega^ {(1)} = 1 / (r a t e \\cdot \\lambda); \\omega^ {(2)} = \\frac {\\omega^ {(1)} - \\omega_ {\\operatorname* {m i n}} ^ {(1)}}{\\omega_ {\\operatorname* {m a x}} ^ {(1)} - \\omega_ {\\operatorname* {m i n}} ^ {(1)}}. \\tag {9}\n$$\n\nWe adopt  $\\omega = \\omega^{(2)}$  as the output. For each augmented representation  $E_{u}^{f}$ , we assign it with an exclusive weight. This weighting process also guides the model in distinguishing how much of the original representation has been injected with the new representation, further improving the robustness of the model. This weight will be used in model training, and we will introduce it in the Model Training section.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/b9cd75e5-a8b1-43ad-9af5-397fb072fb8d/186920c37e6c2c45ff6d0a79a58bfdfe821660d7e43fe014de7fa46435efbff5.jpg)\n\n\n\nFigure 2: The overview of the proposed Balanced data Augmentation method.\n\n\n# Cross-sequence Augmentation\n\nIn Single-sequence Augmentation, the newly generated samples are limited to only independent single users. In recommender systems, each user is likely to have overlapping behaviors and preferences with other users, i.e., collaboration information (Luo, Liu, and Pan 2024; Cheng et al. 2024). Therefore, for Cross-sequence Augmentation, we generate new samples by mixing the different sequence output to discover the preference knowledge among different users further. By feeding the sequence representation  $E_{u}$  and  $E_{u}^{In}$  into the Encoder, we can obtain the output representation of the sequence  $H_{u}$  and  $H_{u}^{In}$ . In sequential recommendation, user representations are usually modeled implicitly, so  $H_{u}$  and  $H_{u}^{In}$  can also be interpreted as user representations. Note that the two modules we proposed are independent augmentation lines. The representation of a sequence that has been augmented by Single-sequence Augmentation will not be fed into Cross-sequence Augmentation.\n\nThe base mixup can only create samples in linear space. Inspired by the nonlinear mixup (Guo 2020), we attempt to assign different weights to every parameter in  $H_{u}$ . However, this mixup strategy incurs significant computational overhead. Thus, we further decompose this process into Item-wise mixup and Feature-wise mixup. Given a batch of sequences  $\\{s_u\\}_{u = 1}^B$ , we can obtain the corresponding batch of representations  $\\{H_{u}\\}_{u = 1}^{B}\\in R^{B\\times N\\times D}$ , where  $B,N$  and  $D$  are the batch size, maximum sequence length, and embedding dimensions, respectively. We start by shuffling  $\\{H_{u}\\}_{u = 1}^{B}$  from the batch perspective:\n\n$$\n\\left\\{H _ {u} ^ {\\prime} \\right\\} _ {u = 1} ^ {B} = \\text {S h u f f l e} \\left\\{H _ {u} \\right\\} _ {u = 1} ^ {B}. \\tag {10}\n$$\n\nFor Item-wise Nonlinear Mixup, we sample a mixup weights matrix  $\\Lambda_I \\in R^{B \\times N}$  from the  $\\mathrm{Beta}(\\alpha, \\alpha)$ , where  $N$  is the predefined maximum sequence length. The mixup is performed as follows:\n\n$$\n\\left\\{H _ {u} ^ {O u t} \\right\\} _ {u = 1} ^ {B} = \\Lambda_ {I} \\circ \\left\\{H _ {u} \\right\\} _ {u = 1} ^ {B} + (1 - \\Lambda_ {I}) \\circ \\left\\{H _ {u} ^ {\\prime} \\right\\} _ {u = 1} ^ {B}, \\tag {11}\n$$\n\nwhere  $\\circ$  denotes the Hadamard product. For Feature-wise Nonlinear Mixup, we sample a mixup weights matrix  $\\Lambda_F \\in R^{B \\times D}$  from the  $\\mathrm{Beta}(\\alpha, \\alpha)$  and perform similar operation:\n\n$$\n\\left\\{H _ {u} ^ {O u t} \\right\\} _ {u = 1} ^ {B} = \\Lambda_ {F} \\circ \\left\\{H _ {u} \\right\\} _ {u = 1} ^ {B} + (1 - \\Lambda_ {F}) \\circ \\left\\{H _ {u} ^ {\\prime} \\right\\} _ {u = 1} ^ {B}. \\tag {12}\n$$\n\nThe Cross-sequence Augmentation will simultaneously perform the same mixup process for the representations of positive and negative items. The final output is used to calculate the recommendation loss. The above two processes can be executed multiple times, and each mixing produces new virtual representations in the representation space.\n\n# Model Training\n\nFollowing previous works (Kang and McAuley 2018; Dang et al. 2023a), we adopt the commonly used binary cross-entropy (BCE) loss for the sequential recommendation task:\n\n$$\n\\begin{array}{l} \\mathcal {L} _ {m a i n} = \\operatorname {B C E} \\left(H _ {u}, E _ {u} ^ {+}, E _ {u} ^ {-}\\right) \\\\ = - \\left[ \\log \\left(\\sigma \\left(H _ {u} \\cdot E _ {u} ^ {+}\\right)\\right) + \\log \\left(1 - \\sigma \\left(H _ {u} \\cdot E _ {u} ^ {-}\\right)\\right) \\right], \\tag {13} \\\\ \\end{array}\n$$\n\nwhere  $H_{u}, E_{u}^{+}$  and  $E_{u}^{-}$  denote the representations of the user, the positive and negative items, respectively.  $\\sigma(\\cdot)$  is the sigmoid function. The representations involved in the  $\\mathcal{L}_{\\text{main}}$  will not be augmented. For each sequence, we apply two operators for augmentation, respectively. The loss is calculated based on  $H_{u}^{In}$ , original positive and negative item representations. Further, we use the pre-computed weights  $\\omega$  to reweight this objective function:\n\n$$\n\\mathcal {L} _ {s s a} = \\omega \\cdot \\operatorname {B C E} \\left(H _ {u} ^ {I n}, E _ {u} ^ {+}, E _ {u} ^ {-}\\right). \\tag {14}\n$$\n\nFor Cross-sequence Augmentation, we use all mixed representations to calculate the recommendation loss:\n\n$$\n\\mathcal {L} _ {c s a} = \\operatorname {B C E} \\left(H _ {u} ^ {O u t}, E _ {u} ^ {O u t +}, E _ {u} ^ {O u t -}\\right). \\tag {15}\n$$\n\nMixing representations at the beginning of training with Randomly initialized embedding may introduce noise and convergence problems. To tackle this, we adopt a two-stage training strategy. In the first stage, we follow the standard\n\nsequential recommendation model training process, with the primary objective of facilitating the learning of high-quality representations for items. We only use Eq. 13 as the objective function at this stage. In the second stage, we employ the two augmentation modules as described previously:\n\n$$\n\\mathcal {L} = \\mathcal {L} _ {\\text {m a i n}} + \\mathcal {L} _ {s s a} + \\mathcal {L} _ {c s a}. \\tag {16}\n$$\n\nWe do not set additional loss weights for  $\\mathcal{L}_{ssa}$  and  $\\mathcal{L}_{csa}$  for the following reasons: 1) The  $\\mathcal{L}_{ssa}$  has been reweighted in the previous sections. 2) For the two proposed modules, we treat the data augmented by them equally to the original data during the training process. Each augmented data can be considered as a new user and interaction generated in the representation space. During the inference phase, all augmentation modules are deactivated.\n\n# Discussion and Analysis\n\nComparison with Existing Methods. For Single-sequence Augmentation, sampling rate from a uniform distribution improves the diversity of the augmented sequence. The fusion with the original sequence representation and the loss reweighting process enables the model to learn based on the correlation of the augmented samples with the original samples. For Cross-sequence Augmentation, our cross-user nonlinear mixup strategy endows the learning process with diverse but relevant preference knowledge and collaborative signals among different users. Traditional operators (Liu et al. 2021; Xie et al. 2022) that directly edit the original sequence with a fixed rate may lead to problems of conservative data augmentation or semantics drift. Editing the original sequence may also remove critical interactions (Dang et al. 2023b). Some work craft trainable data generators to augment the data (Wang et al. 2021; Liu et al. 2023; Wang et al. 2022). However, these methods can only produce discrete user interactions while introducing additional learnable parameters. Our method can generate more samples at the sequence level or across sequences in the representation space without additional model parameters. Besides, some approaches are also limited by the type of backbone network (Jiang et al. 2021; Bian et al. 2022), whereas BASRec is a model-agnostic augmentation plugin.\n\nComplexity Analysis. We choose SASRec as the backbone model for explanation. Other choices can be analyzed similarly. Since Our BASRec does not introduce any auxiliary learnable parameters, the model size of BASRec is identical to SASRec. The time complexity of SASRec is mainly due to the self-attention module, which is  $O\\left(N^{2}D|\\mathcal{U}|\\right)$  (Xie et al. 2022). The time complexity for calculating loss is  $\\mathcal{O}\\left(ND|\\mathcal{U}|\\right)$ . Considering our method, for two operators in BASRec, the complexity of operation is  $O((a + b)N|\\mathcal{U}| / 2)$ . Suppose we need to perform a total of  $Q$  mixup operations for each sequence, so the time complexity is  $O(QD|\\mathcal{U}|)$  since the mixing process is performed through Hadamard product. The total time complexity of SASRec and BASRec are  $\\mathcal{O}\\left((N^2 +N)D|\\mathcal{U}|\\right)$  and  $\\mathcal{O}\\left((N^2 +N + Q)D|\\mathcal{U}|\\right)^1$ , respectively. Their analyti\n\n<table><tr><td>Dataset</td><td>Beauty</td><td>Sports</td><td>Yelp</td><td>Home</td></tr><tr><td># Users</td><td>22,363</td><td>35,958</td><td>30,431</td><td>66,519</td></tr><tr><td># Items</td><td>12,101</td><td>18,357</td><td>20,033</td><td>28,237</td></tr><tr><td># Inter</td><td>198,502</td><td>296,337</td><td>316,354</td><td>551,682</td></tr><tr><td># AvgLen</td><td>8.9</td><td>8.3</td><td>10.4</td><td>8.3</td></tr><tr><td>Sparsity</td><td>99.92%</td><td>99.95%</td><td>99.95%</td><td>99.97%</td></tr></table>\n\nTable 1: The statistics of four datasets. The 'Inter' and 'AvgLen' denote the number of interactions and average length.\n\ncal complexity is the same in magnitude. Our BASRec can generate data with acceptable additional time costs.",
    "experiments": "# Experiments\n\n# Experimental Settings\n\nDatasets. We adopt four widely-used public datasets: Beauty, Sports, and Home are obtained from Amazon (McAuley, Pandey, and Leskovec 2015) with user reviews of products.  $\\text{Yelp}^2$  is a business dataset. We use the transaction records after January 1st, 2019. Users/items with fewer than five interactions are filtered out (Liu et al. 2021). The detailed statistics are summarized in Table 1.\n\nBaselines. The baselines consist of three categories. The first category is general models to validate the effectiveness of BASRec, including GRU4Rec (Hidasi et al. 2015), NextItNet (Yuan et al. 2019), SASRec (Kang and McAuley 2018) and FMLPRec (Zhou et al. 2022). These models employ diverse architectures, including RNN, CNN, Transformer, and MLP. The second category is heuristic augmentation methods: Random (Ran) and Random-seq (RansS) (Liu et al. 2023), Slide Windows (SW) (Tang and Wang 2018), CMR (Xie et al. 2022) and CMRSI (Liu et al. 2021). The third category is training-required augmentation models: ASReP (Jiang et al. 2021), DiffuASR (Liu et al. 2023), and CL4SRec (Xie et al. 2022). Details about baselines are provided in the Appendix. We do not include methods ReDA (Bian et al. 2022), CASR (Wang et al. 2021), and L2Aug (Wang et al. 2022) since they do not provide open-source codes for reliable reproduction (empty code repository or no available code repository links).\n\nImplementation Details. For all baselines, we adopt the implementation provided by the authors. We set the embedding size to 64 and the batch size to 256. The maximum sequence length is set to 50. To ensure fair comparisons, we carefully set and tune all other hyper-parameters of each method as reported and suggested in the original papers. We use the Adam (Kingma and Ba 2014) optimizer with the learning rate  $0.001$ ,  $\\beta_{1} = 0.9$ ,  $\\beta_{2} = 0.999$ . For BASRec, we tune the  $\\alpha$ ,  $a$ ,  $b$  in the range of  $\\{0.2, 0.3, 0.4, 0.5, 0.6\\}$ ,  $\\{0.1, 0.2, 0.3\\}$ ,  $\\{0.6, 0.7, 0.8\\}$ , respectively. We conduct five runs and report the average results for all methods. Generally, greater values imply better ranking accuracy.\n\n<table><tr><td rowspan=\"2\">Method</td><td colspan=\"4\">Beauty</td><td colspan=\"4\">Sports</td><td colspan=\"4\">Yelp</td><td colspan=\"4\">Home</td></tr><tr><td>N@10</td><td>H@10</td><td>N@20</td><td>H@20</td><td>N@10</td><td>H@10</td><td>N@20</td><td>H@20</td><td>N@10</td><td>H@10</td><td>N@20</td><td>H@20</td><td>N@10</td><td>H@10</td><td>N@20</td><td>H@20</td></tr><tr><td>GRU4Rec</td><td>0.0208</td><td>0.0412</td><td>0.0273</td><td>0.0670</td><td>0.0069</td><td>0.0146</td><td>0.0101</td><td>0.0274</td><td>0.0084</td><td>0.0174</td><td>0.0121</td><td>0.0325</td><td>0.0032</td><td>0.0066</td><td>0.0046</td><td>0.0123</td></tr><tr><td>w\\ Ours</td><td>0.0286</td><td>0.0546</td><td>0.0360</td><td>0.0842</td><td>0.0164</td><td>0.0307</td><td>0.0208</td><td>0.0483</td><td>0.0140</td><td>0.0289</td><td>0.0194</td><td>0.0502</td><td>0.0063</td><td>0.0128</td><td>0.0084</td><td>0.0214</td></tr><tr><td>Improve</td><td>37.50%</td><td>32.52%</td><td>31.87%</td><td>25.67%</td><td>137.68%</td><td>110.27%</td><td>105.94%</td><td>76.28%</td><td>66.67%</td><td>66.09%</td><td>60.33%</td><td>54.46%</td><td>96.88%</td><td>93.94%</td><td>82.61%</td><td>73.98%</td></tr><tr><td>NextItNet</td><td>0.0163</td><td>0.0326</td><td>0.0210</td><td>0.0511</td><td>0.0077</td><td>0.0154</td><td>0.0106</td><td>0.0272</td><td>0.0109</td><td>0.0222</td><td>0.0155</td><td>0.0406</td><td>0.0033</td><td>0.0070</td><td>0.0046</td><td>0.0125</td></tr><tr><td>w\\ Ours</td><td>0.0202</td><td>0.0365</td><td>0.0253</td><td>0.0589</td><td>0.0091</td><td>0.0193</td><td>0.0128</td><td>0.0320</td><td>0.0134</td><td>0.0282</td><td>0.0183</td><td>0.0465</td><td>0.0040</td><td>0.0087</td><td>0.0063</td><td>0.0162</td></tr><tr><td>Improve</td><td>23.93%</td><td>11.96%</td><td>20.48%</td><td>15.26%</td><td>18.18%</td><td>25.32%</td><td>20.75%</td><td>17.65%</td><td>22.94%</td><td>27.03%</td><td>18.06%</td><td>14.53%</td><td>21.21%</td><td>24.29%</td><td>36.96%</td><td>29.60%</td></tr><tr><td>SASRec</td><td>0.0338</td><td>0.0639</td><td>0.0413</td><td>0.0935</td><td>0.0174</td><td>0.0320</td><td>0.0214</td><td>0.0482</td><td>0.0136</td><td>0.0277</td><td>0.0180</td><td>0.0453</td><td>0.0078</td><td>0.0149</td><td>0.0100</td><td>0.0239</td></tr><tr><td>w\\ Ours</td><td>0.0455</td><td>0.0810</td><td>0.0539</td><td>0.1145</td><td>0.0242</td><td>0.0436</td><td>0.0294</td><td>0.0641</td><td>0.0164</td><td>0.0326</td><td>0.0216</td><td>0.0537</td><td>0.0128</td><td>0.0223</td><td>0.0154</td><td>0.0327</td></tr><tr><td>Improve</td><td>34.62%</td><td>26.76%</td><td>30.51%</td><td>22.46%</td><td>39.08%</td><td>36.25%</td><td>37.38%</td><td>32.99%</td><td>20.59%</td><td>17.69%</td><td>20.00%</td><td>18.54%</td><td>64.10%</td><td>49.66%</td><td>54.00%</td><td>36.82%</td></tr><tr><td>FMLP-Rec</td><td>0.0298</td><td>0.0563</td><td>0.0361</td><td>0.0814</td><td>0.0131</td><td>0.0255</td><td>0.0163</td><td>0.0383</td><td>0.0093</td><td>0.0195</td><td>0.0134</td><td>0.0357</td><td>0.0071</td><td>0.0134</td><td>0.0091</td><td>0.0215</td></tr><tr><td>w\\ Ours</td><td>0.0441</td><td>0.0767</td><td>0.0519</td><td>0.1076</td><td>0.0240</td><td>0.0432</td><td>0.0286</td><td>0.0615</td><td>0.0180</td><td>0.0347</td><td>0.0233</td><td>0.0559</td><td>0.0147</td><td>0.0245</td><td>0.0174</td><td>0.0353</td></tr><tr><td>Improve</td><td>47.99%</td><td>36.23%</td><td>43.77%</td><td>32.19%</td><td>83.21%</td><td>69.41%</td><td>75.46%</td><td>60.57%</td><td>93.55%</td><td>77.95%</td><td>73.88%</td><td>56.58%</td><td>107.04%</td><td>82.84%</td><td>91.21%</td><td>64.19%</td></tr></table>\n\n\nTable 2: Performance comparison of four backbone models and BASRec on four datasets. The 'w/ Ours' represents adding our BASRec. All improvements are statistically significant, as determined by a paired t-test with  $p \\leq 0.05$ .\n\n\n<table><tr><td>BackBone</td><td colspan=\"8\">GRU4Rec</td><td colspan=\"8\">SASRec</td></tr><tr><td rowspan=\"2\">Method</td><td colspan=\"2\">Beauty</td><td colspan=\"2\">Sports</td><td colspan=\"2\">Yelp</td><td colspan=\"2\">Home</td><td colspan=\"2\">Beauty</td><td colspan=\"2\">Sports</td><td colspan=\"2\">Yelp</td><td colspan=\"2\">Home</td></tr><tr><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td></tr><tr><td>Base</td><td>0.0208</td><td>0.0412</td><td>0.0069</td><td>0.0146</td><td>0.0084</td><td>0.0174</td><td>0.0032</td><td>0.0066</td><td>0.0338</td><td>0.0639</td><td>0.0174</td><td>0.0320</td><td>0.0136</td><td>0.0277</td><td>0.0078</td><td>0.0149</td></tr><tr><td>Ran</td><td>0.0212</td><td>0.0471</td><td>0.0083</td><td>0.0171</td><td>0.0087</td><td>0.0189</td><td>0.0036</td><td>0.0075</td><td>0.0285</td><td>0.0553</td><td>0.0186</td><td>0.0341</td><td>0.0162</td><td>0.0316</td><td>0.0086</td><td>0.0156</td></tr><tr><td>SW</td><td>0.0192</td><td>0.0501</td><td>0.0082</td><td>0.0159</td><td>0.0090</td><td>0.0195</td><td>0.0040</td><td>0.0083</td><td>0.0270</td><td>0.0542</td><td>0.0198</td><td>0.0366</td><td>0.0137</td><td>0.0279</td><td>0.0089</td><td>0.0166</td></tr><tr><td>Ran-S</td><td>0.0231</td><td>0.0520</td><td>0.0103</td><td>0.0207</td><td>0.0096</td><td>0.0210</td><td>0.0049</td><td>0.0099</td><td>0.0289</td><td>0.0563</td><td>0.0167</td><td>0.0300</td><td>0.0184</td><td>0.0364</td><td>0.0109</td><td>0.0208</td></tr><tr><td>CMR</td><td>0.0225</td><td>0.0572</td><td>0.0095</td><td>0.0192</td><td>0.0105</td><td>0.0209</td><td>0.0044</td><td>0.0094</td><td>0.0290</td><td>0.0562</td><td>0.0192</td><td>0.0374</td><td>0.0136</td><td>0.0278</td><td>0.0092</td><td>0.0167</td></tr><tr><td>CMRSI</td><td>0.0242</td><td>0.0555</td><td>0.0090</td><td>0.0183</td><td>0.0101</td><td>0.0214</td><td>0.0051</td><td>0.0104</td><td>0.0316</td><td>0.0603</td><td>0.0203</td><td>0.0395</td><td>0.0156</td><td>0.0310</td><td>0.0099</td><td>0.0173</td></tr><tr><td>BASRec</td><td>0.0286</td><td>0.0546</td><td>0.0164</td><td>0.0307</td><td>0.0140</td><td>0.0289</td><td>0.0063</td><td>0.0128</td><td>0.0455</td><td>0.0810</td><td>0.0242</td><td>0.0436</td><td>0.0164</td><td>0.0326</td><td>0.0128</td><td>0.0223</td></tr></table>\n\n\nTable 3: Performance comparison of heuristic augmentation methods and BASRec on four datasets. All improvements are statistically significant, as determined by a paired t-test with the second best result in each case  $(p\\leq 0.05)$ .\n\n\nEvaluation Settings. We adopt the leave-one-out strategy to partition each user's item sequence into training, validation, and test sets. We rank the prediction over the whole item set rather than negative sampling, otherwise leading to biased discoveries (Krichene and Rendle 2020). The evaluation metrics include Hit Ratio@K (denoted by H@K), and Normalized Discounted Cumulative Gain@K (N@K). We report results with K ∈ {10, 20}.\n\n# Main Results with Various Backbone Models\n\nThe experimental results of the original SR models and adding our BASRec are presented in Table 2. We can observe that BASRec can significantly improve the performance of various types of SR models. Average performance gains on GRU4Rec, NextItNet, SASRec, and FMLPRec were  $72.04\\%$ ,  $21.76\\%$ ,  $33.84\\%$ , and  $68.50\\%$ , respectively. This result shows that the samples synthesized by our method can enhance the model's ability to learn user preferences further. Our approach achieves a win-win situation for both relevance and diversity, significantly improving the performance while ensuring plug-and-play generalization. Besides, the performance of the original model shows that SASRec outperforms the other models overall, demonstrating the power of the transformer in sequence modeling. With BASRec, the SASRec and FMLP-Rec are on par with each other. We believe that different models may have different underutilized performance potential. Our approach further exploits this potential through multiple mixup strategies.\n\n<table><tr><td rowspan=\"2\">Method</td><td colspan=\"2\">Beauty</td><td colspan=\"2\">Sports</td><td colspan=\"2\">Yelp</td><td colspan=\"2\">Home</td></tr><tr><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td></tr><tr><td>Base</td><td>0.0338</td><td>0.0639</td><td>0.0174</td><td>0.0320</td><td>0.0136</td><td>0.0277</td><td>0.0078</td><td>0.0149</td></tr><tr><td>ASReP</td><td>0.0351</td><td>0.0664</td><td>0.0195</td><td>0.0353</td><td>0.0162</td><td>0.0319</td><td>0.0099</td><td>0.0184</td></tr><tr><td>DiffuASR</td><td>0.0372</td><td>0.0679</td><td>0.0202</td><td>0.0387</td><td>0.0150</td><td>0.0308</td><td>0.0105</td><td>0.0179</td></tr><tr><td>CL4SRec</td><td>0.0366</td><td>0.0686</td><td>0.0221</td><td>0.0412</td><td>0.0176</td><td>0.0355</td><td>0.0119</td><td>0.0212</td></tr><tr><td>BASRec</td><td>0.0455</td><td>0.0810</td><td>0.0242</td><td>0.0436</td><td>0.0164</td><td>0.0326</td><td>0.0128</td><td>0.0223</td></tr></table>\n\nTable 4: Performance comparison of training-required methods and BASRec. The backbone network is SASRec.\n\n# Comparison with Data Augmentation Methods\n\nWe compare BASRec with different augmentation methods. For heuristic methods, we choose two representative models, SASRec and GRU4Rec, as the backbone network. For methods that require training, we chose the SASRec since it is available as a backbone network for all baselines.\n\nHeuristic Methods. Table 3 shows that BASRec outperforms existing heuristic augmentation methods in most cases. Our method generates new training samples by mixing representations in the representation space, which can better preserve the original sequence semantics and discover more cross-user preferences than existing methods. Among the baseline methods, CMRSI and Ran-S usually perform better. This suggests that well-designed data augmentation operators or augmentation using interactions in the original sequence are effective. In some cases, existing methods lead to model performance degradation. We believe this may be\n\n<table><tr><td rowspan=\"2\">Method</td><td colspan=\"2\">Beauty</td><td colspan=\"2\">Sports</td><td colspan=\"2\">Yelp</td><td colspan=\"2\">Home</td></tr><tr><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td><td>N@10</td><td>H@10</td></tr><tr><td>Base</td><td>0.0338</td><td>0.0639</td><td>0.0174</td><td>0.0320</td><td>0.0136</td><td>0.0277</td><td>0.0078</td><td>0.0149</td></tr><tr><td>w/o SA</td><td>0.0415</td><td>0.0734</td><td>0.0209</td><td>0.0374</td><td>0.0152</td><td>0.0295</td><td>0.0097</td><td>0.0184</td></tr><tr><td>w/o ALW</td><td>0.0439</td><td>0.0778</td><td>0.0229</td><td>0.0415</td><td>0.0146</td><td>0.0297</td><td>0.0113</td><td>0.0201</td></tr><tr><td>w/o CA</td><td>0.0397</td><td>0.0721</td><td>0.0193</td><td>0.0353</td><td>0.0145</td><td>0.0290</td><td>0.0098</td><td>0.0170</td></tr><tr><td>w/o NL</td><td>0.0422</td><td>0.0752</td><td>0.0227</td><td>0.0412</td><td>0.0152</td><td>0.0300</td><td>0.0111</td><td>0.0197</td></tr><tr><td>w/o Two</td><td>0.0416</td><td>0.0742</td><td>0.0231</td><td>0.0411</td><td>0.0151</td><td>0.0304</td><td>0.0117</td><td>0.0207</td></tr><tr><td>BASRec</td><td>0.0455</td><td>0.0810</td><td>0.0242</td><td>0.0436</td><td>0.0164</td><td>0.0326</td><td>0.0128</td><td>0.0223</td></tr></table>\n\n\nTable 5: Performance of different variants of BASRec. The backbone network is SASRec.\n\n\nrelated to the fact that these methods introduce much noise into the augmented data, which interferes with model learning. In summary, it is essential to balance relevance and diversity in data augmentation, and favoring one side too much can lead to performance degradation.\n\nTraining-required Methods. Table 4 shows the performance of BASRec compared to the training-required baselines. These methods usually contain auxiliary tasks or data generation modules that require training. BASRec achieves the best or second-best results without increasing model parameters. CL4SRec usually performs best among the baseline methods, indicating that contrastive learning can effectively mine preference information from sparse data.\n\n# Ablation Study\n\nWe conduct an ablation study to explore the effectiveness of various components in our method. We compare our BAS-Rec with the following variants: 1) w/o SA: remove the Single Augmentation. 2) w/o ALW: remove the Adaptive Loss Weighting in Single Augmentation. 3) w/o Out: remove the Cross Augmentation. 4) w/o NL: remove the Nonlinear Mixup strategy in Cross Augmentation, i.e., perform general linear Mixup. 5) w/o Two: Use Eq. 16 to jointly train the model from scratch without a two-stage training strategy.\n\nThe results are shown in Table 5. The performances decrease significantly after removing either the Single Augmentation or the Cross Augmentation, suggesting that data augmented by both modules contributes to model training. When we replace Adaptive Loss Weighting with consistent weights, the model is unable to measure the difference between the enhanced data and the original data. Learning and distinguishing this difference can improve the model's performance and robustness. Nonlinear Mixup further extends the possibility of Cross Augmentation to generate augmented samples, and nonlinear combinations between different samples can help the model learn cross/preferences and fine-grained preferences. Besides, jointly training from scratch results in inferior performance compared to BAS-Rec in four datasets, highlighting the significance of the two-stage training procedure. When two-stage training is used, the model can learn accurate representations in the first stage, while the second stage produces high-quality augmented representations by mixing these representations. If Mixup is performed at the beginning of training, inaccurate representations may interfere with each other, which is detrimental to model learning and convergence.\n\n<table><tr><td>Method</td><td>Beauty</td><td>Sports</td><td>Yelp</td><td>Home</td><td>Average</td></tr><tr><td>CMRSI</td><td>0.5673</td><td>0.7273</td><td>0.6324</td><td>0.6884</td><td>0.6539</td></tr><tr><td>ASReP</td><td>0.9585</td><td>0.9476</td><td>0.9307</td><td>0.9752</td><td>0.9530</td></tr><tr><td>CLS4Rec</td><td>0.9612</td><td>0.9574</td><td>0.9580</td><td>0.9631</td><td>0.9599</td></tr><tr><td>BASRec-I</td><td>0.9083</td><td>0.8954</td><td>0.8626</td><td>0.9522</td><td>0.9046</td></tr><tr><td>BASRec-O</td><td>0.9239</td><td>0.9172</td><td>0.9003</td><td>0.9460</td><td>0.9219</td></tr><tr><td>BASRec</td><td>0.9152</td><td>0.9076</td><td>0.8790</td><td>0.9485</td><td>0.9126</td></tr></table>\n\nTable 6: Cosine similarity between the generated samples and the original samples. The backbone network is SASRec. The 'BASRec-I' and 'BASRec-O' represent only use Single-sequence augmentation and Cross-sequence augmentation, respectively.\n\n# Data Similarity Analysis\n\nWe calculated the cosine similarity between the samples generated by different data augmentation methods and the original samples. Since discrete interaction data cannot be computed directly, we compute the similarity of the final output representation of the model for all samples. We report the average similarity value throughout the training process and present the result in Table 6.\n\nThe table shows that the heuristic augmentation method CMRSI generates samples with relatively low similarity (i.e., lack of relevance), resulting in the loss of important preference knowledge and sequence semantics contained in the original samples. For training-required augmentation methods, ASReP employs a bi-directional Transformer to generating similar sequence data directly. The contrastive learning objective in CL4SRc draws close the distance between the original and generated samples. These methods result in high similarity between the augmented and original samples (i.e., lack of diversity). Our method generates samples with suitable similarity through a well-designed augmentation and fusion strategy. The new samples are diverse enough but retain the important semantics of the original data, balancing the relevance and diversity.",
    "hyperparameter": "embedding size = 64, batch size = 256, max sequence length = 50, learning rate = 0.001 (Adam: β1=0.9, β2=0.999), mixup Beta(α) with α∈{0.2,0.3,0.4,0.5,0.6}, reorder/substitute rate drawn from Uniform(a,b) with a∈{0.1,0.2,0.3}, b∈{0.6,0.7,0.8}, two-stage training (stage-1: warm-up, stage-2: augmentation)."
  }