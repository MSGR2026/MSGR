{
  "id": "S3Rec_2020",
  "paper_title": "S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization",
  "alias": "S3Rec",
  "year": 2020,
  "domain": "Recsys",
  "task": "SequentialRecommendation",
  "idea": "S3-Rec proposes a self-supervised learning framework for sequential recommendation that maximizes mutual information across multiple views (attributes, items, segments, sequences) of user interaction data. The approach employs four pre-training objectives: Associated Attribute Prediction (AAP), Masked Item Prediction (MIP), Masked Attribute Prediction (MAP), and Segment Prediction (SP) to capture multi-granularity correlations. Using a bidirectional Transformer architecture in pre-training and unidirectional architecture in fine-tuning, the model learns enhanced representations that significantly improve recommendation performance, especially under data sparsity conditions.",
  "introduction": "# 1 INTRODUCTION\n\nRecent years have witnessed the great success of many online platforms, such as Amazon and Taobao. Within online platforms, users' behaviors are dynamic and evolving over time. Thus it is critical to capture the dynamics of sequential user behaviors for making appropriate recommendations. In order to accurately characterize user interests and provide high-quality recommendations, the task of sequential recommendation has been widely studied in the literature [3, 8, 20, 21, 24].\n\nTypically, sequential recommendation methods [3, 8, 21, 24] capture useful sequential patterns from users' historical behaviors. Such motivation has been extensively explored with deep learning. Various methods using recurrent neural networks (RNNs) [3], convolutional neural networks (CNNs) [24], and self-attention mechanisms [8] have been proposed to learn good representations of user preference and characterize sequential user-item interactions.\n\nFurthermore, researchers have incorporated rich contextual information (such as item attributes) to neural sequential recommenders [4, 6, 29]. It has been demonstrated that contextual information is important to consider for improving the performance of sequential recommender systems.\n\nAlthough existing methods have been shown effective to some extent, there are two major shortcomings that are likely to affect the recommendation performance. First, they rely on the item prediction loss to learn the entire model. When context data is incorporated, the involved parameters are also learned through the only optimization objective. It has been found that such an optimization way is easy to suffer from issues such as data sparsity [21, 22].\n\nSecond, they overemphasize the final performance, while the association or fusion between context data and sequence data has not been well captured in data representations. As shown in increasing evidence from various fields [1, 5, 10], effective data representation (e.g., pre-trained contextualized embedding) has been a key factor to improve the performance of existing models or architectures. Therefore, there is a need to rethink the learning paradigm to develop more effective sequential recommender systems.\n\nTo address the above issues, we borrow the idea of self-supervised learning for improving sequential recommendation. Self-supervised learning [1, 15] is a newly emerging paradigm, which aims to let the model learn from the intrinsic structure of the raw data. A general framework of self-supervised learning is to first construct training signals directly from the raw data and then pre-train the model parameters with additionally devised optimization objectives. As previously discussed, limited supervision signals and ineffective data representations are the two major learning issues with existing neural sequential methods. Fortunately, self-supervised learning seems to provide a promising solution to both problems: it utilizes the intrinsic data correlation to devise auxiliary training objectives and enhances the data representations via pre-trained methods with rich self-supervised signals. However, for sequential recommendation, the context information exists in different forms or with varying intrinsics, including item, attribute, subsequence, or sequence. It is not easy to develop a unified approach to characterizing such data correlations. For this problem, we are inspired by the recently proposed mutual information maximization (MIM) method [5, 10, 11, 30]. It has been shown to be particularly effective to capture the correlation between different views (or parts) of the original input by maximizing the mutual information between the encoded representations of these views.\n\nTo this end, in this paper, we propose a novel Self-Supervised learning approach to improve Sequential Recommendation with MIM, which is called  $S^3$ -Rec. Based on a self-attentive recommender architecture [8], we propose to first pre-train the sequential recommender with self-supervised signals and then fine-tune the model parameters according to the recommendation task. The major novelty lies in the pre-training stage. In particular, we carefully devise four self-supervised optimization objectives for capturing item-attribute, sequence-item, sequence-attribute and sequence-subsequence correlations, respectively. These optimization objectives are developed in a unified form of MIM. As such,  $S^3$ -Rec is able to characterize the correlation in varying levels of granularity or between different forms in a general way. It is also flexible to adapt to new data types or new correlation patterns. Via such a pre-trained method, we can effectively fuse various kinds of context data, and learn attribute-aware contextualized data representations. Finally, the learned data representations are fed into the neural recommender, which will be optimized according to the recommendation performance.\n\nTo validate the effectiveness of our proposed  $S^3$ -Rec method, we conduct extensive experiments on six real-world recommendation datasets of different domains. Experimental results show that  $S^3$ -Rec achieves state-of-the-art performance compared to a number of competitive methods, especially when training data is limited.\n\nWe also show that our  $S^3$ -Rec is effective to adapt to other classes of neural architectures, such as GRU and CNN.\n\nOur main contributions are summarized as follows: (1) To the best of our knowledge, it is the first time that self-supervised learning with MIM has been applied to improve the sequential recommendation task; (2) We propose four self-supervised optimization objectives to maximize the mutual information of context information in different forms or granularities; (3) Extensive experiments conducted on six real-world datasets demonstrate the effectiveness of our proposed approach.",
  "method": "# 4 APPROACH\n\n# 4.1 Overview\n\nExisting studies [3, 4, 8, 24] mainly emphasize the effect of sequential characteristics using an item-level optimization objective alone. Inspired by recent progress with MIM [5, 28], we take a different perspective to develop neural sequential recommenders by maximizing the mutual information among different views of the raw data.\n\nThe basic idea of our approach is to incorporate several elaborately designed self-supervised learning objectives for enhancing the original model. To develop such objectives, we leverage effective correlation signals reflected in the intrinsic characteristics of the input. For our task, we consider the information in different levels of granularity, including attribute, item, segment (i.e., subsequence), and sequence, which are considered as different views of the input. By capturing the multi-view correlation, we unify these self-supervised learning objectives with the recently proposed pretraining framework in language modeling [1].\n\nThe overview of  $S^3$ -Rec is presented in Fig. 1. In the following sections, we first introduce the base model of our proposed approach that is developed on the Transformer architecture [8]. Then, we will describe how we utilize the correlation signals among attributes, items, segments, and sequences to enhance the data representations based on the InfoNCE [10, 25] method. Finally, we present the discussions on our approach.\n\n# 4.2 Base Model\n\nWe develop the basic framework for sequential recommendation model by stacking the embedding layer, self-attention blocks, and the prediction layer.\n\n4.2.1 Embedding Layer. In the embedding mapping stage, we maintain an item embedding matrix  $\\mathbf{M}_I\\in \\mathbb{R}^{|I|\\times d}$  and an attribute embedding matrix  $\\mathbf{M}_A\\in \\mathbb{R}^{|\\mathcal{A}|\\times d}$ . The two matrices project the high-dimensional one-hot representation of an item or attribute to low-dimensional dense representations. Given a  $n$ -length item sequence, we apply a look-up operation from  $\\mathbf{M}_I$  to form the input embedding matrix  $\\mathbf{E}\\in \\mathbb{R}^{n\\times d}$ . Besides, we incorporate a learnable\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/5d8bd2d1859feb62f5046591e51fe2ab32480d648dfc1c27814098ed3fd3f377.jpg)  \nFigure 1: The overview of  $S^3$ -Rec in the pre-training stage. We assume that the user sequence is  $\\{i_1, \\dots, i_n\\}$  and each item  $i$  is associated with several attributes  $\\mathcal{A}_i = \\{a_1, \\dots, a_m\\}$ . We incorporate four self-supervised learning objectives: (1) Associated Attribute Prediction (AAP), (2) Masked Item Prediction (MIP), (3) Masked Attribute Prediction (MAP), and (4) Segment Prediction (SP). The embedding layers and bidirectional self-attention blocks are shared by the four pre-training objectives.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/55335719a1f32e152a1092ed197f578bbd7b39ffacb52c9a28c69e49618bbf5f.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/8db5ba5b2e87e22495831f04af6ff6a6605e60dedd7d3960ea413ed318979041.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/463c20cc8f0f1aec1bfa6e446cf28a12a208ad70a06576b9e937c1d75ae12ec6.jpg)\n\nposition encoding matrix  $\\mathbf{P} \\in \\mathbb{R}^{n \\times d}$  to enhance the input representation of the item sequence. By this means, the sequence representation  $\\mathbf{E}_I \\in \\mathbb{R}^{n \\times d}$  can be obtained by summing two embedding matrices:  $\\mathbf{E}_I = \\mathbf{E} + \\mathbf{P}$ . Since our task utilizes auxiliary context data, we also form an embedding matrix  $\\mathbf{E}_A \\in \\mathbb{R}^{k \\times d}$  for each item from the entire attribute embedding matrix  $\\mathbf{M}_A$ , where  $k$  is the number of item attributes.\n\n4.2.2 Self-Attention Block. Based on the embedding layer, we develop the item encoder by stacking multiple self-attention blocks. A self-attention block generally consists of two sub-layers, i.e., a multi-head self-attention layer and a point-wise feed-forward network. The multi-head self-attention mechanism has been adopted for effectively extracting the information selectively from different representation subspaces. Specifically, the multi-head self-attention is defined as:\n\n$$\n\\operatorname {M u l t i H e a d A t t n} \\left(\\mathbf {F} ^ {l}\\right) = \\left[ h e a d _ {1}, h e a d _ {2}, \\dots , h e a d _ {h} \\right] \\mathbf {W} ^ {O}, \\tag {4}\n$$\n\n$$\n\\operatorname {h e a d} _ {i} = \\operatorname {A t t e n t i o n} \\left(\\mathbf {F} ^ {l} \\mathbf {W} _ {i} ^ {Q}, \\mathbf {F} ^ {l} \\mathbf {W} _ {i} ^ {K}, \\mathbf {F} ^ {l} \\mathbf {W} _ {i} ^ {V}\\right), \\tag {5}\n$$\n\nwhere the  $\\mathbf{F}^l$  is the input for the  $l$ -th layer. When  $l = 0$ , we set  $\\mathbf{F}^0 = \\mathbf{E}_I$ , and the projection matrix  $\\mathbf{W}_i^Q \\in \\mathbb{R}^{d \\times d / h}$ ,  $\\mathbf{W}_i^K \\in \\mathbb{R}^{d \\times d / h}$ ,  $\\mathbf{W}_V^Q \\in \\mathbb{R}^{d \\times d / h}$  and  $\\mathbf{W}^O \\in \\mathbb{R}^{d \\times d}$  are the corresponding learnable parameters for each attention head. The attention function is implemented by scaled dot-product operation:\n\n$$\n\\operatorname {A t t e n t i o n} (\\mathbf {Q}, \\mathbf {K}, \\mathbf {V}) = \\operatorname {s o f t m a x} \\left(\\frac {\\mathbf {Q K} ^ {\\top}}{\\sqrt {d / h}}\\right) \\mathbf {V}, \\tag {6}\n$$\n\nwhere  $\\mathbf{Q} = \\mathbf{F}^{l}\\mathbf{W}_{i}^{Q},\\mathbf{K} = \\mathbf{F}^{l}\\mathbf{W}_{i}^{K}$ , and  $\\mathbf{V} = \\mathbf{F}^{l}\\mathbf{W}_{i}^{V}$  are the linear transformations of the input embedding matrix, and  $\\sqrt{d / h}$  is the scale factor to avoid large values of the inner product.\n\nSince the multi-head attention function is mainly built on the linear projections. We endow the non-linearity of the self-attention\n\nblock by applying a point-wise feed-forward network. The computation is defined as:\n\n$$\n\\mathbf {F} ^ {l} = \\left[ \\mathrm {F F N} \\left(\\mathbf {F} _ {1} ^ {l}\\right) ^ {\\top}; \\dots ; \\mathrm {F F N} \\left(\\mathbf {F} _ {n} ^ {l}\\right) ^ {\\top} \\right], \\tag {7}\n$$\n\n$$\n\\operatorname {F F N} (x) = \\left(\\operatorname {R e L U} \\left(x \\mathbf {W} _ {1} + \\mathbf {b} _ {1}\\right)\\right) \\mathbf {W} _ {2} + \\mathbf {b} _ {2}, \\tag {8}\n$$\n\nwhere  $\\mathbf{W}_1,\\mathbf{b}_1,\\mathbf{W}_2,\\mathbf{b}_2$  are trainable parameters.\n\nIn sequential recommendation, only the information before the current time step can be utilized, thus we apply the mask operation for the output of the multi-head self-attention function to remove all connections between  $\\mathbf{Q}_i$  and  $\\mathbf{K}_i$ . Inspired by BERT [1], at the pre-training stage, we remove the mask mechanism to acquire the bidirectional context-aware representation of each item in an item sequence. It is beneficial to incorporate context from both directions for sequence representation learning [1, 23].\n\n4.2.3 Prediction Layer. In the final layer of  $S^3$ -Rec, we calculate the user's preference score for the item  $i$  in the step  $(t + 1)$  under the context from user history as:\n\n$$\nP \\left(i _ {t + 1} = i \\mid i _ {1: t}\\right) = \\mathbf {e} _ {i} ^ {\\top} \\cdot \\mathbf {F} _ {t} ^ {L}, \\tag {9}\n$$\n\nwhere  $\\mathbf{e}_i$  is the representation of item  $i$  from item embedding matrix  $\\mathbf{M}_I$ ,  $\\mathbf{F}_t^L$  is the output of the  $L$ -layer self-attention block at step  $t$  and  $L$  is the number of self-attention blocks.\n\n# 4.3 Self-supervised Learning with MIM\n\nBased on the above self-attention model, we further incorporate additional self-supervised signals with MIM to enhance the representations of input data. We adopt a pre-training way to construct different loss functions based on the multi-view correlation.\n\n4.3.1 Modeling Item-Attribute Correlation. We first maximize the mutual information between items and attributes. For each item, the attributes provide fine-grained information about it. Therefore, we aim to fuse item- and attribute-level information through modeling item-attribute correlation. In this way, it is expected to inject useful attribute information into item representations.\n\nGiven an item  $i$  and the attribute set  $\\mathcal{A}_i = \\{a_1, \\dots, a_k\\}$ , we treat the item itself and its associated attributes as two different views. Formally, let  $\\mathbf{e}_i$  denote the item embedding obtained by the embedding layer, and  $\\mathbf{e}_{a_j}$  denote the embedding for the  $j$ -th attribute  $a_j \\in \\mathcal{A}_i$ . We design a loss function by the contrastive learning framework that maximizes the mutual information between the two views. Following Eq. 3, we minimize the Associated Attribute Prediction (AAP) loss by:\n\n$$\nL _ {A A P} (i, \\mathcal {A} _ {i}) = \\mathbb {E} _ {a _ {j} \\in \\mathcal {A} _ {i}} [ f (i, a _ {j}) - \\log \\sum_ {\\tilde {a} \\in \\mathcal {A} \\backslash \\mathcal {A} _ {i}} \\exp (f (i, \\tilde {a})) ], \\tag {10}\n$$\n\nwhere we sample negative attributes  $\\tilde{a}$  that enhance the association between the item  $i$  and the ground-truth attributes, \" $\\backslash$  \" defines set subtraction operation. The function  $f(\\cdot ,\\cdot)$  is implemented with a simple bilinear network:\n\n$$\nf (i, a _ {j}) = \\sigma \\left(\\mathbf {e} _ {i} ^ {\\top} \\cdot \\mathbf {W} _ {A A P} \\cdot \\mathbf {e} _ {a _ {j}}\\right), \\tag {11}\n$$\n\nwhere  $\\mathbf{W}_{AAP} \\in \\mathbb{R}^{d \\times d}$  is a parameter matrix to learn and  $\\sigma(.)$  is the sigmoid function. Note that for clarity, we give the loss definition  $L_{AAP}$  for a single item. It will be easy to define this loss over the entire item set.\n\n4.3.2 Modeling Sequence-Item Correlation. Conventional sequential recommendation models are usually trained to predict the item at the next step. This approach only considers the sequential characteristics in an item sequence from left to right. While it is noted that the entire interaction sequence is indeed observed by the model in the training process. Inspired by the masked language model like BERT [1], we propose to model the bidirectional information in item sequence by a Cloze task. For our task, the Cloze setting is described as below: at each training step, we randomly mask a proportion of items in the input sequence (i.e., replace them with special tokens \"[mask)\"). Then we predict the masked items from the original sequence based on the surrounding context in both directions.\n\nTherefore, the second loss we consider is to recover the actual item with the bidirectional context from the input sequences. For this purpose, we prepare a pre-trained version of the base model in Section 4.2, which is a bidirectional Transformer architecture. As illustration, let us mask the  $t$ -th item  $i_t$  in a sequence  $\\{i_1, \\dots, i_t, \\dots, i_n\\}$ . We treat the rest sequence  $\\{i_1, \\dots, \\text{mask}, \\dots, i_n\\}$  as the surrounding context for  $i_t$ , denoted by  $C_{i_t}$ . Given the surrounding context  $C_{i_t}$  and the masked item  $i_t$ , we treat them as two different views to fuse for learning data representations. Following Eq. 3, we minimize the Masked Item Prediction (MIP) loss by:\n\n$$\nL _ {M I P} \\left(C _ {i _ {t}}, i _ {t}\\right) = f \\left(C _ {i _ {t}}, i _ {t}\\right) - \\log \\left[ \\sum_ {\\tilde {i} \\in \\mathcal {I} \\backslash \\{i _ {t} \\}} f \\left(C _ {i _ {t}}, i _ {t}\\right) \\right], \\tag {12}\n$$\n\nwhere  $\\tilde{i}$  denotes an irrelevant item, and  $f(\\cdot ,\\cdot)$  is implemented according to the following formula:\n\n$$\nf \\left(C _ {i _ {t}}, i _ {t}\\right) = \\sigma \\left(\\mathbf {F} _ {t} ^ {\\top} \\cdot \\mathbf {W} _ {M I P} \\cdot \\mathbf {e} _ {i _ {t}}\\right), \\tag {13}\n$$\n\nwhere  $\\mathbf{W}_{MIP} \\in \\mathbb{R}^{d \\times d}$  is a parameter matrix to learn and  $\\mathbf{F}_t$  is the learned representation for the  $t$ -th position using the bidirectional Transformer architecture obtained in the same way as Eq. 7.\n\n4.3.3 Modeling Sequence-Attribute Correlation. Having modeled both item-attribute and sequence-item correlations, we further consider directly fusing attribute information with sequential contexts. Specifically, we adopt a similar way as in Section 4.3.2 to recover the attributes of a masked item based on surrounding contexts. Given a masked item  $i_t$ , we treat its surrounding context  $C_{i_t}$  and its attribute set  $\\mathcal{A}_{i_t}$  as two different views for MIM. As such, we can develop the following Masked Attribute Prediction (MAP) loss by:\n\n$$\nL _ {M A P} (C _ {i _ {t}}, \\mathcal {A} _ {i _ {t}})\n$$\n\n$$\n= \\mathbb {E} _ {a \\in \\mathcal {A} _ {i _ {t}}} [ f (C _ {i _ {t}}, a) - \\log \\sum_ {\\tilde {a} \\in \\mathcal {A} \\backslash \\mathcal {A} _ {i}} \\exp (f (C _ {i _ {t}}, \\tilde {a})) ], \\tag {14}\n$$\n\nwhere  $f(\\cdot, \\cdot)$  is implemented according to the following formula:\n\n$$\nf \\left(C _ {i _ {t}}, a\\right) = \\sigma \\left(\\mathbf {F} _ {t} ^ {\\top} \\cdot \\mathbf {W} _ {M A P} \\cdot \\mathbf {e} _ {a}\\right), \\tag {15}\n$$\n\nwhere  $\\mathbf{W}_{MAP} \\in \\mathbb{R}^{d \\times d}$  is a parameter matrix to learn. Note that existing methods [4, 8, 24] seldom directly model the correlation between the sequential context and attribute information. While, we would like to explicitly model the correlation to derive more meaningful supervision signals, which is useful to improve the data representations for multi-granularity information.\n\n4.3.4 Modeling Sequence-Segment Correlation. As shown above, the Cloze learning strategy plays a key role in our pre-trained approach in fusing sequential contexts with target information. However, a major difference between item sequence with word sequence is that a single target item may not be highly related to surrounding contexts. For example, a user has bought some products just because they were on sale. Based on this concern, we extend the Cloze strategy from a single item to item subsequence (i.e., called segment). Apparently, an item segment reflects more clear, stable user preference than a single item. Therefore, we follow a similar strategy in Section 4.3.2 to recover an item subsequence from surrounding contexts. It is expected to enhance the self-supervised learning signal and improve the pre-trained performance.\n\nLet  $i_{j_1:j_2}$  denote the subsequence from item  $i_{j_1}$  to  $i_{j_2}$ , and  $C_{i_{j_1:j_2}}$  denote the context for  $i_{j_1:j_2}$  within the entire sequence. Similar to Eq. 12, we can recover the missing item segment with a MIM formulation, which is so called the Segment Prediction (SP) loss as:\n\n$$\nL _ {S P} \\left(C _ {i _ {j _ {1}: j _ {2}}}, i _ {j _ {1}: j _ {2}}\\right)\n$$\n\n$$\n= f \\left(C _ {i _ {j _ {1}: j _ {2}}}, i _ {j _ {1}: j _ {2}}\\right) - \\log \\sum_ {\\tilde {i} _ {j _ {1}: j _ {2}}} \\exp \\left(f \\left(C _ {i _ {j _ {1}: j _ {2}}}, \\tilde {i} _ {j _ {1}: j _ {2}}\\right)\\right), \\tag {16}\n$$\n\nwhere  $\\tilde{t}_{j_1,j_2}$  is the corrupted negative subsequence and  $f(\\cdot ,\\cdot)$  is implemented according to the following formula:\n\n$$\nf \\left(C _ {i _ {j _ {1}: j _ {2}}}, i _ {j _ {1}: j _ {2}}\\right) = \\sigma \\left(\\mathbf {s} ^ {\\top} \\cdot \\mathbf {W} _ {S P} \\cdot \\tilde {\\mathbf {s}}\\right), \\tag {17}\n$$\n\nwhere  $\\mathbf{W}_{SP} \\in \\mathbb{R}^{d \\times d}$  is a parameter matrix to learn, and  $\\mathbf{s}$  and  $\\tilde{\\mathbf{s}}$  are the learned representations for the contexts  $C_{i_{j_1:j_2}}$  and subsequence  $i_{j_1:j_2}$ , respectively. In order to learn  $\\mathbf{s}$  and  $\\tilde{\\mathbf{s}}$ , we apply the bidirectional Transformer to obtain the state representations of the last position in a sequence.\n\n# 4.4 Learning and Discussion\n\nIn this part, we present the learning and related discussions of our  $S^3$ -Rec for sequential recommendation.\n\n4.4.1 Learning. The entire procedure of  $S^3$ -Rec consists of two important stages, namely pre-training and fine-tuning stages. We adopt bidirectional and unidirectional Transformer [26] architectures for the two stages, respectively. At the pre-trained stage, we optimize the self-supervised learning objectives by considering four different kinds of correlations (Eq. 10, Eq. 12, Eq. 14 and Eq. 16); at the fine-tuning stage, we utilize the learned parameters from the pre-trained stage to initialize the parameters of the unidirectional Transformer, and then utilize the left-to-right supervised signals to train the network. We adopt the pairwise rank loss to optimize its parameters as:\n\n$$\nL _ {m a i n} = - \\sum_ {u \\in \\mathcal {U}} \\sum_ {t = 1} ^ {n} \\log \\sigma \\left(P \\left(i _ {t + 1} \\mid i _ {1: t}\\right) - P \\left(i _ {t + 1} ^ {-} \\mid i _ {1: t}\\right)\\right), \\tag {18}\n$$\n\nwhere we pair each ground-truth item  $i_{t+1}$  with a negative item  $i_{t+1}^{-}$  that is randomly sampled.\n\n4.4.2 Discussion. Our work provides a novel self-supervised approach to capturing the intrinsic data correlation from the input as an additional signal through the pre-trained models. This approach is quite general so that many existing methods can be included in this framework. We make a brief discussion below.\n\nFeature-based approaches such as Factorization Machine [20] and AutoInt [22] mainly learn data representations through the interaction of context features. The final prediction is made according to the actual interaction results between the user and item features. In  $S^3$ -Rec, the associated attribute prediction loss  $L_{AAP}$  in Eq. 10 and the masked attribute prediction loss  $L_{MAP}$  in Eq. 14 have the similar effect in feature interaction. However, we do not explicitly model the interaction between attributes. Instead, we focus on capturing the association between attribute information and item/sequential contexts. A major difference in our work is to utilize feature interaction as additional supervision signals to enhance data representations instead of making predictions.\n\nSequential models such as GRU4Rec [21] and SASRec [8] mainly focus on modeling the sequential dependencies between contextual items and the target item in a left-to-right order.  $S^3$ -Rec additionally incorporates a pre-trained stage that leverages four different kinds of self-supervised learning signals for enhancing data representations. In particular, the masked item prediction loss  $L_{MIP}$  in Eq. 12 has a similar effect to capture sequential dependencies as in [8, 21] except that it can also utilize bidirectional sequential information.\n\nAttribute-aware sequential models such as TransFM [16] and FDSA [29] leverage the contextual features to improve the sequential recommender models, in which these features are treated as auxiliary information to enhance the representation of items or sequences. In our  $S^3$ -Rec, the  $L_{AAP}$  loss and  $L_{MAP}$  loss aim to fuse attribute with items or sequential contexts, which is able to achieve the same effect as previous methods [16, 29]. Besides, the pre-trained data representations can be also applied to improve existing methods.",
  "experiments": "# 5 EXPERIMENT\n\n# 5.1 Experimental Setup\n\n5.1.1 Dataset. We conduct experiments on six datasets collected from four real-world platforms with varying domains and sparsity levels. The statistics of these datasets after preprocessing are summarized in Table 1.\n\n(1) Meituan<sup>1</sup>: this dataset consists of six-year (from Jan. 2014 to Jan. 2020) transaction records in Beijing on the Meituan platform. We select categories, locations, and the keywords extracted from customer reviews as attributes.  \n(2) Amazon Beauty, Sports, and Toys: these three datasets are obtained from Amazon review datasets in [14]. In this work, we select three subcategories: \"Beauty\", \"Sports and Outdoors\", and \"Toys and Games\", and utilize the fine-grained categories and the brands of the goods as attributes.  \n(3)  $\\mathbf{Yelp}^2$ : this is a popular dataset for business recommendation. As it is very large, we only use the transaction records after January 1st, 2019. We treat the categories of businesses as attributes.  \n(4) LastFM<sup>3</sup>: this is a music artist recommendation dataset and contains user tagging behaviors for artists. In this dataset, the tags of the artists given by the users are used as attributes.\n\nFor all datasets, we group the interaction records by users and sort them by the interaction timestamps ascendingly. Following [21, 29], we only keep the 5-core datasets, and filter unpopular items and inactive users with fewer than five interaction records.\n\n5.1.2 Evaluation Metrics. We employ top- $k$  Hit Ratio  $(\\mathrm{HR}@\\mathbf{k})$ , top- $k$  Normalized Discounted Cumulative Gain (NDCG@k), and Mean Reciprocal Rank (MRR) to evaluate the performance, which are widely used in related works [21, 29]. Since HR@1 is equal to NDCG@1, we report results on HR@{1, 5, 10}, NGCG@{5, 10}, and MRR. Following previous works [8, 19, 23], we apply the leave-one-out strategy for evaluation. Concretely, for each user interaction sequence, the last item is used as the test data, the item before the last one is used as the validation data, and the remaining data is used for training. Since the item set is large, it is time-consuming to use all items as candidates for testing. Following the common strategy [7, 8], we pair the ground-truth item with 99 randomly sampled negative items that the user has not interacted with. We calculate all metrics according to the ranking of the items and report the average score over all test users.\n\n5.1.3 Baseline Models. We compare our proposed approach with the following eleven baseline methods:\n\n(1) PopRec is a non-personalized method that ranks items according to popularity measured by the number of interactions.  \n(2) FM [20] characterizes the pairwise interactions between variables using factorized model.  \n(3) AutoInt [22] utilizes the multi-head self-attentive neural network to learn the feature interaction.  \n(4) GRU4Rec [3] applies GRU to model user click sequence for session-based recommendation. We represent the items using embedding vectors rather than one-hot vectors.  \n(5) Caser [24] is a CNN-based method capturing high-order Markov Chains by applying horizontal and vertical convolutional operations for sequential recommendation.  \n(6) SASRec [8] is a self-attention based sequential recommendation model, which uses the multi-head attention mechanism to recommend the next item.  \n(7) BERT4Rec [23] uses a Cloze objective loss for sequential recommendation by the bidirectional self-attention mechanism.  \n(8) HGN [13] is recently proposed and adopts hierarchical gating networks to capture long-term and short-term user interests.  \n(9) GRU4Rec $_F$  [4] is an improved version of GRU4Rec, which leverages attributes to improve the performance.  \n(10)  $\\mathrm{SASRec}_F$  is our extension of SASRec, which concatenates the representations of item and attribute as the input to the model.  \n(11) FDSA [29] constructs a feature sequence and uses a feature-level self-attention block to model the feature transition patterns. This is the state-of-the-art model in sequential recommendation.\n\n5.1.4 Implementation Details. For Caser and HGN, we use the source code provided by their authors. For other methods, we implement them by PyTorch. All hyper-parameters are set following the suggestions from the original papers.\n\nFor our proposed  $S^3$ -Rec, we set the number of the self-attention blocks and the attention heads as 2. The dimension of the embedding is 64, and the maximum sequence length is 50 (following [8]). Note that our training phase contains two stages (i.e., pre-training and fine-tuning stage), the learned parameters in the pre-training stage are used to initialize the embedding layers and self-attention layers of our model in the fine-tuning stage.\n\nIn the pre-training stage, the mask proportion of item is set as 0.2 and the weights for the four losses (i.e., AAP, MIP, MAP, and SP) are set as 0.2, 1.0, 1.0, and 0.5, respectively, based on our empirical experiments. We use the Adam optimizer [9] with a learning rate of 0.001, where the batch size is set as 200 and 256 in the pre-training and the fine-tuning stage, respectively. We pre-train our model for 100 epochs and fine-tune it on the recommendation task. The code and data set are available at the link: https://github.com/RUCAIBox/CIKM2020-S3Rec<sup>4</sup>.\n\n# 5.2 Experimental Results\n\nThe results of different methods on all datasets are shown in Table 2. Based on the results, we can find:\n\nFor three non-sequential recommendation baselines, the performance order is consistent across all datasets, i.e.,  $PopRec > AutoInt > FM$ . Due to the \"rich-gets-richer\" effect in product adoption, PopRec is a robust baseline. AutoInt performs better than FM on most datasets because the multi-head self-attention mechanism has a stronger capacity to model attributes. However, the performance of AutoInt is worse than that of FM on Meituan dataset. A potential reason is that the multi-head self-attention may incorporate more noise from the attributes since they are keywords extracted from the reviews on Meituan platform. In general, non-sequential recommendation methods perform worse than sequential recommendation methods, since the sequential pattern is important to consider in our task.\n\nAs for sequential recommendation baseline methods, SASRec and BERT4Rec utilize the unidirectional and bidirectional self-attention mechanism respectively, and achieve better performance than GRU4Rec and Caser. It indicates that self-attentive architecture is particularly suitable for modeling sequential data. However, their improvements are not stable when training with the conventional next-item prediction loss. Besides, HGN achieves comparable performance with SASRec and BERT4Rec. This indicates the hierarchical gating network can well model the relations between closely relevant items. However, when directly injecting the attribute information into GRU4Rec and SASRec (i.e., GRU4Rec $_F$  and SASRec $_F$ ), the performance improvement is not consistent. This method yields improvement on Beauty, Sports, Toys, and Yelp datasets, but has a negative influence on other datasets. One possible reason is that simply concatenating item representations and its attributes representations cannot effectively fuse the two kinds of information. In most cases, FDSA achieves the best performance among all baselines. This suggests that the feature-level self-attention blocks can capture useful sequential feature interaction patterns.\n\nFinally, by comparing our approach with all the baselines, it is clear to see that  $S^3$ -Rec performs consistently better than them by a large margin on six datasets. Different from these baselines, we adopt the self-supervised learning to enhance the representations of the attribute, item, and sequence for the recommendation task, which incorporates four pre-training objectives to model multiple data correlations by MIM. This result also shows that the self-supervised approach is effective to improve the performance of the self-attention architecture for sequential recommendation.\n\n# 5.3 Further Analysis\n\nNext, we continue to study whether  $S^3$ -Rec works well in more detailed analysis.\n\n5.3.1 Ablation Study. Our proposed self-supervised approach  $S^3$ -Rec designs four pre-training objectives based on MIM. To verify the effectiveness of each objective, we conduct the ablation study on Meituan, Beauty, Sports, and Toys datasets to analyze the contribution of each objective. NDCG@10 is adopted for this evaluation. The results from the best baseline FDSA are also provided for comparison.\n\nFrom the results in Fig. 2, we can observe that removing any self-supervised objective would lead to the performance decrease. It indicates all the objectives are useful to improve the recommendation performance. Besides, the importance of these objectives\n\nTable 2: Performance comparison of different methods on six datasets. The best performance and the second best performance methods are denoted in bold and underlined fonts respectively. “*” indicates the statistical significance for  $p < 0.01$  compared to the best baseline method.  \n\n<table><tr><td>Datasets</td><td>Metric</td><td>PopRec</td><td>FM</td><td>AutoInt</td><td>GRU4Rec</td><td>Caser</td><td>SASRec</td><td>BERT4Rec</td><td>HGN</td><td>GRU4RecF</td><td>SASRecF</td><td>FDSA</td><td>S3-Rec</td><td>Improv.</td></tr><tr><td rowspan=\"6\">Meituan</td><td>HR@1</td><td>0.0946</td><td>0.1084</td><td>0.0804</td><td>0.1194</td><td>0.1368</td><td>0.1797</td><td>0.1381</td><td>0.1603</td><td>0.1436</td><td>0.1746</td><td>0.1778</td><td>0.2040*</td><td>13.52%</td></tr><tr><td>HR@5</td><td>0.2660</td><td>0.3218</td><td>0.2662</td><td>0.3382</td><td>0.3812</td><td>0.4524</td><td>0.3985</td><td>0.4110</td><td>0.3799</td><td>0.4386</td><td>0.4595</td><td>0.4925*</td><td>7.18%</td></tr><tr><td>NDCG@5</td><td>0.1813</td><td>0.2170</td><td>0.1739</td><td>0.2303</td><td>0.2619</td><td>0.3207</td><td>0.2713</td><td>0.2887</td><td>0.2639</td><td>0.3098</td><td>0.3236</td><td>0.3527*</td><td>8.99%</td></tr><tr><td>HR@10</td><td>0.3863</td><td>0.4709</td><td>0.4077</td><td>0.4881</td><td>0.5267</td><td>0.6053</td><td>0.5514</td><td>0.5573</td><td>0.5378</td><td>0.5962</td><td>0.6164</td><td>0.6368*</td><td>3.31%</td></tr><tr><td>NDCG@10</td><td>0.2200</td><td>0.2651</td><td>0.2194</td><td>0.2787</td><td>0.3090</td><td>0.3700</td><td>0.3208</td><td>0.3359</td><td>0.3149</td><td>0.3607</td><td>0.3743</td><td>0.3994*</td><td>6.71%</td></tr><tr><td>MRR</td><td>0.1923</td><td>0.2242</td><td>0.1854</td><td>0.2359</td><td>0.2617</td><td>0.3146</td><td>0.2689</td><td>0.2863</td><td>0.2666</td><td>0.3064</td><td>0.3167</td><td>0.3421*</td><td>8.02%</td></tr><tr><td rowspan=\"6\">Beauty</td><td>HR@1</td><td>0.0678</td><td>0.0405</td><td>0.0447</td><td>0.1337</td><td>0.1337</td><td>0.1870</td><td>0.1531</td><td>0.1683</td><td>0.1702</td><td>0.1778</td><td>0.1840</td><td>0.2192*</td><td>17.22%</td></tr><tr><td>HR@5</td><td>0.2105</td><td>0.1461</td><td>0.1705</td><td>0.3125</td><td>0.3032</td><td>0.3741</td><td>0.3640</td><td>0.3544</td><td>0.3727</td><td>0.3863</td><td>0.4010</td><td>0.4502*</td><td>12.27%</td></tr><tr><td>NDCG@5</td><td>0.1391</td><td>0.0934</td><td>0.1063</td><td>0.2268</td><td>0.2219</td><td>0.2848</td><td>0.2622</td><td>0.2656</td><td>0.2759</td><td>0.2870</td><td>0.2974</td><td>0.3407*</td><td>14.56%</td></tr><tr><td>HR@10</td><td>0.3386</td><td>0.2311</td><td>0.2872</td><td>0.4106</td><td>0.3942</td><td>0.4696</td><td>0.4739</td><td>0.4503</td><td>0.4753</td><td>0.4843</td><td>0.5096</td><td>0.5506*</td><td>8.05%</td></tr><tr><td>NDCG@10</td><td>0.1803</td><td>0.1207</td><td>0.1440</td><td>0.2584</td><td>0.2512</td><td>0.3156</td><td>0.2975</td><td>0.2965</td><td>0.3090</td><td>0.3185</td><td>0.3324</td><td>0.3732*</td><td>12.27%</td></tr><tr><td>MRR</td><td>0.1558</td><td>0.1096</td><td>0.1226</td><td>0.2308</td><td>0.2263</td><td>0.2852</td><td>0.2614</td><td>0.2669</td><td>0.2751</td><td>0.2844</td><td>0.2943</td><td>0.3340*</td><td>13.49%</td></tr><tr><td rowspan=\"6\">Sports</td><td>HR@1</td><td>0.0763</td><td>0.0489</td><td>0.0644</td><td>0.1160</td><td>0.1135</td><td>0.1455</td><td>0.1255</td><td>0.1428</td><td>0.1466</td><td>0.1573</td><td>0.1585</td><td>0.1841*</td><td>16.15%</td></tr><tr><td>HR@5</td><td>0.2293</td><td>0.1603</td><td>0.1982</td><td>0.3055</td><td>0.2866</td><td>0.3466</td><td>0.3375</td><td>0.3349</td><td>0.3547</td><td>0.3730</td><td>0.3855</td><td>0.4267*</td><td>10.69%</td></tr><tr><td>NDCG@5</td><td>0.1538</td><td>0.1048</td><td>0.1316</td><td>0.2126</td><td>0.2020</td><td>0.2497</td><td>0.2341</td><td>0.2420</td><td>0.2535</td><td>0.2683</td><td>0.2756</td><td>0.3104*</td><td>12.63%</td></tr><tr><td>HR@10</td><td>0.3423</td><td>0.2491</td><td>0.2967</td><td>0.4299</td><td>0.4014</td><td>0.4622</td><td>0.4722</td><td>0.4551</td><td>0.4758</td><td>0.4912</td><td>0.5136</td><td>0.5614*</td><td>9.31%</td></tr><tr><td>NDCG@10</td><td>0.1902</td><td>0.1334</td><td>0.1633</td><td>0.2527</td><td>0.2390</td><td>0.2869</td><td>0.2775</td><td>0.2806</td><td>0.2925</td><td>0.3064</td><td>0.3170</td><td>0.3538*</td><td>11.61%</td></tr><tr><td>MRR</td><td>0.1660</td><td>0.1202</td><td>0.1435</td><td>0.2191</td><td>0.2100</td><td>0.2520</td><td>0.2378</td><td>0.2469</td><td>0.2549</td><td>0.2680</td><td>0.2748</td><td>0.3071*</td><td>11.75%</td></tr><tr><td rowspan=\"6\">Toys</td><td>HR@1</td><td>0.0585</td><td>0.0257</td><td>0.0448</td><td>0.0997</td><td>0.1114</td><td>0.1878</td><td>0.1262</td><td>0.1504</td><td>0.1673</td><td>0.1797</td><td>0.1717</td><td>0.2003*</td><td>6.66%</td></tr><tr><td>HR@5</td><td>0.1977</td><td>0.0978</td><td>0.1471</td><td>0.2795</td><td>0.2614</td><td>0.3682</td><td>0.3344</td><td>0.3276</td><td>0.3695</td><td>0.3927</td><td>0.3994</td><td>0.4420*</td><td>10.67%</td></tr><tr><td>NDCG@5</td><td>0.1286</td><td>0.0614</td><td>0.0960</td><td>0.1919</td><td>0.1885</td><td>0.2820</td><td>0.2327</td><td>0.2423</td><td>0.2719</td><td>0.2911</td><td>0.2903</td><td>0.3270*</td><td>12.33%</td></tr><tr><td>HR@10</td><td>0.3008</td><td>0.1715</td><td>0.2369</td><td>0.3896</td><td>0.3540</td><td>0.4663</td><td>0.4493</td><td>0.4211</td><td>0.4782</td><td>0.4981</td><td>0.5129</td><td>0.5530*</td><td>7.82%</td></tr><tr><td>NDCG@10</td><td>0.1618</td><td>0.0850</td><td>0.1248</td><td>0.2274</td><td>0.2183</td><td>0.3136</td><td>0.2698</td><td>0.2724</td><td>0.3070</td><td>0.3252</td><td>0.3271</td><td>0.3629*</td><td>10.94%</td></tr><tr><td>MRR</td><td>0.1430</td><td>0.0819</td><td>0.1131</td><td>0.1973</td><td>0.1967</td><td>0.2842</td><td>0.2338</td><td>0.2454</td><td>0.2717</td><td>0.2886</td><td>0.2863</td><td>0.3202*</td><td>10.95%</td></tr><tr><td rowspan=\"6\">Yelp</td><td>HR@1</td><td>0.0801</td><td>0.0624</td><td>0.0731</td><td>0.2053</td><td>0.2188</td><td>0.2375</td><td>0.2405</td><td>0.2428</td><td>0.2293</td><td>0.2301</td><td>0.2198</td><td>0.2591*</td><td>6.71%</td></tr><tr><td>HR@5</td><td>0.2415</td><td>0.2036</td><td>0.2249</td><td>0.5437</td><td>0.5111</td><td>0.5745</td><td>0.5976</td><td>0.5768</td><td>0.5858</td><td>0.5937</td><td>0.5728</td><td>0.6085*</td><td>1.82%</td></tr><tr><td>NDCG@5</td><td>0.1622</td><td>0.1333</td><td>0.1501</td><td>0.3784</td><td>0.3696</td><td>0.4113</td><td>0.4252</td><td>0.4162</td><td>0.4137</td><td>0.4178</td><td>0.4014</td><td>0.4401*</td><td>3.50%</td></tr><tr><td>HR@10</td><td>0.3609</td><td>0.3153</td><td>0.3367</td><td>0.7265</td><td>0.6661</td><td>0.7373</td><td>0.7597</td><td>0.7411</td><td>0.7574</td><td>0.7706</td><td>0.7555</td><td>0.7725</td><td>0.25%</td></tr><tr><td>NDCG@10</td><td>0.2007</td><td>0.1692</td><td>0.1860</td><td>0.4375</td><td>0.4198</td><td>0.4642</td><td>0.4778</td><td>0.4695</td><td>0.4694</td><td>0.4751</td><td>0.4607</td><td>0.4934*</td><td>3.26%</td></tr><tr><td>MRR</td><td>0.1740</td><td>0.1470</td><td>0.1616</td><td>0.3630</td><td>0.3595</td><td>0.3927</td><td>0.4026</td><td>0.3988</td><td>0.3929</td><td>0.3962</td><td>0.3834</td><td>0.4190*</td><td>4.07%</td></tr><tr><td rowspan=\"6\">LastFM</td><td>HR@1</td><td>0.0725</td><td>0.0183</td><td>0.0349</td><td>0.0642</td><td>0.0899</td><td>0.1211</td><td>0.1220</td><td>0.0908</td><td>0.1385</td><td>0.1147</td><td>0.0936</td><td>0.1743*</td><td>25.85%</td></tr><tr><td>HR@5</td><td>0.1982</td><td>0.0954</td><td>0.1550</td><td>0.1817</td><td>0.2982</td><td>0.3385</td><td>0.3569</td><td>0.2872</td><td>0.3202</td><td>0.3073</td><td>0.2624</td><td>0.4523*</td><td>26.73%</td></tr><tr><td>NDCG@5</td><td>0.1350</td><td>0.0552</td><td>0.0946</td><td>0.1228</td><td>0.1960</td><td>0.2330</td><td>0.2409</td><td>0.1896</td><td>0.2301</td><td>0.2113</td><td>0.1766</td><td>0.3156*</td><td>31.01%</td></tr><tr><td>HR@10</td><td>0.3037</td><td>0.1578</td><td>0.2596</td><td>0.2817</td><td>0.4431</td><td>0.4706</td><td>0.4991</td><td>0.4193</td><td>0.4670</td><td>0.4569</td><td>0.4055</td><td>0.5835*</td><td>16.91%</td></tr><tr><td>NDCG@10</td><td>0.1687</td><td>0.0753</td><td>0.1285</td><td>0.1550</td><td>0.2428</td><td>0.2755</td><td>0.2871</td><td>0.2324</td><td>0.2775</td><td>0.2594</td><td>0.2225</td><td>0.3583*</td><td>24.80%</td></tr><tr><td>MRR</td><td>0.1506</td><td>0.0743</td><td>0.1122</td><td>0.1405</td><td>0.2033</td><td>0.2364</td><td>0.2424</td><td>0.1983</td><td>0.2410</td><td>0.2201</td><td>0.1884</td><td>0.3072*</td><td>26.73%</td></tr></table>\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/8d653c5c9ae91bb8ae70f8cb00c2c26510f7450aa03af42a3682fc6184443d91.jpg)  \nFigure 2: Ablation study of our approach on four datasets (NDCG@10). “ $\\neg$ ” indicates that the corresponding objective is removed in the pre-training stage, while the rest objectives are kept.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/e5e9eb3d42b381dc1ebb219a5fcac4a9e581e8725982abacde036b1d1e36cf70.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/d9a22dbc1b1b013bfa3045018a97c665b6acefa7a6a7582f22b1599bb9fccb72.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/99e2428c94081524d38b16abdd8216456c5908f33456e686ef7872e9ba57eb8f.jpg)\n\nis varying on different datasets. Overall, the AAP (Associated Attribute Prediction) and the MAP (Masked Attribute Prediction) are more important than the other objectives. Removing each of them\n\nyields a larger drop of performance on all datasets. One possible reason is that these two objectives enhance the representations of item and sequence with the attributes information.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/1aa287bfdaa1f156132d836ade65eac7429de761c6c67a6ae6bd1260df596116.jpg)  \nFigure 3: Performance (NDCG@10) comparison of different models enhanced by our self-supervised learning approach on Beauty and Toys datasets.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/aa0d3ee613a8db84fd9bed3cbd1b5ebb0e82e5232b237c8db582d253db41223a.jpg)  \n(a) Sports  \nFigure 4: Performance (NDCG@10) comparison w.r.t. different sparsity levels on Sport and Yelp datasets.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/4f450c6df09a4615e3b08a2eb0e1803cbd24ccc615f4fc02e97ac5946428a0ec.jpg)  \n(b) Yelp\n\nIt is clearly seen that all model variants are better than the best baseline FDSA, which is trained only with next-item predication loss.\n\n5.3.2 Applying Self-Supervised Learning to Other Models. Since self-supervised learning itself is a learning paradigm, it can generally apply to various models. Thus, in this part, we conduct an experiment to examine whether our method can bring improvements to other models. We use the self-supervised approach to pre-training some baseline models on Beauty and Toys datasets. For GRU4Rec, GRU4Rec $_F$ , SASRec, and SASRec $_F$ , we directly apply our pre-training objectives to improve them. It is worth noting that GRU4Rec and SASRec are unidirectional models, so we maintain the unidirectional encoder layer in the pre-training stage. For AutoInt and Caser, since their architectures do not support some of the pre-training objectives $^5$ , we only utilize the pre-trained parameters to initialize the parameters of the embedding layers.\n\nThe results of NDCG@10 on Beauty and Toys datasets are shown in Fig. 3. First, after pre-training by our approach, all the baselines achieve better performance. This shows that self-supervised learning can also be applied to improve their performance. Second,  $S^3$ -Rec outperforms all the baselines after pre-training. This is because\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/633e4790c5c220709d0767b50183194ab4a274389c3bbc9041d6613c29e9cad6.jpg)  \n(a) Beauty\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/e24c3414c9a7211331c86b7f3b3f2ae6fcf78f3dc194100a1f9ccf37c5f5f115.jpg)  \n(b) Toys  \nFigure 5: Performance (NDCG@10) comparison w.r.t. different numbers of pre-training epochs on Beauty and Toys datasets.\n\nour model adopts the bidirectional Transformer encoder in the pretraining stage, which is more suitable for our approach. Third, we can see the GRU-based models achieve less improvement than the other models. One possible reason is that RNN-based architecture limits the potential of self-supervised learning.\n\n5.3.3 Performance Comparison w.r.t. the Amount of Training Data. Conventional recommendation systems require a considerable amount of training data, thus they are likely to suffer from the cold start problem in real-world applications. This problem can be alleviated by our method because the proposed self-supervised learning approach can better utilize the data correlation from input. We simulate the data sparsity scenarios by using different proportions of the full dataset, i.e.,  $20\\%$ ,  $40\\%$ ,  $60\\%$ ,  $80\\%$ , and  $100\\%$ .\n\nFig. 4 shows the evaluation results on Sports and Yelp datasets. As we can see, the performance substantially drops when less training data is used. While,  $S^3$ -Rec is consistently better than baselines in all cases, especially in an extreme sparsity level (20%). This observation implies that  $S^3$ -Rec is able to make better use of the data with the self-supervised method, which alleviates the influence of data sparsity problem for sequential recommendation to some extent.\n\n5.3.4 Performance Comparison w.r.t. the Number of Pre-training Epochs. Our approach consists of a pre-training stage and a fine-tuning stage. In the pre-training stage, our model can learn the enhanced representations of the attribute, item, subsequence, and sequence for the recommendation task. The number of pre-training epochs affects the performance of the recommendation task. To investigate this, we pre-train our model with a varying number of epochs and fine-tune it on the recommendation task.\n\nFig. 5 presents the results on Beauty and Toys datasets. The horizontal dash lines represent the performance without pre-training. We can see that our model benefits mostly from the first 20 pretraining epochs. And after that, the performance improves slightly. Based on this observation, we can conclude that the correlations among different views (i.e., the attribute, item, subsequence, and sequence) can be well-captured by our self-supervised learning approach through pre-training within a small number of epochs. So that the enhanced data representations can improve the performance of sequential recommendation.\n\n5.3.5 Convergence Speed Comparison. After obtaining the enhanced representations of the attribute, item, and sequence, we fine-tune\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/455c13cbe8832fe2c1875fe164e8d746fcbfed70e99eb44e2c7414de471978c3.jpg)  \n(a) Beauty\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/14ca49d0-24b0-4116-abfb-4de7d08be639/c2c4fb56165015c81ad77e4eb5ffe8398db940ac0cd82376484fe11ba8ae086b.jpg)  \n(b) Toys  \nFigure 6: Performance tuning (NDCG@10) of our approach and other baselines with the increasing iterations in the fin-tuning stage.\n\nour model on the recommendation task. To examine the convergence speed on the final recommendation task, we gradually increase the number of epochs for the fine-tuning stage and compare the performance of our model and other baselines.\n\nFig. 6 shows the results on Beauty and Toys datasets. It can be observed that our model converges quickly and achieves the best performance after about 40 epochs. In contrast to our model, the comparison models need more epochs to achieve stable performance. This result shows that our approach can utilize pre-trained parameters to help the model converge faster and achieve better performance.",
  "hyperparameter": "Number of self-attention blocks: 2; Number of attention heads: 2; Embedding dimension: 64; Maximum sequence length: 50; Mask proportion for items: 0.2; Loss weights - AAP: 0.2, MIP: 1.0, MAP: 1.0, SP: 0.5; Optimizer: Adam with learning rate 0.001; Batch size: 200 (pre-training), 256 (fine-tuning); Pre-training epochs: 100; Scale factor for attention: sqrt(d/h) where d is embedding dimension and h is number of heads"
}