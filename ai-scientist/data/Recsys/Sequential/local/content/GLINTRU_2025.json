{
    "id": "GLINTRU_2025",
    "paper_title": "GLINT-RU: Gated Lightweight Intelligent Recurrent Units for Sequential Recommender Systems",
    "alias": "GLINTRU",
    "year": 2025,
    "domain": "Recsys",
    "task": "SequentialRecommendation",
    "idea": "GLINT-RU replaces stacked transformers with a single-layer, parallel expert-mixing architecture: a Dense Selective GRU that fuses local context via lightweight 1-D convolutions and a data-driven gating mechanism, combined with a linear-attention expert; a mixing gate adaptively weights the two experts and a final gated MLP filters features, yielding O((2k+12)Nd²) complexity and 15–20 % speed-up over previous efficient SRS while maintaining SOTA accuracy.",
    "introduction": "# 1 Introduction\n\nIn this era of data exploding, sequential recommender systems (SRSs) [10, 12, 16-18, 20, 33, 35, 37] have gained much attention in capturing users' preferences within a large amount of sequential interaction data. GRU4Rec [10] as one of the earliest session-based recommendation models, employs stacked Gated Recurrent Units (GRU) for item-to-item recommendations. However, the RNN-based methods [10, 15] are fading from the recommendation realm due to their relatively lower accuracy. In recent years, transformer-based SRSs [12, 26] have become increasingly popular for the powerful multi-head attention mechanism [28, 36]. They exhibit remarkable ability in capturing sequential interactions and delivering accurate predictions [14]. However, despite their effectiveness, current transformer-based models suffer from substantial computational demands and extended inference time, which is caused by the dot product operation in the attention mechanism [18, 29, 40].\n\nTo tackle the issue of the high computational cost of transformer-based SRSs, linear attention mechanisms are applied to reduce the computational complexity. For example, LinRec [18] changes the\n\norder of dot product between query and key matrices by designing a special mapping, dramatically reducing the inference time. LightSAN [6] projects historical interactions into interest representations with shorter lengths, thereby reducing the computational complexity of transformers to a linear scale. MLP-based frameworks [16, 21, 39] can also achieve fast inference speed and high performance by reshaping input sequence tensors [7]. SSM-based models [17, 31] outperforms the existing attention mechanism by utilizing the efficient selective SSM [9], within which a structured state tensor is used to address long-range dependencies.\n\nHowever, to achieve high performance, the transformer-based SRSs, even with linear attention mechanism, require deeply stacked transformers, which decreases the model efficiency [34]. MLP-based SRSs with sequence mixing layers might suffer from extended inference time when dealing with long sequences. In addition, MLP-based models struggle to capture fine-grained positional dependencies. SSM-based models [17] may struggle to model effective semantic features into latent representations in long/short-term recommendation scenarios, as they might have difficulty learning important interactions. In this paper, we aim to further improve the efficiency and the accuracy of efficient models in various scenarios.\n\nTo further reduce resource consumption, accelerate inference speed, and enhance the model performance, we propose a novel efficient SRS framework named Gated Lightweight IntelligeNT Recurrent Units (GLINT-RU). Considering that stacking hybrid architectures may lead to a deeper model, which will cause a significant decrease in inference speed. and the traditional GRU module lacks the ability to adaptively adjust the output and filter out unimportant interactions. To tackle these challenges, we employ various gate mechanisms in appropriate positions to fully perceive the data environment and filter information automatically [1, 3, 34]. We introduce an expert mixing block that captures the item dependencies via GRU and utilizes linear attention to capture the global interaction information between users and items [11, 22]. This strategy not only improves the inference speed due to the linear computational complexity of paralleled GRU and linear attention mechanism but also enhances the context information. Additionally, we implement a dense selective GRU, which selects the output of the GRU adaptively and considers the connections among adjacent items. It leverages the gate mechanism to select crossed channels and extracts short-duration patterns to refine the model's understanding of user behavior dynamics. Moreover, a gated MLP block is utilized to select the outputs of the expert mixing block, deeply filtering the information based on the data environment.\n\nWe summarize the major contributions of our work as follows:\n\n- In this paper, we introduce GLINT-RU, a novel and lightweight SRS that achieves remarkable inference speed only requiring a single layer. It is an advanced model that captures complex semantic features and fine-grained positional representations using an expert mixing mechanism, which substantially improves the performance of GLINT-RU over existing efficient SRS models.\n\n- We introduce a dense selective GRU module, which not only incorporates connections between adjacent items but also empowers the model with the capability to selectively learn long-term dependencies. The integration of this advanced GRU module into the model markedly elevates its performance, establishing a new standard for efficient recommender systems.\n\n- We conduct extensive experiments to verify the efficiency and effectiveness of GLINT-RU on various datasets and parameter settings. Our GLINT-RU improves the training and inference speed significantly and stably exhibits high performance.",
    "method": "# 2 Preliminaries\n\nIn this section we will briefly introduce our recommendation task, and then introduce the basic efficient GRU and linear attention modules used in our framework.\n\n# 2.1 Problem Statement\n\nFor a sequential recommendation task, we have a set of users  $\\mathcal{U} = \\{u_1, u_2, \\dots, u_{|\\mathcal{U}|}\\}$  who have historical interactions with a set of items  $\\mathcal{V} = \\{v_1, v_2, \\dots, v_{|\\mathcal{V}|}\\}$ . Among these users, the  $i$ -th user has a preferred item sequence denoted as  $s_i = [v_1^{(i)}, v_2^{(i)}, \\dots, v_{n_i}^{(i)}]$ , where  $n_i$  is the length of the item list that the  $i$ -th user interacts with. Our goal is to design an efficient framework and predict the rating score of the next item based on the historical interactions.\n\n# 2.2 Gated Recurrent Units\n\nAs an essential part of GLINT-RU, the GRU [2] module contributes to the recommendation task by capturing the dependencies among the items and dynamically adjust its memory content [4, 24]. The update mechanism of a GRU cell is formulated as follows:\n\n$$\n\\begin{array}{l} z _ {t} = \\sigma \\left(\\boldsymbol {W} _ {z} \\cdot \\left[ \\boldsymbol {h} _ {t - 1}, \\boldsymbol {x} _ {t} \\right] + \\boldsymbol {b} _ {z}\\right), \\\\ \\boldsymbol {r} _ {t} = \\sigma \\left(\\boldsymbol {W} _ {r} \\cdot \\left[ \\boldsymbol {h} _ {t - 1}, \\boldsymbol {x} _ {t} \\right] + \\boldsymbol {b} _ {r}\\right), \\\\ \\tilde {\\boldsymbol {h}} _ {t} = \\tanh  (\\boldsymbol {W} \\cdot [ \\boldsymbol {r} _ {t} * \\boldsymbol {h} _ {t - 1}, \\boldsymbol {x} _ {t} ] + \\boldsymbol {b}), \\tag {1} \\\\ \\boldsymbol {h} _ {t} = \\boldsymbol {z} _ {t} * \\boldsymbol {h} _ {t - 1} + (1 - \\boldsymbol {z} _ {t}) * \\dot {\\boldsymbol {h}} _ {t}, \\\\ \\end{array}\n$$\n\nwhere  $\\sigma (\\cdot)$  is the sigmoid activation function,  $x_{t}$  is the input of GRU module in  $t$ -th time step,  $h_t$  represents the  $t$ -th hidden states,  $z_{t}$  and  $r_t$  are the update gate and the reset gate, respectively.  $b_{z}, b_{r}, b$  are bias,  $W_{z}, W_{r}, W$  are trainable weight matrices. As is shown in Eq.(1), GRU uses the update gate to control the retained information volume from previous hidden states in the current time step, while the reset gate controls the information that should be forgotten.\n\nThe GRU (Gated Recurrent Unit) module, equipped with update and reset gates in sequential GRU Cells, is adept at capturing the relationships among the items throughout the sequence while maintaining a relatively low computational complexity. However, the sequential information in GRU cannot be interacted with, and each hidden state is primarily encoded from preceding elements, which restricts the representational capacity of GRU-based recommendation models, particularly in capturing complex item dependencies across the entire sequence.\n\n# 2.3 Linear Attention Mechanism\n\nThe attention mechanism as a powerful core of the transformer structure, exhibits performance in learning sequence interactions in recommendation tasks. However, the high computational cost of the dot product between query matrix  $Q$  and key matrix  $K$  substantially lower the inference speed of transformer-based SRSs especially when the sequence length  $N$  is much larger than hidden size  $d$  [25, 29]. To tackle this issue, the linear attention mechanism [18] designs a special mapping function to change the order of the dot product\n\nand reduce the computational complexity to  $O(Nd^{2})$ . The linear attention mechanism can be written as:\n\n$$\nA ^ {\\prime} (Q, K, V) = \\chi_ {1} (e l u (Q)) (\\chi_ {2} (e l u (K)) ^ {\\mathrm {T}} V), \\tag {2}\n$$\n\nwhere  $\\mathcal{X}_1$  and  $\\mathcal{X}_2$  are row-wise and column-wise  $L_2$  normalization mappings, respectively,  $Q, K, V$  are learnable query, key and value matrices and  $A'$  is the output attention score. This approach mitigates the issue that the softmax layer concentrates on the scores of merely a few positions, enlarging the information capacity of the attention mechanism [18]. By implementing linear attention, our GLINT-RU framework is capable of learning interactions between items in long sequences.\n\n# 3 METHODOLOGY\n\nIn this section, we will introduce the overall framework and its components that effectively capture semantic features and positional information, followed by the complexity analysis of GLINT-RU.\n\n# 3.1 Framework Overview\n\nMany existing recommendation frameworks depend on transformer structure [12, 18, 26], which incurs substantial computational overhead and low inference speed. Restricted by the large computational complexity of stacked transformers, linear attention-based models have approached a plateau in terms of minimizing inference time and resource consumption. Uniquely, we propose an advanced recommendation framework that integrates the linear attention mechanism and efficient dense selective GRU module, which further reduces the computational cost compared with stacked linear transformers and SSM-based models. Additionally, this dense selective GRU module also enables our framework to understand both semantic features and dependencies from item sequences, and substantially reduce the computational cost and inference time.\n\nFigure 1.(a) shows the structure of our GLINT-RU. As is shown in Figure 1.(b)-(d), GLINT-RU integrates an expert mixing block for mixing sequential information from the dense selective GRU expert and the linear attention expert, and a gated MLP block for further learning and filtering complex user behaviors.\n\nIn the expert mixing block, the dense selective GRU module is employed to capture the long/short-term item-wise dependencies, and selectively learn the sequential information. In addition, the linear attention expert is responsible for modeling item interactions from the user. By combining these two powerful expert modules, our GLINT-RU is capable of adaptively learning both temporal and semantic item features from the sequence, which performs fine-grained modeling of complex user behaviors.\n\nAfter the user-item interactions are selectively learned by mixing block, the item scores are conveyed to the gated MLP block, where the information is filtered according to the data environment. The framework employs various gates in appropriate positions to deeply filter information, improving the model's flexibility and the ability to perceive and select information.\n\n# 3.2 Item Embedding Layer\n\nFor sequential recommendation tasks, information on items interacted by users should be encoded to tensors through the embedding layer [38]. We denote the length of input user-item interactions as  $N$ , and embedding size as  $d$ . For a interaction sequence  $s_i = [v_1, v_2, \\dots, v_n, \\dots, v_{n_i}]$ , the  $n$ -th item  $v_n \\in \\mathbb{R}^{D_n}$  can be projected into the representation  $e_n$  by the following formulation:\n\n$$\n\\boldsymbol {e} _ {n} = W _ {n} v _ {n}, \\tag {3}\n$$\n\nwhere  $W_{n}\\in \\mathbb{R}^{d\\times D_{n}}$  is trainable weighted matrix. The embedding layer outputs the encoded item sequence in a tensor:\n\n$$\n\\boldsymbol {E} = \\left[ \\boldsymbol {e} _ {1}, \\boldsymbol {e} _ {2}, \\dots , \\boldsymbol {e} _ {N} \\right] ^ {\\mathrm {T}}. \\tag {4}\n$$\n\nIn traditional transformer-based models, positional embeddings are typically necessary because the attention mechanism lacks the inherent capability to encode temporal information [12]. Uniquely, in this paper we employ the GRU module to model temporal item dependencies, which generates fine-grained representations with positional information for the items. Therefore, we decide not to add the positional embedding layer into the framework.\n\n# 3.3 Dense Selective GRU\n\nExisting GRU cell learns sequential data by conveying information from preceding cells. Although this mechanism has the superiority of capturing the long-term dependencies in the sequence, it predominantly focuses on information from previous items, while potentially overlooking the valuable context information provided by adjacent items, which are often closely related in real-world applications. To address these challenges, we introduce dense selective GRU shown in Figure 1.(b) as the core component of GLINT-TU. This innovation extracts local temporal features and generates fine-grained positional information using the update mechanism in GRU module. By implementing dense selective GRU, the computational complexity can be further reduced, and the recommendation accuracy of the GRU-based framework can be substantially improved.\n\n3.3.1 Dense GRU module. Therefore, to enable each GRU cell to aggregate local temporal features of user behavior, we introduce a temporal convolution layer, where adjacent item information is adaptively fused before being fed into the GRU module:\n\n$$\nC = \\text {T e m p o r a l C o n v 1 d} \\left(X W _ {0} + b _ {0}\\right) \\tag {5}\n$$\n\nwhere  $X = [x_{1}, x_{2}, \\ldots, x_{N}]^{\\mathrm{T}}$  is the input tensor with  $d$  feature dimensions, and  $C = [c_{1}, c_{2}, \\ldots, c_{N}]^{\\mathrm{T}}$  is the output of the convolution operation TemporalConv1d( $\\cdot$ ) with  $N$  steps.  $W_{0}$  and  $b_{0}$  are weight matrix and bias, respectively. The size of the convolution kernel is set as  $k$ . According to Eq.(1), the output of the GRUCell( $\\cdot$ ) can be divided into a latent item representation  $\\hat{h}_{n}$  and a fine-grained positional representation  $p_{n}$  learned by historical hidden states:\n\n$$\n\\begin{array}{l} \\boldsymbol {h} _ {n} = \\operatorname {G R U C e l l} \\left(\\boldsymbol {c} _ {n}, \\boldsymbol {h} _ {n - 1}\\right) = \\hat {\\boldsymbol {h}} _ {n} + \\boldsymbol {p} _ {n} \\\\ \\hat {\\boldsymbol {h}} _ {n} = \\left(1 - z _ {t}\\right) \\tilde {\\boldsymbol {h}} _ {n} + \\prod_ {i = 1} ^ {n} z _ {i} \\boldsymbol {h} _ {0}, \\quad \\boldsymbol {p} _ {n} = \\sum_ {k = 1} ^ {n - 2} \\prod_ {i = k + 1} ^ {n} z _ {i} \\left(1 - z _ {k}\\right) \\boldsymbol {h} _ {k} \\tag {6} \\\\ \\end{array}\n$$\n\nwhere  $z_{k}$  is the reset gate at the  $k$ -th time step. It is noteworthy that each positional representation  $\\pmb{p}_n$  is generated by aggregated historical hidden states with varied update intensities. Then we\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/e4a35e20c05be3bbb8feb189a32d8332d0e7524cb62d20b1eff16c8edbdb0ad1.jpg)\n\n\n\nFigure 1: (a). Framework of proposed GLINT-RU. (b). Expert mixing block employs paralleled attention and GRU to effectively learn semantic features and fine-grained positional information. (c). Dense Selective GRU as the core part of the framework, deeply selects and aggregates the hidden states. (d). Gated MLP block is utilized to deeply filter the feed forward network.\n\n\nproject the hidden states into a latent space using the channel crossing layer, which can be written as:\n\n$$\n\\Phi (\\boldsymbol {H}) = \\boldsymbol {H} \\boldsymbol {W} _ {H} + \\boldsymbol {b} _ {H}, \\tag {7}\n$$\n\nwhere  $\\pmb{H} = [h_1, h_2, \\dots, h_N]^{\\mathrm{T}}$  is the output of GRU,  $W_H$  is the learnable weight matrix and  $b_H$  are bias. Although each input state  $\\pmb{c}_t$  incorporates information from both preceding and subsequent items, each output hidden state is still determined by the hidden state of the preceding time step. Therefore, to capture the context information of the output sequential hidden states, we implement a temporal convolution on the crossed features. This convolution layer extracts local temporal features to understand user behavior dynamics, and enhance the predictive accuracy of our model:\n\n$$\nY = \\text {T e m p o r a l C o n v 1 d} (\\mathcal {G}) \\tag {8}\n$$\n\nwhere  $\\mathcal{G}$  is the Selective Gate function, and  $Y = [\\pmb{y}_1,\\pmb{y}_2,\\dots,\\pmb{y}_N]^{\\mathrm{T}}$  is the output matrix from the dense selective GRU module. The two convolution layers together with GRU cells improve the density of the sequential information, enabling each hidden state to be learned from behaviors of more input time steps.\n\n3.3.2 Selective Gate. To filter the hidden information of the GRU module, we design a selective gate where outputs of the feature crossing layer are selected based on the input state of the GRU. The selective gate weights are generated by two tiny linear layers with SiLU activation function [5], and we use them to select useful hidden states and filter information:\n\n$$\n\\boldsymbol {\\delta} _ {1} (C) = \\boldsymbol {C} \\boldsymbol {W} _ {\\delta} ^ {(1)} + b _ {\\delta} ^ {(1)}, \\tag {9}\n$$\n\n$$\n\\mathcal {G} (\\boldsymbol {H}) = \\Omega (\\delta_ {1} (\\boldsymbol {C}), \\boldsymbol {H}) = (\\mathrm {S i L U} (\\delta_ {1} (\\boldsymbol {C})) \\boldsymbol {W} _ {\\Omega} ^ {(1)} + \\boldsymbol {b} _ {\\Omega} ^ {(1)}) \\otimes \\Phi (\\boldsymbol {H}),\n$$\n\nwhere  $C = [c_1, c_2, \\ldots, c_N]^{\\mathrm{T}}$  also serves as the input of the GRU module,  $W_{\\delta}^{(1)}, W_{\\Omega}^{(1)}$  are weight matrices,  $b_{\\delta}^{(1)}, b_{\\Omega}^{(1)}$  are bias. With this gate mechanism, our GRU-based model could become more flexible with the ability to perceive the data environment.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/29650dc6bb07d39c4e87c50578d2d66a8d2074c9c57eb53e516ec3357679c067.jpg)\n\n\n\nFigure 2: General process of expert mixing mechanism. GRU captures long-term dependencies with recurrent latent and fine-grained positional representations. Attention layer learns semantic features fro important item interactions.\n\n\n# 3.4 Expert Mixing Block\n\nExisting efficient SRSs lack the ability to exploit semantic features, fine-grained positional information, and dependencies simultaneously. As is shown in Figure 1.(c), by introducing the linear attention mechanism and mixing these two powerful experts, the computational complexity will be substantially reduced compared with transformer-based models, and more high-quality item representations can be generated. Moreover, the two employed experts are parallel in our framework, which further improves the model's efficiency. The expert mixing mechanism is shown in Figure 2.\n\nIn real applications, the conditions of the data vary a lot. The GRU is naturally suited for sequential data, demonstrating effectiveness in sequential recommendation tasks that exhibit strong temporal dependencies, while attention focuses on relevant items in the sequence dynamically. To adapt to complex data conditions, we\n\nattribute appropriate weights to the two experts by a mixing gate:\n\n$$\n\\begin{array}{l} \\boldsymbol {M} = \\alpha_ {1} ^ {(t)} \\boldsymbol {A} ^ {\\prime} (\\boldsymbol {Q}, \\boldsymbol {K}, \\boldsymbol {V}) + \\alpha_ {2} ^ {(t)} \\boldsymbol {Y}, \\\\ \\alpha_ {i} ^ {(t)} = \\operatorname {s o f t m a x} \\left(\\alpha_ {i} ^ {(t - 1)}\\right) = \\frac {\\alpha_ {i} ^ {(t - 1)}}{e ^ {\\alpha_ {1} ^ {(t - 1)}} + e ^ {\\alpha_ {2} ^ {(t - 1)}}}, i = 1, 2, \\tag {10} \\\\ \\end{array}\n$$\n\nwhere  $\\alpha_{1}^{(t)},\\alpha_{2}^{(t)}$  are trainable mixing parameters at  $t$ -th training iteration. Then we filter this output by introducing another data-aware gate which selects the outputs based on the original input data batch:\n\n$$\n\\begin{array}{l} \\boldsymbol {\\delta} _ {2} (X) = \\boldsymbol {X} \\boldsymbol {W} _ {\\delta} ^ {(2)} + b _ {\\delta} ^ {(2)}, \\\\ Z = \\Omega_ {2} (\\delta_ {2} (X), M) = (\\operatorname {G e L U} (\\delta_ {2} (X))) \\otimes M, \\\\ \\end{array}\n$$\n\nwhere  $X$  is the input of expert mixing block,  $W_{\\delta}^{(2)}$  is the weight matrix of linear layer,  $\\pmb{b}_{\\delta}^{(2)}$  are bias.\n\n# 3.5 Gated MLP Block\n\nMost existing efficient SRSs, utilize two-layer feed forward networks to capture the nonlinear relationships among features before giving predictions. To further enhance the performance of the model and augment useful features from the expert mixing block, we introduce the gated MLP block shown in Figure 1.(d), which employs a gate mechanism again to deeply filter the information and generate item representations for predictions.\n\n$$\n\\begin{array}{l} \\boldsymbol {\\delta} _ {3} (Z) = Z \\boldsymbol {W} _ {\\delta} ^ {(3)} + b _ {\\delta} ^ {(3)}, \\\\ P = \\Omega_ {2} \\left(\\delta_ {3} (Z), Z\\right) = \\left(\\operatorname {G e L U} \\left(\\delta_ {3} (Z)\\right)\\right) \\otimes \\left(Z W + b\\right), \\tag {12} \\\\ R = P W _ {o} + b _ {o} \\\\ \\end{array}\n$$\n\nwhere  $Z$  is the output of expert mixing block,  $P$  denotes the output of gated linear layer,  $R$  represents the item representation, and  $W_{\\delta}^{(3)}, W_o, W$  are weight matrices,  $b_{\\delta}^{(3)}, b_o, b$  are bias. The recommendation scores are generated by item representations and embeddings, followed by the prediction score  $\\hat{y}_i$  of the  $i$ -th item:\n\n$$\n\\dot {y} _ {i} = \\operatorname {s o f t m a x} \\left(\\boldsymbol {R} _ {i} \\left(\\boldsymbol {e} _ {i}\\right) ^ {\\mathrm {T}}\\right), \\tag {13}\n$$\n\nwhere  $R_{i}$  is the representation of  $i$ -th item. Loss function, model training methods and the algorithm are displayed in Appendix A.\n\n# 3.6 Complexity Analysis\n\nIn this subsection, we will explain why GLINT-RU has inherent superiority over other popular SRS models in model efficiency.\n\nGiven that the sequence length is  $N$ , the embedding size is  $d$  and the kernel size for GLINT-RU is  $k$ , the time complexity of GLINT-RU is  $O((2k + 12)Nd^2)$ . The complexity is calculated throughout the network, from the embedding layer to the prediction layer. Discussion. Our GLINT-RU shows significantly low and linear time complexity, as GLINT-RU is a highly paralleled mixed network with only one layer to achieve high performance. Our framework utilizes paralleled expert networks and employs an efficient GRU module to capture long-term dependencies. GLINT-RU is more efficient than other models in the following aspects:\n\n- GLINT-RU v.s. Transformer-based SRSs: Firstly, traditional transformer-based model [12] suffers from large computational complexity, especially when the sequence length  $N$  is large. Linear attention mechanism [18] can be applied to substantially\n\nreduce the computational cost. However, they still require stacked transformer structures to achieve high performance, while GLINTRU achieves outstanding performance with only one layer.\n\n- GLINT-RU v.s. MLP-based SRSs: Secondly, The inference speed of the MLP-based models [7] may decrease when faced with long sequence length, as the sequence mixing layer has quadratic time complexity. In contrast, the paralleled expert module of GLINT-RU is more suitable for processing long sequential data.\n\n- GLINT-RU v.s. SSM-based SRSs: Thirdly, state-space models [9] may require complex matrix operations and recursive calculations, which may be difficult to parallelize efficiently in practical calculations. In contrast, GLINT-RU's paralleled expert module has a simpler update mechanism and higher efficiency.",
    "experiments": "# 4 Experiments\n\nIn this section, we conduct extensive experiments to show the effectiveness and efficiency of our GLINT-RU Framework. After we introduce our implementation details, the experiment results will be analyzed in detail. The experiments in this section are set to answer the following research questions:\n\n- RQ1: How does GLINT-RU framework perform compared with other state-of-the-art SRS baseline models?\n\n- RQ2: To what extent does GLINT-RU improve model efficiency compared with other state-of-the-art SRS frameworks?\n\n- RQ3: How do the dense selective GRU, the linear attention mechanism, and the gated MLP contribute to GLINT-RU?\n\n- RQ4: How does the hyperparameter setting affect the performance of GLINT-RU?\n\n# 4.1 Datasets and Evaluation Metrics\n\nWe evaluate GLINT-RU based on three benchmark datasets ML-1M $^2$ , Amazon-Beauty and Amazon video Games $^3$ . Below is the basic introduction of MovieLens-1M, Amazon Beauty, and Amazon Video Games datasets.\n\n- MovieLens 1M: comprises user ratings of movies. It includes about 1 million anonymous ratings from users who joined MovieLens. The dataset provides information about user IDs, movie IDs, ratings, and timestamps. It is widely used for research in collaborative filtering and recommendation systems.\n\n- Amazon Beauty: is a subset of the Amazon product data, focusing specifically on beauty products. It includes user reviews and ratings of various beauty products available on Amazon. The dataset contains metadata such as product descriptions, categories, prices, and brand information. It is valuable for research in sentiment analysis, product recommendations, and consumer behavior analysis within the beauty industry.\n\n- Amazon Video Games: is a subset of the Amazon product data, focusing specifically on video game products. It includes user reviews and ratings of various video game products available on Amazon. The dataset contains metadata such as product descriptions, categories, price, and platform information. It is also valuable for research in sentiment analysis, product recommendation, and consumer behavior analysis in the video games domain.\n\n\nTable 1: Statistical Information of Adopted Datasets.\n\n\n<table><tr><td>Datasets</td><td># Users</td><td># Items</td><td># Interactions</td><td>Avg.Length</td><td>Sparsity</td></tr><tr><td>ML-1M</td><td>6,041</td><td>3,707</td><td>1,000,209</td><td>165.60</td><td>95.53%</td></tr><tr><td>Beauty</td><td>22,364</td><td>12,102</td><td>198,502</td><td>8.88</td><td>99.93%</td></tr><tr><td>Video Games</td><td>24,304</td><td>10,673</td><td>231,780</td><td>9.54</td><td>99.91%</td></tr></table>\n\nStatistical information of the three datasets is shown in Table 1, where all the three datasets are sparse. The two Amazon datasets have relatively small data volumes, about 200,000, but they have a large number of users and items, and the average length of interaction sequences is short. In contrast, ML-1M has a larger data volume, reaching 1 million, but the number of users and items is small, with much longer interaction sequence lengths.\n\nWe adopt Recall, Mean Reciprocal Rank (MRR), and Normalized Discounted Cumulative Gain (NDCG) as the evaluation metrics for our experiments. The interactions are grouped by users chronologically, and the datasets are split by the leave-one-out strategy [18]. To be more specific, the penultimate item of the interaction sequence is used for validation. Therefore, the size of validation set is determined by the number of users.\n\n# 4.2 Baselines\n\nIn this paper, we compare our GLINT-RU with two types of baseline models, i.e., traditional SRS models and efficient SRS models. The traditional SRS model includes various SRS benchmarks, while the efficient SRS models improve existing model's structure and computational methods, thus significantly enhancing the model efficiency. Adopted baselines are listed as follows:\n\n# Traditonal SRS models\n\n\n\n(1) GRU4Rec [10]: utilizes GRUs to capture sequential dependencies within user interactions for session-based recommendations.\n\n\n\n\n\n(2) BERT4Rec [26]: adapts the Bidirectional Encoder Representations from Transformers (BERT) architecture to model user behaviors for personalized recommendation.\n\n\n\n\n\n(3) SASRec [12]: captures long-term and short-term user preferences by applying a multi-head attention mechanism.\n\n\n\n# Efficient SRS Models\n\n\n\n(1) LinRec [18]: reduces the computational costs substantially by changing the dot product of attention mechanism in the transformer-based models. We select SASRec as the backbone of LinRec.\n\n\n\n\n\n(2) SMLP4Rec [7] uses a tri-directional fusion scheme to learn correlations on sequence, channel, and feature dimensions efficiently.\n\n\n\n\n\n(3) LightSAN [6] projects the initial interactions into representations with shorter lengths, which is also an efficient approach for transformer-based models.\n\n\n\n\n\n(4) Mamba4Rec [17]: explores the potential of selective SSMs for efficient sequential recommendation, which substantially improve the efficiency of SRS models.\n\n\n\n# 4.3 Implementation\n\nIn this subsection, we introduce the implementation details of the GLINT-RU. We use Adam optimizer [13] with the learning rate of 0.001 for our training process. Both the train and evaluation batch size are set as 2048. The hidden size is set as 128 for ML-1M and 64 for Amazon Beauty and Video Games. As is shown in Table 1, the average length of ML-1M, Beauty, and Video Games are 165, 8.88,\n\nand 9.54, so we set the maximum sequence length as 200 for ML-1M, and 100 for the two amazon datasets. We adopt the dropout rate of 0.5 for Amazon datasets considering their high level of sparsity, compared with 0.2 for ML-1M. We construct the attention-based baselines with 2 transformer layers so that they can achieve high performance. Other implementation details follow the settings of original papers [7, 17, 18]. Please find the complete hyperparameter settings and more implementation details in Appendix B.\n\n# 4.4 Overall Performance (RQ1)\n\nIn this subsection, we compare the performance of GLINT-RU with both traditional recommendation frameworks and state-of-the-art efficient models. The results, as shown in Table 2, demonstrate the effectiveness of GLINT-RU on metrics Recall@10, MRR@10, and NDCG@10 in bold. According to the above table, it is evident that GLINT-RU defeats all the selected transformer-, RNN-, MLP-, and SSM-based baselines. We improve the performance upper bound of efficient recommendation models by  $0.34\\% \\sim 3.74\\%$ .\n\nTraditional RNN-based models, like GRU4Rec, might have difficulty in dealing with complex user behaviors. Although it can capture the long-term dependencies from long sequences, it struggles to learn effectively from extremely sparse datasets. Traditional attention-based methods like BERT4Rec and SASRec have great performance on the three datasets, but it is quite inefficient due to the high computational complexity of the attention mechanism.\n\nEfficient model LinRec changes the softmax operation, and takes attention scores from more positions into consideration, improving the performance on long-term sequential recommendation tasks compared with its backbone SASRec. SMLP4Rec and Mamba4Rec achieve impressive performance on the three datasets. However, Mamba4Rec shows enhanced proficiency in modeling long sequences (ML-1M) but exhibits low performance in relatively short sequences (Beauty and Video Games). Conversely, the SMLP4Rec shows superior performance in tasks with short sequences while being less effective with longer sequences. Additionally, SMLP4Rec requires features from the items to enhance its performance. Uniquely, GLINT-RU integrates the advantages of a linear attention mechanism and dense selective GRU module, adaptively extracting dependencies from recurrent latent item representations, fine-grained positional representations, and important semantic features. The gate mechanism employed in GLINT-RU substantially enhances its ability to filter the information based on the dynamic data environment and mix the experts according to the data adaptively.\n\nIn summary, GLINT-RU as a novel efficient framework, shows its superiority over state-of-the-art baselines. This underscores the potential of dense selective GRU and models with hybrid modules as more powerful tools for recommendation tasks.\n\n# 4.5 Efficiency Comparison (RQ2)\n\nIn this subsection, we analyze the efficiency of GLINT-RU and state-of-the-art sequential recommendation models. We evaluate the model efficiency according to the inference time of each mini-batch, training time, and GPU memory occupation.\n\nThe results, shown in Table 3, provide several valuable insights: Firstly, by utilizing the efficient Dense GRU module and linear attention module, GLINT-RU dramatically reduces the training\n\n\nTable 2: Overall performance comparison between GLINT-RU and baselines.\n\n\n<table><tr><td rowspan=\"2\">Models</td><td colspan=\"3\">ML-1M</td><td colspan=\"3\">Amazon Beauty</td><td colspan=\"3\">Amazon Video Games</td></tr><tr><td>Recall@10</td><td>MRR@10</td><td>NDCG@10</td><td>Recall@10</td><td>MRR@10</td><td>NDCG@10</td><td>Recall@10</td><td>MRR@10</td><td>NDCG@10</td></tr><tr><td>GRU4Rec</td><td>0.6954</td><td>0.4055</td><td>0.4748</td><td>0.3851</td><td>0.1891</td><td>0.2351</td><td>0.6028</td><td>0.2929</td><td>0.3660</td></tr><tr><td>BERT4Rec</td><td>0.7119</td><td>0.4041</td><td>0.4776</td><td>0.3478</td><td>0.1584</td><td>0.2027</td><td>0.5490</td><td>0.2541</td><td>0.2916</td></tr><tr><td>SASRec</td><td>0.7205</td><td>0.4251</td><td>0.4958</td><td>0.4332</td><td>0.2325</td><td>0.2798</td><td>0.6459</td><td>0.3404</td><td>0.4128</td></tr><tr><td>LinRec</td><td>0.7184</td><td>0.4316</td><td>0.5002</td><td>0.4270</td><td>0.2314</td><td>0.2775</td><td>0.6384</td><td>0.3355</td><td>0.4073</td></tr><tr><td>LightSANs</td><td>0.7195</td><td>0.4314</td><td>0.5003</td><td>0.4406</td><td>0.2358</td><td>0.2840</td><td>0.6488</td><td>0.3415</td><td>0.4142</td></tr><tr><td>SMLP4Rec</td><td>0.6753</td><td>0.3870</td><td>0.4558</td><td>0.4457</td><td>0.2408</td><td>0.2891</td><td>0.6480</td><td>0.3484</td><td>0.4195</td></tr><tr><td>Mamba4Rec</td><td>0.7238</td><td>0.4368</td><td>0.5054</td><td>0.4233</td><td>0.2213</td><td>0.2689</td><td>0.6488</td><td>0.3389</td><td>0.4123</td></tr><tr><td>GLINT-RU</td><td>0.7379*</td><td>0.4517*</td><td>0.5202*</td><td>0.4472*</td><td>0.2498*</td><td>0.2964*</td><td>0.6573*</td><td>0.3549*</td><td>0.4266*</td></tr><tr><td>Improv.</td><td>1.95%</td><td>3.30%</td><td>2.93%</td><td>0.34%</td><td>3.74%</td><td>2.53%</td><td>1.31%</td><td>1.87%</td><td>1.69%</td></tr></table>\n\n\nRecommendation performance of GLINT-RU and existing state-of-the-art benchmark SRS models have been shown. \\* indicates the improvements are statistically significant (i.e., two-sided t-test with  $p <   0.05$  ) over baselines). The best results are bolded, and the second-best are underlined.\n\n\n\nTable 3: Efficiency comparison.\n\n\n<table><tr><td>Datasets</td><td>Model</td><td>Infer.</td><td>Training</td><td>GPU Memory</td></tr><tr><td rowspan=\"8\">ML-1M</td><td>BERT4Rec</td><td>88ms</td><td>285s/epoch</td><td>21.51GB</td></tr><tr><td>SASRec</td><td>55ms</td><td>172s/epoch</td><td>21.51GB</td></tr><tr><td>LinRec</td><td>37ms</td><td>101s/epoch</td><td>11.67GB</td></tr><tr><td>LightSANs</td><td>43ms</td><td>130s/epoch</td><td>16.99GB</td></tr><tr><td>SMLP4Rec</td><td>51ms</td><td>151s/epoch</td><td>16.13GB</td></tr><tr><td>Mamba4Rec</td><td>41ms</td><td>108s/epoch</td><td>7.72G</td></tr><tr><td>GLINT-RU</td><td>31ms</td><td>86s/epoch</td><td>8.81G</td></tr><tr><td>Improv.</td><td>16.22%</td><td>17.44%</td><td>-</td></tr><tr><td rowspan=\"8\">Beauty</td><td>BERT4Rec</td><td>1372ms</td><td>13s/epoch</td><td>11.69GB</td></tr><tr><td>SASRec</td><td>444ms</td><td>8.1s/epoch</td><td>7.67GB</td></tr><tr><td>LinRec</td><td>340ms</td><td>5.6s/epoch</td><td>4.14GB</td></tr><tr><td>LightSANs</td><td>427ms</td><td>7.2s/epoch</td><td>4.57GB</td></tr><tr><td>SMLP4Rec</td><td>361ms</td><td>5.3s/epoch</td><td>2.95GB</td></tr><tr><td>Mamba4Rec</td><td>351ms</td><td>4.5s/epoch</td><td>2.32G</td></tr><tr><td>GLINT-RU</td><td>278ms</td><td>3.8s/epoch</td><td>2.62G</td></tr><tr><td>Improv.</td><td>18.24%</td><td>15.56%</td><td>-</td></tr><tr><td rowspan=\"8\">Video Games</td><td>BERT4Rec</td><td>1290ms</td><td>15s/epoch</td><td>10.98GB</td></tr><tr><td>SASRec</td><td>406ms</td><td>9.6s/epoch</td><td>7.65GB</td></tr><tr><td>LinRec</td><td>327ms</td><td>6.6s/epoch</td><td>4.13GB</td></tr><tr><td>LightSANs</td><td>369ms</td><td>8.3s/epoch</td><td>4.55GB</td></tr><tr><td>SMLP4Rec</td><td>389ms</td><td>9.1s/epoch</td><td>3.38GB</td></tr><tr><td>Mamba4Rec</td><td>309ms</td><td>5.6s/epoch</td><td>2.28G</td></tr><tr><td>GLINT-RU</td><td>247ms</td><td>4.5s/epoch</td><td>2.49G</td></tr><tr><td>Improv.</td><td>20.06%</td><td>19.64%</td><td>-</td></tr></table>\n\n\nInference time of each mini-batch (batch size = 2048), training time and GPU memory of GLINT-RU and other baseline models. The best results are bolded, and the second best results are underlined.\n\n\ntime and inference time, improving the training inference time by  $15\\% \\sim 20\\%$  compared with most efficient recommendation baseline models. In addition, due to the low computational cost of GRU and linear attention mechanism, GLINT-RU exhibits minimal GPU memory consumption, which is comparable to the state-of-the-art SSM-based efficient model Mamba4Rec. In Section 3.6, we demonstrate that the GLINT-RU exhibits low theoretical computational\n\n\nTable 4: Ablation study for Components of GLINT-RU.\n\n\n<table><tr><td>Model Components</td><td>Recall@10</td><td>MRR@10</td><td>NDCG@10</td></tr><tr><td>Default</td><td>0.7379*</td><td>0.4517*</td><td>0.5202*</td></tr><tr><td>w/o Gated MLP (Light GLINT-RU)</td><td>0.7260</td><td>0.4369</td><td>0.5060</td></tr><tr><td>w/o Attention</td><td>0.7195</td><td>0.4312</td><td>0.5001</td></tr><tr><td>w/o GRU</td><td>0.6762</td><td>0.3913</td><td>0.4593</td></tr><tr><td>w/o Temporal Conv1d</td><td>0.7232</td><td>0.4322</td><td>0.5019</td></tr></table>\n\n\n$*$  indicates the improvements are statistically significant (i.e., two-sided t-test with  $p < 0.05$ ) over baselines)\n\n\ncomplexity, as we employ the parallel networks and efficient GRU as core components of our recommender system. The theoretical analysis has been verified by the results in Table 3.\n\nTraditional transformer-based recommendation models like SASRec and BERT4Rec suffer from extended inference time and high GPU memory occupation. When processing long sequential data, the conventional attention mechanism falls behind novel efficient models due to its high computational cost. Among all the baseline models, the SSM-based Mamba4Rec framework exhibits impressive efficiency, but Mamba requires complex mathematical computation, which slows down its inference and training speed. Additionally, LinRec suffers from the inherent shortage of its backbone SASRec that requires stacked transformer layers to enhance the model performance. Such large transformer structures extend both the inference and training time. Although SMLP4Rec achieves high performance in the model accuracy, it struggles to train and inference efficiently, especially when processing long-term sequential data.\n\n# 4.6 Ablation Study (RQ3)\n\nIn the ablation study, we remove the gated MLP block, linear attention expert, dense selective GRU expert, and the two temporal convolution layers individually to verify the efficacy of each component. We conduct the ablation study on the ML-1M dataset, and the results are outlined in Table 4, providing insightful observations.\n\nThe results verify the essential role of the dense selective GRU module, as the performance of the model will dramatically decrease\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/b72a54e8f05bdbe9bc7deb084128bf1095b98cadb5de6ad70eb990b459d291f5.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/62c2741e6ac4e934091b3b184cb3031c567d343bb57add498cb5b3634c599cdf.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/9ca99eea89ce7cb7bdd8577fb88443f8f08ee3c353f5f72d9f401b8a81afac3f.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/99f6f5d7d1a163879b8d0fa527171cc5ff254dce75958c9a2f2e37b049545cd0.jpg)\n\n\n\nFigure 3: Impacts of kernel size  $k$  of the temporal convolution on the performance of GLINT-RU and Mamba4Rec and the GPU Memory occupation of GLINT-RU.\n\n\nwithout the GRU module. This reveals the insights that the gated GRU module effectively captures the dependencies of interactions with fine-grained positional representations. The linear attention mechanism understands the interactions of relevant items in the sequence. As is shown in Table 4, it improves the performance of GLINT-RU to some extent. Adding a temporal convolution layer incorporates context information from adjacent items, resulting in an enhancement in model performance. In addition, the gated MLP block plays a similar role as the feed-forward network in our framework, which filters complex information from the expert mixing block. It is noteworthy that even without the gated MLP block our framework still outperforms all the state-of-the-art efficient models, demonstrating its inherent remarkable superiority for sequential recommendation tasks. After we remove the gated MLP, the GPU memory occupation of GLINT-RU becomes 7.63GB, less than Mamba4Rec shown in Table 3, and the inference time will be reduced to 241ms. We name this framework \"Light GLINT-RU\", which is more applicable to resource-constrained scenarios. We further discuss the ablation study on activation functions in Appendix C, where we highlight their impact on performance. Additionally, we provide a detailed analysis of the ablation study conducted on the Amazon Beauty and Amazon Video Games datasets in Appendix E, emphasizing the contributions of each component to the overall performance of GLINT-RU.\n\n# 4.7 Parameter Analysis\n\nWe conduct parameter analysis on the dataset Amazon Beauty. We will first analyze the impact of the crucial hyperparameter kernel size  $k$  in GLINT-RU, and then we will analyze the model performance as the hidden size  $d$  and number of GLINT-RU layers  $L$  changes. The discussion on these parameters provides valuable insights into the superiority of GLINT-RU.\n\nKernel size  $k$ . The impacts of the parameter  $k$  on the model performance are shown in Figure 3 and 4. Figure 3.(a)-(c) displays the model performance of GLINT-RU with different kernel sizes.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/37c287901ac11342ef3c726408ade7d7ddda2e35725fe8460498df73e538accf.jpg)\n\n\n\nFigure 4: Impacts of kernel size  $k$  of the temporal convolution on the training and inference time.\n\n\nOur model exhibits stable and high performance, providing a wide range of kernel sizes. This finding indicates the robustness of the GLINT-RU framework. This enhancement in performance can be attributed to the fact that a larger kernel size aggregates information from more items, thereby learning a more extensive context into the hidden state. However, as the kernel size continues to expand, dense selective GRU might incorporate irrelevant data into the output state, which might lead to a marginal decline in the accuracy. Mamba4Rec as a novel efficient SSM-based model, also employs a temporal convolution layer in the model structure. As the kernel size changes, the performance of Mamba4Rec becomes quite unstable compared with our GLINT-RU. Our GLINT-RU consistently outperforms Mamba4Rec across all kernel sizes, further demonstrating the superiority of this novel GLINT-RU framework.\n\nAs can be seen in the hist plots in Figure 3.(d) and Figure 4, increasing the kernel size has slight impacts on the training/inference time of each mini-batch and the GPU memory occupation, which further verifies the efficiency and stability of our model.\n\nHidden size  $d$ . We change the model size by using different hidden sizes  $d$  and compare the performance of GLINT-RU with state-of-the-art baselines. The results shown in Figure 5.(a)-(c) indicate that GLINT-RU achieves state-of-the-art performance at small hidden sizes. When  $d$  is set as 64, the predictive efficacy of the GLINT-RU substantially surpasses the upper bounds of performance achieved by other baseline models. Achieving excellent results with a relatively small model dimension illustrates the superior expressiveness and significant advantages of the GLINT-RU. SMLP4Rec requires additional features to enhance the model accuracy, and its inference speed is significantly affected by the variation in the hidden size, demonstrating relatively low efficiency. The prediction accuracy of Mamba4Rec is inferior and decreases dramatically as the hidden size  $d$  gets larger, indicating that it struggles to learn effective information from short behavior sequences. Attention-based models SASRec, LightSAN, and LinRec show more stable results, but they can only capture item interactions to predict the ratings and require stacked transformers to achieve relatively high performance, which has negative impacts on model efficiency in Figure 5.(d).\n\nNumber of Layers  $L$ . We increase the number of GLINT-RU layers from 1 to 4 and observe the model performance and efficiency. The results and the experimental details are illustrated in Appendix D.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/d46563cd39f78eda5e84a19b2fbca5385e6cb55b06a520f98cbffe0b149dd4f6.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/c26bf0ca61c5543a8ab556b0c716b0f2b7c5eeb3a6bfd1c810193f12ffccf174.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/73dfb7e07b150daeaeb9b4a198a00b8bdaf7a7db29eddcf8c9c82610027496c7.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-11/ee5fd411-0a36-4c52-84c6-d66a299804ff/757d06e2ecf46f4bdb8fcac1e56dde976d54af51060cefbe346929676de3b940.jpg)\n\n\n\nFigure 5: Impacts of hidden size  $d$  on the performance of GLINT-RU and state-of-the-art baselines.\n\n\nThe results indicate that our single-layer GLINT-RU can achieve high model efficiency and accuracy simultaneously.\n\nIn summary, GLINT-RU effectively combines the long/short-term dependencies with effective positional representations and important interactions which enables it to be an accurate and efficient SRS under a broad range of parameter choices.",
    "hyperparameter": "learning-rate=0.001 (Adam), batch-size=2048, hidden-size=128 for ML-1M and 64 for Amazon datasets, max-seq-length=200 for ML-1M and 100 for Amazon (since avg length 165.6 vs 8-9 respectively), embedding-size=hidden-size (unified), dropout-prob=0.2 for ML-1M and 0.5 for Amazon (higher dropout for 99.93% sparsity), temporal-conv kernel-size k∈[3,7] with best performance around k=5 (wider range provides robustness), num-layers=1 (single expert mixing layer for efficiency), n-heads=2 (for linear attention decomposition), no-positional-embeddings (GRU's recurrent mechanism inherently encodes temporal position through hidden state evolution), layer-norm applied after input embedding and before each gating mechanism to maintain numerical stability especially in linear attention and multiple gates."
  }