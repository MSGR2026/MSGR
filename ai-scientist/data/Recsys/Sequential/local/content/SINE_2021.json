{
  "id": "SINE_2021",
  "paper_title": "Sparse-Interest Network for Sequential Recommendation",
  "alias": "SINE",
  "year": 2021,
  "domain": "Recsys",
  "task": "SequentialRecommendation",
  "idea": "",
  "introduction": "# 1 INTRODUCTION\n\nRecommender systems have been widely applied to many online services such as E-commerce, advertising, and social media to perform personalized information filtering [14, 17, 31, 46]. At its core is to estimate how likely a user will interact with an item based on the past actions, e.g., purchases and clicks. Traditional recommendation methods adopt collaborative filtering approaches [35] to address the problem by assuming that behaviorally similar users would exhibit similar preferences on items. Recently, neural-based deep recommendation models have shown revolutionary performance in many recommendation scenarios, due to the powerful expressive ability of deep learning. For example, NCF [14] extends matrix factorization based models [35] by replacing the interaction function of inner product with nonlinear neural networks. PinSage [46] is built on GraphSage [10], and learns user and item embeddings by conducting convolutional operations on the user-item interaction graph. However, these methods ignore the sequential structure in\n\nuser behaviors and thus fail to capture the correlations between adjacent behaviors.\n\nSome recent works formalize recommendation as a sequential problem. The principal idea behind this is to represent each user with an ordered sequence and assume its order matters. With a user's behavior history, the sequential recommendation approach first sorts the past behaviors to obtain the ordered sequence. After that, the sequence will be fed into different neural sequential modules (e.g., recurrent neural network [17], convolutional network [42], and Transformer [21]) to generate an overall user embedding vector, which is then used to predict the next interested item. Since the sequential recommendation approach reflects the real-world recommendation situation, it has attracted much attention in modern recommendation systems.\n\nDespite the recent advances, we argue that existing sequential recommendation models may be sub-optimal for next-item prediction due to the bottleneck of learning a single embedding from the user's behavior sequence. Each user in an E-commerce platform usually interacts with several types of items over time that are conceptually different. For example, we find that the number of categories of items that belong to different categories in a user's recent fifty behaviors is around 10 on Taobao dataset [51]. With multiple user's intentions<sup>1</sup>, we also observe that, in Figure 1, an overall user embedding vector learned from a behavior sequence is primarily affected by the recent most frequent actions. Thus, it may fail to extract related information for learning to predict the next item if its conceptually similar items are not dominant in recent interactions. Therefore, a promising alternative solution is to learn multiple embedding vectors from a user's behavior sequence, where each embedding vector encodes one aspect of the user's interests.\n\nHowever, there are several challenges for effectively extracting multiple embedding vectors from the user's behavior sequence in industry-level data. First, items are often not conceptually well clustered in real systems. Although category information of items can be used as concepts, in many cases, such type of auxiliary information may not be available or reliable due to annotation noise in practice. The second challenge is to adaptively infer a sparse set of interested concepts for a user from the large concept pool. The inference procedure includes a selection operation, which is a discrete optimization problem and hard to train end-to-end. Third, given multiple interest embedding vectors, we need to determine which interest is likely to be activated for next-item predictions. During training, the next predicted item could be used as a label to activate the preferred intention, but the inference stage has no such label. The model has to predict a user's next intention adaptively.\n\nIn this paper, we propose a novel Sparse-Interest Nework (SINE) for sequential recommendation to address these issues. SINE can learn a large pool of interest groups and capture multiple intentions of users in an end-to-end fashion. Figure 4 shows the overall structure of SINE. Our sparse interest extraction module adaptively infers the interacted interests of a user from a large pool of interest groups and outputs multiple interest embeddings. The aggregation module enables dynamically predicting the user's next intention, which\n\nhelps to capture multi-interests for top-N item recommendation explicitly. We conduct experiments on several public benchmarks and an industrial dataset. Empirical results show that our framework outperforms state-of-the-art models and produces reasonable item clusters. To summarize, the main contributions of this paper are:\n\n- We propose a comprehensive framework that integrates large-scale item clustering and sparse-interest extraction jointly in a recommender system.  \n- We investigate an adaptive interest aggregation module to explicitly model users' multiple interests for top-N recommendation in the sequential recommendation scenario.  \n- Our model not only achieves state-of-the-art performance on several real-world challenging datasets, but also produces reasonable interest groups to assist multi-interest extraction.",
  "method": "# 3 METHODOLOGY\n\nIn this section, we first introduce the problem formulation and then discuss the proposed framework in detail. Finally, we discuss the difference between our framework and existing methods.\n\n# 3.1 Notations and Problem Formulation\n\nAssume  $\\{\\mathbf{x}^{(u)}\\}_{u = 1}^{N}$  be the behavior dataset consists of the interactions between  $N$  users and  $M$  items.  $\\mathbf{x}^{(u)} = [x_1^{(u)},x_2^{(u)},\\dots ,x_n^{(u)}]$  is the ordered sequence of items clicked by user  $u$ , where  $n$  is the number of clicks made by user  $u$ . Each element  $x_{t}^{(u)}\\in \\{1,2,\\dots ,M\\}$\n\nin the sequence is the index of the item being clicked. Note that, due to the strict requirements of latency and performance, industrial recommender systems consist of two stages, the matching stage and ranking stage [6]. The matching stage aims to retrieve top- $N$  candidate items from a large volume of item pool, while the ranking stage targets to sort the candidate items by more precise scores. We focus on improving the effectiveness of the matching stage, where the task is to retrieve high-quality candidate items that the user might be clicked with based on the observed sequence  $\\mathbf{x}^{(u)}$ .\n\n# 3.2 Sparse-Interest Framework\n\nAs the item pools of real-world recommender systems often consist of millions or even billions of items, the matching stage is crucial in modern recommender systems. Specifically, a deep sequential model in the matching stage typically has a sequence encoder  $\\phi_{\\theta}(\\cdot)$  and an item embedding table  $\\mathbf{H} \\in \\mathbb{R}^{M \\times D}$ , where  $\\theta$  is the set that contains all the trainable parameters including  $\\mathbf{H}$ . The encoder takes the user's historical behavior sequence  $\\mathbf{x}^{(u)}$  as input and outputs the representation of the sequence  $\\phi_{\\theta}(\\mathbf{x}^{(u)})$ , which can be viewed as the representation of the user's intention. The user's intention embedding is then used as a query to generate his/her candidate items from the item pool via a fast K nearest neighbor algorithm (i.e., faiss [20]). Most encoders  $\\phi_{\\theta}(\\cdot)$  in the literature output a single  $D$ -dimensional embedding vector, while there are also models that output  $K$ $D$ -dimensional embedding vectors to preserve the user's intentions under  $K$  latent categories. We mainly focus on the latter direction and target to capture a user's diverse intentions accurately.\n\nThe state-of-art sequence encoders for capturing a user's multiple intentions can be summarized into two categories. The first type of methods resort to powerful sequential encoders to implicitly extract the user's multiple intentions, such as models based on multi-head self-attention (aka the Transformer [43]). The other\n\ntype of methods rely on the latent prototype to explicitly capture a user's multiple intentions. In general, the former approach may limit its ability to capture multiple intentions due to the mixed nature of intention detection and embedding in practice. For example, the empirical results show that the multiple vector representations learned by Transformer do not seem to have a clear advantage over the single-head implementation [21] for recommendation. In contrast, the later can effectively extract a user's diverse interests with the help of concept identified via clustering as empirically proved in [27, 29]. However, these methods scale poor because they require each user has an intention embedding under every concept, which easily scales up to thousands in industrial applications. For instance, millions or even billions of items belong to more than 10 thousand expert-labeled leaf categories [24] in the e-commerce platform of Tmall in China. With a large pool of interest concepts in real systems, a scalable multi-interest extraction module is needed.\n\nTherefore, we propose a sparse-interest network here, which offers the ability to adaptively activate a subset of concepts from the large concept pool for a user. The input of our model is the user's behavior sequence  $\\mathbf{x}^{(u)}$ , which is then fed into an embedding layer and transformed into item embedding matrix  $\\mathbf{X}^u \\in \\mathbb{R}^{n \\times D}$ . Let  $\\mathbf{C} \\in \\mathbb{R}^{L \\times D}$  denotes the overall conceptual prototype matrix, and  $\\mathbf{C}^u \\in \\mathbb{R}^{K \\times D}$  indicates the activated prototypical embedding matrix on  $K$  latent concepts for user  $u$ .  $L$  is the total number of concepts.\n\n3.2.1 Concept activation. Our sparse-interest layer starts by inferring the interested conceptual prototypes  $\\mathbf{C}^u$  for each user  $u$ . Given  $\\mathbf{X}^u \\in \\mathbb{R}^{n \\times D}$ , the self-attentive method [26] is first applied to aggregate the input sequence selectively.\n\n$$\n\\mathbf {a} = \\operatorname {s o f t m a x} \\left(\\tanh  \\left(\\mathbf {X} ^ {u} \\mathbf {W} _ {1}\\right) \\mathbf {W} _ {2}\\right), \\tag {1}\n$$\n\nwhere  $\\mathbf{W}_1\\in \\mathbb{R}^{D\\times D}$  and  $\\mathbf{W}_2\\in \\mathbb{R}^D$  are trainable parameters. The vector  $\\mathbf{a}\\in \\mathbb{R}^n$  is the attention weight vector of user behaviors. When we sum up the embeddings of input sequence according to the attention weight, we can obtain a virtual concept vector  $\\mathbf{z}_u = (\\mathbf{a}^\\top \\mathbf{X}^u)^\\top$  for the user.  $\\mathbf{z}_u\\in \\mathbb{R}^D$  reflects the user's general intentions and could be used to activate the interested conceptual prototypes as:\n\n$$\n\\mathbf {s} ^ {u} = \\langle \\mathbf {C}, \\mathbf {z} _ {u} \\rangle ,\n$$\n\n$$\n\\operatorname {i d x} = \\operatorname {r a n k} \\left(\\mathbf {s} ^ {u}, K\\right), \\tag {2}\n$$\n\n$$\n\\mathbf {C} ^ {u} = \\mathbf {C} (\\operatorname {i d x},:) \\odot (\\operatorname {S i g m o i d} (\\mathbf {s} ^ {u} (\\operatorname {i d x},:)) ^ {T}),\n$$\n\nwhere  $\\mathrm{rank}(\\mathbf{s}^u,K)$  is the top-K ranking operator, which returns the indices of the  $K$ -largest values in  $\\mathbf{s}^u$ . The index returned by  $\\mathrm{rank}(\\mathbf{s}^u,K)$  contains the indices of prototypes selected for user  $u$ .  $\\mathbf{C}(\\mathrm{idx},:)$  performs the row extraction to form the sub-prototype matrix, while  $\\mathbf{s}(\\mathrm{idx},:)$  extracts values in  $\\mathbf{s}^u$  with indices idx.  $1\\in \\mathbb{R}^{K}$  is a vector with all elements being 1.  $\\odot$  represents Hadamard product and  $\\langle \\cdot ,\\cdot \\rangle$  is inner product.  $\\mathbf{C}^u\\in \\mathbb{R}^{K\\times D}$  is the final activated  $K$  latent concept embedding matrix for user  $u$ . Equation 2 is a top- $K$  selection trick that enables discrete selection operation differentiable, prior work [8] has found that it is very effective in approximating top- $K$  selection problem.\n\n3.2.2 Intention assignment. After inferring the current conceptual prototypes  $\\mathbf{C}^u$ , we can estimate the user intention related with each item in his/her behavior sequence according to their distance to\n\nthe prototypes.\n\n$$\nP _ {k \\mid t} = \\frac {\\exp \\left(\\text {L a y e r N o r m} _ {1} \\left(\\mathbf {X} _ {t} ^ {u} \\mathbf {W} _ {3}\\right) \\cdot \\text {L a y e r N o r m} _ {2} \\left(\\mathbf {C} _ {k} ^ {u}\\right)\\right)}{\\sum_ {k ^ {\\prime} = 1} ^ {K} \\exp \\left(\\text {L a y e r N o r m} _ {1} \\left(\\mathbf {X} _ {t} ^ {u} \\mathbf {W} _ {3}\\right) \\cdot \\text {L a y e r N o r m} _ {2} \\left(\\mathbf {C} _ {k ^ {\\prime}} ^ {u}\\right)\\right)}, \\tag {3}\n$$\n\nwhere  $P_{k|t}$  measures how likely the primary intention at position  $t$  is related with the  $k^{th}$  latent concept.  $\\mathbf{C}_k^u \\in \\mathbb{R}^D$  is the embedding of the  $k^{th}$  activated conceptual prototype of user  $u$ .  $\\mathbf{W}_3 \\in \\mathbb{R}^{D \\times D}$  is the trainable weight matrix. LayerNorm $l(\\cdot)$  represents a layer normalization layer. Note that we are using cosine similarity instead of the inner product here, due to the normalization. This choice is motivated by the fact that cosine is much less vulnerable than dot product when it comes to model collapse [29], e.g., the degeneration situation where the model is ignoring most prototypes.\n\n3.2.3 Attention weighting. In addition to the attention weight  $P_{k|t}$  calculated from the conceptual perspective, we also consider another attention weight  $P_{t|k}$  to estimate how likely the item at position  $t$  is essential for predicting the user's next intentions.\n\n$$\nP _ {t \\mid k} = \\mathbf {a} _ {t} ^ {k}, \\tag {4}\n$$\n\n$$\n\\mathbf {a} ^ {k} = \\operatorname {s o f t m a x} \\left(\\tanh  \\left(\\mathbf {X} ^ {u} \\mathbf {W} _ {k, 1}\\right) \\mathbf {W} _ {k, 2}\\right) ^ {T},\n$$\n\n$\\mathbf{a}^k \\in \\mathbb{R}^n$  is the attention vector for all positions. The superscript  $k$  represents it's the attention layer for the  $k^{th}$  activated intention. Similar to Equation 1, the above equation is another self-attentive layer. The primary difference lies in that we try to make use of the order of user sequences here and add extra trainable positional embeddings [43] to the input embeddings. The dimensionality of positional embeddings is the same as that of the item embeddings so that they can be directly summed.\n\n3.2.4 Interest embedding generation. We can now generate multiple interest embedding vectors from a user's behavior sequence  $\\mathbf{X}^u$  according to  $P_{k|t}$  and  $P_{t|k}$ . Specifically, the  $k^{th}$  output of our sparse-interest encoder  $\\phi_\\theta^k (\\mathbf{x}^{(u)})\\in \\mathbb{R}^D$  is computed as follows:\n\n$$\n\\phi_ {\\theta} ^ {k} \\left(\\mathbf {x} ^ {(u)}\\right) = \\operatorname {L a y e r N o r m} _ {3} \\left(\\sum_ {t = 1} ^ {n} P _ {k | t} \\cdot P _ {t | k} \\cdot \\mathbf {X} _ {t} ^ {u}\\right). \\tag {5}\n$$\n\nTill now, we have introduced the whole process of the sparse-interest network. Given a user's behavior sequence, we first activate his/her preferred conceptual prototypes from the concept pool. The intention assignment is then performed to estimate the user intention related with each item in the input sequence. After that, the self-attentive layer is applied to calculate all items' attention weights for next-item prediction. Finally, the user's multiple interest embeddings are generated through a weighted sum, according to Equation 5.\n\n# 3.3 Interest Aggregation Module\n\nAfter the sparse-interest extraction module, we obtain multiple interest embeddings for each user. A natural follow-up question is how to leverage various interest for practical inference. An intuitive solution is to use the next predicted item as a target label to select different interest embeddings for training as in MIND [24]. Despite its simplicity, the main drawback is that there are no target labels\n\nduring inference, which leads to a gap between training and testing and may result in performance degeneration.\n\nTo address this issue, we propose an adaptive interest aggregation module based on active prediction. The motivation here is that it is easier to predict a user's temporal preference-based next intentions instead of finding the ideal labels. Specifically, based on the intention assignment score  $P_{k|t}$  computed in Equation 3, we can obtain an intention distribution matrix, denoted by  $\\mathbf{P}^u \\in \\mathbb{R}^{n \\times K}$ , for all items in the behavior sequence. Then, the input behavior sequence  $\\mathbf{x}^u$  can be reformulated from the intention perspective denoted by  $\\widehat{\\mathbf{X}}^u = \\mathbf{P}^u\\mathbf{C}^u$ , where  $\\widehat{\\mathbf{X}}^u \\in \\mathbb{R}^{n \\times D}$  is viewed as the intention sequence of user  $u$ . With  $\\widehat{\\mathbf{X}}^u$ , the user's next intention  $C_{apt}^u$  is adaptively computed as\n\n$$\n\\mathbf {C} _ {a p t} ^ {u} = \\operatorname {L a y e r N o r m} _ {4} \\left(\\left(\\operatorname {s o f t m a x} \\left(\\tanh  \\left(\\widehat {\\mathbf {X}} ^ {u} \\mathbf {W} _ {3}\\right) \\mathbf {W} _ {4}\\right)\\right) ^ {\\top} \\widehat {\\mathbf {X}} ^ {u}\\right) ^ {\\top}, \\tag {6}\n$$\n\nwhere  $\\mathbf{C}_{\\text{apt}}^u \\in \\mathbb{R}^D$  is the predicted intention of user  $u$  for next item.  $\\mathbf{W}_3 \\in \\mathbb{R}^{D \\times D}$  and  $\\mathbf{W}_4 \\in \\mathbb{R}^D$  are trainable parameters. Given  $\\mathbf{C}_{\\text{apt}}^u$  and multiple interest embeddings  $\\{\\phi_\\theta^k (\\mathbf{x}^{(u)})\\}_{k=1}^K$ , the aggregation weights of different interests are calculated as\n\n$$\ne _ {k} ^ {u} = \\frac {\\exp \\left(\\left(\\mathbf {C} _ {a p t} ^ {u}\\right) ^ {\\top} \\phi_ {\\theta} ^ {k} \\left(\\mathbf {x} ^ {(u)}\\right) / \\tau\\right)}{\\sum_ {k ^ {\\prime} = 1} ^ {K} \\exp \\left(\\left(\\mathbf {C} _ {a p t} ^ {u}\\right) ^ {\\top} \\phi_ {\\theta} ^ {k ^ {\\prime}} \\left(\\mathbf {x} ^ {(u)}\\right) / \\tau\\right)}. \\tag {7}\n$$\n\nWhere  $e^u = [e_1^u, e_2^u, \\dots, e_K^u]^T \\in \\mathbb{R}^K$  is the attention vector for diverse interests.  $\\tau$  is a temperature parameter to tune. When  $\\tau$  is large  $(\\tau \\to \\infty)$ ,  $e^u$  approximates a uniformly distributed vector. When  $\\tau$  is small  $(\\tau \\to 0^+)$ ,  $e^u$  approximates a one-hot vector. In experiments, we use  $\\tau = 0.1$  to enforce the aggregator select the most preferred intention for inference. The final user representation  $\\mathbf{v}^u \\in \\mathbb{R}^D$  is computed as\n\n$$\n\\mathbf {v} ^ {u} = \\sum_ {k = 1} ^ {K} e _ {k} ^ {u} \\cdot \\phi_ {\\theta} ^ {k} (\\mathbf {x} ^ {(u)}. \\tag {8}\n$$\n\n# 3.4 Model Optimization\n\nWe follow the common practice [21, 24] to train our model by recovering the next click  $x_{t}^{(u)}$  based on the truncated sequence prior to the click, i.e.,  $[x_1^{(u)},x_1^{(u)},\\dots ,x_{t - 1}^{(u)}]$ . Given a training sample  $(u,t)$  with the user embedding vector  $\\mathbf{v}^u$  and item embedding  $\\mathbf{H}_t$ , we aim to minimize the following negative log-likelihood\n\n$$\n\\begin{array}{l} \\mathcal {L} _ {l i k e} = - \\sum_ {u} \\sum_ {t} \\log P (x _ {t} ^ {(u)} | x _ {1} ^ {(u)}, x _ {2} ^ {(u)}, \\dots , x _ {t - 1} ^ {(u)}) \\\\ = - \\sum_ {u} \\sum_ {t} \\log \\frac {\\exp \\left(\\mathbf {H} _ {t} ^ {\\top} \\mathbf {v} ^ {u}\\right)}{\\sum_ {j \\in \\{1 , 2 , \\cdots , M \\}} \\exp \\left(\\mathbf {H} _ {j} ^ {\\top} \\mathbf {v} ^ {u}\\right)}. \\tag {9} \\\\ \\end{array}\n$$\n\nEquation (9) is usually intractable in practice, because the sum operation of the denominator is computationally prohibitive. We, therefore, leverage a Sampled Softmax technique [6, 18] to train our model. Besides, we also introduce a covariance regularizer following [5] to enforce the learned conceptual prototypes orthogonally. Specifically, denote  $\\mathbf{M} = \\frac{1}{D} (\\mathbf{C} - \\overline{\\mathbf{C}})(\\mathbf{C} - \\overline{\\mathbf{C}})^{\\top}$  as the covariance matrix of prototype embeddings, where  $\\overline{\\mathbf{C}}$  is the mean matrix of C. The regularization loss  $\\mathcal{L}_c$  to regularize the covariance is\n\n$$\n\\mathcal {L} _ {c} = \\frac {1}{2} \\left(\\left| \\left| \\mathbf {M} \\right| \\right| _ {F} ^ {2} - \\left| \\left| \\operatorname {d i a g} (\\mathbf {M}) \\right| \\right| _ {F} ^ {2}\\right). \\tag {10}\n$$\n\nWhere  $||\\cdot ||_F$  is the Frobenius norm matrix. Combine the two losses above, the final loss function of our model is\n\n$$\n\\mathcal {L} = \\mathcal {L} _ {\\text {l i k e}} + \\lambda \\mathcal {L} _ {c}, \\tag {11}\n$$\n\nwhere  $\\lambda$  is the trade-off parameter to balance the two losses.",
  "experiments": "# 4 EXPERIMENTS\n\nIn this section, we conduct experiments over three benchmark datasets and one billion-scale industrial data to validate the proposed approach. Specifically, we try to answer the following questions:\n\n- How effective is the proposed method compared to other state-of-the-art baselines? Q1  \n- What are the effects of the different modules, sparse-interest module, and interest aggregation module through ablation studies? Q2  \n- How sensitive are the hyper-parameter settings, including the preferred  $K$  intentions and the corresponding  $L$  conceptual prototypes? Q3\n\n# 4.1 Experimental Setup\n\nIn this section, we elaborate on the dataset description, evaluation metrics, and comparing methods in our experiments.\n\nDatasets. We conduct experiments on three benchmark datasets and one billion-scale industrial data. The statistics of the datasets are shown in Table 2.\n\nTable 1: Recommendation performance on public datasets. The best results are highlighted with bold fold. All the numbers in the table are percentage numbers with  $\\%$  omitted.  \n\n<table><tr><td rowspan=\"2\"></td><td colspan=\"4\">MovieLens</td><td colspan=\"4\">Amazon</td><td colspan=\"4\">Taobao</td></tr><tr><td colspan=\"2\">Metrics@10</td><td colspan=\"2\">Metrics@50</td><td colspan=\"2\">Metrics@50</td><td colspan=\"2\">Metrics@100</td><td colspan=\"2\">Metrics@50</td><td colspan=\"2\">Metrics@100</td></tr><tr><td></td><td>HR</td><td>NDCG</td><td>HR</td><td>NDCG</td><td>HR</td><td>NDCG</td><td>HR</td><td>NDCG</td><td>HR</td><td>NDCG</td><td>HR</td><td>NDCG</td></tr><tr><td>GRU4Rec</td><td>14.61</td><td>5.66</td><td>41.61</td><td>10.66</td><td>1.70</td><td>0.51</td><td>2.74</td><td>0.67</td><td>9.41</td><td>3.60</td><td>12.43</td><td>4.08</td></tr><tr><td>Caser</td><td>15.44</td><td>6.13</td><td>43.64</td><td>11.53</td><td>2.60</td><td>0.81</td><td>3.96</td><td>1.03</td><td>10.71</td><td>4.96</td><td>13.50</td><td>5.68</td></tr><tr><td>SASRec</td><td>17.34</td><td>7.84</td><td>46.01</td><td>13.53</td><td>3.17</td><td>1.01</td><td>4.43</td><td>1.28</td><td>13.36</td><td>5.64</td><td>15.73</td><td>6.38</td></tr><tr><td>MIND</td><td>15.62</td><td>6.58</td><td>43.98</td><td>12.30</td><td>3.85</td><td>1.29</td><td>5.35</td><td>1.56</td><td>15.35</td><td>8.35</td><td>17.49</td><td>8.72</td></tr><tr><td>MCPRN</td><td>15.82</td><td>6.77</td><td>44.21</td><td>12.83</td><td>3.42</td><td>1.18</td><td>5.22</td><td>1.47</td><td>14.32</td><td>7.34</td><td>16.43</td><td>7.67</td></tr><tr><td>SINE</td><td>16.34</td><td>7.06</td><td>45.79</td><td>13.50</td><td>4.57</td><td>1.61</td><td>6.26</td><td>1.88</td><td>17.69</td><td>10.41</td><td>20.64</td><td>10.89</td></tr></table>\n\nTable 2: Statistics of the datasets.  \n\n<table><tr><td>Dataset</td><td># users</td><td># items</td><td># interactions</td></tr><tr><td>MovieLens</td><td>6,040</td><td>3,952</td><td>1,000,209</td></tr><tr><td>Amazon</td><td>8,026,324</td><td>2,330,066</td><td>22,507,155</td></tr><tr><td>Taobao</td><td>987,994</td><td>4,162,024</td><td>100,150,807</td></tr><tr><td>ULarge</td><td>106,527,123</td><td>25,000,000</td><td>4,000,000,000</td></tr></table>\n\n- MovieLens  ${}^{2}$  collects user's rating score for movies. In experiments, we follow [15] to preprocess the dataset.  \n- Amazon  $^{3}$  consists of product views from Amazon. In experiments, we use the rating only version of Book category behaviors. Note that this version is more challenging than the 5-core version used in [24], due to its large volume and sparsity.  \n- Taobao<sup>4</sup> collects user behaviors from Taobao's recommender system. In experiments, we only use the click behaviors.  \n- ULarge consists of the clicked behaviors collected from the daily logs of an Alibaba company from March 29 to April 4, 2020.\n\nFor all datasets, we follow [21] to split the datasets into training/validation/testing sets. Specifically, we split the historical sequence for each user into three parts: (1) the most recent action for testing, (2) the second most recent action for validation, and (3) all remaining actions for training. Note that during testing, the input sequences contain training actions and the validation actions.\n\nCompetitors. We compare our proposed model SINE with the following state-of-the-art sequential recommendation baselines.\n\n- Single embedding models: GRU4Rec [17] is a pioneering work that employs GRU to model user behavior sequences. Caser [42] is a recent CNN-based sequential recommendation benchmark.  \n- Multi-embedding models: MIND [24] and SASRec [21] are recently proposed multi-interest methods based on capsule network [34] and multi-head self-attention [43]. MCPRN is another state-of-the-art multi-interest framework based on latent conceptual prototypes.\n\nParameter Configuration. For a fair comparison, all methods are implemented in Tensorflow and optimized with Adam optimizer\n\nwith a mini-batch size of 128. The learning rate is fixed as 0.001. We tuned the parameters of comparing methods according to values suggested in original papers and set the embedding size  $D$  as 128 and the number of negative samples as 5 and 10 for MovieLens and other datasets. For our method, it has three crucial hyperparameters: the trade-off parameter  $\\lambda$ , the number of intentions  $K$ , and latent prototypes  $L$ . We search  $K$  from  $\\{4, 8, 12, 16\\}$ ,  $L$  from  $\\{50, 100, 500, 1000, 2000, 5000\\}$  and  $\\lambda$  from 0 to 1 with step size 0.1. We found our model performs relative stable when  $\\lambda$  is around 0.5 and set  $\\lambda = 0.5$ . The configuration of the other two parameters for four datasets are reported in Table 3.\n\nTable 3: The optimal setting of our hyper-parameters for our model. Other parameters like dimension  $D$ , sequence length  $n$  and  $\\lambda$  are set as 128, 20 and 0.5, respectively.  \n\n<table><tr><td></td><td>#intentions K</td><td>#concepts L</td></tr><tr><td>MovieLens</td><td>4</td><td>50</td></tr><tr><td>Amazon</td><td>4</td><td>500</td></tr><tr><td>Taobao</td><td>8</td><td>1000</td></tr><tr><td>ULarge</td><td>8</td><td>5000</td></tr></table>\n\nEvaluation Metrics. For each user in the test set, we treat all the items that the user has not interacted with as negative items. We use two commonly used evaluation criteria [14]: hit rate (HR) and normalized discounted cumulative gain (NDCG) to evaluate the performance of our model. Besides, we also leverage the widely used Normalized Mutual Information (NMI) [30] to quantitative analysis of the effectiveness of the learned conceptual prototypes of our model in clustering items.\n\n# 4.2 Comparisons with SOTA (Q1)\n\nTable 1 summarizes the performance of SINE as well as baselines on three benchmark datasets. Clearly, SINE achieves comparable performance to all of the baselines on all the evaluation criteria in general. Caser obtains the best performance over other models (GRU4Rec) that only single output embedding for each user. It can be observed that employing multiple embedding vectors (SASRec, MIND, MCPRN, SINE) for a user perform generally better than single embedding based methods (Caser and GRU4Rec). Therefore, exploring multiple user-embedding vectors has proved to be an\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-17/98f9772f-9923-4b2f-9862-e1b62004c2da/c3d308f02f8a167e55606bea15e809c6de29e7815df0d6e16768b477f620f6c8.jpg)  \nFigure 3: Concept visualization. We draw four concepts \"dolls\", \"jackets\", \"cosmetics\" and \"cups\" with the top-8 closest items.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-17/98f9772f-9923-4b2f-9862-e1b62004c2da/43bf75156652b00f5008c9d07625c95aba0498bbc015d0445f4bff8184262fdf.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-17/98f9772f-9923-4b2f-9862-e1b62004c2da/7e2e7f45a17d6693ccedc93196a82df4015938178f1f7d89d2a00e1b5e45f213.jpg)  \nFigure 4: Sensitivity of SINE towards  $K$  and  $L$  on Taobao.\n\neffective way of modeling users' diverse interests and boosting sequential recommendation accuracy. Moreover, we can observe that the improvement introduced by capturing user's various intentions is more significant for Taobao and Amazon datasets. The users of Taobao and Amazon tend to exhibit more diverse interests in online shopping than rating movies. The improvement of MIND over SAS-Rec shows that dynamic routing serves as a better multi-interest extractor than multi-head self-attention. An interesting observation is that MIND beats MCPRN on Amazon and Taobao while losses on MovieLens. It is mainly because MCPRN only supports cluster all items into a small set of prototypes, which is difficult well to cluster millions of items on Amazon and Taobao. Considering the MIND and SINE results, SINE consistently outperforms MIND on three datasets over all evaluation metrics. This can be attributed to two points: 1) The sparse-interest extractor layer explicitly utilizes a large set of conceptual prototypes to cluster items and automatically infer a subset of preferred intentions for interest embeddings generation, which achieves a more precise representation of a user. 2) Interest aggregation module actively predicts the user's current intention to directly attend over multiple user embedding vectors, enabling modeling multi-interests for top-N recommendation.\n\nParameter Sensitivity (Q3). We also investigate the sensitivity of the number of intentions  $K$  and conceptual prototypes  $L$ . Figure 4 reports the performance of our model in terms of HR. In particular, we randomly select 1 million users for inference, and the average result of 10 runs is reported. Results hold the same for other datasets, and we omit the figure here for more space. From the figure, we can observe that SINE obtains the best performance when  $K = 8$  and  $L = 1000$ . Considering that Taobao has around 9000 different categories in total, it verifies that the learned concepts indeed have a strong connection of categories of items, and the concept could be viewed as a virtual category that consists of several categories.\n\nTable 4: Recommendation performance on industrial dataset ULarge. Improv. row means the improvement of our model compared with the second-best baseline.  \n\n<table><tr><td></td><td>HR@50</td><td>HR@100</td><td>HR@500</td></tr><tr><td>Caser</td><td>6.93</td><td>16.75</td><td>36.94</td></tr><tr><td>GRU4Rec</td><td>5.46</td><td>14.80</td><td>33.35</td></tr><tr><td>SASRec</td><td>8.64</td><td>18.58</td><td>38.82</td></tr><tr><td>MCPRN</td><td>7.89</td><td>17.65</td><td>37.66</td></tr><tr><td>MIND</td><td>9.13</td><td>19.31</td><td>39.09</td></tr><tr><td>SINE</td><td>12.24</td><td>21.12</td><td>40.81</td></tr><tr><td>Improv.</td><td>34.06%</td><td>9.37%</td><td>4.40%</td></tr></table>\n\n# 4.3 Industrial Results (Q1)\n\nWe further conduct an offline experiment to investigate the effectiveness of our model in extracting user's diverse interests in the industrial dataset. We implemented our model and baselines on the Alibaba company's distributed cloud platform, where every two workers share an NVIDIA Tesla P100GPU with 16GB memory.\n\nTable 4 summarizes the performance in terms of Hit Rate. It is clear that SINE significantly outperforms other baselines by a wide\n\nTable 5: Prototype clustering evaluation compared with the first, second and leaf level category information on ULarge.  \n\n<table><tr><td></td><td>Level-1</td><td>Level-2</td><td>Level-leaf</td></tr><tr><td>NMI</td><td>0.09</td><td>0.37</td><td>0.29</td></tr></table>\n\nTable 6: Ablation study of SINE.  \n\n<table><tr><td>Dataset</td><td>Method</td><td>HR@50</td><td>HR@100</td></tr><tr><td rowspan=\"3\">Taobao</td><td>SINE-cate</td><td>12.45</td><td>15.33</td></tr><tr><td>SINE-label</td><td>16.22</td><td>18.74</td></tr><tr><td>SINE</td><td>17.69</td><td>20.64</td></tr><tr><td rowspan=\"3\">ULarge</td><td>SINE-cate</td><td>7.18</td><td>17.46</td></tr><tr><td>SINE-label</td><td>10.09</td><td>20.33</td></tr><tr><td>SINE</td><td>12.24</td><td>21.12</td></tr></table>\n\nmargin. Another interesting observation is that the gap between SINE and the second-best benchmark (MIND) decreases when the number of recalled items increases. This fact indicates that our sparse-interest network helps capture user's diverse interests and ranks the most preferred items on the top recommendation list.\n\nCase Study We also visualize the learned conceptual prototypes of our model. Concretely, for each concept, we leverage its prototypical embedding vector to retrieve the top-8 closest items under their cosine similarity. Figure 3 illustrates four exemplar concepts to show their clustering performance. As can be seen, our model successfully groups some semantic-similar items into a latent concept. More importantly, the items in one concept come from different semantic-close leaf categories. For example, the \"cosmetics\" concept contains different kinds of skin-nursing products. It indicates that compared to the conventional leaf-category partition, our conceptual prototype is related to the user's high-level intention.\n\nTo confirm this point, we compare the learned concepts with the expert-labeled category hierarchy in Alibaba company, where the number of categories in the first, second, and leaf-level are 178, 7,945, and 14874, respectively. Table 5 reports the results in terms of NMI. We can observe that the learned concepts are closest to the second level category, not in the extreme fine-grained granularity (leaf) or the very coarse granularity (first). This result demonstrates that our model can capture the relative high-level semantics for the user's intention modeling.\n\n# 4.4 Ablation Study (Q2)\n\nWe introduce two variants (SINE-cate and SINE-label) to validate the effectiveness of the learned new prototypes and the interest aggregation module. Specifically, SINE-cate is obtained by using the category attributes as prototypes, while SINE-label is obtained by adopting label-aware attention in [24] for training. We only conduct experiments on Taobao and ULarge, since other datasets do not have category attributes. Taobao and ULarge have 9439 and 14874 distinct categories, respectively. Note that, similar to MIND [24], SINE-label first independently retrieves  $K \\cdot N$  candidate items based on  $K$  embedding vectors and then outputs the final top-N recommendation list by sorting  $K \\cdot N$  items. Table 5 reports the results in\n\nterms of HR. Obviously, SINE significantly outperforms the other two variants in two datasets. The substantial difference between SINE-cate and SINE shows that the learned concepts are better to cluster items than the original items' categories. It verifies our motivation to cluster items in our model jointly. The improvement of SINE over SINE-label validates that our interest attention module is useful to model multiple interests for next-item recommendation.",
  "hyperparameter": ""
}