{
  "id": "GRU4RecCPR_2020",
  "paper_title": "To Copy, or not to Copy; That is a Critical Issue of the Output Softmax Layer in Neural Sequential Recommenders,",
  "alias": "GRU4RecCPR",
  "year": 2020,
  "domain": "Recsys",
  "task": "SequentialRecommendation",
  "idea": "",
  "introduction": "# 1 INTRODUCTION\n\nMany recommendation tasks on the internet can be formulated as a sequential recommendation problem [27], whose goal is to recommend the next item to each user based on the historical sequential interactions (e.g., click stream, purchasing record, and exercise practicing sequence) between the user and items [15]. In a sequential recommendation application, a good recommender often needs to capture the compositional meaning of multiple items in the input sequence, and many researchers have demonstrated that neural networks are able to model the complex interactions of the input items well and achieved state-of-the-art performances [40].\n\nAs shown in Figure 1, a sequential recommender takes the item history of a user as the input and outputs a probability distribution of the next item. A list of the items with the highest predicted probabilities would be recommended to the user. The recommender can assign the highest probabilities to the items in the input history, with which the user interacted before. The repetition behavior is like copying the input items to the recommendation list. The recommender can also choose not to copy and encourage the user to explore the new items. Li et al. [22] found that the modern neural recommender still cannot properly learn to copy or exclude\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/6fdfbffe79d0ed44f6af5f030827b9a3d2aeff76676ff36b8b7b85b2a7c420b0.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/a2c2c60b6ad91cca5dd472d72d3241984e22c7b7c2d99e51f36cd11956783a3b.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/3c1c8178c96e304f2bcf1d64aba44cd4dd027210ada6da31b2ec05756e23f0a9.jpg)  \nFigure 2: The benefits and problems of the output softmax layer in a neural sequential recommender. (a) The output softmax layer implicitly factorizes the interaction matrix into the global item embeddings and the hidden states of the neural encoder. The similarity structure in the item embedding space helps recommender's generalization capability in this example. (b) In a dataset with many duplicated items, the recommender often needs to copy the items from the shopping history, but the item similarity structure in the embedding space does not allow the recommender to output the desired distribution. (c) In a dataset with only few or no duplicated items, the model needs to learn not to recommend the items the users have already interacted with but to recommend something similar to them instead. The ideal distribution would form a donut shape in the item embedding space, which cannot be modeled by the single hidden state and static item embeddings in the softmax layer.\n\nthe items from the history in many situations. Motivated by the practical need, we first identify that the output softmax layer, which is adopted by most of the state-of-the-art neural recommenders, is a major source of the problem and demonstrate a substantial performance improvement after alleviating the softmax problem.\n\nThe softmax layer can be viewed as a matrix factorization layer [32, 42]. Instead of using a fixed user embedding as in a classic collaborative filtering method, the neural recommenders use a RNN\n\n(recurrent neural network) or transformer architecture to encode the historical input item sequence as a user embedding. Then, as shown in Figure 2 (a), the cross entropy loss and softmax layer encourage the high dot product between the generated user embedding and the embeddings of the possible next items.\n\nAs in collaborative filtering, the softmax / matrix factorization layer has several benefits: It would encourage similar items to have similar item embeddings and similar input sequences to be encoded\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/8c873262968d69a24fddc1a672a4467f56aa2317c29a2ac233b380c0d8d186fc.jpg)  \n(a) Math Exercises\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/40d110679eb3cc564c6a473550bfc939a5296499ff4cdbe94ceda37535749faf.jpg)  \n(b) Locations  \nFigure 3: The probability of observing the repeated next item (i.e., the next item has already been in the input sequence) at the certain sequence length in  $x$ -axis. The blue curves are the probability if the input sequence has already had duplicated item(s), while the orange curves indicate the probability when every item in the input sequence is unique.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/4f7a9f2389f9c15d982df4314641604d971a6096a3efba761f1bc8adb9f2c93b.jpg)  \n(c) Video Games\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/922e2e227cb442f170325e101f3a176a67e97b16d31e86faf65da1b0aec53771.jpg)  \n(d) Purchases\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/49a6f8281af6969b8cac7fccf9ca20042c36f16360ad48e0a7c6473497c41528.jpg)  \n(e) E-commercial Clicking\n\nas similar user embeddings. In many cases, the similarity structure in the embedding space boosts the generalization capability of the system. We illustrate an example in Figure 2 (a): Assuming in our training data, we know that (i) many users like to buy a big bottle of drink while buying party supplies and (ii) users like to keep buying Pepsi. Then, when a neural recommender sees a new user bought some Pepsi cans and party supplies before, it can output a user embedding that is between the Pepsi cans and the average of 2-liter drinks. The user embedding would be close to the embeddings of a 2-liter Pepsi bottle because the 2-liter Pepsi bottle is similar to both other Pepsi products and other 2-liter drinks.\n\nDespite the effectiveness of softmax / matrix factorization layer, its item similarity structure is global and sometimes prevents the neural recommender from outputting the desired distribution. As shown in Figure 2 (b), if one user repeatedly bought a diaper product and an apple juice product, the next item should be very likely to be either the diaper product or the apple juice product. In order to output the distribution, the neural recommender needs to output a user embedding that is between the diaper embedding and apple juice embedding, which might be accidentally close to an embedding of apple-flavored baby food and/or an embedding of apple juice for children. In this case, the single hidden state embedding and static item embeddings in the softmax layer causes a difficulty in properly copying the items in the historical item sequence. This problem would become more serious when the embedding space is very crowded (e.g., the number of items is large).\n\nOn the other hand, the similarity structure could also force the neural recommender to improperly copy the previous items. As the example shown in Figure 2 (c), if one user just bought DVDs for the Avengers movies, the users may want to watch the other Marvel movies such as Iron Man or Captain America (i.e., something like Avengers but not Avengers themselves). However, a user embedding close to all the other Marvel movies would be unavoidably close to the embeddings of Avengers because the Avengers movies are related to all the other Marvel movies. This could force the neural recommender to keep recommending the movies that the user has seen before. In this case, the softmax layer causes difficulty in properly excluding the items in the historical item sequence.\n\nTo alleviate the issues caused by the output softmax layer, we adopt softmax-CPR [6], which is originally proposed to reduce the hallucinations of the language generation models. From Figure 2 (b), we can see that the main issue comes from the single hidden state in the item embedding space, so softmax-CPR uses different\n\nhidden states to compute the probabilities of different partitions of items. For example, we can use a hidden state for only the items in the input sequence (e.g., the apple juice and diaper) and another hidden state for the rest of the items (e.g., baby foods). Then, the former hidden state could be placed between the apple juice and diaper without being interfered with by the other baby food items.\n\nWe test our methods in RecBole [41, 44]. Compared to the softmax, which is used in most of the neural sequential recommenders, softmax-CPR improves  $19\\%$  on geometrically averaged NDCG@10 [36] in 12 datasets and the improvement gaps are similar in SAS-Rec [15] and GRU4Rec [13]. Our experiments also identify the source of improvement of RepeatNet [30] comes from alleviating the softmax issue rather than the self-attention mechanism. By identifying the source of the problem better, softmax-CPR can achieve larger improvements using a simpler model and easily be combined with any neural encoder.\n\n# 1.1 Main Contributions\n\n- We found that the single hidden state and static item embeddings in the output softmax layer prevent the neural sequential recommenders from learning the copying/excluding behavior of the users. The perspective explains the improvement of RepeatNet [30] and simple post-processing [22] in the datasets without duplicated items.  \n- We adapt the softmax-CPR, which is recently proposed in Chang* et al. [6] for NLP problems, for sequential recommendation tasks and implement them in RecBole.<sup>1</sup>  \n- Experiments in 12 datasets compare the various softmax alternatives unifiedly that might be able to solve the softmax bottleneck problems. We conduct detailed ablation studies to attribute the improvement to each modification we made in the softmax layer.",
  "method": "# 3 SOLUTIONS\n\nIn this section, we introduce several potential methods that could alleviate the softmax bottleneck problems.\n\n# 3.1 Post Processing\n\nIn industry, the repetition issues are often alleviated by business insights and heuristic rules. For example, a product manager might notice that most users won't watch the same movie twice and many movies in the recommendation list have been watched, so we could simply add a post-processing step to remove the movies that have been watched from our recommendation candidate list [22]. Nevertheless, the simple statistics in Figure 3 suggest that finding generally applicable rules is difficult. Moreover, in some domains, the rules might quickly become too complicated to manage. For example, a user might want a food delivery app to recommend something new but sometimes prefers to buy food from the restaurants he/she has tried more than  $m$  times (to exclude the restaurants that are too bad to try again). In these cases, learning the copy patterns from a large training set should be an easier and more effective approach than the manually designed heuristic rules.\n\n# 3.2 Softmax-CPR\n\nIn this section, we briefly review Softmax-CPR proposed by Chang* et al. [6]. If you would like to know more details of its motivation and formulation, please refer to Chang* et al. [6] or Appendix C.1.\n\nSoftmax-CPR combines three methods: Context partition, Pointer network, and Reranker partition, to improve the output softmax layer. First, we introduce the context partition method. Context partition makes a small change in the logit computation in the softmax\n\nlayer. In Equation (1), the softmax layer lets  $\\mathrm{Logit}(x,i_n) = \\underline{\\boldsymbol{h}}_i^n\\underline{\\boldsymbol{p}}_x$ . In context partition, the logit of item  $x$\n\n$$\n\\operatorname {L o g i t} _ {C} (x, i _ {n}) = \\left\\{ \\begin{array}{l l} \\underline {{f}} _ {i _ {n}, C} ^ {T} \\underline {{p}} _ {x} & \\text {i f} x \\in i _ {n} \\\\ \\underline {{f}} _ {i _ {n}, V} ^ {T} \\underline {{p}} _ {x} & \\mathrm {O / W} \\end{array} , \\right. \\tag {2}\n$$\n\nwhere  $\\underline{f}_{i_n,C} = L_C^f (\\underline{h}_{i_n})$  and  $\\underline{f}_{i_n,V} = L_V^f (\\underline{h}_{i_n})$  are the linear projections of the hidden state. In this paper,  $L_{C}^{f}(\\underline{h}_{i_n}) = W_{C}\\underline{h}_{i_n} + \\underline{b}_{-}$  (e.g.,  $L_{C}^{f}(\\underline{h}_{i_n}) = W_{C}\\underline{h}_{i_n} + \\underline{b}_{-}$  ) and each linear projection layer would learn different parameters (weights  $W_{\\cdot}$  and bias  $\\underline{b}_{-}$  ) during training.\n\nThe context partition allows the recommender to learn when to copy input items and when to exclude the input items. For example, in Figure 2 (b), the recommender can place  $\\underline{f}_{i_n,C}$  between the apple juice and the diaper without being interfered by the baby foods because  $\\underline{f}_{i_n,C}$  is the hidden state only for the input items. Similarly, in Figure 2 (c), the recommender can learn to output a very small value of  $\\underline{f}_{i_n,C}^T\\underline{p}_x$  to exclude all the previously seen movies, while placing  $\\underline{f}_{i_n,V}$  at the center of the movies we should recommend.\n\nThe context partition is related to a pointer network. The main difference is that the pointer network computes the logit of the input items by  $\\underline{f}_{i_n,P}^T\\underline{f}_{x,i_n,L}$  instead of  $\\underline{f}_{i_n,P}^T\\underline{p}_x$ , where  $\\underline{f}_{i_n,P} = L_P^f (\\underline{h}_{i_n})$  and  $\\underline{f}_{x,i_n,L}$  is the average of a linearly projected hidden state embedding corresponding to the item  $x$  (see Equation (5) in the appendix for its formula). This means that the pointer network allows the recommender to predict the local and context-dependent embedding for the input items.\n\nIn the context partition or pointer network, we only compute the logits of input items separately using projected hidden states. However, some unexplored items are also likely to appear next and they might also encounter the softmax bottleneck problem. To alleviate the issue, the reranker partition computes the logits of the most likely  $k$  items separately using another new hidden state (see the term  $\\underline{f}_{i_n,R1}^T\\underline{p}_x$  below for an example).\n\nAs illustrated in Figure 4, Softmax-CPR combines all the above methods by\n\n$$\n\\operatorname {L o g i t} _ {C P R} (x, i _ {n}) = \\left\\{ \\begin{array}{l l} \\underline {{f}} _ {i _ {n}, C} ^ {T} \\underline {{p}} _ {x} + \\underline {{f}} _ {i _ {n}, P} ^ {T} \\underline {{f}} _ {x, i _ {n}, L} & \\text {i f} x \\in i _ {n} \\\\ \\underline {{f}} _ {i _ {n}, R 1} \\underline {{p}} _ {x} & \\text {i f} x \\in P (k _ {1}) - i _ {n} \\\\ \\underline {{f}} _ {i _ {n}, R 2} ^ {T} \\underline {{p}} _ {x} & \\text {i f} x \\in P (k _ {2}) - P (k _ {1}) - i _ {n} \\\\ \\underline {{f}} _ {i _ {n}, R 3} ^ {T} \\underline {{p}} _ {x} & \\text {i f} x \\in P (k _ {3}) - P (k _ {2}) - P (k _ {1}) - i _ {n} \\\\ \\underline {{f}} _ {i _ {n}, V} ^ {T} \\underline {{p}} _ {x} & O / W \\end{array} , \\right.\n$$\n\nwhere  $P(k_{3})$  is the top  $k_{3}$  items with the highest  $\\underline{f}_{i_n,V}^T\\underline{p}_x$ ,  $P(k_{2})$  is the top  $k_{2}$  words with the highest logits, similarly for  $P(k_{1})$ , and  $\\underline{f}_{i_n,Ry} = L_{Ry}^f (\\underline{h}_{i_n})$ . Note that this method could be easily combined with maximum inner product search [4]. We can just use  $\\underline{f}_{i_n,V}$  to search the possible next items and use other hidden states to adjust the logits of these possible next items and input items. Since the number of input items  $|i_{n}|$  and  $k_{3}$  are much smaller than the total number of items, the computational overhead should be relatively small.\n\n<table><tr><td rowspan=\"2\" colspan=\"2\">Dataset</td><td rowspan=\"2\">Item Type</td><td colspan=\"3\">Dataset size (k)</td><td colspan=\"2\">Config</td></tr><tr><td>#User</td><td>#Item</td><td>#Inter</td><td>|h_in|</td><td>bsz</td></tr><tr><td rowspan=\"3\">Amazon-2014 [26]</td><td>Beauty</td><td rowspan=\"3\">Products</td><td>1210</td><td>249</td><td>2023</td><td>64</td><td>[64,128]</td></tr><tr><td>Books</td><td>8026</td><td>2330</td><td>22507</td><td>32</td><td>32</td></tr><tr><td>Video Games</td><td>827</td><td>50</td><td>1325</td><td>64</td><td>[64,128]</td></tr><tr><td rowspan=\"2\">Movie Lens [11]</td><td>10m</td><td rowspan=\"2\">Movies</td><td>70</td><td>11</td><td>10000</td><td>64</td><td>128</td></tr><tr><td>1m</td><td>6</td><td>4</td><td>1000</td><td>64</td><td>[64,128]</td></tr><tr><td>Twitch-100k [29]</td><td></td><td>Videos</td><td>100</td><td>740</td><td>3052</td><td>48</td><td>32</td></tr><tr><td>Yelp-2018Â²</td><td></td><td>Stores</td><td>1326</td><td>175</td><td>5262</td><td>48</td><td>32</td></tr><tr><td>Bridge to Algebra (2008-2009) [34]</td><td></td><td>Exercises</td><td>3</td><td>1259</td><td>8918</td><td>48</td><td>32</td></tr><tr><td>Gowalla [8]</td><td></td><td>Locations</td><td>107</td><td>1281</td><td>6443</td><td>32</td><td>32</td></tr><tr><td>Steam [15]</td><td></td><td>Games</td><td>2568</td><td>32</td><td>7793</td><td>64</td><td>[64,128]</td></tr><tr><td>Tmall-buy [35]</td><td></td><td>Products</td><td>886</td><td>1144</td><td>9349</td><td>32</td><td>32</td></tr><tr><td>Yoochoose-clicks [2]</td><td></td><td>Products</td><td>9250</td><td>53</td><td>33004</td><td>64</td><td>128</td></tr></table>\n\nTable 1: The dataset sizes are reported by the number of thousands (k). We adjust the hidden state size  $(|\\underline{h}_{i_n}|)$  and batch size (bsz) accordingly under our GPU memory constraint.\n\n# 3.3 Multiple Input Hidden States (Mi)\n\nAll the new hidden states  $\\underline{f}_{i_n}$  are the projection of  $\\underline{h}_{i_n}$ . The limited dimension of  $\\underline{h}_{i_n}$  would force  $\\underline{f}_{i_n}$  to linearly depend on each other and not be able to move freely in the item embedding space. To solve this issue, Chang and McCallum [5] concatenate multiple input hidden states  $\\underline{h}_{i_n}$  and project them into a new hidden state  $\\underline{q}_{i_n}$  to expand its dimensionality. We combine their method with softmax-CPR in Figure 4 by replacing  $\\underline{h}_{i_n}$  with  $\\underline{q}_{i_n}$  in Equation (3).\n\n# 3.4 Mixture of Softmax (MoS)\n\nIn Figure 2 (b), one possible solution is to put one hidden state near the diaper and another hidden state near the apple juice to model its multi-modal distribution. The mixture of softmax (MoS) is proposed to achieve the goal [5, 23, 42]. MoS and softmax-CPR both use multiple hidden states, while their roles of each hidden state are different. In MoS, we need to compute the dot product between every hidden state and all the item embeddings; in softmax-CPR, we partition the item set and each hidden state only determines the logits/probabilities of the items in a partition (e.g., only the input items in the context partition). Compared to softmax-CPR, MoS is more computationally expensive and does not explicitly model users' repetition behavior.\n\n# 3.5 RepeatNet\n\nInspired by CopyNet [10] / pointer network, RepeatNet [30] explicitly models the probability of copying the items from the input. In their paper, they do not test its performance on the datasets without duplicated items. Compared to softmax-CPR, RepeatNet has several disadvantages. First, RepeatNet introduces many extra parameters to GRU4Rec, which increases the computational overhead and the difficulties in identifying the source of the improvement. Second, when computing the probabilities of copying the items, RepeatNet does not leverage the global item similarity structure, which might hurt the generality of the model (see Figure 2 (a) for an example). Third, RepeatNet does not solve the softmax bottleneck problem for the items that are not in the input sequence.",
  "experiments": "# 4 EXPERIMENTS\n\nAll the experiments are done in RecBole [41, 44], a library that provides various recommendation models and datasets. We select 12 datasets from RecBole that are large enough and widely used in the previous work to make the results more representative and less sensitive to the hyperparameter setup and random seeds [9]. The datasets come from various domains and have various sizes. We report their statistics in Table 1.\n\n# 4.1 Models and Baselines\n\nWe implement the following softmax alternatives by modifying the model code of SASRec [15] and GRU4Rec [13]. We choose SASRec and GRU4Rec for several reasons. (i) SASRec and GRU4Rec are both state-of-the-art and widely-used encoders [18, 38]. (ii) RepeatNet\n\nis based on GRU4Rec. (iii) We want to compare the improvements over transformer-based encoders and RNN-based encoders.\n\n- Softmax: The performance of the SASRec and GRU4Rec.  \n- Softmax + Mi: Computing the probabilities using multiple input hidden states (Mi). Please see Section 3.3 for more details. Here, Mi uses the hidden states corresponding to the last three input items and all the layers of the neural encoders (i.e., 1 layer for GRU4Rec and 2 layers for SASRec).  \n- Softmax + C: Use context partition in Equation (2).  \n- Softmax + CP: Use context partition and pointer network.  \n- Softmax + CPR:100: Use softmax-CPR and set  $k_{1} = 100$  (i.e., removing the second and third reranker partition in Equation (3)).  \n- Softmax + CPR:100 + Mi: Use softmax-CPR and multiple input hidden states.\n\n<table><tr><td rowspan=\"2\" colspan=\"2\"></td><td rowspan=\"2\">Model Size (M)</td><td rowspan=\"2\">Training Time (s)</td><td rowspan=\"2\">Testing Time (s)</td><td colspan=\"3\">7 datasets w/o dup.</td><td colspan=\"3\">Geometric Mean 5 datasets w/ dup.</td><td colspan=\"3\">All 12 datasets</td></tr><tr><td>NDCG</td><td>HR</td><td>MRR</td><td>NDCG</td><td>HR</td><td>MRR</td><td>NDCG</td><td>HR</td><td>MRR</td></tr><tr><td rowspan=\"9\">SASRec</td><td>Softmax</td><td>5.34</td><td>1178.95</td><td>22.43</td><td>4.79</td><td>8.82</td><td>3.57</td><td>31.60</td><td>40.78</td><td>28.56</td><td>10.75</td><td>17.00</td><td>8.70</td></tr><tr><td>Softmax + Mi</td><td>5.36</td><td>1306.67</td><td>23.71</td><td>4.71</td><td>8.68</td><td>3.50</td><td>31.95</td><td>41.02</td><td>28.95</td><td>10.70</td><td>16.89</td><td>8.66</td></tr><tr><td>Softmax + C</td><td>5.35</td><td>1535.21</td><td>28.53</td><td>5.57</td><td>9.78</td><td>4.29</td><td>33.59</td><td>43.49</td><td>30.32</td><td>12.04</td><td>18.54</td><td>9.92</td></tr><tr><td>Softmax + CP</td><td>5.36</td><td>1601.77</td><td>29.13</td><td>5.69</td><td>10.02</td><td>4.36</td><td>33.77</td><td>43.48</td><td>30.56</td><td>12.20</td><td>18.80</td><td>10.04</td></tr><tr><td>Softmax + CPR:100</td><td>5.37</td><td>2013.69</td><td>34.43</td><td>5.77</td><td>10.07</td><td>4.45</td><td>34.10</td><td>43.88</td><td>30.86</td><td>12.35</td><td>18.92</td><td>10.20</td></tr><tr><td>Softmax + CPR:100 + Mi</td><td>5.41</td><td>2213.77</td><td>35.64</td><td>5.75</td><td>10.06</td><td>4.44</td><td>34.49</td><td>44.09</td><td>31.32</td><td>12.39</td><td>18.95</td><td>10.25</td></tr><tr><td>Softmax + CPR:20,100,500 + Mi</td><td>5.41</td><td>2999.23</td><td>47.63</td><td>5.64</td><td>9.86</td><td>4.34</td><td>34.58</td><td>43.94</td><td>31.48</td><td>12.26</td><td>18.71</td><td>10.14</td></tr><tr><td>Mixture of Softmax (MoS)</td><td>5.35</td><td>1779.93</td><td>33.78</td><td>4.74</td><td>8.75</td><td>3.52</td><td>31.88</td><td>41.08</td><td>28.82</td><td>10.73</td><td>16.98</td><td>8.67</td></tr><tr><td>Softmax w/o Duplication [22]</td><td>5.34</td><td>1183.55</td><td>22.61</td><td>5.41</td><td>9.61</td><td>4.12</td><td>10.23</td><td>15.61</td><td>8.44</td><td>7.11</td><td>11.84</td><td>5.61</td></tr><tr><td rowspan=\"9\">GRU4Rec</td><td>Softmax</td><td>5.42</td><td>1842.56</td><td>31.24</td><td>4.85</td><td>8.99</td><td>3.58</td><td>31.20</td><td>40.23</td><td>28.22</td><td>10.77</td><td>17.09</td><td>8.68</td></tr><tr><td>Softmax + Mi</td><td>5.45</td><td>2239.74</td><td>33.37</td><td>4.98</td><td>9.14</td><td>3.71</td><td>31.18</td><td>40.19</td><td>28.20</td><td>10.93</td><td>17.25</td><td>8.85</td></tr><tr><td>Softmax + C</td><td>5.42</td><td>2333.21</td><td>37.84</td><td>5.75</td><td>10.16</td><td>4.39</td><td>33.55</td><td>43.24</td><td>30.36</td><td>12.24</td><td>18.90</td><td>10.06</td></tr><tr><td>Softmax + CP</td><td>5.43</td><td>2355.90</td><td>38.45</td><td>5.76</td><td>10.14</td><td>4.41</td><td>33.80</td><td>43.48</td><td>30.60</td><td>12.29</td><td>18.93</td><td>10.12</td></tr><tr><td>Softmax + CPR:100</td><td>5.44</td><td>3103.13</td><td>43.18</td><td>6.02</td><td>10.55</td><td>4.63</td><td>34.27</td><td>43.82</td><td>31.11</td><td>12.68</td><td>19.42</td><td>10.47</td></tr><tr><td>Softmax + CPR:100 + Mi</td><td>5.50</td><td>3480.22</td><td>45.60</td><td>6.13</td><td>10.69</td><td>4.72</td><td>34.39</td><td>43.83</td><td>31.27</td><td>12.83</td><td>19.57</td><td>10.62</td></tr><tr><td>Softmax + CPR:20,100,500 + Mi</td><td>5.50</td><td>4128.41</td><td>57.51</td><td>6.01</td><td>10.44</td><td>4.64</td><td>34.42</td><td>43.83</td><td>31.30</td><td>12.69</td><td>19.31</td><td>10.52</td></tr><tr><td>Mixture of Softmax (MoS)</td><td>5.43</td><td>2448.34</td><td>42.67</td><td>4.81</td><td>8.91</td><td>3.56</td><td>31.27</td><td>40.15</td><td>28.33</td><td>10.72</td><td>16.98</td><td>8.66</td></tr><tr><td>Softmax w/o Duplication [22]</td><td>5.42</td><td>1798.91</td><td>31.00</td><td>5.52</td><td>9.83</td><td>4.20</td><td>10.06</td><td>15.42</td><td>8.27</td><td>7.14</td><td>11.92</td><td>5.61</td></tr><tr><td>RepeatNet</td><td>-</td><td>15.97</td><td>NA</td><td>NA</td><td>5.63</td><td>9.69</td><td>4.39</td><td>33.41</td><td>42.48</td><td>30.42</td><td>12.08</td><td>18.26</td><td>10.06</td></tr></table>\n\nTable 4: We report the model size and average time of training/testing the models on Amazon-2014 Books for 1 epoch. The other notations are the same as Table 2.\n\n- Softmax + CPR:20,100,500 + Mi: Use softmax-CPR in Equation (3) and multiple input hidden states as in Figure 4.  \n- Mixture of Softmax (MoS): The baseline similar to Lin [23], Yang et al. [42]. We set the number of softmax to be 3.  \n- Softmax w/o Duplication [22]: Set the probability of the repeated items to be 0 via post-processing to improve the performance on the datasets without duplicated items.\n\nIn addition, we also compare the softmax alternatives on top of SASRec/GRU4Rec with RepeatNet [30].\n\n# 4.2 Setup\n\nWe report three metrics NDCG@10 (normalized discounted cumulative gain) [14], HR@10 (Hit rate) [43], and MRR@10 (Mean Reciprocal Rank) [28]. To be closer to the real-world setup, we do not conduct negative example subsampling when reporting the testing performance, so the scores might look small in some datasets with a large number of items. Since different datasets could have very different performance ranges, we report the geometric mean of all datasets to summarize the performance of every method [36].\n\nWe follow the default evaluation protocol and model setup in RecBole (e.g., input and output item embeddings are shared in GRU4Rec and SASRec). We found that the default hyperparameters in RecBole generally work well except that a smaller dropout rate for SASRec yields much better performances. Overall, we found that our performance improvement is not sensitive to the hyperparameters but we still tried our best to tune the hyperparameters under the constraints of our computational resources.\n\nFor the smaller datasets (i.e., Amazon Beauty, Games, MovieLens 1m, and Steam), we perform a grid search on its hyperparameters using their NDCG@10 scores on validation sets. In the grid search, we use learning rates [5e-4, 1e-3, 2e-3] and batch sizes [64, 128]. For GRU4Rec, the dropout rates are [0, 0.5]. For SASRec, hidden state dropout rates are [0, 0.1]. For all the other 8 larger datasets, the\n\nlearning rate is 1e-3, and dropout rate is 0. All the hyperparameter values or search ranges in RepeatNet are the same as GRU4Rec. To fitting the models into our GPU memory, we adjust our hidden state sizes and training batch sizes as shown in Table 1.\n\nUsing the grid search results, we can analyze the hyperparameter sensitivity of learning rates, dropouts, and batch sizes. To know the sensitivity to the hidden state sizes, we conduct another grid search using hidden state sizes [16, 32, 64, 128] and batch sizes [64,128]. The learning rate and dropout are set according to the previous grid search results to optimize the testing performance of the Softmax + Mi baseline in each of the 4 smaller datasets.\n\nAll experiments are done in Nvidia Tesla M40. The time is measured by computing the probability of all the items without using any nearest neighbor search. The model codes in RecBole are often not optimized for their running time, so the time comparison is more meaningful given the same neural encoder. Thus, we do not report the time of RepeatNet to avoid unfair comparisons.\n\n# 4.3 Results\n\nThe results are presented at Table 2, Table 3, and Table 4. We can see context partition  $(\\mathrm{Softmax} + \\mathbf{C})$  substantially improves over Softmax. After adding pointer network (P), reranker partition (R), and multiple input hidden states (Mi), Softmax + CPR:100 + Mi achieves the best overall performances in Table 4. Unlike the counterpart in language models [6], multiple reranker partitions, Softmax + CPR:20,100,500 + Mi, do not result in better performances in recommendation models.\n\nThe improvement on GRU4Rec is slightly larger than that on SASRec. This shows that there is a small overlap between the benefits of softmax-CPR and the benefits of self-attention in the neural encoder. Noting that the performances of SASRec and GRU4Rec are not directly comparable because we only coarsely tune the hyperparameters.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/c89c58af75415d0e49307590b21d01bbccff1a55bc26d384961419c96543defb.jpg)  \n(a) GRU encoder and  $|\\underline{h}_{i_n}|$\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/0e5dfc7ec25b0aa3d8281cbf57cb912ca4e59c6c3257c45f3050aa8ae7924687.jpg)  \n(b) GRU encoder and Ir\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/5a6bb837910d6c6e852abac50acc4e3cbac71eefb0eb2efe97fc13aac6a67430.jpg)  \n(c) GRU encoder and dropout\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/dfd88374332a1a154b58c80a2aa4b364fb7ca217f76a6d9f37bd05a583c398c7.jpg)  \n(d) GRU encoder and batch size\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/80dc02d653155c9b45d1672235442f0a71016baef1c01c4075668f326d38586d.jpg)  \n(e) Trans. encoder and  $|\\underline{h}_{i_n}|$\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/bf33e5b67f059d8a2ccf9e33d7d0e58031216211346d9f210b16f13432ecfdbb.jpg)  \n(f) Trans. encoder and Ir\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/96ce4f145c89e5bfda7f87afdf4cf3656904acf0ea558adb0d31911c115f0878.jpg)  \nFigure 5: Hyerparameter analyses using the geometric mean of Amazon Beauty, Games, MovieLens 1m, and Steam datasets.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/e8fae812-1fd1-4db3-8f69-3a4abc103ee6/e594a7318d6ba32e38cec611923e3e2d04b42256a1cd955d4f5b1da804e0189c.jpg)  \n(g) Trans. encoder and dropout  \n(h) Trans. encoder and batch size\n\nMoS [23, 42] performs almost the same as Softmax and requires much longer training and inference time. Although Softmax w/o Duplication performs poorly in the 5 datasets with duplications, it significantly outperforms Softmax in 7 datasets without duplications as found in Li et al. [22]. Nevertheless, allowing the models to easily exclude the duplications during the training (e.g., Softmax + C) still slightly outperforms the post-processing baseline in datasets without duplications.\n\nWe discover that although being designed for the datasets with duplicated items, RepeatNet can also substantially improve the datasets without any duplicated items. In many datasets, the performances of RepeatNet are very similar Softmax + C on top of GRU4Rec. This suggests that the main source of improvement from RepeatNet comes from computing the probabilities of the repeated item separately as in Softmax + C rather than its self-attention mechanism or its extra parameters. Furthermore, after identifying the source of improvement from RepeatNet, Softmax + C can achieve similar improvement while only needing one-third of its model size, Softmax + CPR:100 + Mi can further expand the improvement by better overcoming the softmax bottleneck, and we can apply the softmax alternatives to any neural encoder of interest (e.g., they lead to similar improvement in SASRec).\n\nTable 4 shows that the extra parameters introduced by our softmax alternatives are neglectable. Theoretically speaking, the extra computations in Softmax + CPR:100 + Mi are also very small compared to the original softmax layer, which computes the dot product between the hidden state and every item embedding. However, we still see some increases in training and testing time, which might be caused by the constraints of PyTorch's built-in functions. Thus, in applications requiring low latency, we recommend using Softmax + C and/or writing CUDA code to minimize the extra overhead.\n\nThe hyperparameter analyses in Figure 5 show that all the methods are not very sensitive to the particular values of hyperparameters. The lines are pretty flat in batch size and learning rate figures. For dropout rates in GRU4Rec, using 0 dropout uniformly degrades the performance of smaller datasets such as Amazon Video Games. For hidden size, performance starts to degrade when the size is smaller than 64. In RepeatNet, the item embedding size is two times of the hidden state size, so its 16 hidden state size is similar to other methods' 32 hidden state size.",
  "hyperparameter": ""
}