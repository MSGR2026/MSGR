{
    "id": "TALE_2025",
    "paper_title": "Popularity-based Recommendation Systems: A Baseline Approach",
    "alias": "TALE",
    "year": 2025,
    "domain": "Recsys",
    "task": "SequentialRecommendation",
    "idea": "TALE introduces a temporal linear item-item model for sequential recommendation that incorporates (i) single-target augmentation to avoid spurious long-range correlations, (ii) time-interval-aware weighting that decays item influence exponentially with actual elapsed time while keeping a minimum threshold for long-term dependencies, and (iii) trend-aware normalization that re-scales interactions by item popularity computed only over a recent sliding window, all combined into a single closed-form least-squares objective.",
    "introduction": "# 1 Introduction\n\nSequential recommendation (SR) aims to predict the next user interaction based on the user's historical behavior in chronological order. Most existing studies focus on learning the transition pattern and correlation between items to capture hidden user preference drifts. Representative SR models [8, 14, 17, 23, 25, 29, 34, 39, 43] utilize neural architectures, such as recurrent neural networks (RNNs), graph neural networks (GNNs), and transformers. Because the transformer architecture [31] is suitable for learning long-term correlations and dependencies between items, transformer-based SR models [8, 17, 23, 25, 29, 43] have shown outstanding performance.\n\nHowever, existing SR models still struggle to address two challenges. (C1) Efficiency: Neural SR models incur slow training and inference time. In particular, the time complexity of transformers is quadratic for the length of the item sequences. (C2) Temporal information: Sequential information assumes that all time intervals are the same. In practice, the time interval between two consecutive items varies significantly. This highlights the need to handle temporal information in sequential item modeling.\n\nTo tackle the efficiency issue, recent studies [10, 20, 39] have proposed to incorporate efficient mechanisms for SR. Specifically, LinRec [20] adopted L2-normalized linear attention in the self-attention block, improving the efficiency while preserving the capabilities of the conventional dot-product attention. LRUREc [39] utilized a linear recurrent unit to support recursive parallel training. Conversely, some studies [5, 22, 26-28] proposed linear models without using complicated neural architectures. Among them, SLIST [5] is the representative linear SR model using item correlations and dependencies. Despite its simplicity, its accuracy is comparable to neural SR models, and it achieves efficient model training and inference. However, these efficient SR models only consider sequential information and do not account for temporal information.\n\nLearning solely from sequential information without temporal dynamics does not represent user preference drifts accurately. Figure 1 provides an intuitive example of how recommendations vary\n\ndepending on whether temporal information is taken into account. Without temporal information, the SR model recommends \"Milk Bath\" because the sequence is associated with two items related to the target item. On the other hand, the SR model using temporal information leverages the fact that it has been a while since \"Bath Salt\" and Epsom Salt were purchased to recommend \"Face Wash\", which is related to the recently purchased \"Shave Gel\".\n\nIt indicates that temporal information using actual timestamps provides a beneficial clue for capturing user preference drifts. Figure 2 shows the co-occurrence of two consecutive items over various time intervals in real-world datasets. In the Beauty dataset, approximately  $50\\%$  of the consecutive item pairs occurred at intervals of more than 1 day, meaning that the temporal information between items varies significantly. In Appendix C.1, we also show the existence of user preference drifts by utilizing item attributes (e.g., genre and item category) instead of co-occurrences.\n\nRecent studies [7, 19, 30, 40] have attempted to combine temporal information with transformer-based or contrastive learning-based SR models. Specifically, TiSASRec [19] incorporated time interval-aware embedding vectors representing temporal context into the self-attention block. TiCoSeRec [7] introduced sequential augmentation methods using the time interval property. Besides, TCPSRec [30] divided an interaction sequence into coherent subsequences to deal with temporal correlations among items. TGCL4SR [40] proposed local interaction sequences and global temporal graphs to capture item correlations. Although these temporal SR models improve recommendation performance, they do not address the efficiency issue.\n\nTo tackle the above two challenges (i.e., efficiency and temporal information), we propose an efficient linear model incorporating temporal information in SR, called TemporAl LinEar item-item model (TALE). We introduce three key components used in TALE. We first employ single-target augmentation to ensure that temporal information is utilized without distortion. Subsequently, time interval-aware weighting enables the linear model to harness temporal information in its recommendations. Lastly, to address the popularity bias problem [3], which is a pervasive issue in recommender systems, we devise trend-aware normalization considering the temporal context. We explain each component as follows.\n\n- Single-target augmentation: While linear SR models typically leverage source and target matrices for training, we construct the target matrix using a single-item representation rather than multiple items. We prove that although previous models employing multiple target items strengthen long-interval collaborative signals, our single-target augmentation effectively captures temporal correlations between multiple source items and a single target item.\n\n- Time interval-aware weighting: To directly incorporate temporal information into the linear model, we utilize actual timestamps to adjust the importance of items within the source items. In particular, this weighting strategy is divided into short and long time intervals. In this way, the item correlations with different time intervals can be discerned effectively.\n\n- Trend-aware normalization: To reflect dynamic item popularity, we adopt a normalization method for eliminating popularity bias [3]. Although recent studies [2, 13, 33, 38, 41] use various\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/00807a10f06ca9a16588f3566e106bbc2cddd29990dfc484ba1882c1b43174fd.jpg)\n\n\n\n(a) ML-1M\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/35b37649e00448d1ed2bed77b7582e224389af2f8d9ef29aee8367ad0c1b7c88.jpg)\n\n\n\n(b) Beauty\n\n\n\nFigure 2: Co-occurrences between two consecutive items over average time intervals on the ML-1M and Beauty datasets. Appendix C.2 shows a similar trend on Toys, Sports, and Yelp.\n\n\nnormalization methods, they fail to account for temporal context since they use global popularity over the entire period<sup>1</sup>. We utilize local item popularity in the recent  $N$  days, reflecting the dynamic changes in item popularity.\n\nWe extensively evaluate the effectiveness of TALE by comparing it with ten existing SR models on five benchmark datasets, achieving up to  $18.71\\%$  higher accuracy and  $6.9\\mathrm{x}$  to  $57\\mathrm{x}$  faster training times. Notably, TALE shows up to  $30.45\\%$  performance gains on long-tail items, alleviating popularity bias.",
    "method": "# 2 Background\n\n# 2.1 Problem Statement\n\nGiven a historical user sequence  $S^u = [i_1^u,i_2^u,\\dots,i_{|S^u|}^u]$ , SR aims to recommend the next item that user  $u$  is likely to interact with. The timestamp sequence is denoted by  $\\mathcal{T}^u = [t_1^u,t_2^u,\\dots,t_{|S^u|}^u]$ , indicating the temporal information corresponding to  $S^u$ . The entire training sequence is stacked as a set of users  $\\mathcal{U}\\in \\mathbb{R}^{m}$ , and each item in the sequences belongs to a set of items  $\\mathcal{I}\\in \\mathbb{R}^n$ .\n\nThe SR model learns an optimal model parameter  $\\Theta^{*}$  to predict user  $u$ 's ground-truth item  $\\mathrm{gt}(u)$  given user  $u$ 's item sequence  $\\mathcal{S}^u$ . Temporal SR models further exploit the timestamp sequence  $\\mathcal{T}^u$  for model training.\n\n$$\n\\Theta^ {*} = \\underset {\\Theta} {\\operatorname {a r g m a x}} \\sum_ {u = 1} ^ {m} p \\left(i _ {| S ^ {u} | + 1} ^ {u} = \\operatorname {g t} (u) \\mid S ^ {u}, \\mathcal {T} ^ {u}, \\Theta\\right). \\tag {1}\n$$\n\nIn this process, the core part of temporal SR models is how to incorporate temporal information into the model training.\n\n# 2.2 Linear Item-Item Models\n\nGiven a set  $S$  of user-item interactions, we derive two interaction matrices  $\\mathbf{X} \\in \\{0,1\\}^{m \\times n}$  and  $\\mathbf{Y} \\in \\{0,1\\}^{m \\times n}$ , corresponding to training input and target matrices, respectively. Let  $\\mathbf{X}_{u,j}$  be 1 if user  $u$  and item  $j$  have interacted, and 0 otherwise. Similarly,  $\\mathbf{Y}_{u,j}$  is 1 for items to target and 0 otherwise. Given sequence-item interaction matrices  $\\mathbf{X}$  and  $\\mathbf{Y}$ , linear item-item models learn an item-to-item weight matrix  $\\mathbf{B} \\in \\mathbb{R}^{n \\times n}$ .\n\n$$\n\\min  _ {\\mathbf {B}} \\| \\mathbf {Y} - \\mathbf {X B} \\| _ {F} ^ {2} + \\lambda \\| \\mathbf {B} \\| _ {F} ^ {2}, \\tag {2}\n$$\n\nwhere  $\\lambda$  is the hyperparameter to adjust the regularization in B. In Section 3, we will present how to determine the interaction matrices to handle temporal information in detail.\n\nFor inference, the prediction score  $s_{u,j}$  between the user  $u$  and the item  $j$  is computed as follows.\n\n$$\ns _ {u, j} = \\mathbf {X} _ {u, *} \\cdot \\hat {\\mathbf {B}} _ {*}, \\tag {3}\n$$\n\nwhere  $\\mathbf{X}_{u,*}$  is the row vector for the user  $u$  in  $\\mathbf{X}$ , and  $\\hat{\\mathbf{B}}_{*,j}$  is the column vector for the item  $j$  in  $\\hat{\\mathbf{B}}$ .\n\n# 2.3 Normalization\n\nAs the inherent problem in recommendations, popularity bias [3] hurts user experience by predominantly yielding popular items to users. To eliminate the popularity bias, a lot of recommender models [2, 4, 12, 13, 18, 26, 32, 33, 38, 41] utilize normalization. A few studies [4, 12, 18, 32] apply normalization to user/item embeddings to adjust their magnitude, while others [2, 13, 33, 38, 41] implement normalization on the adjacency matrix in GNN-based models to reduce the influence of popular nodes during message passing.\n\nMeanwhile, linear models can utilize normalization to decrease the influence of popular items. It involves dividing the interaction matrix by the square root of the user/item popularity.\n\n$$\n\\tilde {\\mathbf {X}} = \\mathbf {D} _ {U} ^ {- 1 / 2} \\mathbf {X D} _ {I} ^ {- 1 / 2} = \\mathbf {W} _ {\\text {n o r m}} \\odot \\mathbf {X}, \\tag {4}\n$$\n\nwhere  $\\mathbf{D}_I = \\mathrm{diag}(p_1, p_2, \\dots, p_n) \\in \\mathbb{R}^{n \\times n}$ , and  $p_j = \\sum_{v=1}^m \\mathbf{X}_{v,j}$  is the popularity of the item  $i_j$ . It can also be expressed as an interaction-wise operation, i.e.,  $\\mathbf{W}_{\\mathrm{norm}} \\in \\mathbb{R}^{m \\times n}$ . By substituting Eq. (4) into the matrices  $\\mathbf{X}$  and  $\\mathbf{Y}$  of Eq. (2), normalization can be applied for linear item-item models.\n\nExisting normalization methods [2, 13, 33, 38, 41] utilize long-term popularity over the entire time period, being limited to considering item trends. For instance, items that are popular only during specific periods (i.e., fad items) and items that have maintained decent attraction over a long period (i.e., steady sellers) can be normalized equally if they have the same long-term popularity. However, fad items should be considered popular or unpopular depending on the time.\n\n# 3 Temporal Linear Item-Item Model\n\nIn this section, we first present how sequential information is used in linear item-item models. We then propose TemporAl LinEar Item-Item model (TALE), which effectively incorporates temporal information into linear models in SR.\n\nSequential linear item-item models. Several studies [5, 11, 15] have exploited the efficiency of linear models in SR. Notably, Choi et al. [5] proposes the sequential linear item-item model, i.e., SLIST, which consists of two parts such as SLIS and SLIT. In this paper, we focus on improving SLIT because it mainly handles sequential information for linear models. Specifically, SLIT [5] utilizes two components to reflect sequential information as follows.\n\n- Multi-target augmentation: It uses a source matrix S and a target matrix T instead of X and Y in Eq. (2). Specifically, it splits an entire training matrix into S and T in disjoint sequential order. For example, if the user sequence is  $[i_1^u,i_2^u,i_3^u,i_4^u]$ , then (source, target) sub-sequence pairs are constructed by  $([i_1^u],[i_2^u,i_3^u,i_4^u])$ ,  $([i_1^u,i_2^u],[i_3^u,i_4^u])$ , and  $([i_1^u,i_2^u,i_3^u],[i_4^u])$ . Consequently, S and\n\nT are augmented with multiple sub-sequences. Using S and T, SLIT then learns a transition matrix B, representing the transition from source items to target items.\n\n- Position-aware weighting: It is a weighting scheme using position gap outlined in [11]. This scheme prioritizes higher weights for items that are close to the last item in the source sequence and the first item in the target sequence. In other words, the relative order within the sequence reflects different sequential information.\n\nAlthough SLIT [5] handles sequential information of items, it does not incorporate temporal information, thereby failing to reflect the user preference drift over various time intervals.\n\n# 3.1 Overall Framework\n\nAs shown in Figure 3, TALE consists of three key components to reflect temporal information. (i) Single-target augmentation utilizes a single target item to prevent unnecessary intervention in learning the temporal correlation between input and target items. (ii) Time interval-aware weighting discerns different time intervals using actual timestamps. (iii) Trend-aware normalization reflects dynamic item trends and reduces the popularity bias of items in the sequence.\n\nSpecifically, TALE learns the item-item transition matrix  $\\hat{\\mathbf{B}}_{\\mathrm{TALE}}$  from source items to a single target item. By reformulating Eq. (2), the objective function of TALE is as follows.\n\n$$\n\\min  _ {\\mathbf {B}} \\| \\tilde {\\mathbf {T}} - \\tilde {\\mathbf {S}} \\mathbf {B} \\| _ {F} ^ {2} + \\lambda \\| \\mathbf {B} \\| _ {F} ^ {2},\n$$\n\n$$\n\\text {w h e r e} \\tilde {\\mathbf {T}} = \\mathbf {W} _ {\\text {t r e n d}} \\odot \\mathbf {T} \\text {a n d} \\tilde {\\mathbf {S}} = \\mathbf {W} _ {\\text {t i m e}} \\odot \\mathbf {W} _ {\\text {t r e n d}} \\odot \\mathbf {S}. \\tag {5}\n$$\n\nHere,  $\\tilde{\\mathbf{T}},\\tilde{\\mathbf{S}}\\in \\mathbb{R}^{m^{\\prime}\\times n}$  are target and source matrices for training TALE. Let  $\\mathbf{W}_{\\mathrm{time}}$ $\\mathbf{W}_{\\mathrm{trend}}\\in \\mathbb{R}^{m^{\\prime}\\times n}$  denote weight matrices for time interval-aware weighting and trend-aware normalization, and  $\\mathbf{W}_{\\mathrm{trend}}$  serves as the equivalent of  $\\mathbf{W}_{\\mathrm{norm}}$  in Eq. (4). Let  $m^{\\prime}$  be the number of all augmented sub-sequences in  $\\tilde{\\mathbf{T}}$  and  $\\tilde{\\mathbf{S}}$  ,and  $\\odot$  means the element-wise product. Note that computing  $\\tilde{\\mathbf{T}}$  and  $\\tilde{\\mathbf{S}}$  does not increase model training and inference costs.\n\nThe closed-form solution for Eq. (5) is derived through convex optimization, achieving fast model training.\n\n$$\n\\hat {\\mathbf {B}} _ {\\mathrm {T A L E}} = \\left(\\tilde {\\mathbf {S}} ^ {\\top} \\tilde {\\mathbf {S}} + \\lambda \\mathbf {I}\\right) ^ {- 1} \\tilde {\\mathbf {S}} ^ {\\top} \\tilde {\\mathbf {T}}. \\tag {6}\n$$\n\nFor inference, TALE simply utilizes Eq. (3), as used in [5, 11, 22, 27, 28]. Unlike model training, it assigns item weights based on the relative order of test items. Because the temporal correlation between items is learned in  $\\hat{\\mathbf{B}}_{\\mathrm{TALE}}$ , it is sufficient to consider the relative order of items.\n\n# 3.2 Single-Target Augmentation\n\nTo overcome a limitation of multi-target augmentation [5], we introduce single-target augmentation to effectively incorporate temporal information into linear models (Figure 3-(b)). It uses only the first target item per sub-sequence in the target matrix. For example, if user  $u$  sequence is  $[i_1^u, i_2^u, i_3^u, i_4^u]$ , then (source, target) sequence pairs are augmented by  $([i_1^u], [i_2^u])$ ,  $([i_1^u, i_2^u], [i_3^u])$ , and  $([i_1^u, i_2^u, i_3^u], [i_4^u])$ . As a result, it prevents unnecessary correlations between long-distance items.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/097c7e0b4ee11f8a1db9a506aaed1812b6f954e1034d693235b20abfdca2a949.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/cae946949b236f90814f3b3a693e7e83b7b91b81425eed85557d16204d9eab43.jpg)\n\n\n\n(a) Input sequence\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/6fc8a0f5f11b26474261fcfe68d124e10bada2cda456d0898c5a51f7683825f3.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/2d1fdf68c5f47f73efd578e5eb47435afcaca87afe711d4703f5a02e3b759b6e.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/d23e26a4f1ecd870dd03371c4681346daabb745c8a56d142d30dca78128d5b36.jpg)\n\n\n\n(b) Single-target augmentation\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/f96d4c7ce1b4d8cc1314e5ff5f1820ca90d67c59d5f9de6a4553fef2b92b7dce.jpg)\n\n\n\n(c) Time interval-aware weighting\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/3af6a749c64342619f399acfbc59d4b4f3a544759cec55fed6d8e52a21a30499.jpg)\n\n\n\n(d) Trend-aware normalization\n\n\n\nFigure 3: Illustration of three components of TALE. Single-target augmentation takes each item in the input sequence as the target and the previous items as the source to form the training matrices. Time interval-aware weighting adjusts the significance of each source item, and Trend-aware normalization normalizes items based on their popularity around the time.\n\n\nTheoretical analysis. The objective function with multi-target augmentation is derived as follows, and the detailed proof is in Appendix A.1.  $\\mathbf{T}^{\\mathrm{multi}}$  and  $\\mathbf{T}^{\\mathrm{single}}$  denote target matrix for multi- and single-target augmentation, respectively.\n\n$$\n\\begin{array}{l} \\hat {\\mathbf {B}} _ {\\text {m u l t i}} = \\underset {\\mathbf {B}} {\\operatorname {a r g m i n}} \\sum_ {u ^ {\\prime} = 1} ^ {m ^ {\\prime}} \\left\\| \\mathbf {T} _ {u ^ {\\prime}, *} ^ {\\text {m u l t i}} - \\mathbf {S} _ {u ^ {\\prime}, *} \\mathbf {B} \\right\\| _ {F} ^ {2} (7) \\\\ = \\underset {\\mathbf {B}} {\\operatorname {a r g m i n}} \\sum_ {u = 1} ^ {m} \\sum_ {l = 1} ^ {| S ^ {u} | - 1} \\| \\mathbf {x} \\left(i _ {l + 1: | S ^ {u} |} ^ {u}\\right) - \\mathbf {x} \\left(i _ {1: l} ^ {u}\\right) \\mathbf {B} \\| _ {F} ^ {2} (8) \\\\ = \\underset {\\mathbf {B}} {\\operatorname {a r g m i n}} \\sum_ {u = 1} ^ {m} \\sum_ {s = 1} ^ {| S ^ {u} | - 1} \\sum_ {h = s + 1} ^ {| S ^ {u} |} (h - s) \\| \\mathbf {x} \\left(i _ {h} ^ {u}\\right) - \\mathbf {x} \\left(i _ {s} ^ {u}\\right) \\mathbf {B} \\| _ {F} ^ {2} + \\tilde {\\mathbf {B}} ^ {S}, (9) \\\\ \\end{array}\n$$\n\nwhere  $\\mathbf{x}(i_j^u) \\in \\mathbb{R}^{1 \\times n}$  represents a one-hot vector of user  $u$  with item  $i_j^u$  is marked as 1, and  $\\mathbf{x}(i_{j;l}^u)$  denotes a multi-hot vector, marked 1 for an item sequence  $[i_j^u, \\ldots, i_l^u]$ . In Eq. (8),  $\\mathbf{x}(i_{l+1:|S^u|})$  and  $\\mathbf{x}(i_{1:l}^u)$  mean the target and source sequence, respectively. Note that  $\\tilde{\\mathbf{B}}^S$  refers to terms that are only affected by source sequences, and since they use the same source matrix, the effect of the terms can be ignored (The detailed form of  $\\tilde{\\mathbf{B}}^S$  can be found in the Appendix A.1.). From Eq. (9), the objective function with multi-target augmentation gives a weight of  $(h-s)$  (i.e., position gap) in learning the transition scores from the  $s$ -th item to the  $h$ -th item. Since  $(h-s) \\geq 1$ , this inadvertently increases the weight between distant items.\n\nTo solve this problem, we simply employ the next item as a target item. The position weight  $(h - s)$  can be omitted in the objective function with single-target augmentation, so the learned item correlation is influenced by time interval-aware weighting. The detailed proof is presented in Appendix A.2.\n\n$$\n\\begin{array}{l} \\hat {\\mathbf {B}} _ {\\text {s i n g l e}} = \\underset {\\mathbf {B}} {\\operatorname {a r g m i n}} \\sum_ {u ^ {\\prime} = 1} ^ {m ^ {\\prime}} \\| \\mathrm {T} _ {u ^ {\\prime}, *} ^ {\\text {s i n g l e}} - \\mathrm {S} _ {u ^ {\\prime}, *} \\mathrm {B} \\| _ {F} ^ {2} (10) \\\\ = \\underset {\\mathbf {B}} {\\operatorname {a r g m i n}} \\sum_ {u = 1} ^ {m} \\sum_ {l = 1} ^ {| S ^ {u} | - 1} \\| \\mathbf {x} \\left(i _ {l + 1} ^ {u}\\right) - \\mathbf {x} \\left(i _ {1: l} ^ {u}\\right) \\mathbf {B} \\| _ {F} ^ {2} (11) \\\\ = \\underset {\\mathbf {B}} {\\operatorname {a r g m i n}} \\sum_ {u = 1} ^ {m} \\sum_ {s = 1} ^ {| S ^ {u} | - 1} \\sum_ {h = s + 1} ^ {| S ^ {u} |} \\| \\mathbf {x} \\left(i _ {h} ^ {u}\\right) - \\mathbf {x} \\left(i _ {s} ^ {u}\\right) \\mathbf {B} \\| _ {F} ^ {2} + \\tilde {\\mathbf {B}} ^ {S}. (12) \\\\ \\end{array}\n$$\n\nWe also empirically show that single-target augmentation, which does not emphasize the signal between distant items, performs better than multi-target augmentation (Refer to Section 5.2). Also,\n\nit helps enhance training efficiency by reducing the computation of matrix multiplication with a sparser target matrix.\n\n# 3.3 Time Interval-aware Weighting\n\nOwing to single-target augmentation, time interval-aware weighting is capable of injecting temporal information into linear models as intended. As depicted in Figure 3-(c), it utilizes actual timestamps to control item weights in the source matrix and capture temporal item correlations. Specifically, each element of time interval-aware weight matrix  $\\mathbf{W}_{\\mathrm{time}}$  is computed using weighting function  $w_{\\mathrm{time}}(\\cdot ,\\cdot)$ , which calculates item weights using the time interval between each source item and the target item.\n\n$$\nw _ {\\text {t i m e}} \\left(\\mathcal {S} _ {k} ^ {u}, i _ {s} ^ {u}\\right) = \\max  \\left(\\exp \\left(- \\frac {t _ {| \\mathcal {S} _ {k} ^ {u} |} ^ {u} - t _ {s} ^ {u}}{\\tau_ {\\text {t i m e}}}\\right), c\\right), \\tag {13}\n$$\n\nwhere  $S_{k}^{u}$  denotes  $k$ -th augmented sequence for user  $u$ , and  $t_{|S_k^u |}$  and  $t_s^u$  are timestamps of a target item  $i_{|S_k^u |}$  and a source item  $i_s^u$ .  $c \\in [0,1]$  is a hyperparameter for the threshold, and  $\\tau_{\\mathrm{time}}$  adjusts the time decay in sequences.\n\nThe time interval-aware weight becomes larger for shorter time intervals and smaller for longer time intervals. To consider long-time dependency, we weigh items with long-time intervals by threshold  $c$  to learn weak item relationships. For instance, if there is no threshold  $c$ , the weight of two items with a 30-day interval is as  $e^{(-30 / \\tau)} \\approx 0$ . However, if a user who has interacted in the past interacts again after a long time interval, it is still a weak collaborative signal from recent and past items. Therefore, the threshold  $c$  is used to account for this long-time dependency, allowing TALE to capture a wider variety of item relationships.\n\n# 3.4 Trend-aware Normalization\n\nBy harnessing temporal information through the two aforementioned methods, distant popular items with low correlation can be learned with lower weights, thereby indirectly mitigating popularity bias. However, since the popularity bias still persists, we introduce trend-aware normalization that takes temporal context into account. (Appendix C.3 shows the debiasing effect of our proposed components.) It normalizes the training matrix using the item popularity of the recent  $N$  days based on the interaction timestamps. For example, in Figure 3-(d), items interacted in March (or September) are normalized using only March (or September) popularity. The\n\n\nTable 1: Statistics of five benchmark datasets. 'Avg. Interval' indicates the average of time intervals for consecutive items.\n\n\n<table><tr><td>Dataset</td><td>ML-1M</td><td>Beauty</td><td>Toys</td><td>Sports</td><td>Yelp</td></tr><tr><td>#Users</td><td>6,040</td><td>22,363</td><td>19,412</td><td>29,858</td><td>30,494</td></tr><tr><td>#Items</td><td>3,953</td><td>12,101</td><td>11,924</td><td>18,357</td><td>20,061</td></tr><tr><td>#Inter.</td><td>999,611</td><td>198,502</td><td>167,597</td><td>296,337</td><td>317,078</td></tr><tr><td>Density</td><td>5.19%</td><td>0.07%</td><td>0.07%</td><td>0.06%</td><td>0.05%</td></tr><tr><td>Avg. Length</td><td>165.6</td><td>8.9</td><td>8.6</td><td>8.3</td><td>10.4</td></tr><tr><td>Avg. Interval</td><td>0.6d</td><td>69.6d</td><td>86.0d</td><td>74.1d</td><td>18.6d</td></tr></table>\n\ntrend-aware popularity matrix  $\\mathbf{P}_{\\mathrm{trend}} \\in \\mathbb{R}^{m' \\times n}$  is formulated as follows<sup>2</sup>. The trend-aware normalization matrix  $\\mathbf{W}_{\\mathrm{trend}} = (\\mathbf{P}_{\\mathrm{trend}})^{-\\gamma}$  is used in Eq. (5), with  $\\gamma$  set to  $1/2$  as in existing work [13, 33, 37, 38].\n\n$$\n\\mathbf {P} _ {\\text {t r e n d}} = \\left[ \\begin{array}{c c c c} p _ {1, 1} (N) & p _ {1, 2} (N) & \\dots & p _ {1, n} (N) \\\\ p _ {2, 1} (N) & p _ {2, 2} (N) & \\dots & p _ {2, n} (N) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ p _ {m ^ {\\prime}, 1} (N) & p _ {m ^ {\\prime}, 2} (N) & \\dots & p _ {m ^ {\\prime}, n} (N) \\end{array} \\right], \\tag {14}\n$$\n\n$$\n\\text {w h e r e} p _ {u, j} (N) = \\sum_ {v = 1} ^ {m} \\mathbb {1} \\left(\\left| t _ {u, j} - t _ {v, j} \\right| \\leq N\\right).\n$$\n\nLet  $t_{u,j}$  denote a timestamp of the interaction of user  $u$  and item  $j$ , and  $\\mathbb{1}(\\cdot)$  is an indicator function.\n\nSince  $\\mathbf{P}_{\\mathrm{trend}}$  can be pre-computed, there is no additional computation cost in the training/inference phase. We do not perform trend-aware normalization for users because there are fewer interactions per user compared to per item, resulting in less diversity in user trend patterns (Additionally, we found that user-side trend-aware normalization does not contribute to performance improvement.).\n\nThe cumulative popularity over the entire period can be thought of as a special case of trend-aware popularity. As the window size  $N$  approaches infinity, they converge to the same popularity.\n\n$$\np _ {j} = \\lim  _ {N \\rightarrow \\infty} p _ {*, j} (N). \\tag {15}\n$$\n\n",
    "experiments": "# 4 Experimental Setup\n\nDatasets. As shown in Table 1, we use five benchmark datasets, all of which are pre-processed with a 5-core setting, i.e., users and items with less than 5 interactions are removed [7, 8, 30].\n\n- ML-1M<sup>3</sup> is composed of a collection of users' movie reviews. It is about 100 times denser than other datasets, and the average length of user history is up to 20 times longer.\n\n- Beauty, Toys, and Sports<sup>4</sup> are product review datasets with a total period of 14 years, which is quite long compared to other datasets. We used the widely used 2014 versions.\n\n- Yelp<sup>5</sup> consists of user reviews for the businesses. Following previous studies [7, 8, 30], we used transaction records between January 1, 2019 and January 1, 2020.\n\nEvaluation protocol. We adopt a leave-one-out strategy following the convention [7, 8, 25]. For each user, we utilize the last item as the test item, the second last item as the validation item, and the remaining items for the training set. In the inference phase, we take training and validation items as inputs and evaluate the performance on the test item. For evaluation metrics, we adopt Hit Ratio (HR@K) and Normalized Discounted Cumulative Gain (NDCG@K), with  $K$  set to 1, 5, and 10 as default. According to item popularity of the training set, we divide the test set into Head (top  $20\\%$ ) and Tail (bottom  $80\\%$ ). Note that the higher the performance on the tail items, the lower the popularity bias of the model.\n\nCompeting models. To validate the effectiveness and efficiency of the proposed method, we adopt the following ten sequential recommendation (SR) models as baselines. The detailed descriptions of each model are in Section 6.\n\n- Non-temporal SR models: SASRec [17] is a widely used baseline that utilizes a uni-directional self-attention mechanism, and DuoRec [23] improves SASRec through contrastive learning. FEARc [8] and BSARc [25] are state-of-the-art SR models that utilize frequency information to represent user sequences.\n\n- Temporal SR models: TiSASRec [19] uses positional encoding with time interval information, and TCPSRec [30] utilizes the invariance and periodicity of sequences to pre-train the model. TiCoSeRec [7] performs contrastive learning by augmenting uniform sequences with small time intervals.\n\n- Efficient SR models: LinRec [20] proposes linear attention that can be applied to various transformer-based models, while LRUREc [39] converts RNNs into linear recurrent modules to improve their efficiency.  $\\mathbf{SLIST}^6$  [5] is a linear model that only considers sequential order but not temporal information.\n\nImplementation details. All experiments were performed using Recbole [36, 42] framework, which is an open-source library for recommendation systems<sup>7</sup>. We set the maximum sequence length for neural models to 50, following the conventions [7, 8, 30]. The other hyperparameters were tuned using the validation set, with an early stop based on NDCG@10. We performed a grid search with training batch size of {128, 256, 512, 1024, 2048}, learning rates of {1e-4, 5e-4, 1e-3, 5e-3}, number of layers of {1, 2, 3}, number of heads of {1, 2, 3}, and weight decay of {1e-8, 0}. The dropout rate was searched in the interval [0, 0.5] with step size 0.1, referring to [23]. For LinRec [20], we use SASRec [17] as a backbone. Each model's own hyperparameters were searched by following the original papers. The L2-regularization coefficient  $\\lambda$  of TALE was searched in {1, 5, 10, 50, 100, 500, 1000}. For the time interval-aware weighting,  $\\tau_{\\mathrm{time}}$  was searched in the range  $[2^{-10}, 2^{10}]$  with exponentially increasing steps in powers of 2, and threshold  $c$  was tuned in [0, 1] with step size 0.1. The window size  $N$  (days) of trend-aware normalization was searched in {7, 30, 90, 180, 360, 720}. We run all experiments on NVIDIA RTX-3090 24GB GPU and Intel Xeon Gold 6226R CPU.\n\n\nTable 2: Accuracy comparison for the eight traditional SR models on five datasets. The best results are marked in bold, and the second-best results are underlined. 'Imp.' indicates the improvement ratio of TALE compared to SLIST [5].\n\n\n<table><tr><td>Dataset</td><td>Metric</td><td>SASRec</td><td>DuoRec</td><td>FEARec</td><td>BSARec</td><td>TiSASRec</td><td>TCPSRec</td><td>TiCoSeRec</td><td>SLIST</td><td>TALE</td><td>Imp.</td></tr><tr><td rowspan=\"5\">ML-1M</td><td>HR@1</td><td>0.0611</td><td>0.0606</td><td>0.0594</td><td>0.0623</td><td>0.0578</td><td>0.0540</td><td>0.0031</td><td>0.0596</td><td>0.0656</td><td>10.07%</td></tr><tr><td>HR@5</td><td>0.1763</td><td>0.1838</td><td>0.1829</td><td>0.1868</td><td>0.1851</td><td>0.1697</td><td>0.0884</td><td>0.1710</td><td>0.1854</td><td>8.42%</td></tr><tr><td>HR@10</td><td>0.2697</td><td>0.2697</td><td>0.2672</td><td>0.2752</td><td>0.2700</td><td>0.2632</td><td>0.1719</td><td>0.2373</td><td>0.2546</td><td>7.29%</td></tr><tr><td>NDCG@5</td><td>0.1197</td><td>0.1230</td><td>0.1220</td><td>0.1261</td><td>0.1216</td><td>0.1124</td><td>0.0452</td><td>0.1164</td><td>0.1275</td><td>9.54%</td></tr><tr><td>NDCG@10</td><td>0.1496</td><td>0.1506</td><td>0.1492</td><td>0.1543</td><td>0.1488</td><td>0.1423</td><td>0.0721</td><td>0.1377</td><td>0.1500</td><td>8.93%</td></tr><tr><td rowspan=\"5\">Beauty</td><td>HR@1</td><td>0.0071</td><td>0.0122</td><td>0.0126</td><td>0.0112</td><td>0.0092</td><td>0.0080</td><td>0.0178</td><td>0.0267</td><td>0.0288</td><td>7.87%</td></tr><tr><td>HR@5</td><td>0.0558</td><td>0.0566</td><td>0.0579</td><td>0.0553</td><td>0.0579</td><td>0.0567</td><td>0.0504</td><td>0.0597</td><td>0.0674</td><td>12.90%</td></tr><tr><td>HR@10</td><td>0.0821</td><td>0.0864</td><td>0.0876</td><td>0.0888</td><td>0.0842</td><td>0.0855</td><td>0.0740</td><td>0.0797</td><td>0.0887</td><td>11.29%</td></tr><tr><td>NDCG@5</td><td>0.0319</td><td>0.0350</td><td>0.0356</td><td>0.0338</td><td>0.0340</td><td>0.0332</td><td>0.0343</td><td>0.0435</td><td>0.0485</td><td>11.49%</td></tr><tr><td>NDCG@10</td><td>0.0404</td><td>0.0446</td><td>0.0451</td><td>0.0445</td><td>0.0425</td><td>0.0424</td><td>0.0418</td><td>0.0499</td><td>0.0554</td><td>11.02%</td></tr><tr><td rowspan=\"5\">Toys</td><td>HR@1</td><td>0.0059</td><td>0.0095</td><td>0.0107</td><td>0.0195</td><td>0.0094</td><td>0.0043</td><td>0.0176</td><td>0.0333</td><td>0.0355</td><td>6.61%</td></tr><tr><td>HR@5</td><td>0.0601</td><td>0.0642</td><td>0.0667</td><td>0.0606</td><td>0.0675</td><td>0.0648</td><td>0.0545</td><td>0.0722</td><td>0.0815</td><td>12.88%</td></tr><tr><td>HR@10</td><td>0.0863</td><td>0.0941</td><td>0.0967</td><td>0.0906</td><td>0.0963</td><td>0.0936</td><td>0.0801</td><td>0.0919</td><td>0.1021</td><td>11.10%</td></tr><tr><td>NDCG@5</td><td>0.0342</td><td>0.0382</td><td>0.0401</td><td>0.0403</td><td>0.0392</td><td>0.0358</td><td>0.0363</td><td>0.0535</td><td>0.0594</td><td>11.03%</td></tr><tr><td>NDCG@10</td><td>0.0426</td><td>0.0479</td><td>0.0497</td><td>0.0500</td><td>0.0485</td><td>0.0452</td><td>0.0445</td><td>0.0599</td><td>0.0661</td><td>10.35%</td></tr><tr><td rowspan=\"5\">Sports</td><td>HR@1</td><td>0.0021</td><td>0.0053</td><td>0.0044</td><td>0.0022</td><td>0.0026</td><td>0.0018</td><td>0.0109</td><td>0.0155</td><td>0.0184</td><td>18.71%</td></tr><tr><td>HR@5</td><td>0.0292</td><td>0.0331</td><td>0.0329</td><td>0.0324</td><td>0.0308</td><td>0.0331</td><td>0.0342</td><td>0.0380</td><td>0.0418</td><td>10.00%</td></tr><tr><td>HR@10</td><td>0.0462</td><td>0.0498</td><td>0.0511</td><td>0.0544</td><td>0.0473</td><td>0.0521</td><td>0.0515</td><td>0.0517</td><td>0.0564</td><td>9.09%</td></tr><tr><td>NDCG@5</td><td>0.0162</td><td>0.0195</td><td>0.0192</td><td>0.0175</td><td>0.0172</td><td>0.0180</td><td>0.0226</td><td>0.0271</td><td>0.0305</td><td>12.55%</td></tr><tr><td>NDCG@10</td><td>0.0217</td><td>0.0249</td><td>0.0250</td><td>0.0245</td><td>0.0226</td><td>0.0241</td><td>0.0282</td><td>0.0315</td><td>0.0352</td><td>11.75%</td></tr><tr><td rowspan=\"5\">Yelp</td><td>HR@1</td><td>0.0219</td><td>0.0212</td><td>0.0212</td><td>0.0218</td><td>0.0218</td><td>0.0220</td><td>0.0065</td><td>0.0176</td><td>0.0220</td><td>25.00%</td></tr><tr><td>HR@5</td><td>0.0417</td><td>0.0437</td><td>0.0435</td><td>0.0468</td><td>0.0430</td><td>0.0461</td><td>0.0231</td><td>0.0563</td><td>0.0558</td><td>-0.89%</td></tr><tr><td>HR@10</td><td>0.0605</td><td>0.0622</td><td>0.0619</td><td>0.0680</td><td>0.0607</td><td>0.0657</td><td>0.0382</td><td>0.0720</td><td>0.0707</td><td>-1.81%</td></tr><tr><td>NDCG@5</td><td>0.0317</td><td>0.0327</td><td>0.0324</td><td>0.0345</td><td>0.0326</td><td>0.0342</td><td>0.0141</td><td>0.0375</td><td>0.0394</td><td>5.07%</td></tr><tr><td>NDCG@10</td><td>0.0378</td><td>0.0386</td><td>0.0383</td><td>0.0413</td><td>0.0382</td><td>0.0404</td><td>0.0191</td><td>0.0426</td><td>0.0442</td><td>3.76%</td></tr></table>\n\n\nTable 3: Accuracy and efficiency comparison for efficient SR models on five datasets. 'Train' and 'Eval' mean the runtime (seconds) for training and evaluation. For linear models, the runtime is measured on CPU and for other baselines on GPU.\n\n\n<table><tr><td>Dataset</td><td>Model</td><td>HR@5</td><td>NDCG@5</td><td>Train</td><td>Eval</td></tr><tr><td rowspan=\"4\">ML-1M</td><td>LinRec</td><td>0.1843</td><td>0.1254</td><td>1,241</td><td>10</td></tr><tr><td>LRURec</td><td>0.1491</td><td>0.0936</td><td>2,198</td><td>29</td></tr><tr><td>SLIST</td><td>0.1710</td><td>0.1164</td><td>412</td><td>0.2</td></tr><tr><td>TALE</td><td>0.1854</td><td>0.1275</td><td>179</td><td>0.2</td></tr><tr><td rowspan=\"4\">Beauty</td><td>LinRec</td><td>0.0550</td><td>0.0323</td><td>285</td><td>40</td></tr><tr><td>LRURec</td><td>0.0363</td><td>0.0257</td><td>678</td><td>233</td></tr><tr><td>SLIST</td><td>0.0597</td><td>0.0435</td><td>5</td><td>10</td></tr><tr><td>TALE</td><td>0.0674</td><td>0.0485</td><td>5</td><td>10</td></tr><tr><td rowspan=\"4\">Toys</td><td>LinRec</td><td>0.0631</td><td>0.0359</td><td>197</td><td>37</td></tr><tr><td>LRURec</td><td>0.0624</td><td>0.0370</td><td>356</td><td>92</td></tr><tr><td>SLIST</td><td>0.0722</td><td>0.0535</td><td>5</td><td>9</td></tr><tr><td>TALE</td><td>0.0815</td><td>0.0594</td><td>5</td><td>9</td></tr><tr><td rowspan=\"4\">Sports</td><td>LinRec</td><td>0.0314</td><td>0.0172</td><td>529</td><td>52</td></tr><tr><td>LRURec</td><td>0.0178</td><td>0.0105</td><td>725</td><td>163</td></tr><tr><td>SLIST</td><td>0.0380</td><td>0.0271</td><td>14</td><td>19</td></tr><tr><td>TALE</td><td>0.0418</td><td>0.0305</td><td>13</td><td>19</td></tr><tr><td rowspan=\"4\">Yelp</td><td>LinRec</td><td>0.0414</td><td>0.0316</td><td>230</td><td>41</td></tr><tr><td>LRURec</td><td>0.0269</td><td>0.0164</td><td>531</td><td>141</td></tr><tr><td>SLIST</td><td>0.0563</td><td>0.0375</td><td>24</td><td>21</td></tr><tr><td>TALE</td><td>0.0558</td><td>0.0394</td><td>13</td><td>21</td></tr></table>\n\n# 5 Experimental Results\n\n# 5.1 Performance Comparison\n\nComparison with traditional SR models. Table 2 shows the performance comparison of TALE and the eight SR models, and we reveal three key findings. (i) Linear models (i.e., SLIST and TALE) achieve comparable to or better performance than neural SR models. In particular, they outperform the state-of-the-art SR model, BSARec, on four datasets (i.e., Beauty, Toys, Sports, and Yelp) which have short average sequence lengths and sparse interactions. (ii) TALE consistently outperforms SLIST due to considering temporal information with an average gain of  $9.07\\%$  on NDCG@10. (Appendix C.4 shows that the learned weight matrix of TALE reflects more temporal information than that of SLIST.) Meanwhile, utilizing additional temporal information does not always result in higher performance. While TiSASRec and TCPSRec have higher performance than the backbone model (i.e., SASRec), in many cases, DuoRec, FEARec, and BSARec are superior to SR models with temporal information<sup>8</sup>. Based on this result, we can see that temporal information is important in SR, as well as the model architecture and training loss. (iii) For ML-1M, neural models outperform linear models in some metrics. We assume this is because the neural models robustly train on highly dense ML-1M. Nevertheless, TALE performs better on some evaluation metrics (e.g., HR@1 and NDCG@5).\n\n\nTable 4: Tail and Head performance comparison on ML-1M and Beauty. 'Norm.' denotes the existing normalization method (i.e., Eq. (4)). Each metric is NDCG@5.\n\n\n<table><tr><td rowspan=\"2\">Dataset\nModel</td><td colspan=\"3\">ML-1M</td><td colspan=\"3\">Beauty</td></tr><tr><td>All</td><td>Tail</td><td>Head</td><td>All</td><td>Tail</td><td>Head</td></tr><tr><td>SASRec</td><td>0.1197</td><td>0.0648</td><td>0.1567</td><td>0.0319</td><td>0.0167</td><td>0.0508</td></tr><tr><td>BSARec</td><td>0.1261</td><td>0.0740</td><td>0.1642</td><td>0.0338</td><td>0.0169</td><td>0.0548</td></tr><tr><td>TiSASRec</td><td>0.1216</td><td>0.0706</td><td>0.1589</td><td>0.0340</td><td>0.0212</td><td>0.0499</td></tr><tr><td>SLIST</td><td>0.1164</td><td>0.0624</td><td>0.1559</td><td>0.0435</td><td>0.0235</td><td>0.0676</td></tr><tr><td>SLIST+Norm.</td><td>0.1030</td><td>0.0675</td><td>0.1290</td><td>0.0360</td><td>0.0275</td><td>0.0463</td></tr><tr><td>TALE</td><td>0.1275</td><td>0.0814</td><td>0.1612</td><td>0.0485</td><td>0.0271</td><td>0.0736</td></tr></table>\n\n\n\nTable 5: Ablation study of TALE on ML-1M and Beauty. TALE consists of three parts: (1) single-target augmentation, (2) time interval-aware weighting, and (3) trend-aware normalization. Each metric is NDCG@5.\n\n\n<table><tr><td colspan=\"3\">Dataset</td><td colspan=\"3\">ML-1M</td><td colspan=\"3\">Beauty</td></tr><tr><td>(1)</td><td>(2)</td><td>(3)</td><td>All</td><td>Tail</td><td>Head</td><td>All</td><td>Tail</td><td>Head</td></tr><tr><td>✓</td><td>✓</td><td>✓</td><td>0.1275</td><td>0.0814</td><td>0.1614</td><td>0.0485</td><td>0.0271</td><td>0.0736</td></tr><tr><td>-</td><td>✓</td><td>✓</td><td>0.0473</td><td>0.0161</td><td>0.0701</td><td>0.0296</td><td>0.0154</td><td>0.0467</td></tr><tr><td>✓</td><td>-</td><td>✓</td><td>0.1227</td><td>0.0739</td><td>0.1584</td><td>0.0450</td><td>0.0239</td><td>0.0704</td></tr><tr><td>✓</td><td>✓</td><td>-</td><td>0.1257</td><td>0.0773</td><td>0.1611</td><td>0.0468</td><td>0.0243</td><td>0.0739</td></tr><tr><td>-</td><td>-</td><td>✓</td><td>0.1187</td><td>0.0659</td><td>0.1573</td><td>0.0438</td><td>0.0242</td><td>0.0663</td></tr><tr><td>-</td><td>✓</td><td>-</td><td>0.0430</td><td>0.0114</td><td>0.0661</td><td>0.0303</td><td>0.0150</td><td>0.0487</td></tr><tr><td>✓</td><td>-</td><td>-</td><td>0.1172</td><td>0.0685</td><td>0.1528</td><td>0.0444</td><td>0.0235</td><td>0.0696</td></tr><tr><td>-</td><td>-</td><td>-</td><td>0.1164</td><td>0.0624</td><td>0.1559</td><td>0.0435</td><td>0.0235</td><td>0.0676</td></tr></table>\n\nComparison with efficient SR models. Table 3 shows the accuracy and efficiency with efficient SR models (i.e., LinRec [20] and LRURec [39]) on five datasets. For a fair comparison, we use batch sizes of 2048 and 1 for training and evaluation, respectively. For all five datasets, TALE performs the best compared to LinRec and LRURec, with the lowest training and evaluation time. Thanks to the closed-form solution, on ML-1M, Beauty, and Yelp, TALE achieves  $6.9\\mathrm{x}$ ,  $57\\mathrm{x}$ , and  $17.7\\mathrm{x}$  faster training time than LinRec, respectively. In a nutshell, TALE shows higher accuracy and superior efficiency compared to efficient neural SR models. Efficiency comparison with the other seven SR models is shown in Appendix C.5.\n\n# 5.2 In-depth Analysis\n\nIn this section, we provide the empirical results on ML-1M and Beauty due to space limitations. The results on additional datasets (i.e., Toys, Sports, and Yelp) are shown in Appendix C.6-C.8.\n\nPopularity bias. To validate the ability of TALE to mitigate popularity bias, we split the entire test set into Head and Tail, and Table 4 shows the performance for each. (i) TALE performs better than others on both tail and head items. In particular, TALE shows more performance gains for tail items, indicating that it is better at reducing popularity bias than neural models. Specifically, on ML-1M and Beauty, TALE achieves  $30.4\\%$  and  $15.3\\%$  improvement gains in a tail item performance over SLIST, respectively. (We will explore it in more detail in the ablation study.) (ii) Applying traditional normalization (Eq. (4)) to SLIST (i.e.,  $\\mathrm{SLIST + Norm}$ ) improves performance for tail items, but it severely degrades performance for head items, resulting in significantly lower overall performance.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/0bfcad5d933545ee45c3e186751116c3213fa8704924deef869a576f36f4e046.jpg)\n\n\n\n(a) ML-1M\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/116a8b8d9dd7b9619a1708cc69ce9afc099050a105fdd0f9d73765cf5ffd132f.jpg)\n\n\n\n(b) Beauty\n\n\n\nFigure 4: Accuracy comparison by the time interval group on ML-1M and Beauty.\n\n\nThis is because Eq. (4) only considers the cumulative popularity over the entire period, not the trend-aware popularity, which simply leads to recommendations towards unpopular items.\n\nAblation study. Table 5 indicates a breakdown of the effectiveness of each component of TALE. The key observations are as follows. (i) Using all three components is more accurate than using only some of them. Using (1) and (2) together yields the largest performance gains among the partial combinations. Furthermore, using (1) leads to consistent performance improvements in all cases, as it is effective in learning the item relationship because it lowers the weight of items that are distant. (ii) On the other hand, (2) without using (1) results in significant performance degradation. As shown in the theoretical analysis in Section 3.2, not using (1), i.e., using the multi-target augmentation, cannot correctly learn the relationship between items. (iii) (3) shows the debiasing effect, with tail item performance gains of  $5.61\\%$  and  $2.98\\%$  for ML-1M and Beauty, respectively, compared to not using (3). For datasets sensitive to item trends (e.g., ML-1M), applying (3) improves a head item performance besides tail items. It not only removes popularity bias in trend-sensitive datasets but also detects head items that users don't prefer. It indicates that (3) is possible to satisfy both trend-sensitive and non-trend-sensitive users.\n\nPerformance over time intervals. Figure 4 shows performance based on the various time intervals between the test item and the validation item for each user. We divided the test set into three groups using time intervals: Short (0% to  $33.3\\%$ ), Mid (33.3% to  $66.6\\%$ ), and Long (66.6% to  $100\\%$ ). (i) All SR models tend to perform worse as the time interval increases. As the time interval increases, the user interest varies widely, which increases the difficulty of preference prediction. (ii) Nevertheless, TALE outperforms the baselines at relatively long time intervals (i.e., Mid and Long), showing that it effectively utilizes the long-time dependency. (iii) TALE outperforms SLIST in all subsets, which is due to its better capture of item relevance based on the use of temporal information.\n\n# 5.3 Hyperparameter Sensitivity\n\nTime interval-aware weighting. Figure 5 provides the performance of TALE depending on threshold  $c$  and time decay  $\\tau_{\\mathrm{time}}$ , respectively. Both hyperparameters have different optimal values depending on the dataset. ML-1M has a smaller  $\\tau_{\\mathrm{time}}$  than Beauty because the average time interval in ML-1M is relatively small, about 14 hours. Also, threshold  $c$  is greater in Beauty than in ML-1M, where long-time dependency is important. As such, time interval-aware weighting has to be adaptively applied to the characteristics of the dataset by tuning  $c$  and  $\\tau_{\\mathrm{time}}$ .\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/b343f86a2a85dab459b31de56c43002037b5a42fd7d84790d385fddbc44d2449.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/421e1ab21535dc5a4c20a4b871a85c9e4723d9a8261e336f674cb05dc7b3c331.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/78e197731540d7831d53b758309aa17db96670b94cf545d8e8a2050d618052f9.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/7de7c7170416bf0b7db7cbd8fb7e780de54a9948699c897f919bfce75153fdd3.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/db986809b8dfec575a15d0ea40fa458b501403829e9b33e8b7d86c27e81aab3b.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-07/7f12d284-ec1f-40a8-8c2f-de2270dea09f/0861c530beea43cdb7675b0d19c4990e24ccd6d705936b12276f70574a207e68.jpg)\n\n\n\nFigure 5: Performance of TALE over  $c$ ,  $\\tau_{\\mathrm{time}}$ , and  $N$  on ML-1M and Beauty.\n\n\nTrend-aware normalization. Figure 5 shows the performance of TALE for different window sizes  $N$ . As the window size  $N \\to \\infty$ , it is equivalent to general normalization (Eq. (15)), so we can see that the performance converges as  $N$  gets larger. We can observe that the optimal window size depends on the dataset; for example, the optimal  $N$  is relatively small for ML-1M, which has a small average time interval. The empirical results of the three hyperparameters on Toys, Sports, and Yelp are in Appendix C.8.",
    "hyperparameter": "L2-regularization λ ∈ {1, 5, 10, 50, 100, 500, 1000}; time-decay τ_time searched in [2^-10, 2^10] (powers of 2); time-interval threshold c ∈ [0, 1] with step 0.1; trend window N ∈ {7, 30, 90, 180, 360, 720} days; trend exponent γ fixed to 0.5."
  }