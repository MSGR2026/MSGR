{
  "id": "NARM_2018",
  "paper_title": "Neural Attentive Session-based Recommendation",
  "alias": "NARM",
  "year": 2018,
  "domain": "Recsys",
  "task": "SequentialRecommendation",
  "idea": "NARM (Neural Attentive Recommendation Machine) combines two encoding mechanisms for session-based recommendation: a global encoder using GRU to capture sequential behavior patterns across the entire session, and a local encoder with attention mechanism to identify the user's main purpose by dynamically weighting important items. The model uses a bi-linear decoder instead of fully-connected layers to reduce parameters and improve performance, concatenating both global sequential features and local attentive features to form a unified session representation.",
  "introduction": "# 1 INTRODUCTION\n\nA user session is kicked off when a user clicks a certain item; within a user session, clicking on the interesting item, and spending more time viewing it. After that, the user clicks another interesting one to start the view again. Such iterative process will be completed until the user's requirements are satisfied. Current recommendation research confronts challenges when recommendations are merely from those user sessions, where existing recommendation methods\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\nCIKM'17, November 6-10, 2017, Singapore.\n\n© 2017 ACM. ISBN 978-1-4503-4918-5/17/11...$15.00\n\nDOI: https://doi.org/10.1145/3132847.3132926\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/991f815259fff1d2f2421a594a1dc7e802b7a900632998894c252d554a3e0225.jpg)  \n(a) The global recommender\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/058fe38b4b858bf4bbe51be034a9d2a077a129e8ea11c7a9a543e32606d9a8b2.jpg)  \n(b) The local recommender  \nFigure 1: Two different recommenders. The global recommender models the user's whole sequential behavior to make recommendations while the local recommender captures the user's main purpose to make recommendations. The numbers above the items denote the recommendation scores produced by each recommender. In (b), the item in the red dashed box is more relevant to the current user's intention. And the red line is thicker when the item is more important.\n\n[1, 16, 39, 42] cannot perform well. To tackle this problem, session-based recommendation [33] is proposed to predict the next item that the user is probably interested in based merely on implicit feedbacks, i.e., user clicks, in the current session.\n\nHidasi et al. [12] apply recurrent neural networks (RNN) with Gated Recurrent Units (GRU) for session-based recommendation. The model considers the first item clicked by a user as the initial input of RNN, and generates recommendations based on it. Then the user might click one of the recommendations, which is fed into RNN next, and the successive recommendations are produced based on the whole previous clicks. Tan et al. [40] further improve this RNN-based model by utilizing two crucial techniques, i.e., data augmentation and a method to account for shifts in the input data distribution. Though all above RNN-based methods show promising improvements over traditional recommendation approaches, they only take into account the user's sequential behavior in the current session, whereas the user's main purpose in the current session is not emphasized. Relying only on the user's sequential behavior is dangerous when a user accidentally clicks on wrong items or s/he is attracted by some unrelated items due\n\nto curiosity. Therefore, we argue that both the user's sequential behavior and main purpose in the current session should be considered in session-based recommendation.\n\nSuppose that a user wants to buy a shirt on the Internet. As shown in Figure 1, during browsing, s/he tends to click on some shirts with similar styles to make a comparison, meanwhile s/he might click a pair of suit pants by accident or due to curiosity. After that, s/he keeps looking for suitable shirts. In this case, if we only consider about his/her sequential behavior, another shirt or suit pants even a pair of shoes might be recommended because many users click them after clicking some shirts and suit pants, as shown in Figure 1(a). Assume that the recommender is an experienced human purchasing guide, the guide could conjecture that this user is very likely to buy a short sleeve shirt at this time because most of his/her clicked items are related to it. Therefore, more attention would be paid to the short sleeve shirts that the user has clicked and another similar shirt would be recommended, as shown in Figure 1(b). Ideally, in addition to considering about the user's entire sequential behavior, a better recommender should also take into account the user's main purpose which is reflected by some relatively important items in the current session. Note that the sequential behavior and the main purpose in one session are complementary to each other because we can not always conjecture a user's main purpose from a session, e.g., when the session is too short or the user just clicks something aimlessly.\n\nTo tackle the above problem, we propose a novel neural networks framework, namely Neural Attentive Recommendation Machine (NARM). Specifically, we explore a hybrid encoder with an attention mechanism to model the user's sequential behavior and capture the user's main purpose in the current session, which are combined as a unified session representation later. With this item-level attention mechanism, NARM learns to attend differentially to more and less important items. We then compute the recommendation scores for each candidate item with a bi-linear matching scheme based on the unified session representation. NARM is trained by jointly learning the item and session representations as well as their matchings.\n\nThe main contributions of this work are summarized as follows:\n\n- We propose a novel NARM model to take into account both the user's sequential behavior and main purpose in the current session, and compute recommendation scores by using a bi-linear matching scheme.  \n- We apply an attention mechanism to extract the user's main purpose in the current session.  \n- We carried out extensive experiments on two benchmark datasets. The results show that NARM outperforms state-of-the-art baselines in terms of recall and MRR on both datasets. Moreover, we find that NARM achieves better performance on long sessions, which demonstrates its advantages in modeling the user's sequential behavior and main purpose simultaneously.",
  "method": "# 3 METHOD\n\nIn this section, we first introduce the session-based recommendation task. Then we describe the proposed NARM in detail.\n\n# 3.1 Session-based Recommendation\n\nSession-based recommendation is the task of predicting what a user would like to click next when his/her current sequential transaction data is given. Here we give a formulation of the session-based recommendation problem.\n\nLet  $[x_1, x_2, \\ldots, x_{n-1}, x_n]$  be a click session, where  $x_i \\in \\mathcal{I}$  ( $1 \\leq i \\leq n$ ) is the index of one clicked item out of a total number of  $m$  items. We build a model  $\\mathsf{M}$  so that for any given prefix of the click sequence in the session,  $\\mathbf{x} = [x_1, x_2, \\ldots, x_{t-1}, x_t]$ ,  $1 \\leq t \\leq n$ , we get the output  $\\mathbf{y} = \\mathsf{M}(\\mathbf{x})$ , where  $\\mathbf{y} = [y_1, y_2, \\ldots, y_{m-1}, y_m]$ . We view  $\\mathbf{y}$  as a ranking list over all the next items that can occur in that session, where  $y_j$  ( $1 \\leq j \\leq m$ ) corresponds to the recommendation score of item  $j$ . Since a recommender typically needs to make more than one recommendations for the user, thus the top- $k$  ( $1 \\leq k \\leq m$ ) items in  $\\mathbf{y}$  are recommended.\n\n# 3.2 Overview\n\nIn this paper, we propose an improved neural encoder-decoder architecture [26, 35] to address the session-based recommendation problem, named Neural Attentive Recommendation Machine (NARM). The basic idea of NARM is to build a hidden representation of the current session, and then generate predictions based on it. As shown in Figure 2, the encoder converts the input click sequence  $\\mathbf{x} = [x_{1}, x_{2}, \\dots, x_{t - 1}, x_{t}]$  into a set of high-dimensional\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/a97d680ad00946bf8b6d615e62ab42912d4d03243d6dcf943f87f2f5e0409801.jpg)  \nFigure 2: The general framework and dataflow of the encoder-decoder-based NARM.\n\nhidden representations  $\\mathbf{h} = [h_1, h_2, \\dots, h_{t-1}, h_t]$ , which along with the attention signal at time  $t$  (denoted as  $\\alpha_t$ ), are fed to the session feature generator to build the representation of the current session to decode at time  $t$  (denoted as  $\\pmb{c}_t$ ). Finally  $\\pmb{c}_t$  is transformed by a matrix  $\\pmb{U}$  (as part of the decoder) into an activate function to produce a ranking list over all items,  $\\mathbf{y} = [y_1, y_2, \\dots, y_{m-1}, y_m]$ , that can occur in the current session.\n\nThe role of  $\\alpha_{t}$  is to determine which part of the hidden representations should be emphasized or ignored at time  $t$ . It should be noted that  $\\alpha_{t}$  could be fixed over time or changes dynamically during the prediction process. In the dynamic setting,  $\\alpha_{t}$  can be a function of the representations of hidden states or the input item embeddings. We adopt the dynamic setting in our model, more details will be described in §3.4.\n\nThe basic idea of our work is to learn a recommendation model that takes into consideration both the user's sequential behavior and main purpose in the current session. In the following part of this section, we first describe the global encoder in NARM which is used to model the user's sequential behavior (§3.3). Then we introduce the local encoder which is used to capture the user's main purpose in the current session (§3.4). Finally we show our NARM which combines both of them and computes the recommendation scores for each candidate item by using a bilinear matching scheme (§3.5).\n\n# 3.3 Global Encoder in NARM\n\nIn the global encoder, the inputs are entire previous clicks while the output is the feature of the user's sequential behavior in the current session. Both the inputs and output are uniformly represented by high-dimensional vectors.\n\nFigure 3(a) shows the graphical model of the global encoder in NARM. We use a RNN with Gated Recurrent Units (GRU) rather than a standard RNN because Hidasi et al. [12] demonstrate that GRU can outperform the Long Short-Term Memory (LSTM) [14] units for the session-based recommendation task. GRU is a more elaborate RNN unit that aims at dealing with the vanishing gradient problem. The activation of GRU is a linear interpolation\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/b6811f00612f5ccc58c841bd92ac664cb5404dcda08c755e02c5ae6c366932b7.jpg)  \n(a) The graphical model of the global encoder in NARM, where the last hidden state is interpreted as the user's sequential behavior feature  $c_{t}^{\\mathrm{g}} = h_{t}$ .  \nFigure 3: The global encoder and the local encoder in NARM.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/ad31bb0bbcc957722aadfdeec0eb7d0a3a497a8acfb43f766836f85f059c6713.jpg)  \n(b) The graphical model of the local encoder in NARM, where the weighted sum of hidden states is interpreted as the user's main purpose feature  $c_{t}^{1} = \\sum_{j=1}^{t} \\alpha_{tj} h_{j}$ .\n\nbetween the previous activation  $\\pmb{h}_{t-1}$  and the candidate activation  $\\widehat{\\pmb{h}}_t$ ,\n\n$$\n\\boldsymbol {h} _ {t} = \\left(1 - z _ {t}\\right) \\boldsymbol {h} _ {t - 1} + z _ {t} \\widehat {\\boldsymbol {h}} _ {t}, \\tag {1}\n$$\n\nwhere the update gate  $z_{t}$  is given by\n\n$$\n\\boldsymbol {z} _ {t} = \\sigma \\left(\\boldsymbol {W} _ {z} \\boldsymbol {x} _ {t} + \\boldsymbol {U} _ {z} \\boldsymbol {h} _ {t - 1}\\right). \\tag {2}\n$$\n\nThe candidate activation function  $\\pmb{h}_t$  is computed as\n\n$$\n\\widehat {\\boldsymbol {h}} _ {t} = \\tanh  \\left[ \\boldsymbol {W} \\boldsymbol {x} _ {t} + \\boldsymbol {U} \\left(\\boldsymbol {r} _ {t} \\odot \\boldsymbol {h} _ {t - 1}\\right) \\right], \\tag {3}\n$$\n\nwhere the reset gate  $r_t$  is given by\n\n$$\n\\boldsymbol {r} _ {t} = \\sigma \\left(\\boldsymbol {W} _ {r} \\boldsymbol {x} _ {t} + \\boldsymbol {U} _ {r} \\boldsymbol {h} _ {t - 1}\\right). \\tag {4}\n$$\n\nWith a trivial session feature generator, we essentially use the final hidden state  $h_t$  as the representation of the user's sequential behavior\n\n$$\n\\boldsymbol {c} _ {t} ^ {\\mathrm {g}} = \\boldsymbol {h} _ {t}. \\tag {5}\n$$\n\nHowever, this global encoder has its drawbacks such as a vectorial summarization of the whole sequence behavior is often hard to capture a preciser intention of the current user.\n\n# 3.4 Local Encoder in NARM\n\nThe architecture of the local encoder is similar to the global encoder as shown in Figure 3(b). In this encoding scheme we also use RNN with GRU as the basic component. To capture the user's main purpose in the current session, we involve an item-level attention mechanism which allows the decoder to dynamically select and linearly combine different parts of the input sequence,\n\n$$\n\\boldsymbol {c} _ {t} ^ {1} = \\sum_ {j = 1} ^ {t} \\alpha_ {t j} \\boldsymbol {h} _ {j}, \\tag {6}\n$$\n\nwhere the weighted factors  $\\alpha$  determine which part of the input sequence should be emphasized or ignored when making predictions, which in turn is a function of hidden states,\n\n$$\n\\alpha_ {t j} = q \\left(\\boldsymbol {h} _ {t}, \\boldsymbol {h} _ {j}\\right). \\tag {7}\n$$\n\nBasically, the weighted factor  $\\alpha_{tj}$  models the alignment between the inputs around position  $j$  and the output at position  $t$ , so it can be viewed as a specific matching model. In the local encoder, the function  $q$  specifically computes the similarity between the final\n\nhidden state  $\\pmb{h}_t$  and the representation of the previous clicked item  $\\pmb{h}_j$ ,\n\n$$\nq \\left(\\boldsymbol {h} _ {t}, \\boldsymbol {h} _ {j}\\right) = \\boldsymbol {v} ^ {\\mathrm {T}} \\sigma \\left(\\boldsymbol {A} _ {1} \\boldsymbol {h} _ {t} + \\boldsymbol {A} _ {2} \\boldsymbol {h} _ {j}\\right), \\tag {8}\n$$\n\nwhere  $\\sigma$  is an activate function such as sigmoid function, matrix  $A_{1}$  is used to transform  $\\pmb{h}_t$  into a latent space, and  $A_{2}$  plays the same role for  $\\pmb{h}_j$ .\n\nThis local encoder enjoys the advantages of adaptively focusing on more important items to capture the user's main purpose in the current session.\n\n# 3.5 NARM Model\n\nFor the task of session-based recommendation, the global encoder has the summarization of the whole sequential behavior, while the local encoder can adaptively select the important items in the current session to capture the user's main purpose. We conjecture that the representation of the sequential behavior may provide useful information for capturing the user's main purpose in the current session. Therefore, we use the representations of the sequential behavior and the previous hidden states to compute the attention weight for each clicked item. Then a natural extension combines the sequential behavior feature and the user purpose feature by concatenating them to form an extended representation for each time stamp.\n\nAs shown in Figure 4, we can see the summarization  $h_t^g$  is incorporated into  $c_t$  to provide a sequential behavior representation for NARM. It should be noticed that the session feature generator in NARM will evoke different encoding mechanisms in the global encoder and the local encoder, although they will be combined later to form a unified representation. More specifically, the last hidden state of the global encoder  $h_t^g$  plays a role different from that of the local encoder  $h_t^1$ . The former has the responsibility to encode the entire sequential behavior. The latter is used to compute the attention weights with the previous hidden states. By this hybrid encoding scheme, both the user's sequential behavior and main purpose in the current session can be modeled into a unified representation  $c_t$ , which is the concatenation of vectors  $c_t^g$\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/d893b95401d70cfe598baddd1c505f62f1ae07dc24ac5f529d8ad4ef58095ef7.jpg)  \nFigure 4: The graphical model of NARM, where the session feature  $c_t$  is represented by the concatenation of vectors  $c_t^{\\mathrm{g}}$  and  $c_t^{\\mathrm{l}}$  (as computed in equation (5) and (6)). Note that  $h_t^{\\mathrm{g}}$  and  $h_t^{\\mathrm{l}}$  play different roles, while they have the same values. The last hidden state of the global encoder  $h_t^{\\mathrm{g}}$  plays a role to encode the entire input clicks while the last hidden state of the local encoder  $h_t^{\\mathrm{l}}$  is used to compute attention weights with the previous hidden states.\n\nand  $c_t^1$\n\n$$\n\\boldsymbol {c} _ {t} = \\left[ \\boldsymbol {c} _ {t} ^ {\\mathrm {g}}, \\boldsymbol {c} _ {t} ^ {\\mathrm {l}} \\right] = \\left[ \\boldsymbol {h} _ {t} ^ {\\mathrm {g}}; \\sum_ {j = 1} ^ {t} \\alpha_ {t j} \\boldsymbol {h} _ {t} ^ {\\mathrm {l}} \\right]. \\tag {9}\n$$\n\nFigure 4 also gives a graphical illustration of the adopted decoding mechanism in NARM. Generally, a standard RNN utilizes fully-connected layer to decode. But using fully-connected layer means that the number of parameters to be learned in this layer is  $|H| * |N|$  where  $|H|$  is the dimension of the session representation and  $|N|$  is the number of candidate items for prediction. Thus we have to reserve a large space to store these parameters. Though there are some approaches to reduce the parameters such as using a hierarchical softmax layer [24], and negative sampling at random [22], they are not the best choices for our model.\n\nWe propose an alternative bi-linear decoding scheme which not only reduces the number of the parameters, but also improves the performance of NARM. Specifically, a bi-linear similarity function between the representations of the current session and each candidate items is used to compute a similarity score  $S_{i}$ ,\n\n$$\nS _ {i} = e m b _ {i} ^ {\\mathrm {T}} \\boldsymbol {B} \\boldsymbol {c} _ {t}, \\tag {10}\n$$\n\nwhere  $\\pmb{B}$  is a  $|D| * |H|$  matrix,  $|D|$  is the dimension of each item embedding. Then the similarity score of each item is entered to a softmax layer to obtain the probability that the item will occur next. By using this bi-linear decoder, we reduce the number of parameters from  $|N| * |H|$  to  $|D| * |H|$ , where  $|D|$  is usually smaller than  $|N|$ . Moreover, the experiment results demonstrate that using this bi-linear decoder can improve the performance of NARM (as demonstrated in §4.4).\n\nTo learn the parameters of the model, we do not utilize the proposed training procedure in [12], where the model is trained in a session-parallel, sequence-to-sequence manner. Instead, in order to fit the attention mechanism in the local encoder, NARM process each sequence  $[x_1, x_2, \\dots, x_{t-1}, x_t]$  separately. Our model can be trained by using a standard mini-batch gradient descent on the\n\ncross-entropy loss:\n\n$$\nL (p, q) = - \\sum_ {i = 1} ^ {m} p _ {i} \\log \\left(q _ {i}\\right) \\tag {11}\n$$\n\nwhere  $q$  is the prediction probability distribution and  $p$  is the truly distribution. At last, a Back-Propagation Through Time (BPTT) method for a fixed number of time steps is adopted to train NARM.",
  "experiments": "# 4 EXPERIMENTAL SETUP\n\nIn this section, we first describe the datasets, the state-of-the-art methods and the evaluation metrics employed in our experiments. Then we compare NARMs with different decoding schemes. Finally, we compare NARM with state-of-the-art methods.\n\n# 4.1 Dataset\n\nWe evaluate different recommenders on two standard transaction datasets, i.e., YOOCHOOSE dataset and DIGINETICA dataset.\n\n- YOOCHOOSE $^{1}$  is a public dataset released by RecSys Challenge 2015. This dataset contains click-streams on an e-commerce site. After filtering out sessions of length 1 and items that appear less than 5 times, there remains 7981580 sessions and 37483 items.  \n- DIGINETICA<sup>2</sup> comes from CIKM Cup 2016. We only used the released transaction data and also filtered out sessions of length 1 and items that appear less than 5 times. Finally the dataset contains 204771 sessions and 43097 items.\n\nWe first conducted some preprocesses over two datasets. For YOOCHOOSE, we used the sessions of subsequent day for testing and filtered out clicks from the test set where the clicked items did not appear in the training set. For DIGINETICA, the only difference is that we use the sessions of subsequent week for testing. Because we did not train NARM in a session-parallel manner [12], a\n\nTable 1: Statistics of the datasets used in our experiments. (The avg.length means the average length of the complete dataset.)  \n\n<table><tr><td>Datasets</td><td>all the clicks</td><td>train sessions</td><td>test sessions</td><td>all the items</td><td>avg.length</td></tr><tr><td>YOOCHOOSE 1/64</td><td>557248</td><td>369859</td><td>55898</td><td>16766</td><td>6.16</td></tr><tr><td>YOOCHOOSE 1/4</td><td>8326407</td><td>5917746</td><td>55898</td><td>29618</td><td>5.71</td></tr><tr><td>DIGINETICA</td><td>982961</td><td>719470</td><td>60858</td><td>43097</td><td>5.12</td></tr></table>\n\nsequence splitting preprocess is necessary. For the input session  $[x_1, x_2, \\dots, x_{n-1}, x_n]$ , we generated the sequences and corresponding labels  $([x_1], V(x_2), ([x_1, x_2], V(x_3), \\dots, ([x_1, x_2, \\dots, x_{n-1}], V(x_n))$  for training on both YOOCHOOSE and DIGINETICA. The corresponding label  $V(x_i)$  is the last click in the current session.\n\nFor the following reasons: (1) YOOCHOOSE is quite large, (2) Tan et al. [40] verified that the recommendation models do need to account for changing user behavior over time, (3) their experimental results showed that training on the entire dataset yields slightly poorer results than training on more recent fractions of the datasets. Thus we sorted the training sequences of YOOCHOOSE by time and reported our results on the model trained on more recent fractions 1/64 and 1/4 of training sequences as well. Note that some items that in the test set would not appear in the training set since we trained the model only on more recent fractions. The statistics of the three datasets (i.e., YOOCHOOSE 1/64, YOOCHOOSE 1/4 and DIGINETICA) are shown in Table 1.\n\n# 4.2 Baseline Methods\n\nWe compare the proposed NARM with five traditional methods (i.e., POP, S-POP, Item-KNN, BPR-MF and FPMC) and two RNN-based models (i.e., GRU-Rec and Improved GRU-Rec).\n\n- POP: Popular predictor always recommends the most popular items in the training set. Despite its simplicity, it is often a strong baseline in certain domains.  \n- S-POP: This baseline recommends the most popular items for the current session. The recommendation list changes during the session gains more items. Ties are broken up using global popularity values.  \n- Item-KNN: In this baseline, similarity is defined as the co-occurrence number of two items in sessions divided by the square root of the product of the number of sessions in which either item occurs. Regularization is also included to avoid coincidental high similarities between rarely visited items [4, 20].  \n- BPR-MF: BPR-MF [28] optimizes a pairwise ranking objective function via stochastic gradient descent. Matrix factorization can not be directly applied to session-based recommendation because new sessions do not have precomputed latent representations. However, we can make it work by representing a new session with the average latent factors of items occurred in the session so far. In other words, the recommendation score can be computed as the average of the similarities between latent factors of a candidate item and the items in the session so far.  \n- FPMC: FPMC [29] is a state-of-the-art hybrid model on the next-basket recommendation. In order to make it work on session-based recommendation, we do not consider the\n\nuser latent representations when computing recommendation scores.\n\n- GRU-Rec: We denote the model proposed in [12] as GRU-Rec, which utilizes session-parallel mini-batch training process and also employs ranking-based loss functions for learning the model.  \n- Improved GRU-Rec: We denote the model proposed in [40] as Improved GRU-Rec. Improved GRU-Rec adopts two techniques which include data augmentation and a method to account for shifts in the input data distribution to improve the performance of GRU-Rec.\n\n# 4.3 Evaluation Metrics and Experimental Setup\n\n# 4.3.1 Evaluation Metrics.\n\nAs recommender systems can only recommend a few items at each time, the actual item a user might pick should be amongst the first few items of the list. Therefore, we use the following metrics to evaluate the quality of the recommendation lists.\n\n- Recall@20: The primary evaluation metric is Recall@20 that is the proportion of cases when the desired item is amongst the top-20 items in all test cases. Recall@N does not consider the actual rank of the item as long as it is amongst the top-N and also usually correlates well with other metrics such as click-through rate (CTR) [21].  \n- MRR@20: Another used metric is MRR@20 (Mean Reciprocal Rank), which is the average of reciprocal ranks of the desire items. The reciprocal rank is set to zero if the rank is larger than 20. MRR takes the rank of the item into account, which is important in settings where the order of recommendations matters.\n\n# 4.3.2 Experimental Setup.\n\nThe proposed NARM model uses 50-dimensional embeddings for the items. Optimization is done using Adam [15] with the initial learning rate sets to 0.001, and the mini-batch size is fixed at 512. There are two dropout layers used in NARM: the first dropout layer is between the item embedding layer and the GRU layer with  $25\\%$  dropout, the second one is between the GRU layer and the bi-linear similarity layer with  $50\\%$  dropout. We also truncate BPTT at 19 time steps as the setting in the state-of-the-art method [40] and the number of epochs is set to 30 while using  $10\\%$  of the training data as the validation set. We use one GRU layer in our model and the GRU is set at 100 hidden units. The model is defined and trained in Theano on a GeForce GTX TitanX GPU. The source code of our model is available online<sup>3</sup>.\n\nTable 2: The comparison of different decoders in NARM.  \n\n<table><tr><td rowspan=\"2\">Decoders</td><td colspan=\"2\">YOOCHOOSE 1/64</td><td colspan=\"2\">YOOCHOOSE 1/4</td><td colspan=\"2\">DIGINETICA</td></tr><tr><td>Recall@20(%)</td><td>MRR@20(%)</td><td>Recall@20(%)</td><td>MRR@20(%)</td><td>Recall@20(%)</td><td>MRR@20(%)</td></tr><tr><td>Fully-connected decoder</td><td>67.67</td><td>29.17</td><td>69.49</td><td>29.54</td><td>57.84</td><td>24.77</td></tr><tr><td>Bi-linear similarity decoder</td><td>68.32</td><td>28.76</td><td>69.73</td><td>29.23</td><td>62.58</td><td>27.35</td></tr></table>\n\nTable 3: Performance comparison of NARM with baseline methods over three datasets.  \n\n<table><tr><td rowspan=\"2\">Methods</td><td colspan=\"2\">YOOCHOOSE 1/64</td><td colspan=\"2\">YOOCHOOSE 1/4</td><td colspan=\"2\">DIGINETICA</td></tr><tr><td>Recall@20(%)</td><td>MRR@20(%)</td><td>Recall@20(%)</td><td>MRR@20(%)</td><td>Recall@20(%)</td><td>MRR@20(%)</td></tr><tr><td>POP</td><td>6.71</td><td>1.65</td><td>1.33</td><td>0.30</td><td>0.91</td><td>0.23</td></tr><tr><td>S-POP</td><td>30.44</td><td>18.35</td><td>27.08</td><td>17.75</td><td>21.07</td><td>14.69</td></tr><tr><td>Item-KNN</td><td>51.60</td><td>21.81</td><td>52.31</td><td>21.70</td><td>28.35</td><td>9.45</td></tr><tr><td>BPR-MF</td><td>31.31</td><td>12.08</td><td>3.40</td><td>1.57</td><td>15.19</td><td>8.63</td></tr><tr><td>FPMC*</td><td>45.62</td><td>15.01</td><td>-</td><td>-</td><td>31.55</td><td>8.92</td></tr><tr><td>GRU-Rec</td><td>60.64</td><td>22.89</td><td>59.53</td><td>22.60</td><td>43.82</td><td>15.46</td></tr><tr><td>Improved GRU-Rec</td><td>67.84</td><td>29.00</td><td>69.11</td><td>29.22</td><td>57.95</td><td>24.93</td></tr><tr><td>NARM</td><td>68.32</td><td>28.76</td><td>69.73</td><td>29.23</td><td>62.58</td><td>27.35</td></tr></table>\n\n* On YOOCHOOSE 1/4, we do not have enough memory to initialize FPMC. Our available memory is 120G.\n\n# 4.4 Comparison among Different Decoders\n\nWe first empirically compare NARMs with different decoders, i.e., fully-connected decoder and bi-linear similarity decoder. The results over three datasets are shown in Table 2. Here we only illustrate the results on 100-dimensional hidden states because we obtain the same conclusions on other dimension settings.\n\nWe make following observations from Table 2: (1) With regard to Recall@20, the performance improves when using the bi-linear similarity decoder, and the improvements are around  $0.65\\%$ ,  $0.24\\%$  and  $4.74\\%$  respectively over three datasets. (2) And with regard to MRR@20, the performance on the model using the bi-linear decoder becomes a little worse on YOOCHOOSE 1/64 and  $1/4$ . But on DIGINETICA, the model with the bi-linear decoder still obviously outperforms the model with the fully-connected decoder.\n\nFor the session-based recommendation task, as the recommender system recommends top-20 items at once in our settings, the actual item a user might pick should be among the list of 20 items. Thus we consider that the recall metric is more important than the MRR metric in this task, and NARM adopts the bi-linear decoder in the following experiments.\n\n# 4.5 Comparison against Baselines\n\nNext we compare our NARM model with state-of-the-art methods. The results of all methods over three datasets are shown in Table 3. And a more specific comparison between NARM and the best baseline (i.e., Improved GRU-Rec) over three datasets are illustrated in Figure 5.\n\nWe have the following observations from the results: (1) For YOOCHOOSE 1/4 dataset, BPR-MF does not work when we use the average of item factors occurred in the session to replace the\n\nuser factor. Besides, since we regard each session as one user in FPMC, we do not have enough memory to initialize it. These problems indicate traditional user-based methods are no longer suitable for session-based recommendation. (2) Overall, three RNN-based methods consistently outperform the traditional baselines, which demonstrates that RNN-based models are good at dealing with sequence information in sessions. (3) By taking both the user's sequential behavior and main purpose into consideration, the proposed NARM can outperform all the baselines in terms of recall@20 over three datasets and can outperform most of the baselines in terms of MRR@20. Take DIGINETICA dataset as an example, when compared with the best baseline (i.e., Improved GRU-Rec), the relative performance improvements by NARM are around  $7.98\\%$  and  $9.70\\%$  respectively in terms of recall@20 and MRR@20. (4) As we can see, the recall values on two YOOCHOOSE datasets are not as significantly as the results on DIGINETICA and the obtained MRR values are very close to each other. We consider that one of the important reasons is when we split YOOCHOOSE dataset to 1/64 and 1/4, we do not filter out clicks from the test set where the clicked items are not in the training set in order to be consistent with the setting on Improved GRU-Rec [40]. While on DIGINETICA, we filter out these clicks from the test set, and hence NARM outperforms the baselines significantly in terms of both Recall@20 and MRR@20.\n\n# 5 ANALYSIS\n\nIn this section, We further explore the influences of using different session features in NARM and analyze the effectiveness of the adopted attention mechanism.\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/134f917d1d778252572c2c14c6241d1e33d4f5ba863d34757c292d5cae8ff5ba.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/09f757e59742db5331750bfab701f164f88b4283c02d78753619ab8a402e1930.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/c70a1e9d8e6f43b395d3a6276570cc8cc50961177fa36ebe4ce7503245bbede1.jpg)\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/a0fb6ea3d2e5bea1a51c88aab1b1c4b4475467e967dfdc38f042862ef61b7f06.jpg)  \n(a) YOOCHOOSE1/64\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/c197670451e624dd97195f0e3608f503a50c3b35de148ff6dad2ec5461e7a23e.jpg)  \n(b) YOOCHOOSE1/4\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/20900afcbc7ad7dc82b5c7be7ea381b3ae80b471178353238ddfb0d6d0a0aacb.jpg)  \n(c) DIGINETICA  \nFigure 5: Performance comparison between NARM and the best baseline (i.e., Improved GRU-Rec) over three datasets.\n\nTable 4: Performance comparison among three versions of NARM over three datasets.  \n(a) Performance comparison on YOOCHOSE 1/64  \n\n<table><tr><td rowspan=\"2\">Models</td><td colspan=\"2\">d=50</td><td colspan=\"2\">d=100</td></tr><tr><td>Recall@20</td><td>MRR@20</td><td>Recall@20</td><td>MRR@20</td></tr><tr><td>NARMglobal</td><td>67.26</td><td>26.95</td><td>68.15</td><td>28.37</td></tr><tr><td>NARMlocal</td><td>67.07</td><td>26.79</td><td>68.10</td><td>28.38</td></tr><tr><td>NARMhybrid</td><td>68.28</td><td>28.10</td><td>68.32</td><td>28.76</td></tr></table>\n\n(b) Performance comparison on YOOCHOOSE 1/4  \n\n<table><tr><td rowspan=\"2\">Models</td><td colspan=\"2\">d=50</td><td colspan=\"2\">d=100</td></tr><tr><td>Recall@20</td><td>MRR@20</td><td>Recall@20</td><td>MRR@20</td></tr><tr><td>NARMglobal</td><td>67.67</td><td>27.10</td><td>68.91</td><td>28.48</td></tr><tr><td>NARMlocal</td><td>67.50</td><td>27.21</td><td>68.01</td><td>27.36</td></tr><tr><td>NARMhybrid</td><td>69.17</td><td>28.67</td><td>69.73</td><td>29.23</td></tr></table>\n\n(c) Performance comparison on DIGINETICA  \n\n<table><tr><td rowspan=\"2\">Models</td><td colspan=\"2\">d=50</td><td colspan=\"2\">d=100</td></tr><tr><td>Recall@20</td><td>MRR@20</td><td>Recall@20</td><td>MRR@20</td></tr><tr><td>NARMglobal</td><td>59.63</td><td>23.52</td><td>61.88</td><td>26.51</td></tr><tr><td>NARMlocal</td><td>58.74</td><td>22.91</td><td>61.71</td><td>26.04</td></tr><tr><td>NARMhybrid</td><td>61.73</td><td>26.25</td><td>62.58</td><td>27.35</td></tr></table>\n\n# 5.1 Influence of Using Different Features\n\nIn this part, we refer to the NARM that uses the sequential behavior feature only, the NARM that uses the user purpose feature\n\nonly, and the NARM that uses both two features as  $NARM_{global}$ ,  $NARM_{local}$  and  $NARM_{hybrid}$  respectively. As shown in Table 4, (1)  $NARM_{global}$  and  $NARM_{local}$ , which only use a single feature, do not perform well on three datasets. Besides, their performance are very close to each other in terms of two metrics. This indicates that merely considering the sequential behavior or the user purpose in the current session may not be able to learn a good recommendation model. (2) When we take into account both the user's sequential behavior and main purpose,  $NARM_{hybrid}$  performs better than  $NARM_{global}$  and  $NARM_{local}$  in terms of Recall@20 and MRR@20 on different hidden state dimensions over three datasets. Take DIGINETICA dataset as an example, when compared with  $NARM_{global}$  and  $NARM_{local}$  with the dimensionality of the hidden state set to 50, the relative performance improvements by  $NARM_{hybrid}$  are around  $3.52\\%$  and  $5.09\\%$  in terms of Recall@20 respectively. These results demonstrate the advantages of considering both the sequential behavior and the main purpose of the current user in session-based recommendation.\n\n# 5.2 Influence of Different Session Lengths\n\nOur NARM model is based on the assumption that when a user is browsing online, his/her click behavior frequently revolves his/her main purpose in the current session. However, we can hardly capture the user's main purpose when s/he just clicks a few items. Therefore, our NARM model should be good at modeling long sessions. To verify this, we make comparisons among sessions with different lengths on DIGINETICA. As shown in Table 5, (1) NARM performs better when the session lengths are between 4 and 17 in general. This indicates that NARM do capture the user's main purpose more accuracy on long sessions. In other words, it could\n\n![](https://cdn-mineru.openxlab.org.cn/result/2025-12-16/0a330aa6-24b1-4f68-a59e-9b28ba375966/e9bf56d423c5591441e8ab5b0b4d682584262b19a7383fc334690c170042dd88.jpg)  \nFigure 6: Visualization of items weights. The depth of the color corresponds to the importance of items given by equation (7). The numbers above the sessions is the session IDs. (Best viewed in color.)\n\nTable 5: Performance comparison among different session lengths on DIGINETICA dataset. (The baseline method is Improved GRU-Rec [40].)  \n\n<table><tr><td rowspan=\"2\">Length</td><td colspan=\"2\">DIGINETICA DATASET</td><td rowspan=\"2\">Performance</td></tr><tr><td>Baseline correct</td><td>NARM correct</td></tr><tr><td>1</td><td>8747</td><td>9358</td><td>+6.98%</td></tr><tr><td>2</td><td>6601</td><td>7084</td><td>+7.31%</td></tr><tr><td>3</td><td>4923</td><td>5299</td><td>+7.63%</td></tr><tr><td>4</td><td>3625</td><td>3958</td><td>+9.18%</td></tr><tr><td>5</td><td>2789</td><td>3019</td><td>+8.24%</td></tr><tr><td>6</td><td>2029</td><td>2202</td><td>+8.52%</td></tr><tr><td>7</td><td>1520</td><td>1656</td><td>+8.94%</td></tr><tr><td>8</td><td>1198</td><td>1295</td><td>+8.09%</td></tr><tr><td>9</td><td>915</td><td>996</td><td>+8.85%</td></tr><tr><td>10</td><td>690</td><td>753</td><td>+9.13%</td></tr><tr><td>11</td><td>509</td><td>587</td><td>+15.32%</td></tr><tr><td>12</td><td>411</td><td>459</td><td>+11.67%</td></tr><tr><td>13</td><td>304</td><td>323</td><td>+6.25%</td></tr><tr><td>14</td><td>243</td><td>260</td><td>+6.99%</td></tr><tr><td>15</td><td>199</td><td>219</td><td>+10.05%</td></tr><tr><td>16</td><td>149</td><td>165</td><td>+10.73%</td></tr><tr><td>17</td><td>98</td><td>112</td><td>+14.28%</td></tr><tr><td>18</td><td>88</td><td>93</td><td>+5.68%</td></tr><tr><td>19</td><td>70</td><td>75</td><td>+7.14%</td></tr></table>\n\nmake a better prediction if NARM captures more user purpose features on the basis of the existing sequential behavior features. (2) When sessions are too long, the performance improvements of NARM are declined. We consider the reason is that when a session is too long, the user is very likely to click some items aimlessly, so that the local encoder in NARM could not capture the user's main purpose in the current session.\n\n# 5.3 Visualize the Attention Weights\n\nTo illustrate the role of the attention mechanism intuitively, we present an example in Figure 6. The session instances are chosen randomly from DIGINETICA. The depth of the color corresponds\n\nto the importance of items given by equation (7). We have following observations from the example: (1) Overall, it is obvious that not all items are related to the next click and almost all the important items in the current session is continuous. This implies that the users' intentions in sessions are indeed localized, which is one of the reasons why NARM can outperform the general RNN-based model. (2) The most important items are often near the end of the session. This is in line with people's browsing behavior: a user is very likely to click other items that are related to what s/he has clicked just now. Recall that general RNN-based models are able to model this fact, thus they can achieve fairly good performance in session-based recommendation. (3) In some cases, the most important items appear in the beginning or middle of the session (e.g., in session 7974 or 4260). In this situation, we believe that our NARM can perform better than general RNN-based models because the attention mechanism could learn to pay more attention to more important items regardless of its position in one session.",
  "hyperparameter": "Item embedding dimension: 50; GRU hidden units: 100; Learning rate: 0.001 (Adam optimizer); Mini-batch size: 512; Dropout rates: 25% (between embedding and GRU layer), 50% (between GRU and bi-linear layer); BPTT truncation: 19 time steps; Number of epochs: 30; Validation split: 10% of training data"
}