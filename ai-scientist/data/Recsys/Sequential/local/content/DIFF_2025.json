{
    "id": "DIFF_2025",
    "paper_title": "DIFF: Dual Side-Information Filtering and Fusion for Sequential Recommendation",
    "alias": "DIFF",
    "year": 2025,
    "domain": "Recsys",
    "task": "GeneralRecommendation",
    "idea": "DIFF introduces a frequency-based noise filtering mechanism that applies FFT/IFFT to separate low- and high-frequency components of item-ID and attribute sequences, then suppresses high-frequency (noisy) signals via learnable β coefficients. It couples this with a dual-fusion strategy—ID-centric (intermediate) and attribute-enriched (early) self-attention branches—whose outputs are adaptively merged to yield a unified user representation, while a contrastive alignment loss keeps ID and attribute embeddings semantically consistent.",
    "introduction": "# 1 Introduction\n\nSequential Recommendation (SR) [7, 26] aims to predict the next item the user will likely interact with by analyzing past user behavior. It is crucial in various web applications, including e-commerce and streaming services. Existing SR models employ diverse neural architectures to encode an item sequence into user representation. Among them, attention-based models [11, 17, 24] have shown outstanding performance gains by capturing intricate item correlations. However, these models only focus on item IDs, neglecting to utilize valuable item attributes.\n\nRecently, Side-information Integrated Sequential Recommendation (SISR) [15, 30, 33] addresses these limitations by modeling the item sequence using side-information. It incorporates various item attributes, e.g., \"Brand\" and \"Category\", into the recommendation process. SISR models demonstrate enhanced capability in capturing diverse collaborative signals across items, proving particularly effective in sparse user interaction and cold-start item settings.\n\nDepending on item attribute fusion strategies, existing SISR models can be broadly categorized into three pillars: early, late, and intermediate fusion<sup>1</sup>. Early fusion combines item ID and attribute embeddings before feeding to the model, enabling rich interactions across attributes. However, due to inherent differences in representation spaces, this simple aggregation may result in information invasion [15, 29], in which the fused item characteristics become dominated or distorted by the ID or attribute information. Meanwhile, Late fusion [31] encodes IDs and attributes separately, delaying the fusion until the final prediction layer. Although each sequence is modeled effectively, it struggles to capture the correlation between item IDs and attributes. As an alternative, intermediate fusion [15, 27, 29] computes the attention weight of attributes and leverages them to only guide the item correlation, preventing unnecessary interference between IDs and attributes.\n\nWhile these fusion strategies have shown promising results in leveraging item attributes, they still face two critical challenges that need to be addressed.\n\n(i) Noisy signals in item sequences. Item sequences often contain inconsistent patterns not aligned with the user preferences, e.g., accidental clicks, or short-term intent drift. However, most existing studies utilize all available information to derive user representations, resulting in potential deviation from actual user preferences due to\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/d528d8f6d9cee69513f5b436f5c61f68d26b4cb37f17cab64ef1872c956a784c.jpg)\n\n\n\nFigure 1: (i) Frequency signals and (ii) fusion types in side information integrated sequential recommendation. Frequency-based noise filtering removes the fourth item with inconsistent signals. Intermediate fusion (blue) highlights items aligned with key signals, while early fusion (green) captures broader combinations.\n\n\nnoise interference. Recent studies [5, 6, 21, 34] have attempted to address this issue by eliminating noise and emphasizing crucial information with embedding filtering techniques. Nevertheless, they are limited in considering a single sequence, focusing solely on item IDs. While DLFSRec [16] introduces a frequency-based learnable filter in the multi-sequence, it overlooks sequence-level denoising. To overcome this limitation, it is necessary to filter irrelevant signals across individual multiple sequences of item IDs and attributes.\n\n(ii) Limited utilization of side-information. Although intermediate fusion addresses the issue in early and late fusion strategies, it primarily focuses on utilizing item attributes to guide the importance of item IDs. Specifically, NOVA [15], DIF-SR [29], and ASIF [27] exploit item attributes only for calculating attention weights. The final user representation is then obtained by aggregating the item ID vectors in the sequence. As a result, it fails to directly integrate item attributes into user representations, thereby missing strong collaborative signals across attributes.\n\nWe first employ frequency-based noise filtering to remove noisy signals and extract salient patterns. Specifically, we transform each sequence into a frequency signal using discrete Fourier transforms. We then apply a frequency-based filtering algorithm, a common technique in digital signal processing [3, 19, 22]. It can consider periodicity and patterns that may be difficult to discern in the time domain [6, 21, 34]. Since essential information differs across item IDs and attributes, we apply frequency-based filtering to each sequence. For instance, as illustrated in Figure 1, the third item belongs to the \"Brand\" of \"Apple\", which represents a consistent pattern that should be emphasized. However, from the perspective of the category sequence, \"Earphone\" may appear as an inconsistent pattern within the category sequence. Therefore, we employ attribute-level filtering for each sequence to identify and prioritize meaningful signals across different attributes effectively.\n\nWe then introduce dual multi-sequence fusion, combining intermediate and early fusion. Intermediate fusion effectively aggregates ID-centric correlation within the sequence [14, 15, 27, 29]. As depicted in Figure 1, the brand and category sequences may highlight \"Apple\" and \"Cellular phone\", respectively. Intermediate fusion aggregates these highlighted attributes into an item ID value matrix, assigning higher attention scores to items that align with them, such as the first and last items, corresponding to \"Apple cellular phone\". This approach ensures that the most critical attribute combinations are emphasized, allowing the model to focus on items that best represent the user's core preferences. However, it primarily captures relationships within a single attribute and may overlook broader patterns across different attributes. We thus adopt early fusion, which is more effective for identifying correlations between various attributes. For example, if a user consistently prefers the \"Apple\" brand across different categories, early fusion can recognize this preference even when the item is not specifically highlighted in the category sequences, such as \"Apple earphone\". Similarly, if a user prefers the \"Cellular phone\" category regardless of brand, early fusion can effectively capture this pattern by identifying relevant items, such as \"Motorola cellular phone\" and \"Samsung cellular phone\". By representing items with a combination of attributes, early fusion provides a holistic view of user preferences that may not be fully captured through intermediate fusion alone. To mitigate information invasion of the naïve early fusion [15, 29], we also align ID and attribute representations in the same space. This allows the dual fusion approach to mitigate potential drawbacks while leveraging the strengths of both early and intermediate fusion.\n\nTo this end, we propose a novel side-information integrated sequential recommendation model, namely **Dual Side-Information Filtering and Fusion model (DIFF).** It consists of two key components: (i) Frequency-based Noise Filtering and (ii) Dual Multi-sequence Fusion. First, we remove noise and maintain only essential information based on the frequency domain. We then adjust high- and low-frequency signals for each item ID and attribute. Subsequently, filtered ID and attribute sequences are utilized in dual fusion. It consists of two distinct fusion blocks corresponding to intermediate and early fusion. As ID-centric Fusion, intermediate fusion captures the intra-attribute correlation across items. As Attribute-enriched Fusion, early fusion enables us to identify inter-attribute correlations across various attributes. With the proposed filtering and fusion strategy, DIFF is more robust in learning subtle and complex item relationships in multiple sequences. Experimental results show that DIFF significantly outperforms the state-of-the-art SISR models, improving performance by up to  $14.1\\%$  and  $12.5\\%$  on Recall@20 and NDCG@20 across four real-world datasets.",
    "method": "# 3 Preliminaries\n\nProblem Formulation. Let  $\\mathcal{I} = \\{i_1, \\dots, i_n\\}$  represent a set of  $n$  items. The user's item sequence is denoted as  $s = [i_1, \\dots, i_{|s|}]$ , where  $i_j$  is the  $j$ -th item in the sequential order, and  $|s|$  is the total number of items interacted with by the user. Following the previous studies [14, 27, 31], we mainly consider item-related side-information, e.g., brand and category. For side-information integrated sequential recommendation, each item  $i \\in \\mathcal{I}$  is described by its unique item ID and multiple attributes. Specifically, it is represented as  $i_j = \\{v_j, a_{1,j}, \\dots, a_{m,j}\\}$ , where  $v_j$  is its item ID,  $a_{k,j}$  is the  $k$ -th attribute type, and  $m$  is the total number of attributes. Our goal is to predict the next item the user is most likely to prefer, expressed as  $\\arg \\max_{j \\in \\mathcal{I}} P(i_{|s| + 1} = j \\mid s)$ .\n\nDiscrete Fourier Transform (DFT). The DFT is a fundamental component of digital signal processing, converting a sequence in the time domain into the frequency domain. Given a sequence with length  $N$ , the DFT is represented as  $\\mathcal{F}:\\mathbb{R}^N\\to \\mathbb{C}^N$ , and its inverse, i.e., the inverse discrete Fourier transform (IDFT), is denoted as  $\\mathcal{F}^{-1}:\\mathbb{C}^N\\to \\mathbb{R}^N$ . The DFT can be performed by multiplying a sequence matrix  $\\mathbf{X}\\in \\mathbb{R}^{N\\times d}$  by the matrix  $\\mathbf{F}\\in \\mathbb{C}^{N\\times N}$ .\n\n$$\n\\bar {\\mathbf {X}} = \\mathcal {F} (\\mathbf {X}) = \\mathbf {F X} = \\frac {1}{\\sqrt {N}} \\left[ \\begin{array}{c c c c} 1 & 1 & \\dots & 1 \\\\ 1 & e ^ {\\frac {- 2 \\pi i}{N}} & \\dots & e ^ {\\frac {- 2 \\pi i (N - 1)}{N}} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ 1 & e ^ {\\frac {- 2 \\pi i (N - 1)}{N}} & \\dots & e ^ {\\frac {- 2 \\pi i (N - 1) ^ {2}}{N}} \\end{array} \\right] \\mathbf {X}, \\tag {1}\n$$\n\nwhere  $i$  is the imaginary unit, and  $\\bar{\\mathbf{X}}\\in \\mathbb{C}^{N\\times d}$  is the frequency component of sequence  $\\mathbf{X}$ . Interestingly,  $\\bar{\\mathbf{X}}$  can be separated into two parts: low-frequency and high-frequency components. We define the first  $c$  rows as a low-frequency component  $\\bar{\\mathbf{X}}_{LFC}\\in \\mathbb{C}^{c\\times d}$  and the remaining rows as a high-frequency component  $\\bar{\\mathbf{X}}_{HFC}\\in \\mathbb{C}^{(N - c)\\times d}$ . IDFT is then applied to convert each component into a different signal type.\n\n$$\n\\begin{array}{l} \\tilde {\\mathbf {X}} _ {L F C} = \\mathcal {F} ^ {- 1} (\\bar {\\mathbf {X}} _ {L F C}) = [ \\mathbf {f} _ {1} ^ {* T}, \\dots , \\mathbf {f} _ {c} ^ {* T} ] \\bar {\\mathbf {X}} _ {L F C}, \\\\ \\tilde {\\mathbf {X}} _ {H F C} = \\mathcal {F} ^ {- 1} (\\bar {\\mathbf {X}} _ {H F C}) = [ \\mathbf {f} _ {c + 1} ^ {* \\top}, \\dots , \\mathbf {f} _ {N} ^ {* \\top} ] \\bar {\\mathbf {X}} _ {H F C}, \\\\ \\end{array}\n$$\n\nwhere  $\\mathbf{f}_i$  represents the  $i$ -th row vector in the matrix  $\\mathbf{F}$ , and  $*$  denotes the conjugate operation. The low-frequency component  $\\tilde{\\mathbf{X}}_{LFC} \\in \\mathbb{R}^{N \\times d}$  captures the overall trend of the sequence, representing the signal that does not change frequently. In contrast, the\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/4f182ab1be5431b7f48e2449ca03476170a56ad90b8208c774947e3f633e8bcd.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/1158423b8d8cebd2e931609bce63139a25f26597cffaaed61a7780c519ed5005.jpg)\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/51a6be8beff1922a8be89e1f3d6f074ab9ec146d3f07ef76c3d08fc58c39a364.jpg)\n\n\n\nFigure 3: An overview of DIFF. DIFF processes both independent sequences and early fused sequences via  $L$  layers of two components: (i) Frequency-based Noise Filtering and (ii) Dual Multi-sequence Fusion. DIFF yields filtered user representations that fully integrates item attributes. Multi-task learning with representation alignment ensures smooth ID-attribute fusion.\n\n\nhigh-frequency component  $\\tilde{\\mathbf{X}}_{HFC} \\in \\mathbb{R}^{N \\times d}$  represents the signal with abrupt variations. Note that we utilize Fast Fourier Transform (FFT) [4, 8], an efficient algorithm computing the DFT and IDFT.\n\n# 4 Proposed Model: DIFF\n\nIn this section, we present the Dual Side-Information Filtering and Fusion (DIFF) model, which effectively removes noisy signals and fully leverages the correlation across item IDs and attributes. Figure 3 depicts the overall architecture of DIFF, which consists of two main components: (i) Frequency-based Noise Filtering and (ii) Dual Multi-sequence Fusion. Specifically, frequency-based noise filtering is used to eliminate noise and extract essential signals (Section 4.1). Subsequently, dual multi-sequence fusion is employed to learn complex interactions across filtered item ID and attribute sequences (Section 4.2). We also adopt an alignment loss to prevent information invasion between item IDs and attributes (Section 4.3). Lastly, we explain the training and inference of DIFF (Section 4.4).\n\n# 4.1 Frequency-based Noise Filtering\n\nWe employ frequency-based noise filtering to reduce irrelevant variations and distinguish essential patterns associated with consistent user preferences. The item sequence is converted to a frequency signal using the Fourier transform. Since item IDs and attributes exhibit different patterns, frequency-based filtering is applied independently to the item ID and attribute sequences.\n\n**Embedding Layer.** Given a user sequence  $s = [i_1, i_2, \\dots, i_{|s|}]$ , we first obtain the embedding matrices for item ID sequence and attribute sequences.\n\n$$\n\\begin{array}{l} \\mathbf {E} _ {v} = \\mathcal {E} _ {v} (v _ {1}, v _ {2}, \\dots , v _ {| s |}), \\\\ \\mathbf {E} _ {a _ {k}} = \\mathcal {E} _ {a _ {k}} \\left(a _ {k, 1}, a _ {k, 2}, \\dots , a _ {k, | s |}\\right) \\forall k \\in [ 1, m ], \\tag {5} \\\\ \\end{array}\n$$\n\nwhere  $\\mathbf{E}_v$  and  $\\mathbf{E}_{a_k} \\in \\mathbb{R}^{|s| \\times d}$  are the resulting embedding matrices for the item ID sequence and the  $k$ -th attribute sequence, respectively. Also,  $\\mathcal{E}_v$  and  $\\mathcal{E}_{a_k}$  are embedding layers for the item ID and  $k$ -th item attribute, respectively.\n\nWhile existing studies [14, 29] have primarily focused on optimizing the intermediate fusion, our approach considers both early and intermediate fusion to capture essential patterns through integrated embeddings across item IDs and attributes. To achieve this, we obtain a fused embedding  $\\mathbf{E}_{va}$  for early fusion that combines the item ID and all attributes:\n\n$$\n\\mathbf {E} _ {v a} = \\text {F u s i o n} \\left(\\mathbf {E} _ {v}, \\mathbf {E} _ {a _ {1}}, \\dots , \\mathbf {E} _ {a _ {m}}\\right), \\tag {4}\n$$\n\nwhere  $\\mathbf{E}_{va} \\in \\mathbb{R}^{|s| \\times d}$  and  $\\mathrm{Fusion}(\\cdot)$  denotes the fusion function for item ID and attribute embeddings. Following the prior studies [14, 15, 27, 29], various fusion functions can be used, i.e., summation, concatenation, or gating.\n\nFrequency-based Filtering. We employ the filtering method to remove noise and spurious signals for each sequence. As pointed out in previous studies [16, 27], it is crucial to enhance the utilization of side-information by alleviating noisy interference. To achieve this, we utilize the discrete Fourier transform to project a sequence into the frequency domain. Specifically, we define the low- and high-frequency components of item ID embeddings as  $\\bar{\\mathbf{E}}_{v,LFC} \\in \\mathbb{C}^{c \\times d}$  and  $\\bar{\\mathbf{E}}_{v,HFC} \\in \\mathbb{C}^{(|s| - c) \\times d}$ , respectively.\n\n$$\n\\begin{array}{l} \\tilde {\\mathbf {E}} _ {v, L F C} = \\mathcal {F} ^ {- 1} (\\bar {\\mathbf {E}} _ {v, L F C}), \\\\ \\tilde {\\mathbf {E}} _ {v, H F C} = \\mathcal {F} ^ {- 1} (\\bar {\\mathbf {E}} _ {v, H F C}). \\tag {5} \\\\ \\end{array}\n$$\n\n$\\tilde{\\mathbf{E}}_{v,LFC}, \\tilde{\\mathbf{E}}_{v,HFC} \\in \\mathbb{R}^{|s| \\times d}$  represent the low- and high-frequency components of the item ID embedding, respectively. Similarly, we obtain the low- and high-frequency components for each attribute\n\nembedding and fused embedding through frequency-based filtering.\n\n$$\n\\tilde {\\mathbf {E}} _ {a _ {k}, L F C} = \\mathcal {F} ^ {- 1} (\\bar {\\mathbf {E}} _ {a _ {k}, L F C}), \\forall k \\in [ 1, m ],\n$$\n\n$$\n\\tilde {\\mathbf {E}} _ {a _ {k}, H F C} = \\mathcal {F} ^ {- 1} (\\bar {\\mathbf {E}} _ {a _ {k}, H F C}), \\forall k \\in [ 1, m ], \\tag {6}\n$$\n\n$$\n\\tilde {\\mathbf {E}} _ {v a, L F C} = \\mathcal {F} ^ {- 1} (\\tilde {\\mathbf {E}} _ {v a, L F C}),\n$$\n\n$$\n\\tilde {\\mathbf {E}} _ {v a, H F C} = \\mathcal {F} ^ {- 1} (\\bar {\\mathbf {E}} _ {v a, H F C}), \\tag {7}\n$$\n\nwhere  $\\tilde{\\mathbf{E}}_{a_k,LFC},\\tilde{\\mathbf{E}}_{a_k,HFC},\\tilde{\\mathbf{E}}_{va,LFC},\\tilde{\\mathbf{E}}_{va,HFC}\\in \\mathbb{R}^{|s|\\times d}$\n\nFrom a frequency perspective, low-frequency signals represent stable patterns that change minimally over a sequence, while high-frequency signals exhibit rapid fluctuations. In the context of item sequences, the low-frequency component can be interpreted as representing long-term and consistent user interests. In contrast, the high-frequency component reflects short-term and volatile interests. While user's long-term consistent interests are crucial for making accurate recommendations, short-term interests that emerge suddenly are often less significant and may serve as noisy information.\n\nTo prioritize long-term stable user interests, we derive the filtered embeddings  $\\tilde{\\mathbf{E}}_v$ ,  $\\tilde{\\mathbf{E}}_{a_k}$ , and  $\\tilde{\\mathbf{E}}_{va}$  for each sequence by adjusting the impact of the high-frequency component.\n\n$$\n\\tilde {\\mathbf {E}} _ {v} = \\tilde {\\mathbf {E}} _ {v, L F C} + \\beta_ {0} \\tilde {\\mathbf {E}} _ {v, H F C},\n$$\n\n$$\n\\tilde {\\mathbf {E}} _ {a _ {k}} = \\tilde {\\mathbf {E}} _ {a _ {k}, L F C} + \\beta_ {k} \\tilde {\\mathbf {E}} _ {a _ {k}, H F C}, \\forall k \\in [ 1, m ], \\tag {8}\n$$\n\n$$\n\\tilde {\\mathbf {E}} _ {v a} = \\tilde {\\mathbf {E}} _ {v a, L F C} + \\beta_ {m + 1} \\tilde {\\mathbf {E}} _ {v a, H F C},\n$$\n\nwhere  $\\beta_0, \\beta_1, \\dots, \\beta_{m+1}$  are trainable scalar parameters used to adjust the high-frequency components of each input embedding. Empirically, we observe that  $\\beta$  is trained to a very small value, i.e., the impact of short-term fluctuating interests is reduced.\n\n# 4.2 Dual Multi-sequence Fusion\n\nWe leverage both early and intermediate fusion to fully exploit the potential of side-information. Since two fusion strategies can capture different correlations across items and attributes, our dual fusion can be more effective than solely relying on intermediate fusion [15, 27, 29]. Specifically, early fusion effectively captures inter-attribute correlations, while intermediate fusion focuses on intra-attribute correlations within individual attributes.\n\nID-centric Fusion. We employ ID-centric fusion to better capture the correlation between item IDs. This approach, a form of intermediate fusion, is also utilized in existing studies [29]. We project ID and attribute embedding sequences onto different query and key matrices. The query and key matrices for the  $h$ -th attention head are as follows:\n\n$$\n\\mathbf {Q} _ {v} ^ {h} = \\tilde {\\mathbf {E}} _ {v} \\mathbf {W} _ {Q, v} ^ {h}, \\mathbf {K} _ {v} ^ {h} = \\tilde {\\mathbf {E}} _ {v} \\mathbf {W} _ {K, v} ^ {h},\n$$\n\n$$\n\\mathbf {Q} _ {a _ {k}} ^ {h} = \\tilde {\\mathbf {E}} _ {a _ {k}} \\mathbf {W} _ {Q, a _ {k}} ^ {h}, \\mathbf {K} _ {a _ {k}} ^ {h} = \\tilde {\\mathbf {E}} _ {a _ {k}} \\mathbf {W} _ {K, a _ {k}} ^ {h}, \\forall k \\in [ 1, m ],\n$$\n\nwhere  $\\mathbf{W}_{Q,v}^{h},\\mathbf{W}_{K,v}^{h}\\in \\mathbb{R}^{d\\times d_{h}}$  are query and key projection matrices for item IDs, and  $\\mathbf{W}_{Q,a_k}^h,\\mathbf{W}_{K,a_k}^h\\in \\mathbb{R}^{d\\times d_h}$  are query and key projection matrices for the  $k$  -th item attribute. We then compute the attention score for each sequence via the dot-product of the query-key pairs.\n\n$$\n\\begin{array}{l} \\mathbf {A} _ {v} ^ {h} = \\mathbf {Q} _ {v} ^ {h} \\left(\\mathbf {K} _ {v} ^ {h}\\right) ^ {\\top}, \\\\ \\mathbf {A} _ {a _ {k}} ^ {h} = \\mathbf {Q} _ {a _ {k}} ^ {h} \\left(\\mathbf {K} _ {a _ {k}} ^ {h}\\right) ^ {\\top}, \\forall k \\in [ 1, m ], \\\\ \\end{array}\n$$\n\nwhere  $\\mathbf{A}_v^h\\in \\mathbb{R}^{|s|\\times |s|}$  and  $\\mathbf{A}_{a_k}^h\\in \\mathbb{R}^{|s|\\times |s|}$  denote attention score matrices of ID sequence and the  $k$  -th attribute sequence obtained from  $h$  -th attention head. Finally, we fuse the item correlations from item IDs and attributes, i.e., attention score matrices, and aggregate them into an item ID value matrix.\n\n$$\n\\mathbf {R} _ {v} = \\operatorname {F F N} \\left(\\operatorname {c o n c a t} \\left(\\mathbf {R} _ {v} ^ {1}, \\dots , \\mathbf {R} _ {v} ^ {H}\\right) \\mathbf {W} _ {v}\\right),\n$$\n\n$$\n\\text {w h e r e} \\mathbf {R} _ {v} ^ {h} = \\operatorname {s o f t m a x} \\left(\\frac {\\operatorname {F u s i o n} \\left(\\mathrm {A} _ {v} ^ {h} , \\cdots , \\mathrm {A} _ {a _ {m}} ^ {h}\\right)}{\\sqrt {d _ {h}}}\\right) \\mathbf {V} _ {v} ^ {h}. \\tag {11}\n$$\n\nHere,  $H$  is the number of attention heads and  $\\mathbf{V}_v^h = \\tilde{\\mathbf{E}}_v\\mathbf{W}_{V,v}^h$  denotes the value matrix of item IDs at the  $h$ -th attention head.  $\\mathbf{W}_v \\in \\mathbb{R}^{d \\times d}$  is a weight parameter matrix,  $\\mathrm{concat}(\\cdot)$  and  $\\mathrm{FFN}(\\cdot)$  indicate concatenation and feed-forward network, respectively.\n\nAttribute-enriched Fusion. We adopt attribute-enriched fusion to reflect the inter-attribute correlations across various attributes, i.e., early fusion. Specifically, we apply self-attention to the fused embeddings as follows.\n\n$$\n\\mathbf {Q} _ {v a} ^ {h} = \\tilde {\\mathbf {E}} _ {v a} \\mathbf {W} _ {Q, v a} ^ {h}, \\mathbf {K} _ {v a} ^ {h} = \\tilde {\\mathbf {E}} _ {v a} \\mathbf {W} _ {K, v a} ^ {h}, \\tag {12}\n$$\n\nwhere  $\\mathbf{W}_{Q,va}^{h},\\mathbf{W}_{K,va}^{h}\\in \\mathbb{R}^{d\\times d_{h}}$  are query, key projection matrices for the fused sequence, respectively. The attention score is computed using the query and key matrices of the fused sequence, thereby explicitly modeling strong correlations across item IDs and attributes.\n\n$$\n\\mathbf {A} _ {v a} ^ {h} = \\mathbf {Q} _ {v a} ^ {h} \\left(\\mathbf {K} _ {v a} ^ {h}\\right) ^ {\\top}, \\tag {13}\n$$\n\nwhere  $\\mathbf{A}_{va}^{h}\\in \\mathbb{R}^{|s|\\times |s|}$  is an attention score matrix of the fused embedding sequence for  $h$ -th attention head. We then derive the user representation from these fused embeddings.\n\n$$\n\\mathbf {R} _ {v a} = \\operatorname {F F N} \\left(\\operatorname {c o n c a t} \\left(\\mathbf {R} _ {v a} ^ {1}, \\dots , \\mathbf {R} _ {v a} ^ {H}\\right) \\mathbf {W} _ {v a}\\right),\n$$\n\n$$\n\\text {w h e r e} \\mathbf {R} _ {v a} ^ {h} = \\operatorname {s o f t m a x} \\left(\\frac {\\mathbf {A} _ {v a} ^ {h}}{\\sqrt {d _ {h}}}\\right) \\mathbf {V} _ {v a} ^ {h}, \\tag {14}\n$$\n\nwhere  $\\mathbf{V}_{va}^{h}\\in \\mathbb{R}^{d\\times d_{h}}$  denotes a projected value matrix for the fused embeddings.  $\\mathbf{W}_{va}\\in \\mathbb{R}^{d\\times d}$  is a weight parameter matrix.\n\nUser Representation. The final user representation is obtained by aggregating early and intermediate fusion results. While the ID-centric representation via intermediate fusion emphasizes fine-grained interactions at the individual item level, the attribute-enriched representation via early fusion explicitly captures strong attribute correlations. The final representation is computed as:\n\n$$\n\\mathbf {R} _ {u} = \\alpha \\mathbf {R} _ {v} + (1 - \\alpha) \\mathbf {R} _ {v a}, \\tag {15}\n$$\n\nwhere  $\\mathbf{R}_u\\in \\mathbb{R}^{|s|\\times d}$  and  $\\alpha$  denotes the representation aggregating hyperparameter. The last element in  $\\mathbf{R}_u$ , i.e.,  $\\mathbf{r}_{u,|s|}\\in \\mathbb{R}^d$ , is used as the user representation vector for prediction.\n\n# 4.3 Representation Alignment\n\nItem IDs and attributes are initially embedded in separate spaces. However, they need to be semantically consistent since both ID-centric and attribute-enriched representations are used for the final user representation. For that, we leverage a contrastive loss to align the embedding spaces of item IDs and fused attributes. Inspired by\n\n\nTable 1: Data statistics after preprocessing. Avg. Length indicates the average number of interactions per user.\n\n\n<table><tr><td>Dataset</td><td>Yelp</td><td>Beauty</td><td>Sports</td><td>Toys</td></tr><tr><td># Users</td><td>30,449</td><td>22,363</td><td>35,598</td><td>19,412</td></tr><tr><td># Items</td><td>20,068</td><td>12,101</td><td>18,357</td><td>11,924</td></tr><tr><td># Interactions</td><td>317,182</td><td>198,502</td><td>296,337</td><td>167,597</td></tr><tr><td>Avg. Length</td><td>10.4</td><td>8.9</td><td>8.3</td><td>8.6</td></tr><tr><td>Sparsity</td><td>99.95%</td><td>99.93%</td><td>99.95%</td><td>99.93%</td></tr></table>\n\nprevious work [27], we align the similarity between the item ID and the fused attribute embedding vectors.\n\n$$\n\\hat {\\mathbf {Y}} _ {v, a} = \\operatorname {s o f t m a x} \\left(\\frac {\\mathbf {E} _ {v} \\mathbf {E} _ {a} ^ {\\top}}{\\tau}\\right), \\hat {\\mathbf {Y}} _ {a, v} = \\operatorname {s o f t m a x} \\left(\\frac {\\mathbf {E} _ {a} \\mathbf {E} _ {v} ^ {\\top}}{\\tau}\\right), \\tag {16}\n$$\n\nwhere  $\\mathbf{E}_a = \\mathrm{Fusion}(\\mathbf{E}_{a_1},\\dots,\\mathbf{E}_{a_m})$\n\nHere,  $\\mathbf{E}_a\\in \\mathbb{R}^{|s|\\times d}$  is a fused embedding matrix of item attributes with the fusion function. For that, the summation function is used. In this process, we use normalized item ID and fused attribute embeddings for stable training. The learnable temperature  $\\tau$  is used as a scaling factor. The final alignment loss is defined as follows:\n\n$$\n\\mathcal {L} _ {\\text {a l i g n}} = - \\frac {1}{2 b} \\sum_ {i = 1} ^ {b} \\sum \\left(\\mathbf {Y} ^ {i} \\odot \\log \\hat {\\mathbf {Y}} _ {v, a} ^ {i} + \\mathbf {Y} ^ {i} \\odot \\log \\hat {\\mathbf {Y}} _ {a, v} ^ {i}\\right), \\tag {17}\n$$\n\nwhere  $\\odot$  denotes element-wise product,  $\\mathbf{Y}^i\\in \\{0,1\\}^{|s|\\times |s|}$  is the ground truth of the  $i$ -th sequence, and  $b$  is the number of sequences in the mini-batch. Each element of  $\\mathbf{Y}^i$  is defined as follows.\n\n$$\n\\mathbf {Y} _ {j, k} ^ {i} = \\left\\{ \\begin{array}{l l} 1 & \\text {i f} \\mathbf {E} _ {a} ^ {j} = \\mathbf {E} _ {a} ^ {k} \\\\ 0 & \\text {o t h e r w i s e} \\end{array} \\right. \\text {f o r} j, k \\in \\{1, \\dots , | s | \\}, \\tag {18}\n$$\n\nwhere  $\\mathbf{E}_a^j$  and  $\\mathbf{E}_a^k$  are the fused attribute embedding vectors obtained from the  $j$ -th and  $k$ -th items in  $i$ -th sequence, respectively.\n\n# 4.4 Training and Inference\n\nFor inference, we make predictions using the final user representation vector  $\\mathbf{r}_{u,|s|\\}$  and the item ID embedding matrix  $\\mathbf{E}$ .\n\n$$\n\\hat {\\mathbf {y}} = \\operatorname {s o f t m a x} \\left(\\mathbf {r} _ {u, | s |} \\mathbf {E} ^ {\\top}\\right), \\tag {19}\n$$\n\nwhere  $\\hat{\\mathbf{y}}\\in \\mathbb{R}^n$ . To calculate the recommendation loss, we employ the cross-entropy loss function.\n\n$$\n\\mathcal {L} _ {r e c} = - \\frac {1}{b} \\sum_ {i = 1} ^ {b} \\mathbf {y} ^ {(i)} \\log \\hat {\\mathbf {y}} ^ {(i)}, \\tag {20}\n$$\n\nwhere  $\\mathbf{y}^{(i)}\\in \\{0,1\\} ^n$  is the one-hot encoded ground truth vector of the  $i$ -th sequence in the mini-batch, with the element corresponding to the target item set to 1 and all others to 0.\n\nFinally, we train our model by combining the recommendation loss and representation alignment loss.\n\n$$\n\\mathcal {L} = \\mathcal {L} _ {\\text {r e c}} + \\lambda \\mathcal {L} _ {\\text {a l i g n}}, \\tag {21}\n$$\n\nwhere  $\\lambda$  is the hyperparameter to control the loss  $\\mathcal{L}_{\\text{align}}$ .",
    "experiments": "# 5 Experimental Setup\n\nDatasets. We conduct extensive experiments on four real-world datasets following [14, 29], i.e., Yelp $^{2}$  and Amazon review dataset [18] $^{3}$ . Yelp is a well-known business recommendation dataset. The attributes of categories, cities, and positions are utilized as side-information. We select three widely used subcategories that are constructed from the Amazon review datasets: Beauty, Sports, and Toys. They consist of item metadata and reviews collected from 1996 to 2014, and we utilize the categories, brands, and positions as side-information. As in the previous works [14, 29], we use the 5-core setting, which removes users and items that occur less than five times. The detailed statistics for the pre-processed datasets are shown in Table 1.\n\nEvaluation Protocols and Metrics. Following [14, 29], we adopt the leave-one-out strategy to split train, validation, and test sets. For each user sequence, we use the last item for testing, the second last item for validation, and the rest items for training. All models are evaluated in a full ranking scenario on all items rather than sampled items following [14, 29]. We opt not to penalize repeated items unlike [16, 21] that have previously appeared within the user history to maintain consistency across diverse datasets. Applying such penalties can negatively impact models on datasets like Yelp, where repeated interactions are common, leading to biased performance estimation. For evaluation metrics, we employ top- $k$  Recall  $(\\mathbb{R}@\\boldsymbol{k})$  and top- $k$  Normalized Discounted Cumulative Gain  $(\\mathbf{N}@\\boldsymbol{k})$  with  $k = \\{10, 20\\}$ .\n\nBaselines. We thoroughly compare our proposed method with two categories: sequential recommendation (SR) and side-information integrated sequential recommendation (SISR) baselines. For SR baselines, SASRec [11] adopts the uni-directional self-attention method to capture the user interest. DuoRec [20] enhances SASRec [11] with contrastive learning. FMLPRec [34] proposes a filter-enhanced MLP to eliminate frequency domain noise. BSARec [21] leverages the Fourier transform to inject an inductive bias for modeling user patterns. For SISR baselines, GRU4Rec and SASRec are enhanced versions of GRU4Rec [10] and SASRec [11]. Following the previous work [14], the item ID and attributes are fused before feeding to the model via summation and concatenation for GRU4Rec and SASRec, respectively.  $\\mathbf{S}^3$ -Rec [33] utilizes mutual information maximization to capture the correlations between items, sequences, and attributes. FDSA [31] adopts late fusion by utilizing multiple self-attention blocks. NOVA [15] adopts non-invasive self-attention mechanism for effective attention learning. DIF-SR [29] decouples the attention calculation of item ID and attributes. DLFSRec [16] proposes distribution-based learnable filters to effectively utilize side-information. MSSR [14] models the multiple user representations via a multi-sequence integrated attention layer. ASIF [27] utilizes side-information without noisy interference via fused attention with untied position information.\n\nImplementation Details. We implement all models on the open-source recommendation framework Recbole [32] or published code. All models are optimized using Adam optimizer [12], and tune the learning rate in  $\\{10^{-4}, 10^{-3}\\}$ . We set the maximum sequence\n\n<table><tr><td rowspan=\"2\">Dataset</td><td rowspan=\"2\">Metric</td><td colspan=\"4\">SR baselines</td><td colspan=\"9\">SISR baselines</td><td rowspan=\"2\">DIFF</td><td rowspan=\"2\">Gain</td></tr><tr><td>SASRec</td><td>DuoRec</td><td>FMLRec</td><td>BSARec</td><td>GRU4RecF</td><td>SASRecF</td><td>S3-Rec</td><td>DLFSRec</td><td>FDSA</td><td>NOVA</td><td>DIF-SR</td><td>MSSR</td><td>ASIF</td></tr><tr><td rowspan=\"4\">Yelp</td><td>R@10</td><td>0.0607</td><td>0.0631</td><td>0.0711</td><td>0.0701</td><td>0.0414</td><td>0.0435</td><td>0.0598</td><td>0.0551</td><td>0.0537</td><td>0.0614</td><td>0.0686</td><td>0.0712</td><td>0.0724</td><td>0.0815*</td><td>12.5%</td></tr><tr><td>R@20</td><td>0.0875</td><td>0.0909</td><td>0.1029</td><td>0.1023</td><td>0.0679</td><td>0.0706</td><td>0.0869</td><td>0.0857</td><td>0.0856</td><td>0.0886</td><td>0.0998</td><td>0.1040</td><td>0.1052</td><td>0.1200*</td><td>14.1%</td></tr><tr><td>N@10</td><td>0.0383</td><td>0.0385</td><td>0.0424</td><td>0.0423</td><td>0.0213</td><td>0.0225</td><td>0.0377</td><td>0.0312</td><td>0.0284</td><td>0.0384</td><td>0.0415</td><td>0.0425</td><td>0.0427</td><td>0.0470*</td><td>10.2%</td></tr><tr><td>N@20</td><td>0.0451</td><td>0.0455</td><td>0.0506</td><td>0.0503</td><td>0.0280</td><td>0.0293</td><td>0.0445</td><td>0.0388</td><td>0.0364</td><td>0.0452</td><td>0.0493</td><td>0.0507</td><td>0.0510</td><td>0.0567*</td><td>11.1%</td></tr><tr><td rowspan=\"4\">Beauty</td><td>R@10</td><td>0.0842</td><td>0.0865</td><td>0.0855</td><td>0.0871</td><td>0.0682</td><td>0.0804</td><td>0.0839</td><td>0.0774</td><td>0.0811</td><td>0.0817</td><td>0.0891</td><td>0.0883</td><td>0.0920</td><td>0.0935*</td><td>1.6%</td></tr><tr><td>R@20</td><td>0.1191</td><td>0.1225</td><td>0.1239</td><td>0.1260</td><td>0.0991</td><td>0.1123</td><td>0.1186</td><td>0.1217</td><td>0.1152</td><td>0.1169</td><td>0.1281</td><td>0.1256</td><td>0.1322</td><td>0.1347*</td><td>1.9%</td></tr><tr><td>N@10</td><td>0.0424</td><td>0.0448</td><td>0.0426</td><td>0.0437</td><td>0.0380</td><td>0.0468</td><td>0.0420</td><td>0.0337</td><td>0.0461</td><td>0.0415</td><td>0.0444</td><td>0.0454</td><td>0.0463</td><td>0.0526*</td><td>12.5%</td></tr><tr><td>N@20</td><td>0.0511</td><td>0.0538</td><td>0.0522</td><td>0.0535</td><td>0.0458</td><td>0.0549</td><td>0.0508</td><td>0.0448</td><td>0.0547</td><td>0.0504</td><td>0.0542</td><td>0.0548</td><td>0.0564</td><td>0.0632*</td><td>12.0%</td></tr><tr><td rowspan=\"4\">Sports</td><td>R@10</td><td>0.0487</td><td>0.0489</td><td>0.0495</td><td>0.0506</td><td>0.0410</td><td>0.0443</td><td>0.0465</td><td>0.0402</td><td>0.0498</td><td>0.0473</td><td>0.0534</td><td>0.0549</td><td>0.0568</td><td>0.0574</td><td>1.1%</td></tr><tr><td>R@20</td><td>0.0709</td><td>0.0723</td><td>0.0743</td><td>0.0741</td><td>0.0625</td><td>0.0648</td><td>0.0677</td><td>0.0656</td><td>0.0723</td><td>0.0690</td><td>0.0784</td><td>0.0809</td><td>0.0827</td><td>0.0853*</td><td>3.2%</td></tr><tr><td>N@10</td><td>0.0231</td><td>0.0246</td><td>0.0232</td><td>0.0239</td><td>0.0218</td><td>0.0251</td><td>0.0226</td><td>0.0183</td><td>0.0282</td><td>0.0229</td><td>0.0251</td><td>0.0261</td><td>0.0268</td><td>0.0310*</td><td>10.1%</td></tr><tr><td>N@20</td><td>0.0287</td><td>0.0305</td><td>0.0295</td><td>0.0298</td><td>0.0272</td><td>0.0302</td><td>0.0279</td><td>0.0246</td><td>0.0339</td><td>0.0283</td><td>0.0314</td><td>0.0326</td><td>0.0333</td><td>0.0381*</td><td>12.5%</td></tr><tr><td rowspan=\"4\">Toys</td><td>R@10</td><td>0.0889</td><td>0.0939</td><td>0.0923</td><td>0.0928</td><td>0.0643</td><td>0.0789</td><td>0.0913</td><td>0.0820</td><td>0.0884</td><td>0.0930</td><td>0.1011</td><td>0.1020</td><td>0.1007</td><td>0.1023</td><td>0.3%</td></tr><tr><td>R@20</td><td>0.1225</td><td>0.1287</td><td>0.1302</td><td>0.1293</td><td>0.0950</td><td>0.1112</td><td>0.1238</td><td>0.1260</td><td>0.1221</td><td>0.1253</td><td>0.1379</td><td>0.1405</td><td>0.1393</td><td>0.1425*</td><td>1.3%</td></tr><tr><td>N@10</td><td>0.0436</td><td>0.0481</td><td>0.0446</td><td>0.0460</td><td>0.0350</td><td>0.0456</td><td>0.0449</td><td>0.0364</td><td>0.0506</td><td>0.0458</td><td>0.0504</td><td>0.0510</td><td>0.0496</td><td>0.0553*</td><td>8.6%</td></tr><tr><td>N@20</td><td>0.0521</td><td>0.0569</td><td>0.0541</td><td>0.0552</td><td>0.0427</td><td>0.0537</td><td>0.0531</td><td>0.0475</td><td>0.0591</td><td>0.0539</td><td>0.0597</td><td>0.0607</td><td>0.0593</td><td>0.0656*</td><td>8.1%</td></tr></table>\n\nTable 2: Overall performance comparison on four datasets. * denotes that DIFF shows statistically significant improvement  $(p < 0.05)$  over the best competitive model. The best results are marked in bold, and the second best results are underlined.\n\nlength to 50, and we stop the training if the validation N@20 decreases for ten consecutive epochs. We tune all the hyperparameters on the validation data and report the performance on the test set using the models that show the highest performance on the validation set. For the proposed method, we set both the embedding size and batch size to 256, and both the number of layers and heads are set to 2. We set the frequency component split parameter  $c$  to 3 for Beauty, Sports, Yelp datasets and 5 for Toys dataset. We also tune the aggregating hyperparameters  $\\alpha$  among  $\\{0.1, 0.3, 0.5, 0.7, 0.9\\}$  and loss balancing hyperparameter  $\\lambda$  among  $\\{1, 5, 10, 20, 50, 100\\}$ . The fusion function  $\\mathrm{Fusion}(\\cdot)$  is set to gating for the Yelp dataset and concatenation for the Beauty, Sports, and Toys datasets. For the baseline models, we follow the original papers' settings for other hyperparameters of baselines, and we thoroughly tune them if not available. All results are averaged over five runs with different seeds, and we conducted the significance test using a paired t-test. Our code is available at https://github.com/HyeYoung1218/DIFF.\n\n# 6 Experimental Results\n\n# 6.1 Overall Performance\n\nTable 2 reports the performance comparison between DIFF and other baselines in four real-world datasets. The key observations are as follows. (i) DIFF consistently achieves state-of-the-art performance on all datasets against the best competitive baseline, improving R@20 and N@20 by up to  $14.1\\%$  and  $12.5\\%$ , respectively. Especially, DIFF exhibits the best performance against the best competitive SISR baselines, e.g., MSSR [14] and ASIF [27], yielding average gains of  $4.7\\%$  and  $11.2\\%$  on R@20 and N@20. This indicates that DIFF successfully avoids noisy patterns and leverages side-information. (ii) When compared to SR baselines that do not use side-information, SISR baselines, especially MSSR [14], ASIF [27], and DIFF, generally achieve superior performance. It implies that modeling user preferences with rich item context is critical for recommendation performance. (iii) Although DLFSRec [16] leverages\n\n\nTable 3: Ablation study of DIFF. FNF refers to the Frequency-based Noise Filtering. IF and AF represent ID-centric Fusion and Attribute-enriched Fusion, respectively. Lastly, RA denotes Representation Alignment.\n\n\n<table><tr><td></td><td>Metric</td><td>w/o FNF</td><td>w/o IF</td><td>w/o AF</td><td>w/o RA</td><td>DIFF</td></tr><tr><td rowspan=\"2\">Yelp</td><td>R@20</td><td>0.1045</td><td>0.1174</td><td>0.1185</td><td>0.1114</td><td>0.1200</td></tr><tr><td>N@20</td><td>0.0512</td><td>0.0560</td><td>0.0564</td><td>0.0542</td><td>0.0567</td></tr><tr><td rowspan=\"2\">Beauty</td><td>R@20</td><td>0.1289</td><td>0.1290</td><td>0.1334</td><td>0.1300</td><td>0.1347</td></tr><tr><td>N@20</td><td>0.0615</td><td>0.0629</td><td>0.0576</td><td>0.0585</td><td>0.0632</td></tr><tr><td rowspan=\"2\">Sports</td><td>R@20</td><td>0.0843</td><td>0.0795</td><td>0.0851</td><td>0.0827</td><td>0.0853</td></tr><tr><td>N@20</td><td>0.0322</td><td>0.0375</td><td>0.0337</td><td>0.0330</td><td>0.0381</td></tr><tr><td rowspan=\"2\">Toys</td><td>R@20</td><td>0.1373</td><td>0.1357</td><td>0.1459</td><td>0.1357</td><td>0.1420</td></tr><tr><td>N@20</td><td>0.0615</td><td>0.0651</td><td>0.0598</td><td>0.0600</td><td>0.0657</td></tr></table>\n\nfrequency-based learnable filters for SISR, it does not primarily focus on fusion methods, which results in comparatively lower performance than late and intermediate fusion approaches (i.e., FDSA [31], NOVA [15], DIF-SR [29], MSSR [14], and ASIF [27]). This highlights the importance of a well-designed fusion strategy in achieving superior performance. (iv) Among SISR baselines, intermediate fusion approaches (i.e., NOVA [15], DIF-SR [29], MSSR [14], and ASIF [27]) generally demonstrate higher performance than early fusion methods (i.e., GRU4Rec $_\\mathrm{F}$  and SASRec $_\\mathrm{F}$ ) and late fusion method (i.e., FDSA [31]). Notably, two early fusion methods (GRU4Rec $_\\mathrm{F}$  and SASRec $_\\mathrm{F}$ ) lose performance of up to  $23.6\\%$  and  $35.0\\%$  performance at N@20 compared to GRU4Rec and SASRec, respectively. This underscores the importance of delicately designed fusion methods when utilizing side-information. (v) Among SISR baselines, ASIF [27] and DIFF demonstrate particularly promising performance compared to other SISR models. This highlights that, in addition to designing an effective fusion method, eliminating noisy correlations between IDs and attributes further enhances performance by ensuring meaningful interactions are captured.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/cc8b4db5d42db9fa097a7956c7a7a5d2b67a819b73171d0f52810ae7863dd5db.jpg)\n\n\n\nFigure 4: Performance comparison on different target item popularity groups. The target items of Head group are the top  $10\\%$  most popular items, while the Tail group includes sequences with less popular target items.\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/ca89fc66695e86ad7e7537b7adcda266da4e46033f4419afb62e2b9c88e2b050.jpg)\n\n\n\nFigure 5: Performance comparison on different sequence length groups. The Short group consists of sequences with a length of five (43% of Yelp and 51% of Beauty dataset), while the Long group includes sequences longer than five.\n\n\n# 6.2 In-depth Analysis\n\nAblation Study. We validate the effectiveness of the key components of the proposed method through the ablation study as shown in Table 3. (i) Frequency-based Noise Filtering (FNF) significantly impacts performance across all datasets, delivering a performance gain of up to  $14.8\\%$  and  $10.7\\%$  in R@20 and N@20, respectively. It demonstrates that noisy signals are removed and only essential information is successfully extracted, leading to more accurate user representation. (ii) The proposed dual fusion strategy remarkably improves the accuracy compared to using only ID-centric Fusion (IF) or Attribute-enriched Fusion (AF) by more than  $7.3\\%$  and  $13.1\\%$  on R@20 and N@20. It shows that each fusion successfully captures complementary information to another. (iii) The representation alignment loss (RA) seamlessly integrates item ID and attribute information by aligning their embedding spaces, showing gains of up to  $7.7\\%$  and  $14.4\\%$  on R@20 and N@20. By harmonizing the representation spaces, ID and attribute information are effectively incorporated into the model.\n\nPerformance by Item Popularity. In Figure 4, we evaluate the performance of DIFF and baseline models by dividing the test user sequences into two groups: Head, consisting of sequences with target items from the top  $10\\%$  most popular items, and Tail, with sequences containing less popular target items. The experimental results demonstrate strong performance of DIFF across both groups, effectively alleviating the popularity bias. By leveraging side-information filtering and fusion mechanisms, DIFF can extract meaningful signals from side-information, compensating for the sparse interactions typically associated with tail items. This suggests that DIFF also outperforms other competitive models for\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/46972fa5fda66aa5f8387f25ae48a0941c9487db820ccdebccf390ff73cbc0fd.jpg)\n\n\n\nFigure 6: Robustness to noisy sequences on Yelp and Beauty datasets. It shows the performance of DIF-SR, MSSR, ASIF, and DIFF by varying the item substitution ratio.\n\n\ncold-start scenarios. In particular, for the Tail group, DIFF achieves up to  $38.9\\%$  improvement on Yelp and  $10.3\\%$  on the Beauty dataset. Performance by Sequence Length. In Figure 5, we evaluate the performance of DIFF and baseline models by dividing user sequences into two groups based on their length. The Short group consists of users with five interacted items, while the Long group includes users with more than five interacted items. The results show that DIFF consistently outperforms the baseline models across both groups, effectively capturing user preferences regardless of sequence length. Notably, DIFF achieves significant improvements in the Short sequence group, where limited user interaction data. In particular, DIFF shows the performance gains in Recall@20 by up to  $15.8\\%$  and  $10\\%$  on the Yelp and Beauty dataset, respectively. This indicates that DIFF is particularly effective in scenarios with sparse historical interaction, showcasing its capability to leverage available information more efficiently.\n\n# 6.3 Robustness to Noisy Sequence\n\nIn Figure 6, we examine the robustness of the proposed method to demonstrate the effectiveness of Frequency-based Noise Filtering. Here, we adopt the most competitive SISR models, i.e., DIF-SR [29], MSSR [14], and ASIF [27], for comparison. Following the approach in [5], we simulate noisy conditions by injecting synthetic noise into the test sequences. While they add random uniform noise to the original representations, we adopt a more challenging approach by replacing some items in each item ID sequence with random items, resulting in a more realistic and complex evaluation scenario. These substituted items can be regarded as fluctuating items that should ideally be ignored.\n\nThe key findings are as follows. (i) Even with a low noise ratio (i.e.,  $5\\%$ ), all models exhibit performance degradation across all datasets, highlighting the challenges posed by noisy inputs. However, DIFF demonstrates greater resilience than DIF-SR, MSSR, and ASIF. Notably, on the Beauty dataset, DIFF shows only a  $7.1\\%$  performance drop, whereas ASIF, MSSR, and DIF-SR suffer significant performance drops of  $16.2\\%$ ,  $15.4\\%$ , and  $10.5\\%$ , respectively. (ii) As the noise ratio increases incrementally up to  $25\\%$ , the performance gap between DIFF and other models consistently widens across all datasets. Notably, on the Yelp dataset, DIFF exhibits a relatively modest decline of  $21.4\\%$ , whereas the baseline models show substantial drops, ranging from  $26.6\\%$  to  $32.9\\%$ . This suggests that baseline models struggle to capture user preferences under noisy conditions. In contrast, our approach effectively filters out noisy signals, ensuring the preservation of critical information.\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/3bdc383520b8b8bcb1467769a85db580aa2b20565b7404f2ba7d91608471217a.jpg)\n\n\n\n(a) Yelp\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/eefe3b65853a0b6d022c8cb81ea14b4db6077e7101a75638d07240d05e1d54f5.jpg)\n\n\n\n(b) Beauty\n\n\n\nFigure 7: Performance with varying representation aggregating hyperparameter  $\\alpha$ . When  $\\alpha = 0$ , only AF is utilized, and when  $\\alpha = 1$ , only IF is employed.\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/d94dccb4d9ce72bcc243a41d56adc89e662f8c2d8f20cb9355d62359bf4818c9.jpg)\n\n\n\n(a) Yelp\n\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/4890a517b3a1b3624e1af43f86b3128c0ec901592d73a7e066b0bfc351657dfa.jpg)\n\n\n\n(b) Beauty\n\n\n\nFigure 8: Performance with varying alignment loss balancing hyperparameter  $\\lambda$ .\n\n\n# 6.4 Hyperparameter Sensitivity\n\nRepresentation Aggregating Hyperparameter. Figure 7 illustrates the sensitivity of the proposed method to representation aggregating hyperparameter  $\\alpha$  on Yelp and Beauty datasets. In the Yelp dataset, we observe that both Recall and NDCG peak at moderate  $\\alpha$  values around 0.5, with particularly small fluctuations in NDCG. However, the optimal value of  $\\alpha$  for the Recall@20 and NDCG@20 performance differs on the Beauty dataset. Higher  $\\alpha$  values improve recall performance, while lower  $\\alpha$  values lead to more significant NDCG gains, indicating complementary roles of two fusion types. Our dual fusion approach can effectively enhance performance by leveraging the distinct fusion characteristics.\n\nLoss Balancing Hyperparameter. Figure 8 presents the impact of the loss balancing hyperparameter  $\\lambda$  across four datasets. The results demonstrate that incorporating the alignment loss consistently improves performance across all datasets. Specifically, we observe performance gains of up to  $4.6\\%$  and  $6.9\\%$  in NDCG@20 on the Yelp and Beauty datasets, respectively. The Yelp dataset shows a steady increase and peak performance at  $\\lambda = 20$ , after which performance decreases slightly. This indicates that an excessively high  $\\lambda$  may result in over-aligning, which has less impact on performance improvement. For the Beauty dataset, increasing  $\\lambda$  results in consistent improvements in Recall@20 and NDCG@20, suggesting that greater alignment contributes to better fusion of diverse features. These findings suggest that an optimal  $\\lambda$  value is crucial for balancing alignment and performance, with different datasets exhibiting varying sensitivities to this hyperparameter.\n\n# 6.5 Case Study\n\nIn Figure 9, we conducted a case study on the Yelp dataset to analyze the effectiveness of dual fusion strategies in capturing user preferences. We explore the distribution of attention weights from two fusion strategies, i.e., ID-centric Fusion (IF) and Attribute-enriched Fusion (AF) to understand their individual contributions to the recommendation process. (i) IF allocates the highest attention weight\n\n![image](https://cdn-mineru.openxlab.org.cn/result/2026-01-10/3dbc8a02-e08a-4829-b8f2-75a4d99ade1a/1b45330f7a502c30e788051dff5968e1684fe8b66f5370dd4e3f1802123694e3.jpg)\n\n\n\nFigure 9: Case study of attention distribution in the dual fusion types of DIFF, i.e., ID-centric fusion (Left) and Attribute-enriched fusion (Right), on the Yelp dataset.\n\n\nto  $i_7$  sharing a category of \"Coffee & Tea\" with the target item, demonstrating the ability to prioritize relevant attributes. However, IF alone fails to capture  $i_2$ , which shares a different but relevant category with the target item. (ii) AF allocates high attention weight to  $i_2$  and  $i_7$ , which shares the \"Sandwiches\" category with the target item, covering more diverse items. However, AF alone does not emphasize  $i_7$  as strongly as IF does, potentially overlooking highly relevant items. These observations indicate that the two fusion strategies capture different aspects of user preferences, with IF exceeding at reinforcing specific attribute relevance and AF offering a more diverse coverage. Therefore, the complementary strengths of AF and IF suggest a synergistic potential in combining them into a dual fusion.\n",
    "hyperparameter": "embedding_size = 256, batch_size = 256, num_layers = 2, num_heads = 2, max_seq_len = 50, learning_rate ∈ {1e-4, 1e-3}, frequency_split c = 3 (Yelp/Beauty/Sports) or 5 (Toys), fusion_α ∈ {0.1, 0.3, 0.5, 0.7, 0.9} (optimal ≈ 0.5), alignment_loss_λ ∈ {1, 5, 10, 20, 50, 100} (optimal ≈ 20 on Yelp), fusion function = gating (Yelp) / concatenation (others), trainable high-frequency weights β₀…β_{m+1} initialized small, temperature τ in alignment loss is learnable."
}