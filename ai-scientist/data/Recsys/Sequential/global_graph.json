{
  "domain": "Recsys",
  "task": "SequentialRecommendation",
  "items": [
    {
      "id": "sequential_recommender_interface",
      "title": "SequentialRecommender 基类接口规范",
      "content": "模型类继承 SequentialRecommender，__init__ 首行调用 super().__init__(config, dataset)。父类提供核心属性：self.n_items（物品数）、self.max_seq_length（最大序列长度）、self.device。父类提供字段常量：ITEM_SEQ（历史序列）、ITEM_SEQ_LEN（序列长度）、POS_ITEM_ID（目标物品）、NEG_ITEM_ID（负样本物品）、ITEM_ID（测试物品）、USER_ID。必须实现 forward(item_seq, item_seq_len) 返回 [B, H] 序列表示、calculate_loss(interaction)、predict(interaction)、full_sort_predict(interaction)。父类提供 gather_indexes(output, indices) 按位置提取隐状态、get_attention_mask(item_seq, bidirectional=False) 生成注意力掩码。",
      "tags": [
        "framework",
        "recbole",
        "interface",
        "critical"
      ],
      "source": "framework_analysis",
      "priority": 10,
      "created_at": "2025-12-26T12:00:00.000000",
      "updated_at": "2025-12-26T20:00:00.000000"
    },
    {
      "id": "sequence_encoding_paradigms",
      "title": "序列建模范式",
      "content": "序列推荐存在四种主流建模范式：(1) 自注意力 Transformer，支持单向因果掩码（SASRec 风格，仅看历史）或双向注意力（BERT4Rec 风格，需配合掩码预训练）；(2) 循环神经网络 GRU/LSTM，通过隐状态传递时序信息，计算效率高但并行性差；(3) 图神经网络，将序列转为会话图捕捉物品转移关系，适合建模复杂跳转模式；(4) 卷积网络，水平卷积捕捉联合级别模式、垂直卷积捕捉时间点级别模式。序列最终表示通常取最后有效位置的隐状态：output = gather_indexes(encoder_output, item_seq_len - 1)。",
      "tags": [
        "architecture",
        "transformer",
        "rnn",
        "gnn",
        "cnn",
        "critical"
      ],
      "source": "model_analysis",
      "priority": 10,
      "created_at": "2025-12-26T20:00:00.000000",
      "updated_at": "2025-12-26T20:00:00.000000"
    },
    {
      "id": "position_encoding",
      "title": "位置编码",
      "content": "序列模型需显式建模位置信息。标准做法是可学习位置嵌入 nn.Embedding(max_seq_length, hidden_size)，与物品嵌入相加：input_emb = item_emb + position_embedding。位置索引生成：position_ids = torch.arange(seq_len, device=item_seq.device).unsqueeze(0).expand_as(item_seq)。输入嵌入后需 LayerNorm + Dropout 正则化。部分高级方法解耦位置编码与内容编码分别计算注意力再融合。",
      "tags": [
        "embedding",
        "position",
        "transformer"
      ],
      "source": "model_analysis",
      "priority": 8,
      "created_at": "2025-12-26T20:00:00.000000",
      "updated_at": "2025-12-26T20:00:00.000000"
    },
    {
      "id": "attention_mask_generation",
      "title": "注意力掩码生成",
      "content": "序列推荐中注意力掩码需处理两类情况：(1) padding 掩码，对 item_seq==0 的位置屏蔽；(2) 因果掩码，确保位置 i 只能注意到 ≤i 的位置，用 torch.tril() 生成下三角矩阵。掩码值设为 -10000.0（乘以 attention_scores 后 softmax 接近零）。双向注意力（BERT 风格）仅使用 padding 掩码，单向注意力（GPT 风格）两者结合。父类 get_attention_mask(item_seq, bidirectional=False) 已封装此逻辑。",
      "tags": [
        "attention",
        "mask",
        "transformer"
      ],
      "source": "engineering_standards",
      "priority": 8,
      "created_at": "2025-12-26T20:00:00.000000",
      "updated_at": "2025-12-26T20:00:00.000000"
    },
    {
      "id": "loss_functions",
      "title": "损失函数选择",
      "content": "序列推荐主流两种损失：(1) BPR 排序损失，需负采样，loss = -log(sigmoid(pos_score - neg_score))，强调正负样本相对顺序，适合隐式反馈；(2) CrossEntropy 分类损失，logits = matmul(seq_output, item_embedding.weight.T)，将所有物品作为类别，计算 softmax 后的交叉熵。CE 损失无需显式负采样但计算量大（需对所有物品计算 logits）。实现时用 loss_type 配置切换，BPR 需从 interaction[NEG_ITEM_ID] 获取负样本。\n\n常见报错：当 loss_type='CE' 时仍启用负采样，会触发 RecBole 配置校验异常（train_neg_sample_args），典型报错为：ValueError: train_neg_sample_args ... should be None when the loss_type is CE. 解决方式是在模型或全局配置中显式关闭负采样：\ntrain_neg_sample_args: ~  # Disable negative sampling for CE loss\n若使用 BPR，则保留负采样配置并确保 loss_type 与采样策略一致。",
      "tags": [
        "loss",
        "bpr",
        "crossentropy",
        "critical"
      ],
      "source": "model_analysis",
      "priority": 10,
      "created_at": "2025-12-26T20:00:00.000000",
      "updated_at": "2025-12-27T11:00:00.000000"
    },
    {
      "id": "scoring_and_prediction",
      "title": "评分与预测",
      "content": "三种预测场景：(1) calculate_loss 训练时对正/负样本评分：score = (seq_output * item_emb).sum(dim=-1)；(2) predict 测试单个候选物品：scores = torch.mul(seq_output, test_item_emb).sum(dim=1)；(3) full_sort_predict 对所有物品排序：scores = torch.matmul(seq_output, item_embedding.weight.transpose(0, 1))，返回 [B, n_items]。全排序是性能瓶颈，需一次矩阵乘法完成，禁止逐物品循环。",
      "tags": [
        "prediction",
        "scoring",
        "performance"
      ],
      "source": "engineering_standards",
      "priority": 9,
      "created_at": "2025-12-26T20:00:00.000000",
      "updated_at": "2025-12-26T20:00:00.000000"
    },
    {
      "id": "transformer_architecture",
      "title": "Transformer 编码器结构",
      "content": "序列推荐 Transformer 标准配置：n_layers=2、n_heads=2、hidden_size=64、inner_size=256（4 倍 hidden_size）。使用 RecBole 的 TransformerEncoder 组件，参数包括 hidden_dropout_prob、attn_dropout_prob（典型 0.2-0.5）、hidden_act='gelu'、layer_norm_eps=1e-12。注意 hidden_size 必须能被 n_heads 整除。输出取最后一层：trm_output = encoder(input_emb, attention_mask, output_all_encoded_layers=True)[-1]。",
      "tags": [
        "transformer",
        "architecture",
        "hyperparameter"
      ],
      "source": "model_analysis",
      "priority": 9,
      "created_at": "2025-12-26T20:00:00.000000",
      "updated_at": "2025-12-26T20:00:00.000000"
    },
    {
      "id": "session_graph_construction",
      "title": "会话图构建",
      "content": "将序列转为图结构的方法：遍历序列构建物品转移边，连续出现的 (item_i, item_{i+1}) 构成有向边。区分入边和出边邻接矩阵，按行/列归一化（度归一化防止度数大的节点主导）。使用 numpy 高效构建后转 torch.FloatTensor。图中每个节点对应序列中的唯一物品，通过 alias_inputs 建立原始位置到图节点的映射，用 torch.gather 将图节点表示映射回序列位置。",
      "tags": [
        "graph",
        "session",
        "gnn"
      ],
      "source": "model_analysis",
      "priority": 7,
      "created_at": "2025-12-26T20:00:00.000000",
      "updated_at": "2025-12-26T20:00:00.000000"
    },
    {
      "id": "config_yaml_format",
      "title": "超参数 YAML 格式规范",
      "content": "YAML 采用扁平结构，每行一个参数，格式 key: value # (type) description。值必须为标量或整数列表（仅 MLP 隐层如 mlp_hidden_size: [256,256]）。键名必须与代码中 config['key'] 完全一致。Transformer 类模型典型参数：n_layers: 2、n_heads: 2、hidden_size: 64、inner_size: 256、hidden_dropout_prob: 0.5、attn_dropout_prob: 0.5、hidden_act: 'gelu'、layer_norm_eps: 1e-12、initializer_range: 0.02、loss_type: 'CE'。",
      "tags": [
        "hyperparameter",
        "yaml",
        "config",
        "critical"
      ],
      "source": "engineering_standards",
      "priority": 9,
      "created_at": "2025-12-26T12:00:00.000000",
      "updated_at": "2025-12-26T20:00:00.000000"
    },
    {
      "id": "device_tensor_handling",
      "title": "设备与张量处理",
      "content": "关键设备一致性规则：(1) 动态创建的张量需显式指定 device，如 torch.arange(..., device=item_seq.device)；(2) 预计算结构（邻接矩阵、掩码模板）在 __init__ 中移至 self.device；(3) numpy 数组转 tensor 后需 .to(self.device)。序列数据访问通过 interaction 字典，如 item_seq = interaction[self.ITEM_SEQ]。序列长度 item_seq_len 为 LongTensor，用于 gather 操作时无需额外处理。",
      "tags": [
        "device",
        "tensor",
        "engineering"
      ],
      "source": "engineering_standards",
      "priority": 8,
      "created_at": "2025-12-26T20:00:00.000000",
      "updated_at": "2025-12-26T20:00:00.000000"
    },
    {
      "id": "sequence_augmentation_strategies",
      "title": "序列增强策略",
      "content": "序列推荐中的数据增强通过扩充训练样本提升模型泛化能力。常见策略包括：(1) 序列级增强：随机裁剪、子序列重排、掩码、插入/删除操作；(2) 嵌入级增强：在表示空间进行插值混合（Mixup），可在物品维度、特征维度或批次维度进行。Mixup 通常使用 Beta 分布采样混合系数 λ~Beta(α,α)，combined_emb = λ * emb1 + (1-λ) * emb2。增强样本需配合自适应损失权重避免引入过多噪声。实现时注意：增强操作应在 forward 中通过 augment 标志控制，测试时禁用；对于两阶段训练，通过 epoch 计数器判断是否启用增强。",
      "tags": [
        "augmentation",
        "mixup",
        "training",
        "generalization"
      ],
      "source": "training_techniques",
      "priority": 8,
      "created_at": "2026-01-10T12:00:00.000000",
      "updated_at": "2026-01-10T12:00:00.000000"
    },
    {
      "id": "frequency_domain_processing",
      "title": "频域信号处理技术",
      "content": "频域分析可将序列信号分解为不同频率成分，捕捉长期稳定模式（低频）和短期波动（高频）。PyTorch 实现：使用 torch.fft.rfft(x, dim=1, norm='ortho') 进行实数快速傅里叶变换，输出形状 [B, c//2+1, H]，其中 c 为序列长度。低频分量保留前 k 个系数，高频分量为原始信号减去低频部分。逆变换用 torch.fft.irfft(x, n=seq_len, dim=1, norm='ortho') 恢复时域信号。可引入可学习参数 β 控制高频权重：filtered = low_freq + β² * high_freq，通过 nn.Parameter(torch.randn(1,1,1)) 定义。应用场景：去噪、长短期兴趣解耦、多尺度特征提取。实现时需在滤波层中添加 LayerNorm 和残差连接保证训练稳定性。",
      "tags": [
        "frequency",
        "fft",
        "signal_processing",
        "advanced"
      ],
      "source": "signal_processing",
      "priority": 7,
      "created_at": "2026-01-10T12:00:00.000000",
      "updated_at": "2026-01-10T12:00:00.000000"
    },
    {
      "id": "multimodal_feature_fusion",
      "title": "多模态特征融合机制",
      "content": "当模型需整合物品 ID、类别、品牌等多种信息时，常用三种融合策略：(1) 加法融合 (sum)：直接逐元素相加，要求各模态维度相同，计算高效但表达力受限；(2) 拼接融合 (concat)：沿特征维度拼接后通过线性层投影，fusion_layer = nn.Linear(sum_of_dims, target_dim)，灵活但参数量大；(3) 门控融合 (gate)：使用注意力机制动态加权，VanillaAttention 计算各模态重要性后加权求和，适合模态重要性差异大的场景。实现时通过 fusion_type 配置项切换。对于序列数据，融合可发生在嵌入层后（early fusion）、注意力计算中（intermediate fusion）或编码器输出后（late fusion）。Early fusion 直接融合原始嵌入，intermediate fusion 融合注意力分数矩阵，late fusion 融合最终表示。多路径架构可结合不同阶段的融合策略，通过 α 参数平衡：final_repr = α * path1 + (1-α) * path2。",
      "tags": [
        "fusion",
        "multimodal",
        "attention",
        "architecture"
      ],
      "source": "multimodal_learning",
      "priority": 8,
      "created_at": "2026-01-10T12:00:00.000000",
      "updated_at": "2026-01-10T12:00:00.000000"
    },
    {
      "id": "attention_mechanism_variants",
      "title": "注意力机制变体与扩展",
      "content": "标准 Transformer 注意力可通过多种方式扩展：(1) 解耦位置与内容注意力：分别计算 pos_attn = Q_pos @ K_pos^T 和 item_attn = Q_item @ K_item^T，融合后再 softmax，捕捉位置依赖和内容依赖；(2) 多来源注意力融合：对不同信息源（如 ID、属性）分别计算注意力矩阵，通过加法/拼接/门控融合，attention_fused = Fusion([attn_id, attn_attr1, ...])，然后与 value 聚合；(3) 分层注意力：不同 Transformer 层专注不同模式，早期层捕捉局部模式，后期层捕捉全局依赖。实现时 Q/K/V 投影矩阵需分别定义，self.query_id = nn.Linear(hidden_size, all_head_size)，对于多属性需用 nn.ModuleList 存储多组投影层。注意缩放因子 1/sqrt(d_k) 防止内积过大导致梯度消失。",
      "tags": [
        "attention",
        "transformer",
        "architecture",
        "advanced"
      ],
      "source": "attention_mechanisms",
      "priority": 7,
      "created_at": "2026-01-10T12:00:00.000000",
      "updated_at": "2026-01-10T12:00:00.000000"
    },
    {
      "id": "training_strategies_regularization",
      "title": "训练策略与正则化技术",
      "content": "深度序列模型常用训练技巧：(1) 两阶段训练：先在原始数据上预训练稳定基础模型，再引入增强/辅助任务微调，通过 epoch 计数器判断阶段（如 if epoch < stage1_epochs）；(2) 多任务学习：主任务 loss_main + λ * loss_auxiliary，λ 控制辅助任务权重，典型取值 0.1-0.5；(3) 自适应损失加权：根据样本难度或增强强度动态调整损失权重，weight = f(difficulty)，避免简单样本主导训练；(4) 对比学习：通过正负样本对齐表示空间，常用 InfoNCE 损失或余弦相似度约束；(5) Dropout 策略：浅层使用较低 dropout（0.2），深层或过拟合风险高时提高至 0.5。实现时在 calculate_loss 中组合多个损失项，total_loss = loss_rec + λ1 * loss_aux1 + λ2 * loss_aux2，确保各损失项量级相近（通过系数调节）。",
      "tags": [
        "training",
        "regularization",
        "multi_task",
        "optimization"
      ],
      "source": "training_techniques",
      "priority": 9,
      "created_at": "2026-01-10T12:00:00.000000",
      "updated_at": "2026-01-10T12:00:00.000000"
    },
    {
      "id": "recbole_feature_embedding",
      "title": "RecBole 特征嵌入层使用",
      "content": "RecBole 提供 FeatureSeqEmbLayer 统一处理序列特征嵌入。使用方式：feature_embed_layer = FeatureSeqEmbLayer(dataset, embedding_size, selected_features, pooling_mode, device)，其中 selected_features=['categories', 'brand'] 指定要使用的特征字段。调用时 sparse_embedding, dense_embedding = feature_embed_layer(None, item_seq)，返回字典结构 {'item': tensor}。稀疏特征（类别型）返回 [B, L, 1, d_f] 形状张量，dense 特征为 None（如无连续特征）。多个特征需用 nn.ModuleList 分别创建嵌入层：[FeatureSeqEmbLayer(..., [feat], ...) for feat in selected_features]，然后拼接 torch.cat(feature_table, dim=2)。pooling_mode 可选 'sum'/'mean'/'max'，控制同一物品多个特征值的聚合方式。特征嵌入维度 attribute_hidden_size 可与主嵌入 hidden_size 不同，融合时需投影对齐。",
      "tags": [
        "recbole",
        "feature",
        "embedding",
        "framework",
        "critical"
      ],
      "source": "framework_analysis",
      "priority": 9,
      "created_at": "2026-01-10T12:00:00.000000",
      "updated_at": "2026-01-10T12:00:00.000000"
    }
  ],
  "metadata": {
    "created_at": "2025-12-26T12:00:00.000000",
    "updated_at": "2026-01-10T12:00:00.000000",
    "item_count": 16
  }
}
