# FEARec: Frequency Enhanced Hybrid Attention Network for Sequential Recommendation
# Reference: Xinyu Du et al. "Frequency Enhanced Hybrid Attention Network for Sequential Recommendation" SIGIR 2023

# Transformer encoder parameters
n_layers: 2                     # (int) The number of transformer layers in FEA encoder.
n_heads: 2                      # (int) The number of attention heads for multi-head attention layer.
hidden_size: 64                 # (int) The number of features in the hidden state.
inner_size: 256                 # (int) The inner hidden size in feed-forward layer.
hidden_dropout_prob: 0.5        # (float) The probability of an element to be zeroed.
attn_dropout_prob: 0.5          # (float) The probability of an attention score to be zeroed.
hidden_act: 'gelu'              # (str) The activation function in feed-forward layer.
layer_norm_eps: 1e-12           # (float) A value added to the denominator for numerical stability.
initializer_range: 0.02         # (float) The standard deviation for normal initialization.

# FEARec specific parameters - Frequency Enhanced Attention
global_ratio: 0.5               # (float) Alpha: frequency sampling ratio for ramp structure (Section 3.2.1).
topk_factor: 3                  # (int) m: factor for top-k time delay selection in auto-correlation (Eq. 15).
gamma: 0.5                      # (float) Weight for combining time and frequency domain attention (Eq. 18).

# Contrastive learning parameters
lmd: 0.1                        # (float) Lambda_1: weight for contrastive learning loss (Eq. 23, 24).
lmd_sem: 0.1                    # (float) Weight for supervised contrastive learning.
tau: 1.0                        # (float) Temperature parameter for contrastive learning.

# Frequency domain regularization
fredom: True                    # (bool) Whether to use frequency domain regularization.
fredom_weight: 0.1              # (float) Lambda_2: weight for frequency domain regularization loss (Eq. 26).

# Loss function
loss_type: 'CE'                 # (str) The type of loss function. Range in ['BPR', 'CE'].

# Disable negative sampling for CE loss
train_neg_sample_args: ~