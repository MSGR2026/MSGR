```json
{
  "similarities": "1. Both methods construct item-item graphs based on multimodal feature similarity using kNN sparsification (k=10) and Laplacian normalization, pre-computing these graphs before training to avoid computational overhead during training.\n2. Both employ LightGCN-style message passing on user-item bipartite graphs without learnable transformation matrices, using simple neighborhood aggregation.\n3. Both use degree-sensitive edge sampling for user-item graph processing - FREEDOM uses probability p_k = 1/sqrt(w_i*w_j) for pruning, and PGL uses the same weighting scheme 1/sqrt(|N_u|*|N_i|) for local-aware extraction.\n4. Both combine representations from item-item graph and user-item graph for final item embeddings, using additive fusion.\n5. Both adopt BPR loss as the primary optimization objective for recommendation.\n6. Both use MLP layers to project raw multimodal features (visual and textual) into a shared embedding space with ID embeddings.\n7. Both methods differentiate between training and inference phases - using processed/sampled graphs during training but original complete graphs during inference.\n8. Both weight different modality item-item graphs with hyperparameters (alpha_v in FREEDOM, similar weighting in PGL) to obtain the final fused item-item similarity matrix.",
  "differences": "1. **Embedding Initialization**: FREEDOM uses separate user ID embeddings and item ID embeddings as raw representations, while PGL concatenates projected multimodal content features to form item raw representations, arguing content features are more informative for convergence.\n2. **User-Item Graph Processing Strategy**: FREEDOM applies degree-sensitive edge pruning (dropout) that randomly removes edges based on degree probability in each epoch. PGL offers two extraction methods: (a) Global-aware extraction using randomized SVD decomposition followed by truncated reconstruction with eigenvalue retention ratio γ and sparsification threshold ε; (b) Local-aware extraction using multinomial sampling with retention ratio p (typically 0.3).\n3. **SVD-based Principal Graph Learning**: PGL introduces a novel global-aware extraction using ApproxSVD(A, d) decomposition, truncating eigenvalues to retain top γd and bottom (1-γ)d eigenvalues, then reconstructing and sparsifying. This is entirely absent in FREEDOM.\n4. **Message Passing Formula**: PGL uses a generalized form H(F(A))x where F is the subgraph extraction function and H is the message passing function. FREEDOM directly applies sparse matrix multiplication on the processed adjacency matrix.\n5. **Self-Supervised Learning**: PGL incorporates an auxiliary SSL task using feature masking and InfoNCE loss to enhance representation distinguishability (L = L_BPR + λ_SSL * L_SSL). FREEDOM only uses BPR loss with additional modality-specific BPR terms.\n6. **Modality Feature Usage in Loss**: FREEDOM includes modality-specific BPR losses (mf_v_loss, mf_t_loss) weighted by λ in the training objective. PGL does not explicitly include separate modality losses but relies on SSL for auxiliary supervision.\n7. **Readout Function**: FREEDOM uses mean pooling across all GCN layers for user-item graph embeddings (following LightGCN). PGL's paper does not explicitly specify but implies direct output from message passing.\n8. **Implementation of Graph Normalization**: For the reconstructed principal graph in PGL, additional sparsification with threshold ε (typically 1e-3) is applied after SVD reconstruction, which is not present in FREEDOM's processing pipeline.\n9. **Training Graph vs Inference Graph**: While both differ between training and inference, PGL explicitly extracts a 'principal subgraph' concept for training to capture local structural features, whereas FREEDOM frames it as 'denoising' through edge dropout."
}
```