```json
{
  "similarities": "1. Both methods construct item-item graphs based on multimodal feature similarity using cosine similarity computation between item pairs, as shown in FREEDOM's Eq.(1) and SMORE's Eq.(8).\n2. Both methods apply kNN-based graph sparsification to retain only top-K similar edges for each item, converting dense similarity matrices into sparse graphs (FREEDOM Eq.(2), SMORE Eq.(9)).\n3. Both methods normalize the item-item adjacency matrices using symmetric normalization with degree matrices (D^{-1/2} * A * D^{-1/2}) to stabilize graph convolution operations.\n4. Both methods use LightGCN-style message passing on the user-item bipartite graph without learnable transformation matrices, aggregating multi-hop neighbor information (FREEDOM Eq.(7), SMORE Eq.(15)).\n5. Both methods employ MLP layers to project raw multimodal features into a shared latent space with the same dimensionality as ID embeddings (FREEDOM Eq.(9), SMORE Eq.(1)).\n6. Both methods use BPR loss as the primary optimization objective for ranking-based recommendation (FREEDOM Eq.(10), SMORE Eq.(24)).\n7. Both methods combine ID embeddings with multimodal-enhanced representations for final user/item embeddings through additive fusion.\n8. Both methods handle visual and textual modalities separately before fusion, maintaining modality-specific processing pipelines.",
  "differences": "1. **Modality Fusion Strategy**: FREEDOM uses a simple weighted sum to fuse modality-specific item-item graphs (Eq.3 with hyperparameter α_v), while SMORE introduces Spectrum Modality Fusion using FFT to convert features to frequency domain, apply learnable filters for denoising, and perform point-wise multiplication for fusion (Eq.2-7). For implementation, SMORE requires: (a) FFT transformation of projected features, (b) complex-valued learnable filter weights W_{2,m}^c, (c) point-wise product fusion in frequency domain, (d) IDFT to convert back.\n2. **Graph Structure**: FREEDOM freezes a single fused item-item graph before training, while SMORE maintains separate modality-specific graphs AND a fusion graph constructed via max-pooling across modalities (Eq.11). Implementation requires maintaining multiple sparse adjacency matrices and computing max operation across modality graphs.\n3. **Denoising Approach**: FREEDOM applies degree-sensitive edge pruning on the user-item graph during training (sampling edges inversely proportional to node degrees), while SMORE performs denoising in frequency domain through learnable spectral filters. SMORE's approach requires implementing complex-valued neural network components.\n4. **Feature Gating Mechanism**: SMORE introduces behavioral-guided gating (Eq.12) that modulates multimodal features using ID embeddings through sigmoid gates before graph propagation. This requires element-wise multiplication of ID embeddings with sigmoid-transformed modal features.\n5. **Modality-Aware Preference Module**: SMORE adds an attention mechanism (Eq.17-18) to learn modality-specific weights using fusion features, and explicit preference gates (Eq.19-20) derived from behavioral signals. Implementation needs: attention computation over fusion features, separate gate networks for uni-modal and fusion preferences.\n6. **Contrastive Learning**: SMORE incorporates InfoNCE contrastive loss (Eq.22) to align behavioral embeddings with modality-side information, which FREEDOM lacks. Implementation requires computing contrastive loss between ID embeddings and aggregated modal features with temperature scaling.\n7. **User Modality Features**: FREEDOM only propagates item features on item-item graph, while SMORE explicitly computes user modality features through weighted-sum aggregation from interacted items (Eq.14). This requires additional aggregation layer for user modal representations.\n8. **Graph Convolution Depth**: FREEDOM uses configurable multiple layers (n_mm_layers) on item-item graph, while SMORE explicitly uses shallow (single) layer on item-item graphs to avoid high-order noise, with deeper propagation only on user-item graph.\n9. **Loss Function**: FREEDOM's loss includes BPR on both ID embeddings and projected modal features (Eq.10 with λ weighting), while SMORE uses BPR + contrastive loss + L2 regularization (Eq.25) without explicit modal feature reconstruction loss."
}
```